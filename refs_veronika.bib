% Encoding: UTF-8
@inproceedings{gao2008knowledge,
  title={Knowledge transfer via multiple model local structure mapping},
  author={Gao, Jing and Fan, Wei and Jiang, Jing and Han, Jiawei},
  booktitle={Knowledge Discovery and Data mining},
  pages={283--291},
  year={2008},
  organization={ACM}
}

@article{smith2002fast,
  title={Fast robust automated brain extraction},
  author={Smith, Stephen M},
  journal={Human Brain Mapping},
  volume={17},
  number={3},
  pages={143--155},
  year={2002},
  publisher={Wiley Online Library}
}


@article{tustison2010n4itk,
  title={{N4ITK}: improved {N3} bias correction},
  author={Tustison, Nicholas J and Avants, Brian B and Cook, Philip A and Zheng, Yuanjie and Egan, Alexander and Yushkevich, Paul A and Gee, James C},
  journal={IEEE Transactions on Medical Imaging},
  volume={29},
  number={6},
  pages={1310--1320},
  year={2010},
  publisher={IEEE}
}


@article{styner20083d,
  title={{3D} segmentation in the clinic: A grand challenge {II}: {MS} lesion segmentation},
  author={Styner, Martin and Lee, Joohwi and Chin, Brian and Chin, M and Commowick, Olivier and Tran, H and Markovic-Plese, S and Jewells, V and Warfield, S},
  journal={MIDAS Journal},
  volume={2008},
  pages={1--6},
  year={2008},
}

@inproceedings{souplet2008automatic,
  title={An automatic segmentation of {T2-FLAIR} multiple sclerosis lesions},
  author={Souplet, Jean-Christophe and Lebrun, Christine and Ayache, Nicholas and Malandain, Gr{\'e}goire and others},
  booktitle={MIDAS Journal},
  year={2008},
}

@article{ashburner2005unified,
  title={Unified segmentation},
  author={Ashburner, John and Friston, Karl J},
  journal={Neuroimage},
  volume={26},
  number={3},
  pages={839--851},
  year={2005},
  publisher={Elsevier}
}

@inproceedings{asman2014statistical,
  title={Statistical label fusion with hierarchical performance models},
  author={Asman, Andrew J and Dagley, Alexander S and Landman, Bennett A},
  booktitle={SPIE Medical Imaging},
  pages={90341E--90341E},
  year={2014},
  organization={International Society for Optics and Photonics}
}

@article{polman2011diagnostic,
  title={Diagnostic criteria for multiple sclerosis: 2010 revisions to the McDonald criteria},
  author2={Polman, Chris H and Reingold, Stephen C and others},
  author={Polman, Chris H and Reingold, Stephen C and Banwell, Brenda and Clanet, Michel and Cohen, Jeffrey A and Filippi, Massimo and Fujihara, Kazuo and Havrdova, Eva and Hutchinson, Michael and Kappos, Ludwig and others},
  journal={Annals of Neurology},
  volume={69},
  number={2},
  pages={292--302},
  year={2011},
  publisher={Wiley Online Library}
}


@incollection{geremia2010spatial,
  title={Spatial decision forests for {MS} lesion segmentation in multi-channel {MR} images},
  author={Geremia, Ezequiel and Menze, Bjoern H and Clatz, Olivier and Konukoglu, Ender and Criminisi, Antonio and Ayache, Nicholas},
  booktitle={Medical Image Computing and Computer-Assisted Interventions},
  pages={111--118},
  year={2010},
  publisher={Springer}
}

@article{garcia2013review,
  title={Review of automatic segmentation methods of multiple sclerosis white matter lesions on conventional magnetic resonance imaging},
  author2={Garc{\'\i}a-Lorenzo, Daniel and Francis, Simon and others},
  author={Garc{\'\i}a-Lorenzo, Daniel and Francis, Simon and Narayanan, Sridar and Arnold, Douglas L and Collins, D Louis},
  journal={Medical Image Analysis},
  volume={17},
  number={1},
  pages={1--18},
  year={2013},
  publisher={Elsevier}
}


@misc{ibsr,
	title={Internet Brain Segmentation Repository},
	howpublished={\url{http://www.nitrc.org/projects/ibsr}}
}

@article{anbeek2005probabilistic,
  title={Probabilistic segmentation of brain tissue in {MR} imaging},
  author={Anbeek, Petronella and Vincken, Koen L and Van Bochove, Glenda S and Van Osch, Matthias JP and van der Grond, Jeroen},
  journal={NeuroImage},
  volume={27},
  number={4},
  pages={795--804},
  year={2005},
  publisher={Elsevier}
}

@InCollection{leemput2014cautionary,
  author    = {Van Leemput, Koen and Sabuncu, Mert R},
  title     = {A Cautionary Analysis of {STAPLE} Using Direct Inference of Segmentation Truth},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  publisher = {Springer},
  year      = {2014},
  pages     = {398--406},
}

@InProceedings{zheng2015cross,
  author    = {Zheng, Yefeng},
  title     = {Cross-modality medical image detection and segmentation by transfer learning of shape priors},
  booktitle = {International Symposium on Biomedical Imaging},
  year      = {2015},
  groups    = {Not-so-supervised papers},
}


@book{silverman1986density,
  title={Density estimation for statistics and data analysis},
  author={Silverman, Bernard W},
  volume={26},
  year={1986},
  publisher={CRC press}
}


@inproceedings{chen2011co,
  title={Co-training for domain adaptation},
  author={Chen, Minmin and Weinberger, Kilian Q and Blitzer, John},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2456--2464},
  year={2011}
}

@incollection{rajan2005exploiting,
  title={Exploiting class hierarchies for knowledge transfer in hyperspectral data},
  author={Rajan, Suju and Ghosh, Joydeep},
  booktitle={Multiple Classifier Systems},
  pages={417--427},
  year={2005},
  publisher={Springer}
}

@article{ikram2015rotterdam,
  title={The Rotterdam Scan Study: design update 2016 and main findings},
  author={Ikram, M Arfan and van der Lugt, Aad and Niessen, Wiro J and Koudstaal, Peter J and Krestin, Gabriel P and Hofman, Albert and Bos, Daniel and Vernooij, Meike W},
  journal={European journal of epidemiology},
  volume={30},
  number={12},
  pages={1299--1315},
  year={2015},
  publisher={Springer}
}

@incollection{zhuang2014transfer,
  title={Transfer learning with multiple sources via consensus regularized autoencoders},
  author={Zhuang, Fuzhen and Cheng, Xiaohu and Pan, Sinno Jialin and Yu, Wenchao and He, Qing and Shi, Zhongzhi},
  booktitle={Machine Learning and Knowledge Discovery in Databases},
  pages={417--431},
  year={2014},
  publisher={Springer}
}

@InCollection{nguyen2011rapidly,
  author    = {Nguyen, Nhat H and Norris, Eric and Clemens, Mark G and Shin, Min C},
  title     = {Rapidly adaptive cell detection using transfer learning with a global parameter},
  booktitle = {Machine Learning in Medical Imaging},
  publisher = {Springer},
  year      = {2011},
  pages     = {209--216},
  groups    = {Not-so-supervised papers},
}

@InCollection{zikic2014classifier,
  author    = {Zikic, Darko and Glocker, Ben and Criminisi, Antonio},
  title     = {Classifier-based multi-atlas label propagation with test-specific atlas weighting for correspondence-free scenarios},
  booktitle = {Medical Computer Vision: Algorithms for Big Data},
  publisher = {Springer},
  year      = {2014},
  pages     = {116--124},
  groups    = {Not-so-supervised papers},
}


@inproceedings{salperwyck2011learning,
  title={Learning with few examples: An empirical study on leading classifiers},
  author={Salperwyck, Christophe and Lemaire, Vincent},
  booktitle={International Joint Conference on Neural Networks (IJCNN)},
  pages={1010--1019},
  year={2011},
  organization={IEEE}
}


@article{bron2015standardized,
  title={Standardized evaluation of algorithms for computer-aided diagnosis of dementia based on structural {MRI}: the {CADDementia} challenge},
  author={Bron, Esther E and Smits, Marion and Van Der Flier, Wiesje M and Vrenken, Hugo and Barkhof, Frederik and Scheltens, Philip and Papma, Janne M and Steketee, Rebecca ME and Orellana, Carolina M{\'e}ndez and Meijboom, Rozanna and others},
  journal={NeuroImage},
  volume={111},
  pages={562--579},
  year={2015},
  publisher={Elsevier}
}

@inproceedings{yosinski2014transferable,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3320--3328},
  year={2014}
}

@InProceedings{zhang2012sparse,
  author       = {Zhang, Daoqiang and Guo, Qimiao and Wu, Guorong and Shen, Dinggang},
  title        = {Sparse patch-based label fusion for multi-atlas segmentation},
  booktitle    = {Multimodal Brain Image Analysis (MICCAI MBIA)},
  year         = {2012},
  pages        = {94--102},
  organization = {Springer},
}


%
@article{ojala1996comparative,
  title={A comparative study of texture measures with classification based on featured distributions},
  author={Ojala, Timo and Pietik{\"a}inen, Matti and Harwood, David},
  journal={Pattern recognition},
  volume={29},
  number={1},
  pages={51--59},
  year={1996},
  publisher={Elsevier}
}

@article{kouw2015feature,
  title={Feature-Level Domain Adaptation},
  author={Kouw, Wouter M and van der Maaten, Laurens J P and Krijthe, Jesse H and Loog, Marco},
  journal={Journal of Machine Learning Research},
  year={2016},
  volume={17},
  number={171},
  pages={1--32},
}

@inproceedings{cortes2010learning,
  title={Learning bounds for importance weighting},
  author={Cortes, Corinna and Mansour, Yishay and Mohri, Mehryar},
  booktitle={Advances in neural information processing systems},
  pages={442--450},
  year={2010}
}
 

@inproceedings{cortes2011domain,
  title={Domain adaptation in regression},
  author={Cortes, Corinna and Mohri, Mehryar},
  booktitle={Algorithmic Learning Theory},
  pages={308--323},
  year={2011},
  organization={Springer}
}

@inproceedings{huang2006correcting,
  title={Correcting sample selection bias by unlabeled data},
  author={Huang, Jiayuan and Gretton, Arthur and Borgwardt, Karsten M and Sch{\"o}lkopf, Bernhard and Smola, Alex J},
  booktitle={Advances in neural information processing systems},
  pages={601--608},
  year={2006}
}

@inproceedings{zadrozny2003cost,
  title={Cost-sensitive learning by cost-proportionate example weighting},
  author={Zadrozny, Bianca and Langford, John and Abe, Naoki},
  booktitle={International Conference on Data Mining},
  pages={435--442},
  year={2003},
  organization={IEEE}
}

@article{pauwels2001global,
  title={Global strategy for the diagnosis, management, and prevention of chronic obstructive pulmonary disease: National Heart, Lung, and Blood Institute and World Health Organization Global Initiative for Chronic Obstructive Lung Disease (GOLD): executive summary.},
  author={Pauwels, Romain A and Buist, A Sonia and others},
  author2={Ma, P and Jenkins, Christine R and Hurd, Suzanne S and {GOLD Scientific Committee} and others},
  journal={Respiratory care},
  volume={46},
  number={8},
  pages={798},
  year={2001}
}

@article{gretton2009covariate,
  title={Covariate shift by kernel mean matching},
  author={Gretton, Arthur and Smola, Alex and Huang, Jiayuan and Schmittfull, Marcel and Borgwardt, Karsten and Sch{\"o}lkopf, Bernhard},
  journal={Dataset shift in machine learning},
  volume={3},
  number={4},
  pages={5},
  year={2009},
  publisher={MIT press Cambridge, MA}
}

@inproceedings{opbroek2015feature,
title={Feature-Space Transformation Improves Supervised Segmentation Across Scanners},
author={Annegreet van Opbroek and Hakim C. Achterberg and Marleen de Bruijne},
booktitle={Machine Learning Meets Medical Imaging},
pages={85--93},
year={2015}
}

@Article{engelen2015multi,
  author    = {van Engelen, Arna and van Dijk, Anouk C and Truijman, Martine T B and van't Klooster, Ronald and van Opbroek, Annegreet and van der Lugt, Aad and Niessen, Wiro J and Kooi, M Eline and de Bruijne, Marleen},
  title     = {Multi-center {MRI} carotid plaque component segmentation using feature normalization and transfer learning},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2015},
  volume    = {34},
  number    = {6},
  pages     = {1294--1305},
  groups    = {Not-so-supervised papers},
  publisher = {IEEE},
}

@TechReport{ablavsky2012transfer,
  author = {Ablavsky, Vitaly Henry and Becker, Carlos Joaquin and Fua, Pascal},
  title  = {Transfer learning by sharing support vectors},
  year   = {2012},
  groups = {Not-so-supervised papers},
}

@inproceedings{mol2010correction,
    author          = {C.P. Mol and B. van Ginneken and M. de Bruijne and P.A. de Jong and M. Oudkerk and A. Dirksen and P. Zanen},
    title           = {{Correction of Quantitative Emphysema Measures with Density Calibration Based on Measurements in the Trachea}},
    booktitle       = {{Annual Meeting of the Radiological Society of North America}},
    year            = {2010}
}

@Article{haralick1973textural,
  author    = {Haralick, Robert M and Shanmugam, Karthikeyan and Dinstein, Its' Hak},
  title     = {Textural features for image classification},
  journal   = {IEEE Transactions on Systems, Man and Cybernetics},
  year      = {1973},
  number    = {6},
  pages     = {610--621},
  publisher = {IEEE},
}


@article{vestbo2013global,
  title={Global strategy for the diagnosis, management, and prevention of chronic obstructive pulmonary disease: GOLD executive summary},
  author={Vestbo, J{\o}rgen and Hurd, Suzanne S and Agust{\'\i}, Alvar G and Jones, Paul W and Vogelmeier, Claus and Anzueto, Antonio and Barnes, Peter J and Fabbri, Leonardo M and Martinez, Fernando J and Nishimura, Masaharu and others},
  journal={American journal of respiratory and critical care medicine},
  volume={187},
  number={4},
  pages={347--365},
  year={2013},
  publisher={Am Thoracic Soc}
}

@Article{korsager2015use,
  author    = {Korsager, Anne Sofie and Fortunati, Valerio and van der Lijn, Fedde and Carl, Jesper and Niessen, Wiro and {\O}stergaard, Lasse Riis and van Walsum, Theo},
  title     = {The use of atlas registration and graph cuts for prostate segmentation in magnetic resonance images},
  journal   = {Medical Physics},
  year      = {2015},
  volume    = {42},
  number    = {4},
  pages     = {1614--1624},
  publisher = {American Association of Physicists in Medicine},
}


%

@Article{fink2014crowdsourcing,
  author  = {Fink, Daniel and Damoulas, Theodoros and Bruns, Nicholas E and La Sorte, Frank A and Hochachka, Wesley M and Gomes, Carla P and Kelling, Steve},
  title   = {Crowdsourcing meets ecology: hemisphere-wide spatiotemporal species distribution models},
  journal = {AI magazine},
  year    = {2014},
  volume  = {35},
  number  = {2},
  pages   = {19--30},
  groups  = {Veni},
}

@article{veta2015assessment,
  title={Assessment of algorithms for mitosis detection in breast cancer histopathology images},
  author={Veta, Mitko and Van Diest, Paul J and Willems, Stefan M and Wang, Haibo and Madabhushi, Anant and Cruz-Roa, Angel and Gonzalez, Fabio and Larsen, Anders BL and Vestergaard, Jacob S and Dahl, Anders B and others},
  journal={Medical image analysis},
  volume={20},
  number={1},
  pages={237--248},
  year={2015},
  publisher={Elsevier}
}

@Article{carbonneau2017multiple,
  author       = {{Carbonneau}, M.-A. and {Cheplygina}, V. and {Granger}, E. and {Gagnon}, G.},
  title        = {{Multiple Instance Learning: A Survey of Problem Characteristics and Applications}},
  journal      = {Pattern Recognition},
  year         = {2017},
  groups       = {My papers, Veni},
  keywords     = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Computer Science - Information Retrieval},
  primaryclass = {cs.CV},
}

@conference{Dashtbozorg2016b,
title = {RetinaCheck: An Interactive Platform for Retinal Image Analysis},
author = {Behdad Dashtbozorg and  Jiong Zhang and Fan Huang and Bart M. ter Haar Romeny},
year = {2016},
date = {2016-04-15},
booktitle = {The IEEE International Symposium Biomedical },
keywords = {Retinal image analysis},
pubstate = {published},
tppubtype = {conference}
}

@Article{carbonneau2016robust,
  author    = {Carbonneau, Marc-Andr{\'e} and Granger, Eric and Raymond, Alexandre J and Gagnon, Ghyslain},
  title     = {Robust multiple-instance learning ensembles using random subspace instance selection},
  journal   = {Pattern Recognition},
  year      = {2016},
  volume    = {58},
  pages     = {83--99},
  groups    = {Veni},
  publisher = {Elsevier},
}

@Article{howe2006rise,
  author  = {Howe, Jeff},
  title   = {The rise of crowdsourcing},
  journal = {Wired magazine},
  year    = {2006},
  volume  = {14},
  number  = {6},
  pages   = {1--4},
  groups  = {Veni},
}

@article{khatib2011algorithm,
  title={Algorithm discovery by protein folding game players},
  author={Khatib, Firas and Cooper, Seth and Tyka, Michael D and Xu, Kefan and Makedon, Ilya and Popovi{\'c}, Zoran and Baker, David},
  journal={Proceedings of the National Academy of Sciences},
  volume={108},
  number={47},
  pages={18949--18953},
  year={2011},
  publisher={National Acad Sciences}
}

@Article{fritz2009geo,
  author    = {Fritz, Steffen and McCallum, Ian and Schill, Christian and Perger, Christoph and Grillmayer, Roland and Achard, Fr{\'e}d{\'e}ric and Kraxner, Florian and Obersteiner, Michael},
  title     = {Geo-Wiki. Org: The use of crowdsourcing to improve global land cover},
  journal   = {Remote Sensing},
  year      = {2009},
  volume    = {1},
  number    = {3},
  pages     = {345--354},
  groups    = {Veni},
  publisher = {Molecular Diversity Preservation International},
}

@conference{Cui2016,
title = {Fine-grained Categorization and Dataset Bootstrapping using Deep Metric Learning with Humans in the Loop},
author = {Yin Cui and Feng Zhou and Yuanqing Lin and Serge Belongie},
url = {http://vision.cornell.edu/se3/wp-content/uploads/2016/04/1950.pdf},
year = {2016},
date = {2016-06-27},
booktitle = {Computer Vision and Pattern Recognition (CVPR)},
address = {Las Vegas, NV},
keywords = {}
}

@inproceedings{sugiyama2008direct,
  title={Direct importance estimation with model selection and its application to covariate shift adaptation},
  author={Sugiyama, Masashi and Nakajima, Shinichi and Kashima, Hisashi and Buenau, Paul V and Kawanabe, Motoaki},
  booktitle={Advances in neural information processing systems},
  pages={1433--1440},
  year={2008}
}

@article{sugiyama2007covariate,
  title={Covariate shift adaptation by importance weighted cross validation},
  author={Sugiyama, Masashi and Krauledat, Matthias and M{\~A}{\v{z}}ller, Klaus-Robert},
  journal={Journal of Machine Learning Research},
  volume={8},
  number={May},
  pages={985--1005},
  year={2007}
}

@inproceedings{weinberger2005distance,
  title={Distance metric learning for large margin nearest neighbor classification},
  author={Weinberger, Kilian Q and Blitzer, John and Saul, Lawrence K},
  booktitle={Advances in neural information processing systems},
  pages={1473--1480},
  year={2005}
}

@Article{bengio2013representation,
  author    = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  title     = {Representation learning: A review and new perspectives},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year      = {2013},
  volume    = {35},
  number    = {8},
  pages     = {1798--1828},
  publisher = {IEEE},
}

@inproceedings{ananthakrishnan2006epidemiology,
  title={Epidemiology of primary and secondary liver cancers},
  author={Ananthakrishnan, Ashwin and Gogineni, Veena and Saeian, Kia},
  booktitle={Seminars in Interventional Radiology},
  volume={23},
  number={1},
  pages={47},
  year={2006},
  organization={Thieme Medical Publishers}
}

@inproceedings{perez2015automated,
  title={Automated quantification of bronchiectasis, airway wall thickening and lumen tapering in chest CT},
  author={Perez-Rovira, Adria and Kuo, Wieying and Petersen, Jens and Tiddens, Harm AWM and de Bruijne, Marleen},
  booktitle={ECR 2015-European Congress of Radiology},
  year={2015}
}

@inproceedings{kuo2015assessment,
  title={Assessment of bronchiectasis in children with cystic fibrosis by comparing airway and artery dimensions to normal controls on inspiratory and expiratory spirometer guided chest computed tomography},
  author={Kuo, Wieying and others},
  year={2015},
  organization={European Congress of Radiology 2015}
}

@article{soler2001fully,
  title={Fully automatic anatomical, pathological, and functional segmentation from {CT} scans for hepatic surgery},
  author={Soler, Luc and Delingette, Herv{\'e} and Malandain, Gr{\'e}goire and Montagnat, Johan and Ayache, Nicholas and Koehl, Christophe and Dourthe, Olivier and Malassagne, Benoit and Smith, Michelle and Mutter, Didier and others},
  journal={Computer Aided Surgery},
  volume={6},
  number={3},
  pages={131--142},
  year={2001},
  publisher={Wiley Online Library}
}

@article{tao2012fast,
  title={A fast and robust sparse approach for hyperspectral data classification using a few labeled samples},
  author={Tao, Linmi and Sun, Fuchun and Yang, Shiqiang and others},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={50},
  number={6},
  pages={2287--2302},
  year={2012},
  publisher={IEEE}
}


@article{bosch2004primary,
  title={Primary liver cancer: worldwide incidence and trends},
  author={Bosch, F Xavier and Ribes, Josepa and D{\'\i}az, Mireia and Cl{\'e}ries, Ramon},
  journal={Gastroenterology},
  volume={127},
  number={5},
  pages={S5--S16},
  year={2004},
  publisher={Elsevier}
}

@article{seitel2011computer,
  title={Computer-assisted trajectory planning for percutaneous needle insertions},
  author={Seitel, Alexander and Engel, Markus and Sommer, Christof M and Radeleff, Boris A and Essert-Villard, Caroline and Baegert, Claire and Fangerau, Markus and Fritzsche, Klaus H and Yung, Kwong and Meinzer, Hans-Peter and others},
  journal={Medical Physics},
  volume={38},
  number={6},
  pages={3246--3259},
  year={2011},
  publisher={American Association of Physicists in Medicine}
}

@article{maier2008vivo,
  title={In vivo accuracy assessment of a needle-based navigation system for {CT}-guided radiofrequency ablation of the liver},
  author={Maier-Hein, Lena and Tekbas, Aysun and Seitel, Alexander and Pianka, Frank and M{\"u}ller, Sascha A and Satzl, Stefanie and Schawo, Simone and Radeleff, Boris and Tetzlaff, Ralf and Franz, Alfred M and others},
  journal={Medical Physics},
  volume={35},
  number={12},
  pages={5385--5396},
  year={2008},
  publisher={American Association of Physicists in Medicine}
}


@incollection{frangi1998multiscale,
  title={Multiscale vessel enhancement filtering},
  author={Frangi, Alejandro F and Niessen, Wiro J and Vincken, Koen L and Viergever, Max A},
  booktitle={Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  pages={130--137},
  year={1998},
  publisher={Springer}
}

@article{moreno2015gradient,
  title={Gradient-based enhancement of tubular structures in medical images},
  author={Moreno, Rodrigo and Smedby, {\"O}rjan},
  journal={Medical Image Analysis},
  volume={26},
  number={1},
  pages={19--29},
  year={2015},
  publisher={Elsevier}
}

@InProceedings{goetz2016learning,
  author       = {G{\"o}tz, M and Heim, E and M{\"a}rz, K and Norajitra, T and Hafezi, M and Fard, N and Mehrabi, A and Knoll, M and Weber, C and Maier-Hein, L and Maier-Hein KH},
  title        = {A learning-based, fully automatic liver tumor segmentation pipeline based on sparsely annotated training data.},
  booktitle    = {SPIE Medical Imaging},
  year         = {2016},
  organization = {International Society for Optics and Photonics},
  groups       = {Veni},
}

@article{wolf2005medical,
  title={The medical imaging interaction toolkit},
  author={Wolf, Ivo and Vetter, Marcus and Wegner, Ingmar and B{\"o}ttger, Thomas and Nolden, Marco and Sch{\"o}binger, Max and Hastenteufel, Mark and Kunert, Tobias and Meinzer, Hans-Peter},
  journal={Medical Image Analysis},
  volume={9},
  number={6},
  pages={594--604},
  year={2005},
  publisher={Elsevier}
}

@article{nolden2013medical,
  title={The medical imaging interaction toolkit: challenges and advances},
  author={Nolden, Marco and Zelzer, Sascha and Seitel, Alexander and Wald, Diana and M{\"u}ller, Michael and Franz, Alfred M and Maleike, Daniel and Fangerau, Markus and Baumhauer, Matthias and Maier-Hein, Lena and others},
  journal={International Journal of Computer Assisted Radiology and Surgery},
  volume={8},
  number={4},
  pages={607--620},
  year={2013},
  publisher={Springer}
}

@article{fraz2012blood,
  title={Blood vessel segmentation methodologies in retinal images--a survey},
  author={Fraz, Muhammad Moazam and Remagnino, Paolo and Hoppe, Andreas and Uyyanonvara, Bunyarit and Rudnicka, Alicja R and Owen, Christopher G and Barman, Sarah A},
  journal={Computer Methods and Programs in Biomedicine},
  volume={108},
  number={1},
  pages={407--433},
  year={2012},
  publisher={Elsevier}
}

@article{lee2011imaging,
  title={Imaging assessment of congenital and acquired abnormalities of the portal venous system},
  author={Lee, Wai-Kit and Chang, Silvia D and Duddalwar, Vinay A and Comin, Jules M and Perera, Warren and Lau, Wing-Fai E and Bekhit, Elhamy K and Hennessy, Oliver F},
  journal={Radiographics},
  volume={31},
  number={4},
  pages={905--926},
  year={2011},
  publisher={Radiological Society of North America}
}

@article{krupinski2010current,
  title={Current perspectives in medical image perception},
  author={Krupinski, Elizabeth A},
  journal={Attention, Perception, \& Psychophysics},
  volume={72},
  number={5},
  pages={1205--1217},
  year={2010},
  publisher={Springer}
}

@article{sahani2004preoperative,
  title={Preoperative Hepatic Vascular Evaluation with {CT} and {MR} Angiography: Implications for Surgery 1},
  author={Sahani, Dushyant and Mehta, Aparna and Blake, Michael and Prasad, Srinivasa and Harris, Gordan and Saini, Sanjay},
  journal={Radiographics},
  volume={24},
  number={5},
  pages={1367--1380},
  year={2004},
  publisher={Radiological Society of North America}
}

@article{seung2012eyewire,
  title={Eyewire},
  author={Seung, HS and Burnes, L},
  journal={Available at eyewire.org},
  year={2012}
}

@article{fraz2012ensemble,
  title={An ensemble classification-based approach applied to retinal blood vessel segmentation},
  author={Fraz, Muhammad Moazam and Remagnino, Paolo and Hoppe, Andreas and Uyyanonvara, Bunyarit and Rudnicka, Alicja R and Owen, Christopher G and Barman, Sarah A},
  journal={IEEE Transactions on Biomedical Engineering},
  volume={59},
  number={9},
  pages={2538--2548},
  year={2012},
  publisher={IEEE}
}


@article{kumar2015three,
  title={Three-dimensional blood vessel segmentation and centerline extraction based on two-dimensional cross-section analysis},
  author={Kumar, Rahul Prasanna and Albregtsen, Fritz and Reimers, Martin and Edwin, Bj{\o}rn and Lang{\o}, Thomas and Elle, Ole Jakob},
  journal={Annals of Biomedical Engineering},
  volume={43},
  number={5},
  pages={1223--1234},
  year={2015},
  publisher={Springer}
}

@article{schaap2011robust,
  title={Robust shape regression for supervised vessel segmentation and its application to coronary segmentation in {CTA}},
  author={Schaap, Michiel and van Walsum, Theo and Neefjes, Lisan and Metz, Coert and Capuano, Ermanno and De Bruijne, Marleen and Niessen, Wiro},
  journal={IEEE Transactions on Medical Imaging},
  volume={30},
  number={11},
  pages={1974--1986},
  year={2011},
  publisher={IEEE}
}

@inproceedings{heim2015crowd,
  title={Crowdgest{\"u}tzte Organsegmentierung: M{\"o}glichkeiten und Grenzen},
  author={Heim, E. and Ross, T. and Norajitra, T. and Nolden, M. and M{\"a}rz, K. and Kondermann, D. and Speidel, S. and Maier-Hein, K. and Maier-Hein, L.},
  booktitle={Jahrestagung der Deutschen Gesselschaft f{\"u}r Computer- und Robotassistierte Chirurgie, Bremen},
  year={2015}
}


@article{conversano2011hepatic,
  title={Hepatic vessel segmentation for {3D} planning of liver surgery: experimental evaluation of a new fully automatic algorithm},
  author={Conversano, Francesco and Franchini, Roberto and Demitri, Christian and Massoptier, Laurent and Montagna, Francesco and Maffezzoli, Alfonso and Malvasi, Antonio and Casciaro, Sergio},
  journal={Academic Radiology},
  volume={18},
  number={4},
  pages={461--470},
  year={2011},
  publisher={Elsevier}
}


@article{numminen2005preoperative,
  title={Preoperative hepatic {3D} models: virtual liver resection using three-dimensional imaging technique},
  author={Numminen, Kirsti and Sipil{\"a}, Outi and M{\"a}kisalo, Heikki},
  journal={European Journal of Radiology},
  volume={56},
  number={2},
  pages={179--184},
  year={2005},
  publisher={Elsevier}
}

@InCollection{lin2014microsoft,
  author    = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  title     = {Microsoft {COCO}: Common objects in context},
  booktitle = {European Conference on Computer Vision (ECCV)},
  publisher = {Springer},
  year      = {2014},
  pages     = {740--755},
  groups    = {Veni},
}

@article{ivsgum2009multi,
  title={Multi-atlas-based segmentation with local decision fusion: application to cardiac and aortic segmentation in {CT} scans},
  author={I{\v{s}}gum, Ivana and Staring, Marius and Rutten, Annemarieke and others},
  journal={IEEE Transactions on Medical Imaging},
  volume={28},
  number={7},
  pages={1000--1010},
  year={2009},
  publisher={IEEE}
}

@article{gurney1992regional,
  title={Regional distribution of emphysema: correlation of high-resolution {CT} with pulmonary function tests in unselected smokers.},
  author={Gurney, JW and Jones, KK and Robbins, RA and Gossman, GL and Nelson, KJ and Daughton, D and Spurzem, JR and Rennard, SI},
  journal={Radiology},
  volume={183},
  number={2},
  pages={457--463},
  year={1992}
}

@article{mcclure2015representational,
  title={Representational Distance Learning for Deep Neural Networks},
  author={McClure, Patrick and Kriegeskorte, Nikolaus},
  journal={arXiv preprint arXiv:1511.03979},
  year={2015}
}

@incollection{duin2008euclidean,
  title={On Euclidean corrections for non-Euclidean dissimilarities},
  author={Duin, Robert P W and P{\k{e}}kalska, El{\.z}bieta and Harol, Artsiom and Lee, Wan-Jui and Bunke, Horst},
  booktitle={Structural, Syntactic and Statistical Pattern Recognition},
  pages={551--561},
  year={2008},
}

@article{yang2006distance,
  title={Distance metric learning: A comprehensive survey},
  author={Yang, Liu and Jin, Rong},
  journal={Michigan State Universiy},
  volume={2},
  year={2006}
}


@misc{mturk,
   title={Mechanical Turk},
   author ={{Amazon.com}},
   year={2014},
   howpublished={online, https://www.mturk.com},
}

@misc{factsheet,
   title={Fact sheet N°310},
   author ={World Health Organization},
   year={2014},
   howpublished={online},
}
@article{del2014visceral,
  title={{VISCERAL--VISual Concept Extraction challenge in RAdioLogy: ISBI 2014 challenge organization}},
  author={del Toro, Oscar Alfonso Jim{\'e}nez and Goksel, Orcun and Menze, Bjoern and M{\"u}ller, Henning and Langs, Georg and Weber, Marc-Andr{\'e} and Eggel, Ivan and Gruenberg, Katharina and Holzer, Markus and Kotsios-Kontokotsios, Georgios and others},
  journal={Proceedings of the VISCERAL Challenge at ISBI},
  number={1194},
  pages={6--15},
  year={2014}
}

@Article{pluim2003mutual,
  author    = {Pluim, Josien P W and Maintz, J B Antoine and Viergever, Max A},
  title     = {Mutual-information-based registration of medical images: a survey},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2003},
  volume    = {22},
  number    = {8},
  pages     = {986--1004},
  publisher = {IEEE},
}

@Article{murphy2011evaluation,
  author    = {Murphy, Keelin and Van Ginneken, Bram and Reinhardt, Joseph M and Kabus, Sven and Ding, Kai and Deng, Xiang and Cao, Kunlin and Du, Kaifang and Christensen, Gary E and Garcia, Vincent and others},
  title     = {Evaluation of registration methods on thoracic {CT}: the {EMPIRE10} challenge},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2011},
  volume    = {30},
  number    = {11},
  pages     = {1901--1920},
  publisher = {IEEE},
}

@Article{klein2010elastix,
  author    = {Klein, Stefan and Staring, Marius and Murphy, Keelin and Viergever, Max A and Pluim, Josien PW},
  title     = {Elastix: a toolbox for intensity-based medical image registration},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2010},
  volume    = {29},
  number    = {1},
  pages     = {196--205},
  publisher = {IEEE},
}

@Article{lijn2012automated,
  author    = {Van der Lijn, Fedde and De Bruijne, Marleen and Klein, Stefan and Heijer, Tom Den and Hoogendam, Yoo Y and Van der Lugt, Aad and Breteler, Monique and Niessen, Wiro J},
  title     = {Automated brain structure segmentation based on atlas registration and appearance models},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2012},
  volume    = {31},
  number    = {2},
  pages     = {276--286},
  publisher = {IEEE},
}

@article{loeve2009cystic,
  title={Cystic Fibrosis: Are Volumetric Ultra-Low-Dose Expiratory CT Scans Sufficient for Monitoring Related Lung Disease? 1},
  author={Loeve, Martine and Lequin, Maarten H and de Bruijne, Marleen and Hartmann, Ieneke JC and Gerbrands, Krista and van Straten, Marcel and Hop, Wim CJ and Tiddens, Harm AWM},
  journal={Radiology},
  volume={253},
  number={1},
  pages={223--229},
  year={2009},
  publisher={Radiological Society of North America, Inc.}
}

@InProceedings{hernandez2015dissimilarity,
  author    = {Hern{\'a}ndez-Dur{\'a}n, M. and Cheplygina, V. and Plasencia-Cala{\~n}a, Y.},
  title     = {Dissimilarity representations for low-resolution face recognition},
  booktitle = {Similarity-Based Pattern Recognition},
  year      = {2015},
  pages     = {70--83},
  groups    = {My papers},
}



@Misc{prtools,
  Title                    = {{PRTools, A MATLAB toolbox for pattern recognition}},

  Author                   = {Duin, R P W and Juszczak, P and Paclik, P and Pekalska, E and de Ridder, D and Tax, D M J and Verzakov, S},
  HowPublished             = {online, http://www.prtools.org},
  Year                     = {2013}
}

@article{kruskal1964multidimensional,
  title={Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis},
  author={Kruskal, Joseph B},
  journal={Psychometrika},
  volume={29},
  number={1},
  pages={1--27},
  year={1964},
}

@inproceedings{yan2011active,
  title={Active learning from crowds},
  author={Yan, Yan and Fung, Glenn M and Rosales, R{\'o}mer and Dy, Jennifer G},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1161--1168},
  year={2011}
}


@article{cooper2010predicting, title={Predicting protein structures with a multiplayer online game}, author={Cooper, Seth and Khatib, Firas and Treuille, Adrien and Barbero, Janos and Lee, Jeehyung and Beenen, Michael and Leaver-Fay, Andrew and Baker, David and Popovi{\'c}, Zoran and others}, journal={Nature}, volume={466}, number={7307}, pages={756--760}, year={2010}, publisher={Nature Publishing Group} }



@article{tu2008brain,
  title={Brain anatomical structure segmentation by hybrid discriminative/generative models},
  author={Tu, Zhuowen and Narr, Katherine L and Doll{\'a}r, Piotr and Dinov, Ivo and Thompson, Paul M and Toga, Arthur W},
  journal={IEEE Transactions on Medical Imaging},
  volume={27},
  number={4},
  pages={495--508},
  year={2008},
  publisher={IEEE}
}






@inproceedings{krijthe2012improving,
  title={Improving cross-validation based classifier selection using meta-learning},
  author={Krijthe, Jesse H and Ho, Tin Kam and Loog, Marco},
  booktitle={International Conference on Pattern Recognition},
  pages={2873--2876},
  year={2012},
  organization={IEEE}
}

@phdthesis{marques2013osteoarthritis,
  title={Osteoarthritis imaging by quantification of tibial trabecular bone},
  author={Marques, Joselene},
  school={K{\o}benhavns Universitet},
  year={2013}
}


@article{fawcett2006introduction,
  title={An introduction to {ROC} analysis},
  author={Fawcett, Tom},
  journal={Pattern Recognition Lettetrs},
  volume={27},
  number={8},
  pages={861--874},
  year={2006},
  publisher={Elsevier}
}
@article{aksela2006using,
  title={Using diversity of errors for selecting members of a committee classifier},
  author={Aksela, Matti and Laaksonen, Jorma},
  journal={Pattern Recognition},
  volume={39},
  number={4},
  pages={608--623},
  year={2006},
  publisher={Elsevier}
}

@book{kuncheva2004combining,
  title={Combining pattern classifiers: methods and algorithms},
  author={Kuncheva, Ludmila I},
  year={2004},
  publisher={John Wiley \& Sons}
}

@InProceedings{welinder2010multidimensional,
  author    = {Welinder, Peter and Branson, Steve and Perona, Pietro and Belongie, Serge J},
  title     = {The multidimensional wisdom of crowds},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2010},
  pages     = {2424--2432},
  file      = {welinder2010multidimensional.pdf:welinder2010multidimensional.pdf:PDF},
}

@article{drineas2005nystrom,
  title={On the Nystr{\"o}m method for approximating a Gram matrix for improved kernel-based learning},
  author={Drineas, Petros and Mahoney, Michael W},
  journal={The Journal of Machine Learning Research},
  volume={6},
  pages={2153--2175},
  year={2005},
  publisher={JMLR. org}
}

@Article{settles2010active,
  author  = {Settles, Burr},
  title   = {Active learning literature survey},
  journal = {University of Wisconsin, Madison},
  year    = {2010},
  volume  = {52},
  number  = {55-66},
  pages   = {11},
  groups  = {Not-so-supervised general},
}

@article{tiddens2010cystic,
  title={Cystic fibrosis lung disease starts in the small airways: can we treat it more effectively?},
  author={Tiddens, Harm AWM and Donaldson, Scott H and Rosenfeld, Margaret and Par{\'e}, Peter D},
  journal={Pediatric pulmonology},
  volume={45},
  number={2},
  pages={107--117},
  year={2010},
  publisher={Wiley Online Library}
}

@article{viera2005understanding,
  title={Understanding interobserver agreement: the kappa statistic},
  author={Viera, Anthony J and Garrett, Joanne M},
  journal={Family Medicine},
  volume={37},
  number={5},
  pages={360--363},
  year={2005}
}

@article{cinbis2016weakly,
  title={Weakly Supervised Object Localization with Multi-fold Multiple Instance Learning},
  author={Cinbis, Ramazan Gokberk and Verbeek, Jakob and Schmid, Cordelia},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2016}
}

@Article{kalousis2007stability,
  author    = {Kalousis, Alexandros and Prados, Julien and Hilario, Melanie},
  title     = {Stability of feature selection algorithms: a study on high-dimensional spaces},
  journal   = {Knowledge and Information Systems},
  year      = {2007},
  volume    = {12},
  number    = {1},
  pages     = {95--116},
  file      = {kalousis2007stability.pdf:kalousis2007stability.pdf:PDF},
  publisher = {Springer},
}

@inproceedings{kuncheva2007stability,
  title={A stability index for feature selection},
  author={Kuncheva, Ludmila I},
  booktitle={Artificial Intelligence and Applications},
  pages={421--427},
  year={2007}
}

@incollection{duin2014metric,
  title={Metric Learning in Dissimilarity Space for Improved Nearest Neighbor Performance},
  author={Duin, Robert P W and Bicego, Manuele and Orozco-Alzate, Mauricio and Kim, Sang-Woon and Loog, Marco},
  booktitle={Structural, Syntactic, and Statistical Pattern Recognition},
  pages={183--192},
  year={2014},
  publisher={Springer}
}


@article{ferri2009experimental,
  title={An experimental comparison of performance measures for classification},
  author={Ferri, C{\'e}sar and Hern{\'a}ndez-Orallo, Jos{\'e} and Modroiu, R},
  journal={Pattern Recognition Letters},
  volume={30},
  number={1},
  pages={27--38},
  year={2009},
  publisher={Elsevier}
}




@inproceedings{maaten2013learning,
  title={Learning with marginalized corrupted features},
  author={van der Maaten, Laurens and Chen, Minmin and Tyree, Stephen and Weinberger, Kilian Q},
  booktitle={International Conference on Machine Learning},
  pages={410--418},
  year={2013}
}

@Book{aggarwal2008general,
  Title                    = {A general survey of privacy-preserving data mining models and algorithms},
  Author                   = {Aggarwal, Charu C and Philip, S Yu},
  Publisher                = {Springer},
  Year                     = {2008}
}

@Article{akbas2011mis,
  Title                    = {MIS-Boost: Multiple Instance Selection Boosting},
  Author                   = {Akbas, Emre and Ghanem, Bernard and Ahuja, Narendra},
  Journal                  = {arXiv preprint arXiv:1109.2388},
  Year                     = {2011}
}

@InProceedings{andrews2002multiple,
  Title                    = {Multiple instance learning with generalized support vector machines},
  Author                   = {Andrews, S. and Hofmann, T. and Tsochantaridis, I.},
  Booktitle                = {National Conference on Artificial Intelligence},
  Year                     = {2002},
  Pages                    = {943--944}
}

@InProceedings{arandjelovic2006face,
  Title                    = {Face set classification using maximally probable mutual modes},
  Author                   = {Arandjelovic, O. and Cipolla, R.},
  Booktitle                = {International Conference on Pattern Recognition},
  Year                     = {2006},
  Organization             = {IEEE},
  Pages                    = {511--514},
  Volume                   = {1}
}

@InProceedings{babenko2009visual,
  Title                    = {Visual tracking with online multiple instance learning},
  Author                   = {Babenko, Boris and Yang, Ming-Hsuan and Belongie, Serge},
  Booktitle                = {Computer Vision and Pattern Recognition},
  Year                     = {2009},
  Organization             = {IEEE},
  Pages                    = {983--990}
}

@PhdThesis{bailey2001class,
  Title                    = {Class-dependent features and multicategory classification},
  Author                   = {Bailey, A.},
  Year                     = {2001}
}

@Article{barshan2011supervised,
  Title                    = {Supervised principal component analysis: Visualization, classification and regression on subspaces and submanifolds},
  Author                   = {Barshan, Elnaz and Ghodsi, Ali and Azimifar, Zohreh and Zolghadri Jahromi, Mansoor},
  Journal                  = {Pattern Recognition},
  Year                     = {2011},
  Number                   = {7},
  Pages                    = {1357--1371},
  Volume                   = {44},

  Publisher                = {Elsevier}
}

@Article{basu2005syntactic,
  Title                    = {Syntactic and Structural Pattern Recognition},
  Author                   = {M. Basu and H. Bunke and A. Del Bimbo},
  Journal                  = {Special Section of IEEE Transaction on Pattern Analysis and Machine Intelligence},
  Year                     = {2005},
  Number                   = {27},
  Volume                   = {7}
}

@InProceedings{belongie2001shape,
  Title                    = {Shape context: A new descriptor for shape matching and object recognition},
  Author                   = {Belongie, Serge and Malik, Jitendra and Puzicha, Jan},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2001},
  Pages                    = {831--837},
  Publisher                = {MIT; 1998}
}

@Article{bertoni2005bio,
  Title                    = {Bio-molecular cancer prediction with random subspace ensembles of support vector machines},
  Author                   = {Bertoni, Alberto and Folgieri, Raffaella and Valentini, Giorgio},
  Journal                  = {Neurocomputing},
  Year                     = {2005},
  Pages                    = {535--539},
  Volume                   = {63},

  Publisher                = {Elsevier}
}

@Article{bhattacharyya2003simultaneous,
  Title                    = {Simultaneous classification and relevant feature identification in high-dimensional spaces: application to molecular profiling data},
  Author                   = {Bhattacharyya, Chiranjib and Grate, LR and Rizki, A and Radisky, D and Molina, FJ and Jordan, Michael I and Bissell, Mina J and Mian, I Saira},
  Journal                  = {Signal Processing},
  Year                     = {2003},
  Number                   = {4},
  Pages                    = {729--743},
  Volume                   = {83},

  Publisher                = {Elsevier}
}

@InCollection{bibby2008robust,
  Title                    = {Robust real-time visual tracking using pixel-wise posteriors},
  Author                   = {Bibby, Charles and Reid, Ian},
  Booktitle                = {European Conference on Computer Vision},
  Publisher                = {Springer},
  Year                     = {2008},
  Pages                    = {831--844}
}

@Article{briggs2012acoustic,
  Title                    = {Acoustic classification of multiple simultaneous bird species: A multi-instance multi-label approach},
  Author                   = {Briggs, F. and Lakshminarayanan, B. and Neal, L. and Fern, X. Z. and Raich, R. and Hadley, S. J. K. and Hadley, A. S. and Betts, M. G.},
  Journal                  = {The Journal of the Acoustical Society of America},
  Year                     = {2012},
  Pages                    = {4640},
  Volume                   = {131}
}

@InCollection{brown2010good,
  Title                    = {“{G}ood” and “bad” diversity in majority vote ensembles},
  Author                   = {Brown, Gavin and Kuncheva, Ludmila I},
  Booktitle                = {Multiple Classifier Systems},
  Publisher                = {Springer},
  Year                     = {2010},
  Pages                    = {124--133}
}

@Article{brown2005diversity,
  author    = {Brown, Gavin and Wyatt, Jeremy and Harris, Rachel and Yao, Xin},
  title     = {Diversity creation methods: a survey and categorisation},
  journal   = {Information Fusion},
  year      = {2005},
  volume    = {6},
  number    = {1},
  pages     = {5--20},
  file      = {brown2005diversity.PDF:brown2005diversity.PDF:PDF},
  publisher = {Elsevier},
}

@Article{budka2011accuracy,
  author  = {Budka, M. and Gabrys, B. and Musial, K.},
  title   = {On accuracy of {PDF} divergence estimators and their applicability to representative data sampling},
  journal = {Entropy},
  year    = {2011},
  volume  = {13},
  number  = {7},
  pages   = {1229--1266},
  file    = {budka2011accuracy.pdf:budka2011accuracy.pdf:PDF},
}

@InProceedings{bunescu2007learning,
  Title                    = {Learning to extract relations from the web using minimal supervision},
  Author                   = {Bunescu, Razvan and Mooney, Raymond},
  Booktitle                = {Annual meeting - association for Computational Linguistics},
  Year                     = {2007},
  Number                   = {1},
  Pages                    = {576},
  Volume                   = {45}
}

@Article{bunke1983inexact,
  Title                    = {Inexact Graph Matching for Structural Pattern Recognition},
  Author                   = {H. Bunke and G. Allermann},
  Journal                  = {Pattern Recognition Letters},
  Year                     = {1983},
  Pages                    = {245-253},
  Volume                   = {1}
}

@Article{bunke2004graph,
  Title                    = {Graph Matching in Pattern Recognition and Machine Vision},
  Author                   = {H. Bunke and T. Caelli},
  Journal                  = {International Journal of Pattern Recognition and Artifitial Intelligence},
  Year                     = {2004},
  Number                   = {3},
  Volume                   = {18}
}

@Article{bunke2011recent,
  Title                    = {Recent Advances in Graph-Based Pattern Recognition with
 Applications in Document Analysis},
  Author                   = {H. Bunke and
 K. Riesen},
  Journal                  = {Pattern Recognition},
  Year                     = {2011},
  Number                   = {5},
  Pages                    = {1057-1067},
  Volume                   = {44}
}

@Article{bunke2007family,
  author  = {Bunke, Horst and Riesen, Kaspar},
  title   = {A Family of Novel Graph Kernels for Structural Pattern Recognition},
  journal = {Pattern Recognition},
  year    = {2007},
  pages   = {20--31},
  file    = {bunke2007family.pdf:bunke2007family.pdf:PDF},
}

@Book{bunke1990syntactic,
  Title                    = {Syntactic and Structural Pattern Recognition: Theory and Applications},
  Author                   = {H. Bunke and A. Sanfeliu},
  Publisher                = {Singapore: World Scientific},
  Year                     = {1990}
}

@Article{caelli2004eigenspace,
  Title                    = {An Eigenspace Projection Clustering Method for Inexact Graph Matching},
  Author                   = {T. Caelli and S. Kosinov},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {2004},
  Pages                    = {515-519},
  Volume                   = {26}
}

@Article{carcassoni2003spectral,
  Title                    = {Spectral correspondence for point pattern matching},
  Author                   = {Carcassoni, Marco and Hancock, Edwin R},
  Journal                  = {Pattern Recognition},
  Year                     = {2003},
  Number                   = {1},
  Pages                    = {193--204},
  Volume                   = {36},

  Publisher                = {Elsevier}
}

@InProceedings{carvalho2005collective,
  Title                    = {On the collective classification of email speech acts},
  Author                   = {Carvalho, Vitor R and Cohen, William W},
  Booktitle                = {International ACM SIGIR Conference on Research and Development in Information Retrieval},
  Year                     = {2005},
  Organization             = {ACM},
  Pages                    = {345--352}
}

@Article{chang2011libsvm,
  Title                    = {{LIBSVM}: a library for support vector machines},
  Author                   = {Chang, C. C. and Lin, C. J.},
  Journal                  = {ACM Transactions on Intelligent Systems and Technology},
  Year                     = {2011},
  Number                   = {3},
  Pages                    = {27},
  Volume                   = {2}
}

@Article{chapelle2007training,
  Title                    = {Training a support vector machine in the primal},
  Author                   = {Chapelle, Olivier},
  Journal                  = {Neural Computation},
  Year                     = {2007},
  Number                   = {5},
  Pages                    = {1155--1178},
  Volume                   = {19},

  Publisher                = {MIT Press}
}

@book{criminisi2013decision,
  title={Decision forests for computer vision and medical image analysis},
  author={Criminisi, Antonio and Shotton, Jamie},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@Book{chung1997spectral,
  Title                    = {Spectral Graph Theory},
  Author                   = {F.R.K Chung},
  Publisher                = {CBMS Regional Conference Series in Mathematics, No. 92, USA: AMS},
  Year                     = {1997}
}

@Article{cordella2004sub,
  Title                    = {A (sub) graph isomorphism algorithm for matching large graphs},
  Author                   = {Cordella, L. P. and Foggia, P. and Sansone, C. and Vento, M.},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {2004},
  Number                   = {10},
  Pages                    = {1367--1372},
  Volume                   = {26}
}

@Article{cover1967nearest,
  Title                    = {Nearest Neighbor Pattern Classification},
  Author                   = {T.M. Cover and P. Hart},
  Journal                  = {IEEE Transactions on Information Theory},
  Year                     = {1967},
  Number                   = {1},
  Pages                    = {21-27},
  Volume                   = {13}
}

@InProceedings{dinh2012study,
  Title                    = {A study on semi-supervised dissimilarity representation},
  Author                   = {Dinh, V. C. and Duin, R. P. W. and Loog, M.},
  Booktitle                = {International Conference on Pattern Recognition},
  Year                     = {2012},
  Organization             = {IEEE},
  Pages                    = {2861--2864}
}

@InProceedings{doran2014learning,
  Title                    = {Learning Instance Concepts from Multiple-Instance Data with Bags as Distributions},
  Author                   = {Doran, Gary and Ray, Soumya},
  Booktitle                = {AAAI Conference on Artificial Intelligence},
  Year                     = {2014}
}

@InProceedings{doran2013smile,
  author    = {Doran, Gary and Ray, Soumya},
  title     = {SMILe: Shuffled Multiple-Instance Learning.},
  booktitle = {AAAI},
  year      = {2013},
  file      = {doran2013smile.pdf:doran2013smile.pdf:PDF},
}

@InProceedings{dubuisson1994modified,
  Title                    = {A modified {Hausdorff} distance for object matching},
  Author                   = {Dubuisson, M. P. and Jain, A. K.},
  Booktitle                = {International Conference on Pattern Recognition},
  Year                     = {1994},
  Pages                    = {566--568},
  Volume                   = {1}
}

@Misc{distools,
  Title                    = {{Dis}-{T}ools},

  Author                   = {Duin, R. P. W. and P{\k{e}}kalska, E.},
  Year                     = {2009},

  Publisher                = {Delft University of Technology}
}

@InProceedings{duin2002combining,
  Title                    = {The combining classifier: to train or not to train?},
  Author                   = {Duin, Robert P W},
  Booktitle                = {International Conference on Pattern Recognition},
  Year                     = {2002},
  Organization             = {IEEE},
  Pages                    = {765--770},
  Volume                   = {2}
}

@Article{duin2012dissimilarity,
  Title                    = {The dissimilarity space: Bridging structural and statistical pattern recognition},
  Author                   = {Duin, Robert P W and P{\k{e}}kalska, El{\.z}bieta},
  Journal                  = {Pattern Recognition Letters},
  Year                     = {2012},
  Number                   = {7},
  Pages                    = {826--832},
  Volume                   = {33},

  Publisher                = {Elsevier}
}

@InProceedings{elkan2008learning,
  author       = {Elkan, Charles and Noto, Keith},
  title        = {Learning classifiers from only positive and unlabeled data},
  booktitle    = {International Conference on Knowledge Discovery and Data Mining},
  year         = {2008},
  pages        = {213--220},
  organization = {ACM},
  file         = {elkan2008learning.pdf:elkan2008learning.pdf:PDF},
}

@InCollection{erdem2011multiple,
  Title                    = {Multiple-instance learning with instance selection via dominant sets},
  Author                   = {Erdem, Aykut and Erdem, Erkut},
  Booktitle                = {Similarity-Based Pattern Recognition},
  Publisher                = {Springer},
  Year                     = {2011},
  Pages                    = {177--191}
}

@Article{gartner2005predictive,
  author    = {G{\"a}rtner, Thomas},
  title     = {{Predictive Graph Mining with Kernel Methods}},
  journal   = {Advanced methods for knowledge discovery from complex data},
  year      = {2005},
  pages     = {95--121},
  file      = {gartner2005predictive.pdf:gartner2005predictive.pdf:PDF},
  publisher = {Springer},
}

@Article{grauman2007pyramid,
  Title                    = {The pyramid match kernel: Efficient learning with sets of features},
  Author                   = {Grauman, Kristen and Darrell, Trevor},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2007},
  Pages                    = {725--760},
  Volume                   = {8},

  Publisher                = {JMLR. org}
}

@Article{guyon2002gene,
  Title                    = {Gene selection for cancer classification using support vector machines},
  Author                   = {Guyon, Isabelle and Weston, Jason and Barnhill, Stephen and Vapnik, Vladimir},
  Journal                  = {Machine Learning},
  Year                     = {2002},
  Number                   = {1-3},
  Pages                    = {389--422},
  Volume                   = {46},

  Publisher                = {Springer}
}

@Article{ham2005investigation,
  Title                    = {Investigation of the random forest framework for classification of hyperspectral data},
  Author                   = {Ham, Jisoo and Chen, Yangchi and Crawford, Melba M and Ghosh, Joydeep},
  Journal                  = {IEEE Transactions on Geoscience and Remote Sensing},
  Year                     = {2005},
  Number                   = {3},
  Pages                    = {492--501},
  Volume                   = {43},

  Publisher                = {IEEE}
}

@Article{hart1968formal,
  author  = {P. E. Hart and N. J. Nilson and B. Raphael},
  title   = {A Formal Basis for the Heuristic Determination of Minimum Cost Paths},
  journal = {IEEE Transactions on Systems, Science, and Cybernetics},
  year    = {1968},
  volume  = {4},
  number  = {2},
  pages   = {100-107},
}

@Book{hastie2001elements,
  Title                    = {The Elements of Statistical Learning},
  Author                   = {T. Hastie and R. Tibshirani and J. Friedman},
  Publisher                = {New York: Springer-Verlag},
  Year                     = {2001}
}

@InProceedings{he2004multiscale,
  Title                    = {Multiscale conditional random fields for image labeling},
  Author                   = {He, Xuming and Zemel, Richard S and Carreira-Perpin{\'a}n, Miguel A},
  Booktitle                = {Computer Vision and Pattern Recognition},
  Year                     = {2004},
  Organization             = {IEEE},
  Pages                    = {II--695},
  Volume                   = {2}
}

@Conference{horvath2004cyclic,
  Title                    = {{Cyclic Pattern Kernels for Predictive Graph Mining}},
  Author                   = {Horv\'{a}th, T. and G\"{a}rtner, T. and Wrobel, S.},
  Booktitle                = {Knowledge Discovery and Data Mining},
  Year                     = {2004},
  Organization             = {ACM},
  Pages                    = {158--167},

  ISBN                     = {1581138881}
}

@Article{huang2005using,
  Title                    = {Using {AUC} and accuracy in evaluating learning algorithms},
  Author                   = {Huang, J. and Ling, C. X.},
  Journal                  = {IEEE Transactions on Knowledge and Data Engineering},
  Year                     = {2005},
  Number                   = {3},
  Pages                    = {299--310},
  Volume                   = {17},

  Publisher                = {IEEE}
}

@Article{huttenlocher1993comparing,
  Title                    = {Comparing images using the {Hausdorff} distance},
  Author                   = {Huttenlocher, D. P. and Klanderman, G. A. and Rucklidge, W. J.},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {1993},
  Number                   = {9},
  Pages                    = {850--863},
  Volume                   = {15},

  Publisher                = {IEEE}
}

@InProceedings{ibba2010study,
  Title                    = {A study on combining sets of differently measured dissimilarities},
  Author                   = {Ibba, A. and Duin, R. P. W. and Lee, W. J.},
  Booktitle                = {International Conference on Pattern Recognition},
  Year                     = {2010},
  Pages                    = {3360--3363}
}

@Article{jain2000statistical,
  Title                    = {Statistical pattern recognition: A review},
  Author                   = {Jain, Anil K and Duin, Robert P. W. and Mao, Jianchang},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {2000},
  Number                   = {1},
  Pages                    = {4--37},
  Volume                   = {22},

  Publisher                = {IEEE}
}

@InProceedings{jebara2003images,
  author    = {Jebara, Tony},
  title     = {Images as bags of pixels},
  booktitle = {International Conference on Computer Vision},
  year      = {2003},
  pages     = {265--272},
  file      = {jebara2003images.pdf:jebara2003images.pdf:PDF},
}

@Conference{kashima2003marginalized,
  Title                    = {{Marginalized Kernels Between Labeled Graphs}},
  Author                   = {Kashima, H. and Tsuda, K. and Inokuchi, A.},
  Booktitle                = {International Conference on Machine Learning},
  Year                     = {2003},
  Pages                    = {321},
  Volume                   = {3}
}

@Article{kim2007discriminative,
  Title                    = {Discriminative learning and recognition of image set classes using canonical correlations},
  Author                   = {Kim, Tae-Kyun and Kittler, Josef and Cipolla, Roberto},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {2007},
  Number                   = {6},
  Pages                    = {1005--1018},
  Volume                   = {29},

  Publisher                = {IEEE}
}

@Book{kindermann1980markov,
  Title                    = {Markov random fields and their applications},
  Author                   = {Kindermann, Ross and Snell, James Laurie and others},
  Publisher                = {American Mathematical Society Providence, RI},
  Year                     = {1980},
  Volume                   = {1}
}

@Article{kotsiantis2007supervised,
  Title                    = {Supervised machine learning: A review of classification techniques},
  Author                   = {Kotsiantis, S B and Zaharakis, I D and Pintelas, P E},
  Journal                  = {Frontiers in Artificial Intelligence and Applications},
  Year                     = {2007},
  Pages                    = {3},
  Volume                   = {160},

  Publisher                = {IOS Press}
}

@InProceedings{kriegel2004classification,
  author    = {Kriegel, Hans-Peter and Schubert, Matthias},
  title     = {Classification of websites as sets of feature vectors},
  booktitle = {Databases and Applications},
  year      = {2004},
  pages     = {127--132},
  file      = {kriegel2004classification.pdf:kriegel2004classification.pdf:PDF},
}

@InProceedings{kuck2005learning,
  Title                    = {Learning about individuals from group statistics},
  Author                   = {Kuck, Hendrik and de Freitas, Nando},
  Booktitle                = {Uncertainty in Artificial Intelligence},
  Year                     = {2005},
  Pages                    = {332--339}
}

@InProceedings{kummamuru2005learning,
  Title                    = {On learning asymmetric dissimilarity measures},
  Author                   = {Kummamuru, K. and Krishnapuram, R. and Agrawal, R.},
  Booktitle                = {International Conference on Data Mining},
  Year                     = {2005},
  Organization             = {IEEE},
  Pages                    = {4--pp}
}

@InProceedings{lafferty2001conditional,
  Title                    = {Conditional random fields: Probabilistic models for segmenting and labeling sequence data},
  Author                   = {Lafferty, John and McCallum, Andrew and Pereira, Fernando C N},
  Booktitle                = {International Conference on Machine Learning},
  Year                     = {2001},
  Pages                    = {282--289}
}

@InCollection{li2013link,
  Title                    = {The Link between Multiple-Instance Learning and Learning from Only Positive and Unlabelled Examples},
  Author                   = {Li, Yan and Tax, D M J and Duin, R P W and Loog, Marco},
  Booktitle                = {Multiple Classifier Systems},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2013},
  Pages                    = {157-166},
  Volume                   = {7872}
}

@Article{li2012multiple,
  Title                    = {Multiple-instance learning as a classifier combining problem},
  Author                   = {Li, Yan and Tax, David M J and Duin, Robert P W and Loog, Marco},
  Journal                  = {Pattern Recognition},
  Year                     = {2012},

  Publisher                = {Elsevier}
}

@Article{littlestone1988learning,
  Title                    = {Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm},
  Author                   = {Littlestone, N.},
  Journal                  = {Machine Learning},
  Year                     = {1988},
  Number                   = {4},
  Pages                    = {285--318},
  Volume                   = {2},

  Publisher                = {Springer}
}

@Article{lowe2004distinctive,
  Title                    = {Distinctive Image Features from Scale-Invariant Keypoints},
  Author                   = {D. G. Lowe},
  Journal                  = {International Journal of Computer Vision},
  Year                     = {2004},
  Number                   = {2},
  Pages                    = {91-110},
  Volume                   = {60}
}

@Article{madden2007tracking,
  author    = {Madden, Christopher and Cheng, Eric Dahai and Piccardi, Massimo},
  title     = {Tracking people across disjoint camera views by an illumination-tolerant appearance representation},
  journal   = {Machine Vision and Applications},
  year      = {2007},
  volume    = {18},
  number    = {3-4},
  pages     = {233--247},
  file      = {madden2007tracking.pdf:madden2007tracking.pdf:PDF},
  publisher = {Springer},
}

@InProceedings{maron1998multiple,
  Title                    = {Multiple-instance learning for natural scene classification},
  Author                   = {Maron, O. and Ratan, A. L.},
  Booktitle                = {International Conference on Machine Learning},
  Year                     = {1998},
  Pages                    = {341--349},
  Volume                   = {15}
}

@Conference{menchetti2005weighted,
  Title                    = {{Weighted Decomposition Kernels}},
  Author                   = {Menchetti, S. and Costa, F. and Frasconi, P.},
  Booktitle                = {International Conference on Machine Learning},
  Year                     = {2005},
  Organization             = {ACM},
  Pages                    = {585--592},

  ISBN                     = {1595931805}
}

@Article{munoz2003support,
  Title                    = {Support vector machine classifiers for asymmetric proximities},
  Author                   = {Mu{\~n}oz, A. and Mart{\'\i}n de Diego, I. and Moguerza, J.},
  Journal                  = {Artificial Neural Networks and Neural Information Processing},
  Year                     = {2003},
  Pages                    = {179--179},

  Publisher                = {Springer}
}

@InProceedings{muandet2012learning,
  Title                    = {Learning from distributions via support measure machines},
  Author                   = {Muandet, Krikamol and Fukumizu, Kenji and Dinuzzo, Francesco and Sch{\"o}lkopf, Bernhard},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2012},
  Pages                    = {10--18}
}

@Article{munkres1957algorithm,
  Title                    = {Algorithm for the Assignment and Transportation Problems},
  Author                   = {J. Munkres},
  Journal                  = {Journal of the Society for Industrial and Applied Mathematics},
  Year                     = {1957},
  Pages                    = {32-38},
  Volume                   = {5}
}

@Article{murray2006machine,
  Title                    = {Machine learning methods for predicting failures in hard drives: A multiple-instance application},
  Author                   = {Murray, Joseph F and Hughes, Gordon F and Kreutz-Delgado, Kenneth},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2006},
  Number                   = {1},
  Pages                    = {783},
  Volume                   = {6},

  Publisher                = {Citeseer}
}

@TechReport{nene1996columbia,
  Title                    = {Columbia Object Image Liberary: Coil-100},
  Author                   = {S. Nene and S. Nayar and H. Murase},
  Institution              = {Department of Computer Science, Columbia University, New York},
  Year                     = {1996}
}

@Book{neuhaus2007bridging,
  Title                    = {Bridging the gap between graph edit distance and kernel machines},
  Author                   = {Neuhaus, M. and Bunke, H.},
  Publisher                = {World Scientific},
  Year                     = {2007}
}

@InProceedings{pekalska2001combining,
  author    = {P{\k{e}}kalska, E. and Duin, R. P W},
  title     = {On combining dissimilarity representations},
  booktitle = {Multiple Classifier Systems},
  year      = {2001},
  pages     = {359--368},
  publisher = {Springer},
  file      = {pekalska2001combining.pdf:pekalska2001combining.pdf:PDF},
}

@Article{paclik2006building,
  Title                    = {Building road-sign classifiers using a trainable similarity measure},
  Author                   = {Pacl{\'\i}k, P. and Novovicov{\'a}, J. and Duin, R. P. W.},
  Journal                  = {Intelligent Transportation Systems},
  Year                     = {2006},
  Number                   = {3},
  Pages                    = {309--321},
  Volume                   = {7},

  Publisher                = {IEEE}
}

@Article{paredes2000class,
  Title                    = {A class-dependent weighted dissimilarity measure for nearest neighbor classification problems},
  Author                   = {Paredes, R. and Vidal, E.},
  Journal                  = {Pattern Recognition Letters},
  Year                     = {2000},
  Number                   = {12},
  Pages                    = {1027--1036},
  Volume                   = {21},

  Publisher                = {Elsevier}
}

@Misc{tax2016mil,
  author = {Tax, D. M. J. and Cheplygina, V.},
  title  = {{MIL}, A {M}atlab Toolbox for Multiple Instance Learning},
  year   = {2016},
  note   = {version 1.2.1},
  groups = {My papers},
  url    = {http://prlab.tudelft.nl/david-tax/mil.html},
}

@InProceedings{prest2012learning,
  Title                    = {Learning object class detectors from weakly annotated video},
  Author                   = {Prest, Alessandro and Leistner, Christian and Civera, Javier and Schmid, Cordelia and Ferrari, Vittorio},
  Booktitle                = {Computer Vision and Pattern Recognition},
  Year                     = {2012},
  Organization             = {IEEE},
  Pages                    = {3282--3289}
}

@Article{qiu2007clustering,
  Title                    = {Clustering and Embedding Using Commute Times},
  Author                   = {H. J. Qiu and E. R. Hancock},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {2007},
  Pages                    = {1873-1890},
  Volume                   = {29}
}

@Article{rabe2007global,
  Title                    = {Global strategy for the diagnosis, management, and prevention of chronic obstructive pulmonary disease: GOLD executive summary},
  Author                   = {Rabe, Klaus F and Hurd, Suzanne and Anzueto, Antonio and Barnes, Peter J and Buist, Sonia A and Calverley, Peter and Fukuchi, Yoshinosuke and Jenkins, Christine and Rodriguez-Roisin, Roberto and van Weel, Chris and others},
  Journal                  = {American Journal of Respiratory and Critical Care Medicine},
  Year                     = {2007},
  Number                   = {6},
  Pages                    = {532--555},
  Volume                   = {176},

  Publisher                = {American Thoracic Society}
}

@Conference{ramon2003expressivity,
  Title                    = {{Expressivity Versus Efficiency of Graph Kernels}},
  Author                   = {Ramon, J. and G\"{a}rtner, T.},
  Booktitle                = {International Workshop on Mining Graphs, Trees and Sequences},
  Year                     = {2003},
  Organization             = {Citeseer},
  Pages                    = {65--74}
}

@Article{riesen2010iam,
  Title                    = {{IAM Graph Database Repository for Graph Based Pattern Recognition and Machine Learning}},
  Author                   = {Riesen, K. and Bunke, H.},
  Journal                  = {Structural, Syntactic, and Statistical Pattern Recognition},
  Year                     = {2010},
  Pages                    = {287--297},

  Publisher                = {Springer}
}

@Article{riesen2009approximate,
  Title                    = {Approximate Graph Edit Distance Computation by Means of
 Bipartite Graph Matching},
  Author                   = {K. Riesen and
 H. Bunke},
  Journal                  = {Image and Vision Computing},
  Year                     = {2009},
  Number                   = {7},
  Pages                    = {950-959},
  Volume                   = {27}
}

@InProceedings{riesen2009cluster,
  Title                    = {Cluster Ensembles Based on Vector Space Embeddings of Graphs},
  Author                   = {K. Riesen and
 H. Bunke},
  Booktitle                = {Multiple Classifier Systems},
  Year                     = {2009},
  Pages                    = {211-221}
}

@InProceedings{riesen2009feature,
  Title                    = {Feature Ranking Algorithms for Improving Classification
 of Vector Space Embedded Graphs},
  Author                   = {K. Riesen and
 H. Bunke},
  Booktitle                = {Computer Analysis of Images and Patterns},
  Year                     = {2009},
  Pages                    = {377-384}
}

@Article{riesen2009graph,
  Title                    = {Graph Classification Based on Vector Space Embedding},
  Author                   = {K. Riesen and H. Bunke},
  Journal                  = {International Journal of Pattern Recognition and Artificial Intelligence},
  Year                     = {2009},
  Number                   = {6},
  Pages                    = {1053-1081},
  Volume                   = {23}
}

@InProceedings{riesen2009efficient,
  Title                    = {Efficient Suboptimal Graph Isomorphism},
  Author                   = {K. Riesen and
 S. Fankhauser and
 H. Bunke and
 P. J. Dickinson},
  Booktitle                = {Graph-based Representations in Pattern Recognition},
  Year                     = {2009},
  Pages                    = {124-133}
}

@InProceedings{riesen2007bipartite,
  Title                    = {Bipartite Graph Matching for Computing the Edit Distance
 of Graphs},
  Author                   = {K. Riesen and
 M. Neuhaus and
 H. Bunke},
  Booktitle                = {Graph-based Representations in Pattern Recognition},
  Year                     = {2007},
  Pages                    = {1-12}
}

@Article{rueda2004new,
  Title                    = {New bounds and approximations for the error of linear classifiers},
  Author                   = {Rueda, L.},
  Journal                  = {Progress in Pattern Recognition, Image Analysis and Applications},
  Year                     = {2004},
  Pages                    = {51--70},

  Publisher                = {Springer}
}

@InCollection{sorensen2009learning,
  Title                    = {Learning {COPD} sensitive filters in pulmonary {CT}},
  Author                   = {S{\o}rensen, Lauge and Lo, Pechin and Ashraf, Haseem and Sporring, Jon and Nielsen, Mads and de Bruijne, Marleen},
  Booktitle                = {Medical Image Computing and Computer-Assisted Intervention},
  Year                     = {2009},
  Pages                    = {699--706}
}

@InProceedings{sorensen2011dissimilarity,
  Title                    = {Dissimilarity-based classification of anatomical tree structures},
  Author                   = {S{\o}rensen, Lauge and Lo, Pechin and Dirksen, Asger and Petersen, Jens and De Bruijne, Marleen},
  Booktitle                = {Information Processing in Medical Imaging},
  Year                     = {2011},
  Pages                    = {475--485}
}

@InCollection{sorensen2010image,
  author    = {S{\o}rensen, Lauge and Loog, Marco and Lo, Pechin and Ashraf, Haseem and Dirksen, Asger and Duin, Robert P W and de Bruijne, Marleen},
  title     = {Image dissimilarity-based quantification of lung disease from {CT}},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention},
  year      = {2010},
  pages     = {37--44},
  file      = {sorensen2010image.pdf:sorensen2010image.pdf:PDF},
}

@InProceedings{sorensen2010dissimilarity,
  author    = {S{\o}rensen, L. and Loog, M. and Tax, D. M J and Lee, Wan-Jui and de Bruijne, M. and Duin, R. P W},
  title     = {Dissimilarity-based multiple instance learning},
  booktitle = {Structural, Syntactic, and Statistical Pattern Recognition},
  year      = {2010},
  pages     = {129--138},
  publisher = {Springer},
  file      = {sorensen2010dissimilarity.pdf:sorensen2010dissimilarity.pdf:PDF},
}

@Article{scott2005generalized,
  Title                    = {On generalized multiple-instance learning},
  Author                   = {Scott, S. and Zhang, J. and Brown, J.},
  Journal                  = {International Journal of Computational Intelligence and Applications},
  Year                     = {2005},
  Number                   = {01},
  Pages                    = {21--35},
  Volume                   = {5},

  Publisher                = {World Scientific}
}

@InCollection{sen2010collective,
  Title                    = {Collective Classification},
  Author                   = {Sen, Prithviraj and Namata, Galileo and Bilgic, Mustafa and Getoor, Lise},
  Booktitle                = {Encyclopedia of Machine Learning},
  Publisher                = {Springer},
  Year                     = {2010},
  Pages                    = {189--193}
}

@Article{sen2008collective,
  Title                    = {Collective classification in network data},
  Author                   = {Sen, Prithviraj and Namata, Galileo and Bilgic, Mustafa and Getoor, Lise and Galligher, Brian and Eliassi-Rad, Tina},
  Journal                  = {AI magazine},
  Year                     = {2008},
  Number                   = {3},
  Pages                    = {93},
  Volume                   = {29}
}

@InCollection{shotton2006textonboost,
  Title                    = {Textonboost: Joint appearance, shape and context modeling for multi-class object recognition and segmentation},
  Author                   = {Shotton, Jamie and Winn, John and Rother, Carsten and Criminisi, Antonio},
  Booktitle                = {European Conference on Computer Vision},
  Publisher                = {Springer},
  Year                     = {2006},
  Pages                    = {1--15}
}

@InCollection{skurichina2001bagging,
  Title                    = {Bagging and the random subspace method for redundant feature spaces},
  Author                   = {Skurichina, Marina and Duin, Robert P W},
  Booktitle                = {Multiple Classifier Systems},
  Publisher                = {Springer},
  Year                     = {2001},
  Pages                    = {1--10}
}

@InProceedings{taskar2005learning,
  Title                    = {Learning structured prediction models: A large margin approach},
  Author                   = {Taskar, Ben and Chatalbashev, Vassil and Koller, Daphne and Guestrin, Carlos},
  Booktitle                = {International Conference on Machine Learning},
  Year                     = {2005},
  Pages                    = {896--903}
}

@InProceedings{tax2008learning,
  Title                    = {Learning curves for the analysis of multiple instance classifiers},
  Author                   = {Tax, D M J and Duin, R P W},
  Booktitle                = {Structural, Syntactic, and Statistical Pattern Recognition},
  Year                     = {2008},
  Pages                    = {724--733},
  Publisher                = {Springer}
}

@InProceedings{tsochantaridis2004support,
  Title                    = {Support vector machine learning for interdependent and structured output spaces},
  Author                   = {Tsochantaridis, Ioannis and Hofmann, Thomas and Joachims, Thorsten and Altun, Yasemin},
  Booktitle                = {International Conference on Machine learning},
  Year                     = {2004},
  Organization             = {ACM},
  Pages                    = {104}
}

@Article{tsoumakas2007multi,
  author    = {Tsoumakas, Grigorios and Katakis, Ioannis},
  title     = {Multi-label classification: An overview},
  journal   = {International Journal of Data Warehousing and Mining},
  year      = {2007},
  volume    = {3},
  number    = {3},
  pages     = {1--13},
  file      = {tsoumakas2007multilabel.pdf:tsoumakas2007multilabel.pdf:PDF},
  publisher = {IGI Global},
}

@Article{uppaluri1997quantification,
  Title                    = {Quantification of pulmonary emphysema from lung computed tomography images},
  Author                   = {Uppaluri, Renuka and Mitsa, Theophano and Sonka, Milan and Hoffman, Eric A and McLennan, Geoffrey},
  Journal                  = {American Journal of Respiratory and Critical Care Medicine},
  Year                     = {1997},
  Number                   = {1},
  Pages                    = {248--254},
  Volume                   = {156},

  Publisher                = {Am Thoracic Soc}
}

@InProceedings{vanwinckelen2014meta,
  author    = {Vanwinckelen, Gitte and Blockeel, Hendrik},
  title     = {A meta-learning system for multi-instance classification},
  booktitle = {ECML Workshop on Learning over Multiple Contexts},
  year      = {2014},
  pages     = {1--14},
  file      = {vanwinckelen2014meta.pdf:vanwinckelen2014meta.pdf:PDF},
  groups    = {Veni},
}

@Book{vapnik1995nature,
  Title                    = {The Nature of Statistical Learning Theory},
  Author                   = {V. Vapnik},
  Publisher                = {New York: Springer-Verlag},
  Year                     = {1995}
}

@InProceedings{vaswani2002linear,
  Title                    = {A linear classifier for gaussian class conditional distributions with unequal covariance matrices},
  Author                   = {Vaswani, N.},
  Booktitle                = {International Conference on Pattern Recognition},
  Year                     = {2002},
  Organization             = {IEEE},
  Pages                    = {60--63},
  Volume                   = {2}
}

@InProceedings{vijayanarasimhan2008keywords,
  Title                    = {Keywords to visual categories: Multiple-instance learning forweakly supervised object categorization},
  Author                   = {Vijayanarasimhan, Sudheendra and Grauman, Kristen},
  Booktitle                = {Computer Vision and Pattern Recognition},
  Year                     = {2008},
  Organization             = {IEEE},
  Pages                    = {1--8}
}

@InProceedings{wang2000solving,
  Title                    = {Solving the multiple-instance problem: A lazy learning approach},
  Author                   = {Wang, J.},
  Booktitle                = {International Conference on Machine Learning},
  Year                     = {2000}
}

@Article{wolf2003learning,
  Title                    = {Learning over sets using kernel principal angles},
  Author                   = {Wolf, Lior and Shashua, Amnon},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2003},
  Pages                    = {913--931},
  Volume                   = {4},

  Publisher                = {JMLR. org}
}

@PhdThesis{xu2003statistical,
  author = {Xu, X.},
  title  = {Statistical learning in multiple instance problems},
  school = {the University of Waikato},
  year   = {2003},
  file   = {xu2003statistical.pdf:xu2003statistical.pdf:PDF},
}

@Article{zafra2010reducing,
  author    = {Zafra, A. and Pechenizkiy, M. and Ventura, S.},
  title     = {Reducing dimensionality in multiple instance learning with a filter method},
  journal   = {Hybrid Artificial Intelligence Systems},
  year      = {2010},
  pages     = {35--44},
  file      = {zafra2010reducing.pdf:zafra2010reducing.pdf:PDF},
  publisher = {Springer},
}

@Article{zhao2005new,
  Title                    = {A new {Hausdorff} distance for image matching},
  Author                   = {Zhao, C. and Shi, W. and Deng, Y.},
  Journal                  = {Pattern Recognition Letters},
  Year                     = {2005},
  Number                   = {5},
  Pages                    = {581--586},
  Volume                   = {26},

  Publisher                = {Elsevier}
}

@Article{zhou2006sample,
  Title                    = {From sample similarity to ensemble similarity: Probabilistic distance measures in reproducing kernel hilbert space},
  Author                   = {Zhou, Shaohua Kevin and Chellappa, Rama},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {2006},
  Number                   = {6},
  Pages                    = {917--929},
  Volume                   = {28},

  Publisher                = {IEEE}
}

@InProceedings{zhou2010promoter,
  Title                    = {Promoter prediction based on a multiple instance learning scheme},
  Author                   = {Zhou, X. and Ruan, J. and Zhang, W.},
  Booktitle                = {International Conference on Bioinformatics and Computational Biology},
  Year                     = {2010},
  Organization             = {ACM},
  Pages                    = {295--301}
}

@Article{zhou2005multi,
  Title                    = {Multi-instance learning based web mining},
  Author                   = {Zhou, Z. H. and Jiang, K. and Li, M.},
  Journal                  = {Applied Intelligence},
  Year                     = {2005},
  Number                   = {2},
  Pages                    = {135--147},
  Volume                   = {22},

  Publisher                = {Springer}
}

@TechReport{zhou2004multi,
  author      = {Zhou, Zhi-Hua},
  title       = {Multi-instance learning: A survey},
  institution = {Department of Computer Science and Technology, Nanjing University},
  year        = {2004},
  groups      = {Not-so-supervised general},
}

@InProceedings{zhou2007relation,
  author    = {Zhou, Zhi-Hua and Xu, Jun-Ming},
  title     = {On the relation between multi-instance learning and semi-supervised learning},
  booktitle = {International Conference on Machine learning (ICML)},
  year      = {2007},
  pages     = {1167--1174},
}

@Article{ahn2007classification,
  author    = {Ahn, H. and Moon, H. and Fazzari, M.J. and Lim, N. and Chen, J.J. and Kodell, R.L.},
  title     = {{Classification by ensembles from random partitions of high-dimensional data}},
  journal   = {Computational Statistics \& Data Analysis},
  year      = {2007},
  volume    = {51},
  number    = {12},
  pages     = {6166--6179},
  file      = {ahn2007classification.pdf:ahn2007classification.pdf:PDF},
  publisher = {Elsevier},
}

@Article{altincay2007ensembling,
  author    = {Altin{\c{c}}ay, H.},
  title     = {{Ensembling evidential k-nearest neighbor classifiers through multi-modal perturbation}},
  journal   = {Applied Soft Computing},
  year      = {2007},
  volume    = {7},
  number    = {3},
  pages     = {1072--1083},
  file      = {altincay2007ensembling.PDF:altincay2007ensembling.PDF:PDF},
  publisher = {Elsevier},
}

@MISC{uci,
  author = {{Asuncion, A. and Newman, D.J.}},
  title = {{UCI Machine Learning Repository}},
  year = {2007},
  institution = {University of California, Irvine, School of Information and Computer
	Sciences},
  url = {http://www.ics.uci.edu/$\sim$mlearn/{MLR}epository.html}
}

@Article{biggio2010multiple,
  author    = {Biggio, B. and Fumera, G. and Roli, F.},
  title     = {{Multiple classifier systems under attack}},
  journal   = {Multiple Classifier Systems},
  year      = {2010},
  pages     = {74--83},
  file      = {biggio2010multiple.PDF:biggio2010multiple.PDF:PDF},
  publisher = {Springer},
}

@Article{bryll2003attribute,
  author    = {Bryll, R. and Gutierrez-Osuna, R. and Quek, F.},
  title     = {{Attribute bagging: improving accuracy of classifier ensembles by using random feature subsets}},
  journal   = {Pattern Recognition},
  year      = {2003},
  volume    = {36},
  number    = {6},
  pages     = {1291--1302},
  file      = {bryll2003attribute.PDF:bryll2003attribute.PDF:PDF},
  publisher = {Elsevier},
}

@Conference{caruana2006getting,
  author    = {Caruana, R. and Munson, A. and Niculescu-Mizil, A.},
  title     = {{Getting the most out of ensemble selection}},
  booktitle = {Sixth International Conference on Data Mining, ICDM'06},
  year      = {2006},
  pages     = {828--833},
  file      = {caruana2006getting.PDF:caruana2006getting.PDF:PDF},
}

@ARTICLE{chawla2004editorial,
  author = {Chawla, N.V. and Japkowicz, N. and Kotcz, A.},
  title = {{Editorial: special issue on learning from imbalanced data sets}},
  journal = {ACM SIGKDD Explorations Newsletter},
  year = {2004},
  volume = {6},
  pages = {1--6},
  number = {1},
  publisher = {ACM}
}

@BOOK{condorcet,
  title = {{Essai sur l'application de l'analyse á la probabilité des décisions
	rendues á la pluralité des voix"}},
  publisher = {Impremerie Royale, Paris},
  year = {1785},
  author = {de Condorcet, N.C.}
}

@Article{corona2008intrusion,
  author    = {Corona, I. and Giacinto, G. and Roli, F.},
  title     = {{Intrusion detection in computer systems using multiple classifier systems}},
  journal   = {Supervised and Unsupervised Ensemble Methods and their Applications},
  year      = {2008},
  pages     = {91--113},
  file      = {corona2008intrusion.PDF:corona2008intrusion.PDF:PDF},
  publisher = {Springer},
}

@Article{cunningham2000diversity,
  author    = {Cunningham, P. and Carney, J.},
  title     = {{Diversity versus quality in classification ensembles based on feature selection}},
  journal   = {Machine Learning: ECML 2000},
  year      = {2000},
  pages     = {109--116},
  file      = {cunningham2000diversity.PDF:cunningham2000diversity.PDF:PDF},
  publisher = {Springer},
}

@ARTICLE{bock2010ensemble,
  author = {De Bock, K.W. and Coussement, K. and Van den Poel, D.},
  title = {{Ensemble classification based on generalized additive models}},
  journal = {Computational Statistics \& Data Analysis},
  year = {2010},
  publisher = {Elsevier}
}

@Article{dietterich2000ensemble,
  author    = {Dietterich, T.},
  title     = {{Ensemble methods in machine learning}},
  journal   = {Multiple Classifier Systems},
  year      = {2000},
  pages     = {1--15},
  file      = {dietterich2000ensemble.PDF:dietterich2000ensemble.PDF:PDF},
  publisher = {Springer},
}

@Article{dietterich2000experimental,
  author    = {Dietterich, T.G.},
  title     = {{An experimental comparison of three methods for constructing ensembles of decision trees: Bagging, boosting, and randomization}},
  journal   = {Machine Learning},
  year      = {2000},
  volume    = {40},
  number    = {2},
  pages     = {139--157},
  file      = {dietterich2000experimental.pdf:dietterich2000experimental.pdf:PDF},
  publisher = {Springer},
}

@Article{duang2010bootstrap,
  author    = {Duangsoithong, R. and Windeatt, T.},
  title     = {{Bootstrap Feature Selection for Ensemble Classifiers}},
  journal   = {Advances in Data Mining. Applications and Theoretical Aspects},
  year      = {2010},
  pages     = {28--41},
  file      = {duang2010bootstrap.PDF:duang2010bootstrap.PDF:PDF},
  publisher = {Springer},
}

@ARTICLE{diaz2006gene,
  author = {D{\'\i}az-Uriarte, R. and de Andr{\'e}s, A.},
  title = {{Gene selection and classification of microarray data using random
	forest}},
  journal = {BMC Bioinformatics},
  year = {2006},
  volume = {7},
  pages = {3},
  number = {1},
  publisher = {BioMed Central Ltd}
}

@Article{evangelista2006taming,
  author    = {Evangelista, P. and Embrechts, M. and Szymanski, B.},
  title     = {{Taming the curse of dimensionality in kernels and novelty detection}},
  journal   = {Applied Soft Computing Technologies: The Challenge of Complexity},
  year      = {2006},
  pages     = {425--438},
  file      = {evangelista2006taming.PDF:evangelista2006taming.PDF:PDF},
  publisher = {Springer},
}

@Conference{freund1996experiments,
  author       = {Schapire, R. and Freund, Y.},
  title        = {{Experiments with a new boosting algorithm}},
  booktitle    = {Proceedings of the Thirteenth International Conference on Machine Learning (ICML'96)},
  year         = {1996},
  pages        = {148},
  organization = {Morgan Kaufmann Pub},
  file         = {freund1996experiments.pdf:freund1996experiments.pdf:PDF},
  isbn         = {1558604197},
}


@ARTICLE{giacinto2008intrusion,
  author = {Giacinto, G. and Perdisci, R. and Del Rio, M. and Roli, F.},
  title = {{Intrusion detection in computer networks by a modular ensemble of
	one-class classifiers}},
  journal = {Information Fusion},
  year = {2008},
  volume = {9},
  pages = {69--82},
  number = {1},
  publisher = {Elsevier}
}

@ARTICLE{hansen1990neural,
  author = {Hansen, L.K. and Salamon, P.},
  title = {{Neural network ensembles}},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {1990},
  volume = {12},
  pages = {993--1001},
  number = {10}
}

@CONFERENCE{janssens2009outlier,
  author = {Janssens, J.H.M. and Flesch, I. and Postma, E.O.},
  title = {{Outlier detection with one-class classifiers from ML and KDD}},
  booktitle = {Proceedings of the International Conference on Machine Learning and Applications},
  year = {2009},
  pages = {147--153},
  organization = {IEEE}
}

@Conference{john1994irrelevant,
  author       = {John, G.H. and Kohavi, R. and Pfleger, K.},
  title        = {{Irrelevant features and the subset selection problem}},
  booktitle    = {Proceedings of the Eleventh International Conference on Machine Learning},
  year         = {1994},
  volume       = {129},
  organization = {Citeseer},
  file         = {john1994irrelevant.pdf:john1994irrelevant.pdf:PDF},
}

@ARTICLE{krogh1995neural,
  author = {Krogh, A. and Vedelsby, J.},
  title = {{Neural network ensembles, cross validation, and active learning}},
  journal = {Advances in Neural Information Processing Systems},
  year = {1995},
  pages = {231--238},
  publisher = {Citeseer}
}

@Article{kuncheva2003elusive,
  author    = {Kuncheva, L.},
  title     = {{That elusive diversity in classifier ensembles}},
  journal   = {Pattern Recognition and Image Analysis},
  year      = {2003},
  pages     = {1126--1138},
  file      = {kuncheva2003elusive.PDF:kuncheva2003elusive.PDF:PDF},
  publisher = {Springer},
}

@Article{lai2002combining,
  author    = {Lai, C. and Tax, D. and Duin, R. and P{\k{e}}kalska, E. and Pacl{\'\i}k, P.},
  title     = {{On combining one-class classifiers for image database retrieval}},
  journal   = {Multiple Classifier Systems},
  year      = {2002},
  pages     = {212--221},
  file      = {lai2002combining.PDF:lai2002combining.PDF:PDF},
  publisher = {Springer},
}

@Conference{lazarevic2005feature,
  author       = {Lazarevic, A. and Kumar, V.},
  title        = {{Feature bagging for outlier detection}},
  booktitle    = {Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining},
  year         = {2005},
  pages        = {157--166},
  organization = {ACM},
  file         = {lazarevic2005feature.PDF:lazarevic2005feature.PDF:PDF},
}

@Conference{lazarevic2001effective,
  author    = {Lazarevic, A. and Obradovic, Z.},
  title     = {{Effective pruning of neural network classifier ensembles}},
  booktitle = {Proceedings of the International Joint Conference on Neural Networks},
  year      = {2001},
  volume    = {2},
  file      = {lazarevic2001effective.PDF:lazarevic2001effective.PDF:PDF},
}

@Article{li2005learning,
  author    = {Li, P. and Chan, K.L. and Krishnan, SM},
  title     = {{Learning a multi-size patch-based hybrid kernel machine ensemble for abnormal region detection in colonoscopic images}},
  year      = {2005},
  file      = {li2005learning.PDF:li2005learning.PDF:PDF},
  publisher = {IEEE Computer Society},
}

@Article{lumini2009ensemble,
  author    = {Lumini, A. and Nanni, L.},
  title     = {{Ensemble of on-line signature matchers based on OverComplete feature generation}},
  journal   = {Expert Systems with Applications},
  year      = {2009},
  volume    = {36},
  number    = {3},
  pages     = {5291--5296},
  file      = {lumini2009ensemble.PDF:lumini2009ensemble.PDF:PDF},
  publisher = {Elsevier},
}

@Conference{munoz2007combination,
  author       = {Munoz-Mar{\i}, J. and Camps-Valls, G. and G{\'o}mez-Chova, L. and Calpe-Maravilla, J.},
  title        = {{Combination of One-Class Remote Sensing Image Classifiers}},
  booktitle    = {IEEE International Geoscience and Remote Sensing Symposium (IGARSS)},
  year         = {2007},
  pages        = {1509--1512},
  organization = {Citeseer},
  file         = {munoz2007combination.PDF:munoz2007combination.PDF:PDF},
}

@ARTICLE{nanni2006experimental,
  author = {Nanni, L.},
  title = {{Experimental comparison of one-class classifiers for online signature
	verification}},
  journal = {Neurocomputing},
  year = {2006},
  volume = {69},
  pages = {869--873},
  number = {7-9},
  publisher = {Elsevier}
}

@Conference{nguyen2010mining,
  author       = {Nguyen, H. and Ang, H. and Gopalkrishnan, V.},
  title        = {{Mining Outliers with Ensemble of Heterogeneous Detectors on Random Subspaces}},
  booktitle    = {Database Systems for Advanced Applications},
  year         = {2010},
  pages        = {368--383},
  organization = {Springer},
  file         = {nguyen2010mining.PDF:nguyen2010mining.PDF:PDF},
}

@Conference{opitz1999feature,
  author       = {Opitz, D.W.},
  title        = {{Feature selection for ensembles}},
  booktitle    = {Proceedings of the National Conference on Artificial Intelligence},
  year         = {1999},
  pages        = {379--384},
  organization = {John Wiley \& Sons Ltd},
  file         = {opitz1999feature.PDF:opitz1999feature.PDF:PDF},
}

@Article{opitz1999popular,
  author    = {Opitz, D. and Maclin, R.},
  title     = {{Popular ensemble methods: An empirical study}},
  journal   = {Journal of Artificial Intelligence Research},
  year      = {1999},
  volume    = {11},
  number    = {169--198},
  pages     = {12},
  file      = {opitz1999popular.PDF:opitz1999popular.PDF:PDF},
  publisher = {Citeseer},
}

@ARTICLE{oza2008classifier,
  author = {Oza, N.C. and Tumer, K.},
  title = {{Classifier ensembles: Select real-world applications}},
  journal = {Information Fusion},
  year = {2008},
  volume = {9},
  pages = {4--20},
  number = {1},
  publisher = {Elsevier}
}

@Conference{panov2007combining,
  author       = {Panov, P. and D{\v{z}}eroski, S.},
  title        = {{Combining bagging and random subspaces to create better ensembles}},
  booktitle    = {Proceedings of the Seventh International Conference on Intelligent Data Analysis},
  year         = {2007},
  pages        = {118--129},
  organization = {Springer-Verlag},
  file         = {panov2007combining.PDF:panov2007combining.PDF:PDF},
}

@Conference{perdisci2006using,
  author    = {Perdisci, R. and Gu, G. and Lee, W.},
  title     = {{Using an ensemble of one-class SVM classifiers to harden payload-based anomaly detection systems}},
  booktitle = {Proceedings of the Sixth International Conference on Data Mining (ICDM'06)},
  year      = {2006},
  pages     = {488--498},
  file      = {perdisci2006using.PDF:perdisci2006using.PDF:PDF},
}

@Article{ratle2007comparison,
  author    = {Ratle, F. and Kanevski, M. and Terrettaz-Zufferey, A.L. and Esseiva, P. and Ribaux, O.},
  title     = {{A comparison of one-class classifiers for novelty detection in forensic case data}},
  journal   = {Intelligent Data Engineering and Automated Learning (IDEAL)},
  year      = {2007},
  pages     = {67--76},
  file      = {ratle2007comparison.PDF:ratle2007comparison.PDF:PDF},
  publisher = {Springer},
}

@Conference{reyes2008combining,
  author       = {Reyes, J. and Gilbert, D.},
  title        = {{Combining one-class classification models based on diverse biological data for prediction of protein-protein interactions}},
  booktitle    = {Data Integration in the Life Sciences},
  year         = {2008},
  pages        = {177--191},
  organization = {Springer},
  file         = {reyes2008combining.PDF:reyes2008combining.PDF:PDF},
}

@CONFERENCE{rijcke2005issues,
  author = {Rijcke, M. and Bojovic, M. and Homan, W. and Nuijt, M.},
  title = {{Issues in developing a commercial parcel reading system}},
  booktitle = {Proceedings of the Eighth International Conference on Document Analysis
	and Recognition},
  year = {2005},
  pages={1015--1019},
  organization = {IEEE}
}

@Article{rokach2009collective,
  author    = {Rokach, L.},
  title     = {{Collective-agreement-based pruning of ensembles}},
  journal   = {Computational Statistics \& Data Analysis},
  year      = {2009},
  volume    = {53},
  number    = {4},
  pages     = {1015--1026},
  file      = {rokach2009collective.PDF:rokach2009collective.PDF:PDF},
  publisher = {Elsevier},
}

@ARTICLE{rokach2008genetic,
  author = {Rokach, L.},
  title = {{Genetic algorithm-based feature set partitioning for classification
	problems}},
  journal = {Pattern Recognition},
  year = {2008},
  volume = {41},
  pages = {1676--1700},
  number = {5},
  publisher = {Elsevier}
}

@Article{roli2001methods,
  author    = {Roli, F. and Giacinto, G. and Vernazza, G.},
  title     = {{Methods for designing multiple classifier systems}},
  journal   = {Multiple Classifier Systems},
  year      = {2001},
  pages     = {78--87},
  file      = {roli2001methods.pdf:roli2001methods.pdf:PDF},
  publisher = {Springer},
}

@ARTICLE{saeys2007review,
  author = {Saeys, Y. and Inza, I. and Larra{\~n}aga, P.},
  title = {{A review of feature selection techniques in bioinformatics}},
  journal = {Bioinformatics},
  year = {2007},
  volume = {23},
  pages = {2507},
  number = {19},
  publisher = {Oxford University Press}
}

@Article{segui2010weighted,
  author    = {Segu{\'\i}, S. and Igual, L. and Vitri{\`a}, J.},
  title     = {{Weighted bagging for graph based one-class classifiers}},
  journal   = {Multiple Classifier Systems},
  year      = {2010},
  pages     = {1--10},
  file      = {segui2010weightedbagging.PDF:segui2010weightedbagging.PDF:PDF},
  publisher = {Springer},
}

@ARTICLE{shirai2010bagging,
  author = {Shirai, S. and Kudo, M. and Nakamura, A.},
  title = {{Bagging, Random Subspace Method and Biding}},
  journal = {Structural, Syntactic, and Statistical Pattern Recognition},
  year = {2010},
  pages = {801--810},
  publisher = {Springer}
}

@ARTICLE{skurichinaduin2002bagging,
  author = {Skurichina, M. and Duin, R.P.W.},
  title = {{Bagging, Boosting and the Random Subspace Method for linear classifiers}},
  journal = {Pattern Analysis \& Applications},
  year = {2002},
  volume = {5},
  pages = {121--135},
  number = {2},
  publisher = {Springer}
}

@Article{spinosa2005combining,
  author    = {Spinosa, E.J. and de Carvalho, A.C.},
  title     = {{Combining one-class classifiers for robust novelty detection in gene expression data}},
  journal   = {Advances in Bioinformatics and Computational Biology},
  year      = {2005},
  pages     = {54--64},
  file      = {spinosa2005combining.PDF:spinosa2005combining.PDF:PDF},
  publisher = {Springer},
}

@Article{sun2007improved,
  author    = {Sun, S.},
  title     = {{An improved Random Subspace Method and its application to EEG signal classification}},
  journal   = {Multiple Classifier Systems},
  year      = {2007},
  pages     = {103--112},
  file      = {sun2007improved.PDF:sun2007improved.PDF:PDF},
  publisher = {Springer},
}

@MISC{ddtools2010,
  author = {Tax, D.M.J.},
  title = {{DDtools, the Data Description toolbox for Matlab}},
  year = {2010},
  note = {version 1.7.4}
}

@MISC{ocsets,
  author = {D.M.J. Tax},
  title = {{OC classifier results}},
  year = {2010},
  institution = {Delft University of Technology, the Netherlands},
  url = {http://homepage.tudelft.nl/n9d04/occ/index.html}
}

@PHDTHESIS{tax2001thesis,
  author = {Tax, D.M.J.},
  title = {{One-class classification; Concept-learning in the absence of counter-examples}},
  school = {Delft University of Technology},
  year = {2001},
  month = {June},
  isbn = {90-75691-05-x}
}

@Article{tax2008growing,
  author    = {Tax, D.M.J. and Duin, R.P.W.},
  title     = {{Growing a multi-class classifier with a reject option}},
  journal   = {Pattern Recognition Letters},
  year      = {2008},
  volume    = {29},
  number    = {10},
  pages     = {1565--1570},
  file      = {tax2008growing.PDF:tax2008growing.PDF:PDF},
  publisher = {Elsevier},
}

@ARTICLE{taxduin2001combining,
  author = {Tax, D. and Duin, R.},
  title = {{Combining one-class classifiers}},
  journal = {Multiple Classifier Systems},
  year = {2001},
  pages = {299--308},
  publisher = {Springer}
}

@Article{tsymbal2005diversity,
  author    = {Tsymbal, A. and Pechenizkiy, M. and Cunningham, P.},
  title     = {{Diversity in search strategies for ensemble feature selection}},
  journal   = {Information Fusion},
  year      = {2005},
  volume    = {6},
  number    = {1},
  pages     = {83--98},
  file      = {tsymbal2005diversity.pdf:tsymbal2005diversity.pdf:PDF},
  publisher = {Elsevier},
}

@Article{tsymbal2005sequential,
  author    = {Tsymbal, A. and Pechenizkiy, M. and Cunningham, P.},
  title     = {{Sequential genetic search for ensemble feature selection}},
  journal   = {International Joint Conferences on Artificial Intelligence (IJCAI)},
  year      = {2005},
  file      = {tsymbal2005sequential.pdf:tsymbal2005sequential.pdf:PDF},
  publisher = {Citeseer},
}

@Article{tsymbal2003ensemble,
  author    = {Tsymbal, A. and Puuronen, S. and Patterson, D.W.},
  title     = {{Ensemble feature selection with the simple Bayesian classification}},
  journal   = {Information Fusion},
  year      = {2003},
  volume    = {4},
  number    = {2},
  pages     = {87--100},
  file      = {tsymbal2003ensemble.pdf:tsymbal2003ensemble.pdf:PDF},
  publisher = {Elsevier},
}

@Article{tumer1996error,
  author    = {Tumer, K. and Ghosh, J.},
  title     = {{Error correlation and error reduction in ensemble classifiers}},
  journal   = {Connection Science},
  year      = {1996},
  volume    = {8},
  number    = {3},
  pages     = {385--404},
  file      = {tumer1996error.PDF:tumer1996error.PDF:PDF},
  publisher = {Taylor \& Francis},
}

@Article{valentini2002ensembles,
  author    = {Valentini, G. and Masulli, F.},
  title     = {{Ensembles of learning machines}},
  journal   = {Neural Nets},
  year      = {2002},
  pages     = {3--20},
  file      = {valentini2002ensembles.PDF:valentini2002ensembles.PDF:PDF},
  publisher = {Springer},
}

@Article{villalba2007evaluation,
  author    = {Villalba, S.D. and Cunningham, P.},
  title     = {{An evaluation of dimension reduction techniques for one-class classification}},
  journal   = {Artificial Intelligence Review},
  year      = {2007},
  volume    = {27},
  number    = {4},
  pages     = {273--294},
  file      = {villalba2007evaluation.PDF:villalba2007evaluation.PDF:PDF},
  publisher = {Springer},
}

@Article{zenobi2001using,
  author    = {Zenobi, G. and Cunningham, P.},
  title     = {{Using diversity in preparing ensembles of classifiers based on different feature subsets to minimize generalization error}},
  journal   = {Machine Learning (ECML 2001)},
  year      = {2001},
  pages     = {576--587},
  file      = {zenobi2001using.PDF:zenobi2001using.PDF:PDF},
  publisher = {Springer},
}

@ARTICLE{zhou2002ensembling,
  author = {Zhou, Z.H. and Wu, J. and Tang, W.},
  title = {{Ensembling neural networks: Many could be better than all}},
  journal = {Artificial Intelligence},
  year = {2002},
  volume = {137},
  pages = {239--263},
  number = {1-2},
  publisher = {Elsevier}
}

@Article{zhou2005ensembling,
  author  = {Zhou, Z.H. and Yu, Y.},
  title   = {{Ensembling local learners through multimodal perturbation}},
  journal = {IEEE Transactions on Systems, Man and Cybernetics},
  year    = {2005},
  volume  = {35},
  number  = {4},
  pages   = {725--735},
  file    = {zhou2005ensembling.PDF:zhou2005ensembling.PDF:PDF},
}

@article{salzberg1997comparing,
  title={{On comparing classifiers: Pitfalls to avoid and a recommended approach}},
  author={Salzberg, S.L.},
  journal={Data Mining and Knowledge Discovery},
  volume={1},
  number={3},
  pages={317--328},
  year={1997},
  publisher={Springer}
}

@Article{xu1992methods,
  author  = {Xu, L. and Krzyzak, A. and Suen, C.Y.},
  title   = {{Methods of combining multiple classifiers and their applications to handwriting recognition}},
  journal = {IEEE Transactions on Systems Man and Cybernetics},
  year    = {1992},
  volume  = {22},
  number  = {3},
  pages   = {418--435},
  file    = {xu1992methods.pdf:xu1992methods.pdf:PDF},
}

@article{roli2002design,
  title={{Design of multiple classifier systems}},
  author={Roli, F. and Giacinto, G.},
  journal={Series in Machine Perception and Artificial Intelligence},
  volume={47},
  pages={199--226},
  year={2002},
  publisher={Springer}
}

@Article{wilcoxon1945individual,
  author    = {Wilcoxon, F.},
  title     = {{Individual comparisons by ranking methods}},
  journal   = {Biometrics Bulletin},
  year      = {1945},
  volume    = {1},
  number    = {6},
  pages     = {80--83},
  file      = {wilcoxon1945individual.pdf:wilcoxon1945individual.pdf:PDF},
  publisher = {JSTOR},
}

@phdthesis{nemenyi1963distribution,
  title={{Distribution-free multiple comparisons}},
  author={Nemenyi, P.},
  year={1963},
  school={Princeton}
}

@InCollection{venkataraman2012brain,
  author    = {Venkataraman, Archana and Kubicki, Marek and Golland, Polina},
  title     = {From brain connectivity models to identifying foci of a neurological disorder},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  publisher = {Springer},
  year      = {2012},
  pages     = {715--722},
}

@article{he2010stable,
  title={Stable feature selection for biomarker discovery},
  author={He, Zengyou and Yu, Weichuan},
  journal={Computational biology and chemistry},
  volume={34},
  number={4},
  pages={215--225},
  year={2010},
  publisher={Elsevier}
}

@article{ulacs2011dissimilarity,
  title={Dissimilarity-based detection of schizophrenia},
  author={Ula{\c{s}}, Ayd{\i}n and Duin, Robert PW and Castellani, Umberto and Loog, Marco and Mirtuono, Pasquale and Bicego, Manuele and Murino, Vittorio and Bellani, Marcella and Cerruti, Stefania and Tansella, Michele and others},
  journal={International Journal of Imaging Systems and Technology},
  volume={21},
  number={2},
  pages={179--192},
  year={2011},
  publisher={Wiley Online Library}
}


@article{haynes2006decoding,
  title={Decoding mental states from brain activity in humans},
  author={Haynes, John-Dylan and Rees, Geraint},
  journal={Nature Reviews Neuroscience},
  volume={7},
  number={7},
  pages={523--534},
  year={2006},
  publisher={Nature Publishing Group}
}

@article{baron2009prevalence,
  title={Prevalence of autism-spectrum conditions: UK school-based population study},
  author={Baron-Cohen, Simon and Scott, Fiona J and Allison, Carrie and Williams, Joanna and Bolton, Patrick and Matthews, Fiona E and Brayne, Carol},
  journal={The British Journal of Psychiatry},
  volume={194},
  number={6},
  pages={500--509},
  year={2009},
  publisher={The Royal College of Psychiatrists}
}

@article{courchesne2001unusual,
  title={Unusual brain growth patterns in early life in patients with autistic disorder an MRI study},
  author={Courchesne, Eric and Karns, CM and Davis, HR and Ziccardi, R and Carper, RA and Tigue, ZD and Chisum, HJ and Moses, P and Pierce, K and Lord, C and others},
  journal={Neurology},
  volume={57},
  number={2},
  pages={245--254},
  year={2001},
  publisher={AAN Enterprises}
}



@article{stigler2011structural,
  title={Structural and functional magnetic resonance imaging of autism spectrum disorders},
  author={Stigler, Kimberly A and McDonald, Brenna C and Anand, Amit and Saykin, Andrew J and McDougle, Christopher J},
  journal={Brain research},
  volume={1380},
  pages={146--161},
  year={2011},
  publisher={Elsevier}
}

@InProceedings{varoquaux2013cohort,
  author       = {Varoquaux, Ga{\"e}l and Schwartz, Yannick and Pinel, Philippe and Thirion, Bertrand},
  title        = {Cohort-level brain mapping: learning cognitive atoms to single out specialized regions},
  booktitle    = {Information Processing in Medical Imaging},
  year         = {2013},
  pages        = {438--449},
  organization = {Springer},
  file         = {varoquaux2013cohort.pdf:varoquaux2013cohort.pdf:PDF},
}

@Article{brown2012ucla,
  author    = {Brown, Jesse A and Rudie, Jeffrey D and Bandrowski, Anita and Van Horn, John D and Bookheimer, Susan Y},
  title     = {The UCLA multimodal connectivity database: a web-based platform for brain connectivity matrix sharing and analysis},
  journal   = {Frontiers in neuroinformatics},
  year      = {2012},
  volume    = {6},
  file      = {brown2012ucla.pdf:brown2012ucla.pdf:PDF},
  publisher = {Frontiers Media SA},
}

@article{michel2012supervised,
  title={A supervised clustering approach for fMRI-based inference of brain states},
  author={Michel, Vincent and Gramfort, Alexandre and Varoquaux, Ga{\"e}l and Eger, Evelyn and Keribin, Christine and Thirion, Bertrand},
  journal={Pattern Recognition},
  volume={45},
  number={6},
  pages={2041--2049},
  year={2012},
  publisher={Elsevier}
}

@Article{levy2009autism,
  author    = {Levy, SE and Mandell, DS and Schultz, RT},
  title     = {Autism (vol 374, pg 1627-1628, 2009)},
  journal   = {LANCET},
  year      = {2009},
  volume    = {378},
  number    = {9802},
  pages     = {1546--1546},
  file      = {levy2009autism.pdf:levy2009autism.pdf:PDF},
  publisher = {ELSEVIER SCIENCE INC 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA},
}

@inproceedings{tunccmultinomial,
  title={Multinomial Probabilistic Fiber Representation for Connectivity Driven Clustering},
  author={Tun{\c{c}}, Birkan and Smith, Alex R and Wasserman, Demian and Pennec, Xavier and Wells, William M and Verma, Ragini and Pohl, Kilian M},
  booktitle={Information Processing in Medical Imaging},
  pages={730-741},
  year={2013},
  organization={Springer}
}

@inproceedings{morup2010infinite,
  title={{Infinite relational modeling of functional connectivity in resting state fMRI}},
  author={M{\o}rup, Morten and Madsen, Kristoffer and Dogonowski, Anne-Marie and Siebner, Hartwig and Hansen, Lars K},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1750--1758},
  year={2010}
}

@article{iturria2007characterizing,
  title={{Characterizing brain anatomical connections using diffusion weighted MRI and graph theory}},
  author={Iturria-Medina, Y and Canales-Rodriguez, EJ and Melie-Garcia, L and Valdes-Hernandez, PA and Martinez-Montes, E and Aleman-Gomez, Y and S{\'a}nchez-Bornot, JM},
  journal={Neuroimage},
  volume={36},
  number={3},
  pages={645--660},
  year={2007},
  publisher={Elsevier}
}

@Article{stam2012organization,
  author    = {Stam, CJ and Van Straaten, ECW},
  title     = {The organization of physiological brain networks},
  journal   = {Clinical Neurophysiology},
  year      = {2012},
  volume    = {123},
  number    = {6},
  pages     = {1067--1087},
  file      = {stam2012organization.pdf:stam2012organization.pdf:PDF},
  publisher = {Elsevier},
}

@article{hagmann2007mapping,
  title={{Mapping human whole-brain structural networks with diffusion MRI}},
  author={Hagmann, Patric and Kurant, Maciej and Gigandet, Xavier and Thiran, Patrick and Wedeen, Van J and Meuli, Reto and Thiran, Jean-Philippe},
  journal={PloS one},
  volume={2},
  number={7},
  pages={e597},
  year={2007},
  publisher={Public Library of Science}
}


@article{hagmann2008mapping,
  title={Mapping the structural core of human cerebral cortex},
  author={Hagmann, Patric and Cammoun, Leila and Gigandet, Xavier and Meuli, Reto and Honey, Christopher J and Wedeen, Van J and Sporns, Olaf},
  journal={PLoS biology},
  volume={6},
  number={7},
  pages={e159},
  year={2008},
  publisher={Public Library of Science}
}

@article{azencott2013efficient,
  title={Efficient network-guided multi-locus association mapping with graph cuts},
  author={Azencott, Chlo{\'e}-Agathe and Grimm, Dominik and Sugiyama, Mahito and Kawahara, Yoshinobu and Borgwardt, Karsten M},
  journal={Bioinformatics},
  volume={29},
  number={13},
  pages={i171--i179},
  year={2013},
  publisher={Oxford Univ Press}
}

@article{thoma2010discriminative,
  title={Discriminative frequent subgraph mining with optimality guarantees},
  author={Thoma, Marisa and Cheng, Hong and Gretton, Arthur and Han, Jiawei and Kriegel, Hans-Peter and Smola, Alex and Song, Le and Yu, Philip S and Yan, Xifeng and Borgwardt, Karsten M},
  journal={Statistical Analysis and Data Mining},
  volume={3},
  number={5},
  pages={302--318},
  year={2010},
  publisher={Wiley Online Library}
}

@Article{vishwanathan2010graph,
  author    = {Vishwanathan, SVN and Schraudolph, Nicol N and Kondor, Risi and Borgwardt, Karsten M},
  title     = {Graph kernels},
  journal   = {The Journal of Machine Learning Research},
  year      = {2010},
  volume    = {99},
  pages     = {1201--1242},
  file      = {vishwanathan2010graph.pdf:vishwanathan2010graph.pdf:PDF},
  publisher = {MIT Press},
}

@inproceedings{shervashidze2009fast,
  title={Fast subtree kernels on graphs},
  author={Shervashidze, Nino and Borgwardt, Karsten M},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1660--1668},
  year={2009}
}

@inproceedings{shervashidze2009efficient,
  title={Efficient graphlet kernels for large graph comparison},
  author={Shervashidze, Nino and Petri, Tobias and Mehlhorn, Kurt and Borgwardt, Karsten M and Viswanathan, Svn},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={488--495},
  year={2009}
}

@article{he2008structural,
  title={{Structural insights into aberrant topological patterns of large-scale cortical networks in Alzheimer's disease}},
  author={He, Yong and Chen, Zhang and Evans, Alan},
  journal={The Journal of Neuroscience},
  volume={28},
  number={18},
  pages={4756--4766},
  year={2008},
  publisher={Soc Neuroscience}
}

@article{bassett2008hierarchical,
  title={Hierarchical organization of human cortical networks in health and schizophrenia},
  author={Bassett, Danielle S and Bullmore, Edward and Verchinski, Beth A and Mattay, Venkata S and Weinberger, Daniel R and Meyer-Lindenberg, Andreas},
  journal={The Journal of Neuroscience},
  volume={28},
  number={37},
  pages={9239--9248},
  year={2008},
  publisher={Soc Neuroscience}
}

@inproceedings{brown2011networks,
title={Networks in the Cloud: Web-based Neuroimaging Brain Network Analysis and Data Sharing}, 
author={Jesse Brown, Jeff Rudie, and Susan Bookheimer},
booktitle={Organization for Human Brain Mapping}, 
year = {2011},
url={http://umcd.ccn.ucla.edu}
}

@Article{essen2013hcp,
  author    = {Van Essen, David C and Smith, Stephen M and Barch, Deanna M and Behrens, Timothy EJ and Yacoub, Essa and Ugurbil, Kamil},
  title     = {{The WU-Minn Human Connectome Project: An Overview}},
  journal   = {Neuroimage},
  year      = {2013},
  publisher = {Elsevier},
}

@article{ramsoy2012healthy,
  title={Healthy aging attenuates task-related specialization in the human medial temporal lobe},
  author={Rams{\o}y, Thomas Z and Liptrot, Matthew G and Skimminge, Arnold and Lund, Torben E and Sidaros, Karam and Christensen, Mark Schram and Baar{\'e}, William and Paulson, Olaf B and Jernigan, Terry L and Siebner, Hartwig R},
  journal={Neurobiology of Aging},
  volume={33},
  number={9},
  pages={1874--1889},
  year={2012},
  publisher={Elsevier}
}
  
  @incollection{feragen2012complexity,
  title={Complexity of computing distances between geometric trees},
  author={Feragen, Aasa},
  booktitle={Structural, Syntactic, and Statistical Pattern Recognition},
  pages={89--97},
  year={2012},
  publisher={Springer}
}

@article{bunke1998graph,
  title={A graph distance metric based on the maximal common subgraph},
  author={Bunke, Horst and Shearer, Kim},
  journal={Pattern Recognition Letters},
  volume={19},
  number={3},
  pages={255--259},
  year={1998},
  publisher={Elsevier}
}

@techreport{haussler1999convolution,
  title={Convolution kernels on discrete structures},
  author={Haussler, David},
  year={1999},
  institution={Department of Computer Science, University of California at Santa Cruz}
}

@article{anwander2007connectivity,
  title={Connectivity-based parcellation of Broca's area},
  author={Anwander, Alfred and Tittgemeyer, Marc and von Cramon, D Yves and Friederici, Angela D and Kn{\"o}sche, Thomas R},
  journal={Cerebral Cortex},
  volume={17},
  number={4},
  pages={816--825},
  year={2007},
  publisher={Oxford Univ Press}
}

@article{behrens2003non,
  title={Non-invasive mapping of connections between human thalamus and cortex using diffusion imaging},
  author={Behrens, TEJ and Johansen-Berg, H and Woolrich, MW and Smith, SM and Wheeler-Kingshott, CAM and Boulby, PA and Barker, GJ and Sillery, EL and Sheehan, K and Ciccarelli, O and others},
  journal={Nature Neuroscience},
  volume={6},
  number={7},
  pages={750--757},
  year={2003},
  publisher={Nature Publishing Group}
}

@article{passingham2002anatomical,
  title={The anatomical basis of functional localization in the cortex},
  author={Passingham, Richard E and Stephan, Klaas E and K{\"o}tter, Rolf},
  journal={Nature Reviews Neuroscience},
  volume={3},
  number={8},
  pages={606--616},
  year={2002},
  publisher={Nature Publishing Group}
}


@article{meunier2009age,
  title={Age-related changes in modular organization of human brain functional networks},
  author={Meunier, David and Achard, Sophie and Morcom, Alexa and Bullmore, Ed},
  journal={Neuroimage},
  volume={44},
  number={3},
  pages={715--723},
  year={2009},
  publisher={Elsevier}
}

@article{tuch2002high,
  title={High angular resolution diffusion imaging reveals intravoxel white matter fiber heterogeneity},
  author={Tuch, David S and Reese, Timothy G and Wiegell, Mette R and Makris, Nikos and Belliveau, John W and Wedeen, Van J},
  journal={Magnetic Resonance in Medicine},
  volume={48},
  number={4},
  pages={577--582},
  year={2002},
  publisher={Wiley Online Library}
}

@article{gaser1999detecting,
  title={Detecting structural changes in whole brain based on nonlinear deformations: application to schizophrenia research},
  author={Gaser, Christian and Volz, Hans-Peter and Kiebel, Stefan and Riehemann, Stefan and Sauer, Heinrich},
  journal={Neuroimage},
  volume={10},
  number={2},
  pages={107--113},
  year={1999},
  publisher={Elsevier}
}

@article{braak1991neuropathological,
  title={{Neuropathological stageing of Alzheimer-related changes}},
  author={Braak, H and Braak, E},
  journal={Acta Neuropathologica},
  volume={82},
  number={4},
  pages={239--259},
  year={1991},
  publisher={Springer}
}

@article{raz2005regional,
  title={Regional brain changes in aging healthy adults: general trends, individual differences and modifiers},
  author={Raz, Naftali and Lindenberger, Ulman and Rodrigue, Karen M and Kennedy, Kristen M and Head, Denise and Williamson, Adrienne and Dahle, Cheryl and Gerstorf, Denis and Acker, James D},
  journal={Cerebral Cortex},
  volume={15},
  number={11},
  pages={1676--1689},
  year={2005},
  publisher={Oxford Univ Press}
}

@article{scheltens2002structural,
  title={Structural magnetic resonance imaging in the practical assessment of dementia: beyond exclusion},
  author={Scheltens, Philip and Fox, Nick and Barkhof, Frederik and De Carli, Charles},
  journal={The Lancet Neurology},
  volume={1},
  number={1},
  pages={13--21},
  year={2002},
  publisher={Elsevier}
}

@article{killiany2000use,
  title={{Use of structural magnetic resonance imaging to predict who will get Alzheimer's disease}},
  author={Killiany, Ronald J and Gomez-Isla, Teresa and Moss, Mark and Kikinis, Ron and Sandor, Tamas and Jolesz, Ferenc and Tanzi, Rudolph and Jones, Kenneth and Hyman, Bradley T and Albert, Marilyn S},
  journal={Annals of Neurology},
  volume={47},
  number={4},
  pages={430--439},
  year={2000}
}

@article{raudys1991small,
  title={Small sample size effects in statistical pattern recognition: Recommendations for practitioners},
  author={Raudys, Sarunas J and Jain, Anil K},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={13},
  number={3},
  pages={252--264},
  year={1991}
}

@inproceedings{huang2006sparse,
  title={Sparse representation for signal classification},
  author={Huang, Ke and Aviyente, Selin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={609--616},
  year={2006}
}

@article{li2008network,
  title={Network-constrained regularization and variable selection for analysis of genomic data},
  author={Li, Caiyan and Li, Hongzhe},
  journal={Bioinformatics},
  volume={24},
  number={9},
  pages={1175--1182},
  year={2008},
  publisher={Oxford Univ Press}
}

@Article{alisonnoble2016reflections,
  author   = {Alison Noble, J.},
  title    = {Reflections on ultrasound image analysis},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {33--37},
  abstract = {Ultrasound (US) image analysis has advanced considerably in twenty years. Progress in ultrasound image analysis has always been fundamental to the advancement of image-guided interventions research due to the real-time acquisition capability of ultrasound and this has remained true over the two decades. But in quantitative ultrasound image analysis - which takes US images and turns them into more meaningful clinical information - thinking has perhaps more fundamentally changed. From roots as a poor cousin to Computed Tomography (CT) and Magnetic Resonance (MR) image analysis, both of which have richer anatomical definition and thus were better suited to the earlier eras of medical image analysis which were dominated by model-based methods, ultrasound image analysis has now entered an exciting new era, assisted by advances in machine learning and the growing clinical and commercial interest in employing low-cost portable ultrasound devices outside traditional hospital-based clinical settings. This short article provides a perspective on this change, and highlights some challenges ahead and potential opportunities in ultrasound image analysis which may both have high impact on healthcare delivery worldwide in the future but may also, perhaps, take the subject further away from CT and MR image analysis research with time.},
  doi      = {10.1016/j.media.2016.06.015},
  keywords = {Ultrasound, Ultrasound image analysis},
  url      = {http://dx.doi.org/10.1016/j.media.2016.06.015},
}

@InProceedings{aljundi2015transfer,
  author    = {Aljundi, Rahaf and Lehaire, J??r??me and Prost-Boucle, Fabrice and Rouvi??re, Olivier and Lartizien, Carole},
  title     = {Transfer learning for prostate cancer mapping based on multicentric {MR} imaging databases},
  booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
  year      = {2015},
  volume    = {9487},
  pages     = {74--82},
  publisher = {Springer International Publishing},
  doi       = {10.1007/978-3-319-27929-9_8},
  groups    = {Not-so-supervised papers},
  isbn      = {978-3-319-27928-2},
  keywords  = {Computer-aided detection system, Transfer learning},
  url       = {http://link.springer.com/10.1007/978-3-319-27929-9_8},
}

@Article{alon2009how,
  author   = {Alon, Uri},
  title    = {How {To} {Choose} a {Good} {Scientific} {Problem}},
  journal  = {Molecular Cell},
  year     = {2009},
  volume   = {35},
  number   = {6},
  pages    = {726--728},
  abstract = {Choosing good problems is essential for being a good scientist. But what is a good problem, and how do you choose one? The subject is not usually discussed explicitly within our profession. Scientists are expected to be smart enough to figure it out on their own and through the observation of their teachers. This lack of explicit discussion leaves a vacuum that can lead to approaches such as choosing problems that can give results that merit publication in valued journals, resulting in a job and tenure. ?? 2009 Elsevier Inc. All rights reserved.},
}

@Article{anbeek2004probabilistic,
  author   = {Anbeek, Petronella and Vincken, Koen L. and van Osch, Matthias J.P. and Bisschops, Robertus H.C. and van der Grond, Jeroen},
  title    = {Probabilistic segmentation of white matter lesions in {MR} imaging},
  journal  = {NeuroImage},
  year     = {2004},
  volume   = {21},
  number   = {3},
  pages    = {1037--1044},
  abstract = {A new method has been developed for fully automated segmentation of white matter lesions (WMLs) in cranial MR imaging. The algorithm uses information from T1-weighted (T1-w), inversion recovery (IR), proton density-weighted (PD), T2-weighted (T2-w) and fluid attenuation inversion recovery (FLAIR) scans. It is based on the K-Nearest Neighbor (KNN) classification technique that builds a feature space from voxel intensities and spatial information. The technique generates images representing the probability per voxel being part of a WML. By application of thresholds on these probability maps, binary segmentations can be obtained. ROC curves show that the segmentations achieve both high sensitivity and specificity. A similarity index (SI), overlap fraction (OF) and extra fraction (EF) are calculated for additional quantitative analysis of the result. The SI is also used for determination of the optimal probability threshold for generation of the binary segmentation. Using probabilistic equivalents of the SI, OF and EF, the probability maps can be evaluated directly, providing a powerful tool for comparison of different classification results. This method for automated WML segmentation reaches an accuracy that is comparable to methods for multiple sclerosis (MS) lesion segmentation and is suitable for detection of WMLs in large and longitudinal population studies.},
  doi      = {10.1016/j.neuroimage.2003.10.012},
}

@Article{angermueller2016deep,
  author   = {Angermueller, Christof and Pärnamaa, Tanel and Parts, Leopold and Stegle, Oliver and Albert, FW. and Treusch, S. and Shockley, AH. and Bloom, JS. and Kruglyak, L. and Alipanahi, B. and Delong, A. and Weirauch, MT. and Frey, BJ. and Angermueller, C. and Lee, H. and Reik, W. and Stegle, O. and Asgari, E. and Mofrad, MRK. and Bach, S. and Binder, A. and Montavon, G. and Klauschen, F. and Muller, KR. and Samek, W. and Battle, A. and Khan, Z. and Wang, SH. and Mitrano, A. and Ford, MJ. and Pritchard, JK. and Gilad, Y. and Bell, JT. and Pai, AA. and Pickrell, JK. and Gaffney, DJ. and Pique?Regi, R. and Degner, JF. and Gilad, Y. and Pritchard, JK. and Bengio, Y. and Courville, A. and Vincent, P. and Cheng, C. and Yan, KK. and Yip, KY. and Rozowsky, J. and Alexander, R. and Shou, C. and Gerstein, M. and Deng, L. and Eduati, F. and Mangravite, LM. and Wang, T. and Tang, H. and Bare, JC. and Huang, R. and Norman, T. and Kellen, M. and Menden, MP. and Yang, J. and Zhan, X. and Zhong, R. and Xiao, G. and Xia, M. and Abdo, N. and Kosyk, O. and Collaboration, N?N?UDT. and Friend, S. and Dearry, A. and Simeonov, A. and Eickholt, J. and Cheng, J. and Eickholt, J. and Cheng, J. and Farley, B. and Clark, W. and Gawehn, E. and Hiss, JA. and Schneider, G. and Gibbs, JR. and Brug, MP. van der and Hernandez, DG. and Traynor, BJ. and Nalls, MA. and Lai, S?L. and Arepalli, S. and Dillman, A. and Rafferty, IP. and Troncoso, J. and Grubert, F. and Zaugg, JB. and Kasowski, M. and Ursu, O. and Spacek, DV. and Martin, AR. and Greenside, P. and Srivas, R. and Phanstiel, DH. and Pekowska, A. and Heidari, N. and Euskirchen, G. and Huber, W. and Pritchard, JK. and Bustamante, CD. and Steinmetz, LM. and Kundaje, A. and Snyder, M. and Hastie, T. and Tibshirani, R. and Friedman, J. and Franklin, J. and Hinton, GE. and Salakhutdinov, RR. and Hinton, GE. and Osindero, S. and Teh, Y?W. and Hinton, G. and Deng, L. and Yu, D. and Dahl, GE. and Mohamed, A?R. and Jaitly, N. and Senior, A. and Vanhoucke, V. and Nguyen, P. and Sainath, TN. and Hubel, D. and Wiesel, T. and Hubel, DH. and Wiesel, TN. and Hutter, F. and Hoos, HH. and Leyton?Brown, K. and Kang, HM. and Ye, C. and Eskin, E. and Karlic, R. and Chung, HR. and Lasserre, J. and Vlahovicek, K. and Vingron, M. and Kell, DB. and Kelley, DR. and Snoek, J. and Rinn, J. and Koh, PW. and Pierson, E. and Kundaje, A. and LeCun, Y. and Boser, B. and Denker, JS. and Henderson, D. and Howard, RE. and Hubbard, W. and Jackel, LD. and LeCun, Y. and Bengio, Y. and Hinton, G. and Leung, MKK. and Xiong, HY. and Lee, LJ. and Frey, BJ. and Li, J. and Ching, T. and Huang, S. and Garmire, LX. and Libbrecht, MW. and Noble, WS. and Lyons, J. and Dehzangi, A. and Heffernan, R. and Sharma, A. and Paliwal, K. and Sattar, A. and Zhou, Y. and Yang, Y. and Mamoshina, P. and Vieira, A. and Putin, E. and Zhavoronkov, A. and Märtens, K. and Hallin, J. and Warringer, J. and Liti, G. and Parts, L. and McCulloch, WS. and Pitts, W. and Menden, MP. and Iorio, F. and Garnett, M. and McDermott, U. and Benes, CH. and Ballester, PJ. and Saez?Rodriguez, J. and Montgomery, SB. and Sammeth, M. and Gutierrez?Arcelus, M. and Lach, RP. and Ingle, C. and Nisbett, J. and Guigo, R. and Dermitzakis, ET. and Nesterov, Y. and Ning, F. and Delhomme, D. and LeCun, Y. and Piano, F. and Bottou, L. and Barbano, PE. and Park, Y. and Kellis, M. and Pärnamaa, T. and Parts, L. and Parts, L. and Stegle, O. and Winn, J. and Durbin, R. and Parts, L. and Liu, YC. and Tekkedil, MM. and Steinmetz, LM. and Caudy, AA. and Fraser, AG. and Boone, C. and Andrews, BJ. and Rosebrock, AP. and Pickrell, JK. and Marioni, JC. and Pai, AA. and Degner, JF. and Engelhardt, BE. and Nkadori, E. and Veyrieras, JB. and Stephens, M. and Gilad, Y. and Pritchard, JK. and Rakitsch, B. and Stegle, O. and Rampasek, L. and Goldenberg, A. and Rosenblatt, F. and Rumelhart, DE. and Hinton, GE. and Williams, RJ. and Russakovsky, O. and Deng, J. and Su, H. and Krause, J. and Satheesh, S. and Ma, S. and Huang, Z. and Karpathy, A. and Khosla, A. and Bernstein, M. and Salakhutdinov, R. and Hinton, G. and Schmidhuber, J. and Spencer, M. and Eickholt, J. and Cheng, J. and Srivastava, N. and Hinton, G. and Krizhevsky, A. and Sutskever, I. and Salakhutdinov, R. and Stegle, O. and Parts, L. and Durbin, R. and Winn, J. and Stormo, GD. and Schneider, TD. and Gold, L. and Ehrenfeucht, A. and Swan, AL. and Mobasheri, A. and Allaway, D. and Liddell, S. and Bacardit, J. and Vincent, P. and Larochelle, H. and Lajoie, I. and Bengio, Y. and Manzagol, P?A. and Waszak, SM. and Delaneau, O. and Gschwind, AR. and Kilpinen, H. and Raghav, SK. and Witwicki, RM. and Orioli, A. and Wiederkehr, M. and Panousis, NI. and Yurovsky, A. and Romano?Palumbo, L. and Planchon, A. and Bielser, D. and Padioleau, I. and Udin, G. and Thurnheer, S. and Hacker, D. and Hernandez, N. and Reymond, A. and Deplancke, B. and Xiong, HY. and Alipanahi, B. and Lee, LJ. and Bretschneider, H. and Merico, D. and Yuen, RKC. and Hua, Y. and Gueroussov, S. and Najafabadi, HS. and Hughes, TR. and Morris, Q. and Barash, Y. and Krainer, AR. and Jojic, N. and Scherer, SW. and Blencowe, BJ. and Frey, BJ. and Xu, R. and Wunsch, D. and Frank, R. and Zhou, J. and Troyanskaya, OG.},
  title    = {Deep learning for computational biology},
  journal  = {Molecular Systems Biology},
  year     = {2016},
  volume   = {12},
  number   = {7},
  pages    = {878--878},
  month    = jul,
  abstract = {Technological advances in genomics and imaging have led to an explosion of molecular and cellular profiling data from large numbers of samples. This rapid increase in biological data dimension and acquisition rate is challenging conventional analysis strategies. Modern machine learning methods, such as deep learning, promise to leverage very large data sets for finding hidden structure within them, and for making accurate predictions. In this review, we discuss applications of this new breed of analysis approaches in regulatory genomics and cellular imaging. We provide background of what deep learning is, and the settings in which it can be successfully applied to derive biological insights. In addition to presenting specific applications and providing tips for practical use, we also highlight possible pitfalls and limitations to guide computational biologists when and how to make the most use of this new technology.

Mol Syst Biol. (2016) 12: 878},
  doi      = {10.15252/msb.20156651},
  url      = {http://msb.embopress.org/lookup/doi/10.15252/msb.20156651},
}

@InProceedings{antony2016quantifying,
  author    = {Antony, Joseph and McGuinness, Kevin and Connor, Noel E O and Moran, Kieran},
  title     = {Quantifying Radiographic Knee Osteoarthritis Severity using Deep Convolutional Neural Networks},
  booktitle = {International Conference on Pattern Recognition (ICPR)},
  year      = {2016},
  abstract  = {This paper proposes a new approach to automatically quantify the severity of knee osteoarthritis (OA) from radiographs using deep convolutional neural networks (CNN). Clinically, knee OA severity is assessed using Kellgren {\textbackslash}\& Lawrence (KL) grades, a five point scale. Previous work on automatically predicting KL grades from radiograph images were based on training shallow classifiers using a variety of hand engineered features. We demonstrate that classification accuracy can be significantly improved using deep convolutional neural network models pre-trained on ImageNet and fine-tuned on knee OA images. Furthermore, we argue that it is more appropriate to assess the accuracy of automatic knee OA severity predictions using a continuous distance-based evaluation metric like mean squared error than it is to use classification accuracy. This leads to the formulation of the prediction of KL grades as a regression problem and further improves accuracy. Results on a dataset of X-ray images and KL grades from the Osteoarthritis Initiative (OAI) show a sizable improvement over the current state-of-the-art.},
  groups    = {Not-so-supervised papers},
  url2      = {http://arxiv.org/abs/1609.02469},
}

@Article{aridhi2015prediction,
  author   = {Aridhi, Sabeur and Sghaier, Haïtham and Zoghlami, Manel and Maddouri, Mondher and Nguifo, Engelbert Mephu},
  title    = {Prediction of {Ionizing} {Radiation} {Resistance} in {Bacteria} {Using} a {Multiple} {Instance} {Learning} {Model}.},
  journal  = {Journal of computational biology : a journal of computational molecular cell biology},
  year     = {2015},
  volume   = {22},
  number   = {00},
  pages    = {1--11},
  abstract = {Ionizing-radiation-resistant bacteria (IRRB) are important in biotechnology. In this context, in silico methods of phenotypic prediction and genotype-phenotype relationship discovery are limited. In this work, we analyzed basal DNA repair proteins of most known proteome sequences of IRRB and ionizing-radiation-sensitive bacteria (IRSB) in order to learn a classifier that correctly predicts this bacterial phenotype. We formulated the problem of predicting bacterial ionizing radiation resistance (IRR) as a multiple-instance learning (MIL) problem, and we proposed a novel approach for this purpose. We provide a MIL-based prediction system that classifies a bacterium to either IRRB or IRSB. The experimental results of the proposed system are satisfactory with 91.5\% of successful predictions.},
  doi      = {10.1089/cmb.2015.0134},
  file     = {aridhi2015prediction.pdf:aridhi2015prediction.pdf:PDF},
  groups   = {Not-so-supervised papers},
  keywords = {bacterial ionizing radiation resistance, multiple instance learning, prediction},
  url      = {http://www.ncbi.nlm.nih.gov/pubmed/26484752},
}

@Article{artan2013cross,
  author   = {Artan, Yusuf and Oto, Aytekin and Yetik, Imam Samil},
  title    = {Cross-device automated prostate cancer localization with multiparametric {MRI}},
  journal  = {IEEE Transactions on Image Processing},
  year     = {2013},
  volume   = {22},
  number   = {12},
  pages    = {5385--5394},
  month    = dec,
  issn     = {9781424441198},
  abstract = {Prostate cancer localization using supervised classification techniques has aroused considerable interest in medical imaging community in recent years. However, it is crucial to have an accurate training data set for supervised classification techniques. Since different devices with, e.g., different protocols and/or field strengths cause different intensity profiles, each device/protocol must have an accompanying training data set, which is very costly to obtain. It is highly desirable to adapt the existing classifier(s) trained for one device/protocol to help classify data coming from another device/protocol. In this paper, we propose a novel method that has the ability to design classifiers obtained from one imaging protocol and/or MRI device to be used on a data set from another protocol and/or imaging device. As an example problem, we consider prostate cancer localization with multiparametric MRI. We show that simple normalization techniques such as z-score are not sufficient for cross-device automated cancer localization. On the other hand, the method we have originally developed based on relative intensity allows us to successfully use a classifier obtained from one device to be applied on a test patient imaged with another device. Proposed method also allows us to employ T2-weighted MR images directly instead of an additional step to normalize T2-weighted images usually performed in an ad hoc manner when T2 maps are not available. To demonstrate the effectiveness of the proposed method, we use a multiparametric MRI data set acquired from 18 biopsy-confirmed cancer patients with two separate scanners: 1) 1.5-T (Excite HD) GE and 2) 1.5-T (Achieva) Philips Healthcare scanners. A comprehensive visual, quantitative, and statistical analysis of the results show that methods we have developed allow us to: 1) perform cross-device automated classification and 2) use T2-weighted images without an ad hoc subject-specific normalization.},
  doi      = {10.1109/TIP.2013.2285626},
  groups   = {Not-so-supervised papers},
  keywords = {Discriminant analysis, Intensity normalization, Magnetic resonance imaging (MRI), Prostate cancer},
  url      = {http://www.ncbi.nlm.nih.gov/pubmed/24236301},
}

@Article{azmi2011impst,
  author   = {Azmi, Reza and Norozi, Narges and Anbiaee, Robab and Salehi, Leila and Amirzadi, Azardokht},
  title    = {{IMPST}: {A} {New} {Interactive} {Self}-{Training} {Approach} to {Segmentation} {Suspicious} {Lesions} in {Breast} {MRI}.},
  journal  = {Journal of medical signals and sensors},
  year     = {2011},
  volume   = {1},
  number   = {2},
  pages    = {138--148},
  month    = may,
  abstract = {Breast lesion segmentation in magnetic resonance (MR) images is one of the most important parts of clinical diagnostic tools. Pixel classification methods have been frequently used in image segmentation with two supervised and unsupervised approaches up to now. Supervised segmentation methods lead to high accuracy, but they need a large amount of labeled data, which is hard, expensive, and slow to be obtained. On the other hand, unsupervised segmentation methods need no prior knowledge and lead to low performance. However, semi-supervised learning which uses not only a few labeled data, but also a large amount of unlabeled data promises higher accuracy with less effort. In this paper, we propose a new interactive semi-supervised approach to segmentation of suspicious lesions in breast MRI. Using a suitable classifier in this approach has an important role in its performance; in this paper, we present a semi-supervised algorithm improved self-training (IMPST) which is an improved version of self-training method and increase segmentation accuracy. Experimental results show that performance of segmentation in this approach is higher than supervised and unsupervised methods such as K nearest neighbors, Bayesian, Support Vector Machine, and Fuzzy c-Means.},
  language = {eng},
}

@Article{azmi2013ensemble,
  author   = {Azmi, Reza and Pishgoo, Boshra and Norozi, Narges and Yeganeh, Samira},
  title    = {Ensemble {Semi}-supervised {Frame}-work for {Brain} {Magnetic} {Resonance} {Imaging} {Tissue} {Segmentation}.},
  journal  = {Journal of medical signals and sensors},
  year     = {2013},
  volume   = {3},
  number   = {2},
  pages    = {94--106},
  month    = apr,
  abstract = {Brain magnetic resonance images (MRIs) tissue segmentation is one of the most important parts of the clinical diagnostic tools. Pixel classification methods have been frequently used in the image segmentation with two supervised and unsupervised approaches up to now. Supervised segmentation methods lead to high accuracy, but they need a large amount of labeled data, which is hard, expensive, and slow to obtain. Moreover, they cannot use unlabeled data to train classifiers. On the other hand, unsupervised segmentation methods have no prior knowledge and lead to low level of performance. However, semi-supervised learning which uses a few labeled data together with a large amount of unlabeled data causes higher accuracy with less trouble. In this paper, we propose an ensemble semi-supervised frame-work for segmenting of brain magnetic resonance imaging (MRI) tissues that it has been used results of several semi-supervised classifiers simultaneously. Selecting appropriate classifiers has a significant role in the performance of this frame-work. Hence, in this paper, we present two semi-supervised algorithms expectation filtering maximization and MCo\_Training that are improved versions of semi-supervised methods expectation maximization and Co\_Training and increase segmentation accuracy. Afterward, we use these improved classifiers together with graph-based semi-supervised classifier as components of the ensemble frame-work. Experimental results show that performance of segmentation in this approach is higher than both supervised methods and the individual semi-supervised classifiers.},
  language = {eng},
}

@Article{balcan2006kernels,
  author  = {Balcan, Maria-Florina and Blum, Avrim and Vempala, Santosh},
  title   = {Kernels as features: {On} kernels, margins, and low-dimensional mappings},
  journal = {Machine Learning},
  year    = {2006},
  volume  = {65},
  number  = {1},
  pages   = {79--94},
  month   = oct,
  doi     = {10.1007/s10994-006-7550-1},
  url     = {http://link.springer.com/10.1007/s10994-006-7550-1},
}

@Article{bandyopadhyay2015mbstar,
  author   = {Bandyopadhyay, Sanghamitra and Ghosh, Dip and Mitra, Ramkrishna and Zhao, Zhongming},
  title    = {{MBSTAR}: multiple instance learning for predicting specific functional binding sites in {microRNA} targets.},
  journal  = {Scientific reports},
  year     = {2015},
  volume   = {5},
  pages    = {8004--8004},
  month    = jan,
  abstract = {MicroRNA (miRNA) regulates gene expression by binding to specific sites in the 3'untranslated regions of its target genes. Machine learning based miRNA target prediction algorithms first extract a set of features from potential binding sites (PBSs) in the mRNA and then train a classifier to distinguish targets from non-targets. However, they do not consider whether the PBSs are functional or not, and consequently result in high false positive rates. This substantially affects the follow up functional validation by experiments. We present a novel machine learning based approach, MBSTAR (Multiple instance learning of Binding Sites of miRNA TARgets), for accurate prediction of true or functional miRNA binding sites. Multiple instance learning framework is adopted to handle the lack of information about the actual binding sites in the target mRNAs. Biologically validated 9531 interacting and 973 non-interacting miRNA-mRNA pairs are identified from Tarbase 6.0 and confirmed with PAR-CLIP dataset. It is found that MBSTAR achieves the highest number of binding sites overlapping with PAR-CLIP with maximum F-Score of 0.337. Compared to the other methods, MBSTAR also predicts target mRNAs with highest accuracy. The tool and genome wide predictions are available at http://www.isical.ac.in/{\textasciitilde}bioinfo\_miu/MBStar30.htm.},
  doi      = {10.1038/srep08004},
  language = {en},
  url      = {http://www.nature.com/srep/2015/150123/srep08004/full/srep08004.html},
}

@Article{barillot2016imaging,
  author   = {Barillot, Christian and Edan, Gilles and Commowick, Olivier},
  title    = {Imaging biomarkers in multiple {Sclerosis}: {From} image analysis to population imaging},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {134--139},
  abstract = {The production of imaging data in medicine increases more rapidly than the capacity of computing models to extract information from it. The grand challenges of better understanding the brain, offering better care for neurological disorders, and stimulating new drug design will not be achieved without significant advances in computational neuroscience. The road to success is to develop a new, generic, computational methodology and to confront and validate this methodology on relevant diseases with adapted computational infrastructures. This new concept sustains the need to build new research paradigms to better understand the natural history of the pathology at the early phase; to better aggregate data that will provide the most complete representation of the pathology in order to better correlate imaging with other relevant features such as clinical, biological or genetic data. In this context, one of the major challenges of neuroimaging in clinical neurosciences is to detect quantitative signs of pathological evolution as early as possible to prevent disease progression, evaluate therapeutic protocols or even better understand and model the natural history of a given neurological pathology. Many diseases encompass brain alterations often not visible on conventional MRI sequences, especially in normal appearing brain tissues (NABT). MRI has often a low specificity for differentiating between possible pathological changes which could help in discriminating between the different pathological stages or grades. The objective of medical image analysis procedures is to define new quantitative neuroimaging biomarkers to track the evolution of the pathology at different levels. This paper illustrates this issue in one acute neuro???inflammatory pathology: Multiple Sclerosis (MS). It exhibits the current medical image analysis approaches and explains how this field of research will evolve in the next decade to integrate larger scale of information at the temporal, cellular, structural and morphological levels.},
  doi      = {10.1016/j.media.2016.06.017},
  keywords = {Diffusion MRI, Imaging biomarkers, Medical image analysis, MRI, Multiple sclerosis, Segmentation},
  url      = {http://dx.doi.org/10.1016/j.media.2016.06.017},
}

@Article{barrington2012correction,
  author  = {Barrington, Luke and Turnbull, Douglas and Lanckriet, Gert},
  title   = {Correction for {Barrington} et al., {Game}-powered machine learning},
  journal = {Proceedings of the National Academy of Sciences},
  year    = {2012},
  volume  = {109},
  number  = {22},
  pages   = {8786--8786},
  doi     = {10.1073/pnas.1205806109},
}

@Article{baumgartner2015self,
  author   = {{Baumgartner}},
  title    = {Self-{Aligning} {Manifolds} for {Matching} {Disparate} {Medical} {Image} {Datasets} {Christian}},
  journal  = {Information processing in medical imaging : IPMI 2015},
  year     = {2015},
  volume   = {9123},
  pages    = {179--190},
  issn     = {978-3-319-19991-7},
  doi      = {10.1007/978-3-319-19992-4},
  file     = {baumgartner2015selfaligning.pdf:baumgartner2015selfaligning.pdf:PDF},
  keywords = {biomimetic phan-, coaxial electrospraying, core, di ff usion mri, shell microspheres, toms, tumour microstructure},
  url      = {http://link.springer.com/10.1007/978-3-319-19992-4},
}

@Article{becker2014domain,
  author   = {Becker, Carlos and Christoudias, Mario and Fua, Pascal and Christoudias, C. Mario and Fua, Pascal},
  title    = {Domain {Adaptation} for {Microscopy} {Imaging}},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2014},
  volume   = {34},
  number   = {c},
  pages    = {1--14},
  doi2     = {10.1109/TMI.2014.2376872},
  file     = {becker2014domain.pdf:becker2014domain.pdf:PDF},
  groups   = {Not-so-supervised papers},
  keywords = {3D data volumes, AdaBoost, annotation process, biomedical optical imaging, Boosting, classifier, domain adaptation, domain adaptation algorithm, electron and light microscopy, Electron microscopy, electron microscopy imaging, high-dimensional feature spaces, high-quality image stacks, human annotation effort, image modalities, learning (artificial intelligence), light microscopy imaging, machine learning, machine learning algorithms, medical image processing, microscopy datasets, neural structures, neurophysiology, nonlinear image feature transformations, optical microscopy, Regression tree analysis, Three-dimensional displays, Training, Training data, Transfer learning},
  url2     = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6971126},
}

@Article{ben-david2008notion,
  author   = {Ben-David, Shai and Schuller Borbely, Reba},
  title    = {A {Notion} of {Task} {Relatedness} {Yielding} {Provable} {Multiple}-{Task} {Learning} {Guarantees}},
  year     = {2008},
  abstract = {The approach of learning of multiple " related " tasks simultaneously has proven quite successful in practice; however, theoretical justification for this success has remained elusive. The starting point for previous work on multiple task learning has been that the tasks to be learned jointly are somehow " algorithmically related " , in the sense that the results of applying a specific learning algorithm to these tasks are assumed to be similar. We offer an alternative approach, defining relatedness of tasks on the basis of similarity between the example generating distributions that underlie these tasks. We provide a formal framework for this notion of task relatedness, which captures a sub-domain of the wide scope of issues in which one may apply a multiple task learning approach. Our notion of task similarity is relevant to a variety of real life multitask learning scenarios and allows the formal derivation of generalization bounds that are strictly stronger than the previously known bounds for both the learning-to-learn and the multitask learning scenarios. We give precise conditions under which our bounds guarantee generalization on the basis of smaller sample sizes than the standard single-task approach 3 .},
}

@Article{bendels2016gendermetricsnet,
  author   = {Bendels, Michael H. K. and Brüggmann, Dörthe and Schöffel, Norman and Groneberg, David A. and Akhabue, E and Lautenbach, E and Bates, T and Ani?, A and Marusi?, M and Marusi?, A and Boyle, PJ and Smith, LK and Cooper, NJ and Williams, KS and O?Connor, H and Brüggmann, D and Handl, V and Klingelhöfer, D and Jaque, J and Groneberg, DA and Buitendijk, S and Corda, D and Flodström, A and Holdcroft, A and Hunter, J and Pollitzer, E and Falagas, ME and Flannery, AM and Grauwin, S and Jensen, P and Larivière, V and Ni, C and Gingras, Y and Cronin, B and Sugimoto, CR and Leslie, S-J and Cimpian, A and Meyer, M and Freeland, E and Sander, J and Ester, M and Kriegel, H-P and Xu, X and Schöffel, N and Kirchdörfer, M and Brüggmann, D and Bundschuh, M and Ohlendorf, D and Groneberg, D and Bendels, M and Sillet, A and Tesch, BJ and Wood, HM and Helwig, AL and Nattinger, AB and Urry, M and Eck, Null and Jan, N and Waltman, L and Eck, Null and Jan, N and Waltman, L and Zhuge, Y and Kaufman, J and Simeone, DM and Chen, H and Velazquez, OC},
  title    = {Gendermetrics.{NET}: a novel software for analyzing the gender representation in scientific authoring},
  journal  = {Journal of Occupational Medicine and Toxicology},
  year     = {2016},
  volume   = {11},
  number   = {1},
  pages    = {43--43},
  month    = dec,
  abstract = {Imbalances in female career promotion are believed to be strong in the field of academic science. A primary parameter to analyze gender inequalities is the gender authoring in scientific publications. Since the presently available data on gender distribution is largely limited to underpowered studies, we here develop a new approach to analyze authors? genders in large bibliometric databases. A SQL-Server based multiuser software suite was developed that serves as an integrative tool for analyzing bibliometric data with a special emphasis on gender and topographical analysis. The presented system allows seamless integration, inspection, modification, evaluation and visualization of bibliometric data. By providing an adaptive and almost fully automatic integration and analysis process, the inter-individual variability of analysis is kept at a low level. Depending on the scientific question, the system enables the user to perform a scientometric analysis including its visualization within a short period of time. In summary, a new software suite for analyzing gender representations in scientific articles was established. The system is suitable for the comparative analysis of scientific structures on the level of continents, countries, cities, city regions, institutions, research fields and journals.},
  doi      = {10.1186/s12995-016-0133-6},
  keywords = {Occupational Medicine/Industrial Medicine, Pharmacology/Toxicology, Public Health},
  url      = {http://occup-med.biomedcentral.com/articles/10.1186/s12995-016-0133-6},
}

@Article{blitzer2006domain,
  author = {Blitzer, John},
  title  = {Domain {Adaptation} with {Structural} {Correspondence} {Learning}},
  year   = {2006},
  number = {July},
  pages  = {120--128},
  file   = {blitzer2006domain.pdf:blitzer2006domain.pdf:PDF},
}

@InProceedings{boiman2008defense,
  author    = {Boiman, Oren and Shechtman, Eli and Irani, Michal},
  title     = {In defense of nearest-neighbor based image classification},
  booktitle = {26th {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}, {CVPR}},
  year      = {2008},
  pages     = {1--8},
  month     = jun,
  publisher = {IEEE},
  abstract  = {State-of-the-art image classification methods require an intensive learning/training stage (using SVM, Boosting, etc.) In contrast, non-parametric nearest-neighbor (NN) based image classifiers require no training time and have other favorable properties. However, the large performance gap between these two families of approaches rendered NN-based image classifiers useless. We claim that the effectiveness of non-parametric NN-based image classification has been considerably undervalued. We argue that two practices commonly used in image classification methods, have led to the inferior performance of NN-based image classifiers: (i) Quantization of local image descriptors (used to generate "bags-of-words ", codebooks). (ii) Computation of 'image-to-image' distance, instead of 'image-to-class' distance. We propose a trivial NN-based classifier - NBNN, (Naive-Bayes nearest-neighbor), which employs NN- distances in the space of the local image descriptors (and not in the space of images). NBNN computes direct 'image- to-class' distances without descriptor quantization. We further show that under the Naive-Bayes assumption, the theoretically optimal image classifier can be accurately approximated by NBNN. Although NBNN is extremely simple, efficient, and requires no learning/training phase, its performance ranks among the top leading learning-based image classifiers. Empirical comparisons are shown on several challenging databases (Caltech-101 ,Caltech-256 and Graz-01).},
  doi       = {10.1109/CVPR.2008.4587598},
  isbn      = {978-1-4244-2243-2},
  keywords  = {Boosting, Classification tree analysis, data compression, Degradation, image classification, image coding, Image databases, image-to-class distance, image-to-image distance, local image descriptors quantization, nearest-neighbor based image classification, Neural networks, nonparametric based image classifiers, nonparametric statistics, Quantization, Rendering (computer graphics), Support vector machine classification, Support vector machines},
  url       = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4587598},
}

@Article{bonney2014next,
  author  = {Bonney, Rick and Shirk, Jennifer L. and Phillips, Tina B. and Wiggins, Andrea and Ballard, Heidi L. and Miller-Rushing, Abraham J. and Parrish, Julia K.},
  title   = {Next {Steps} for {Citizen} {Science}},
  journal = {Science},
  year    = {2014},
  volume  = {343},
  number  = {6178},
}

@Article{borkinevaluation,
  author   = {Borkin, Michelle A and Gajos, Krzysztof Z and Peters, Amanda and Mitsouras, Dimitrios and Melchionna, Simone and Rybicki, Frank J and Feldman, Charles L and Pfister, Hanspeter},
  title    = {Evaluation of {Artery} {Visualizations} for {Heart} {Disease} {Diagnosis}},
  abstract = {Fig. 1. Left: Traditional 2D projection (A) of a single artery, and 3D representation (C) of a right coronary artery tree with a rainbow color map. Right: 2D tree diagram representation (B) and equivalent 3D representation (D) of a left coronary artery tree with a diverging color map. Abstract? Heart disease is the number one killer in the United States, and finding indicators of the disease at an early stage is critical for treatment and prevention. In this paper we evaluate visualization techniques that enable the diagnosis of coronary artery disease. A key physical quantity of medical interest is endothelial shear stress (ESS). Low ESS has been associated with sites of lesion formation and rapid progression of disease in the coronary arteries. Having effective visualizations of a patient's ESS data is vital for the quick and thorough non-invasive evaluation by a cardiologist. We present a task taxonomy for hemodynamics based on a formative user study with domain experts. Based on the results of this study we developed HemoVis, an interactive visualization application for heart disease diagnosis that uses a novel 2D tree diagram representation of coronary artery trees. We present the results of a formal quantitative user study with domain experts that evaluates the effect of 2D versus 3D artery representations and of color maps on identifying regions of low ESS. We show statistically significant results demonstrating that our 2D visualizations are more accurate and efficient than 3D representations, and that a perceptually appropriate color map leads to fewer diagnostic mistakes than a rainbow color map.},
  keywords = {biomedical and medical visualization, Index Terms?Quantitative evaluation, qualitative evaluation},
}

@Article{bradlow2010perceptual,
  author   = {Bradlow, Ann and Clopper, Cynthia and Smiljanic, Rajka and Walter, Mary Ann},
  title    = {A perceptual phonetic similarity space for languages: {Evidence} from five native language listener groups},
  journal  = {Speech Communication},
  year     = {2010},
  volume   = {52},
  number   = {11},
  pages    = {930--942},
  abstract = {The goal of the present study was to devise a means of representing languages in a perceptual similarity space based on their overall phonetic similarity. In Experiment 1, native English listeners performed a free classification task in which they grouped 17 diverse languages based on their perceived phonetic similarity. A similarity matrix of the grouping patterns was then submitted to clustering and multidimensional scaling analyses. In Experiment 2, an independent group of native English listeners sorted the group of 17 languages in terms of their distance from English. Experiment 3 repeated Experiment 2 with four groups of non-native English listeners: Dutch, Mandarin, Turkish and Korean listeners. Taken together, the results of these three experiments represent a step towards establishing an approach to assess the overall phonetic similarity of languages. This approach could potentially provide the basis for developing predictions regarding foreign-accented speech intelligibility for various listener groups, and regarding speech perception accuracy in the context of background noise in various languages.},
  doi      = {10.1016/j.specom.2010.06.003},
  file     = {bradlow2010perceptual.pdf:bradlow2010perceptual.pdf:PDF},
}

@Article{brady2016oncological,
  author   = {Brady, Sir Michael and Highnam, Ralph and Irving, Benjamin and Schnabel, Julia A.},
  title    = {Oncological image analysis},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {7--12},
  abstract = {Cancer is one of the world's major healthcare challenges and, as such, an important application of medical image analysis. After a brief introduction to cancer, we summarise some of the major developments in oncological image analysis over the past 20 years, but concentrating those in the authors??? laboratories, and then outline opportunities and challenges for the next decade.},
  doi      = {10.1016/j.media.2016.06.012},
  keywords = {Angiogenesis, Cancer, Mammography, Molecular imaging, Radiotherapy},
}

@Article{brazdil2003ranking,
  author   = {Brazdil, Pavel B},
  title    = {Ranking {Learning} {Algorithms}: {Using} {IBL} and {Meta}-{Learning} on {Accuracy} and {Time} {Results}},
  journal  = {Machine Learning},
  year     = {2003},
  volume   = {50},
  pages    = {251--277},
  abstract = {We present a meta-learning method to support selection of candidate learning algorithms. It uses a k-Nearest Neighbor algorithm to identify the datasets that are most similar to the one at hand. The distance between datasets is assessed using a relatively small set of data characteristics, which was selected to represent properties that affect algorithm performance. The performance of the candidate algorithms on those datasets is used to generate a recommendation to the user in the form of a ranking. The performance is assessed using a multicriteria evaluation measure that takes not only accuracy, but also time into account. As it is not common in Machine Learning to work with rankings, we had to identify and adapt existing statistical techniques to devise an appropriate evaluation methodology. Using that methodology, we show that the meta-learning method presented leads to significantly better rankings than the baseline ranking method. The evaluation methodology is general and can be adapted to other ranking problems. Although here we have concentrated on ranking classification algorithms, the meta-learning framework presented can provide assistance in the selection of combinations of methods or more complex problem solving strategies.},
  keywords = {algorithm recommendation, data characterization, meta-learning, ranking},
}

@Article{breda2016teaching,
  author   = {Breda, Thomas and Hillion, Mélina and Sheltzer, J. M. and Smith, J. C. and Foschi, M. and Lai, L. and Sigerson, K. and Steinpreis, R. and Anders, K. and Ritzke, D. and Swim, J. and Borgida, E. and Maruyama, G. and Myers, D. G. and Moss-Racusin, C. A. and Dovidio, J. F. and Brescoll, V. L. and Graham, M. J. and Handelsman, J. and Reuben, E. and Sapienza, P. and Zingales, L. and Ceci, S. J. and Williams, W. M. and Ceci, S. J. and Ginther, D. K. and Kahn, S. and Williams, W. M. and Williams, W. M. and Ceci, S. J. and Wolfinger, N. H. and Mason, M. A. and Goulden, M. and Glass, C. and Minnotte, K. and Irvine, A. D. and Breda, T. and Ly, S. T. and Leslie, S. J. and Cimpian, A. and Meyer, M. and Freeland, E. and Eagly, A. H. and Spelke, E. S. and Hyde, J. S. and Fryer, R. G. and Heilman, M. and Martell, R. and Simon, M. and Koch, A. J. and D?Mello, S. D. and Sackett, P. R. and Goldin, C. and Rouse, C. and Lavy, V. and Ladd, H. F. and Walsh, R. P. and Spencer, S. J. and Steele, C. M. and Quinn, D. M. and Fryer, R. G. and Levitt, S. D. and List, J. A.},
  title    = {Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in {France}},
  journal  = {Science},
  year     = {2016},
  volume   = {353},
  number   = {6298},
  pages    = {326--339},
  abstract = {In many professions, getting ahead requires evidence of both effort and ability. This is especially true if one is not a member of the dominant group and thus surmounting social norms. Breda and Hillion show that oral examiners of candidates for teaching positions in the French education system reward such applicants. Specifically, women applying for high-level teaching positions in male-dominated fields, such as physics and philosophy, are favored, as are men who apply in female-dominated fields, such as literature and foreign languages.{\textbackslash}n{\textbackslash}nScience , this issue p. [474][1]{\textbackslash}n{\textbackslash}n [1]: /lookup/doi/10.1126/science.aaf4372},
  doi      = {10.1126/science.aaf4372},
}

@Article{brin1995neighbor,
  author   = {Brin, S.},
  title    = {Near {Neighbor} {Search} in {Large} {Metric} {Spaces}},
  year     = {1995},
  abstract = {Given user data, one often wants to find approximate matches in a large database. A good example of such a task is finding images similar to a given image in a large collection of images. We focus on the important and technically diffcult case where each data element is high dimensional, or more generally, is represented by a point in a large metric spaceand distance calculations are computationally expensive. In this paper we introduce a data structure to solve this problem called a GNAT \{\vphantom{\}} Geometric Near-neighbor Access Tree. It is based on the philosophy that the data structure should act as a hierarchical geometrical model of the data as opposed to a simple decomposition of the data that does not use its intrinsic geometry. In experiments, we find that GNAT's outperform previous data structures in a number of applications. Keywords \{\vphantom{\}} near neighbor, metric space, approximate queries, data mining, Dirichlet domains, Voronoi regions},
  keywords = {Databases and the Web},
}

@Article{bruijne2016learning,
  author = {Bruijne, Marleen De},
  title  = {Learning imaging biomarkers : challenges and pitfalls {What} is a biomarker and why do we need one ?},
  year   = {2016},
}

@Article{bruijne2016far,
  author = {Bruijne, Marleen De},
  title  = {So far : standard supervised learning},
  year   = {2016},
}

@Article{burghouts2008distribution,
  author = {Burghouts, Gertjan and Smeulders, Arnold and Geusebroek, Jan-mark},
  title  = {The {Distribution} {Family} of {Similarity} {Distances}},
  year   = {2008},
  pages  = {201--208},
}

@InProceedings{burner2012texture,
  author    = {Burner, Andreas and Donner, René and Mayerhoefer, Marius and Holzer, Markus and Kainberger, Franz and Langs, Georg},
  title     = {Texture bags: {Anomaly} retrieval in medical images based on local 3D-texture similarity},
  booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
  year      = {2012},
  volume    = {7075 LNCS},
  pages     = {116--127},
  abstract  = {Providing efficient access to the huge amounts of existing medical imaging data is a highly relevant but challenging problem. In this paper, we present an effective method for content-based image retrieval (CBIR) of anomalies in medical imaging data, based on similarity of local 3D texture. During learning, a texture vocabulary is obtained from training data in an unsupervised fashion by extracting the dominant structure of texture descriptors. It is based on a 3D extension of the Local Binary Pattern operator (LBP), and captures texture properties via descriptor histograms of supervoxels, or texture bags. For retrieval, our method computes a texture histogram of a query region marked by a physician, and searches for similar bags via diffusion distance. The retrieval result is a ranked list of cases based on the occurrence of regions with similar local texture structure. Experiments show that the proposed local texture retrieval approach outperforms analogous global similarity measures. © 2012 Springer-Verlag.},
  doi       = {10.1007/978-3-642-28460-1_11},
  isbn      = {978-3-642-28459-5},
  keywords  = {Content-based medical image retrieval (CBIR), emphysema disease, feature extraction, high-resolution CT (HRCT), Local Binary Pattern (LBP), localized features, texture analysis, unsupervised texture learning},
}

@Article{cabral2015matrix,
  author   = {Cabral, Ricardo and De La Torre, Fernando and Costeira, João Paulo and Bernardino, Alexandre},
  title    = {Matrix completion for weakly-supervised multi-label image classification},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year     = {2015},
  volume   = {37},
  number   = {1},
  pages    = {121--135},
  issn     = {9781618395993},
  abstract = {In the last few years, image classification has become an incredibly active research topic, with widespread applications. Most methods for visual recognition are fully supervised, as they make use of bounding boxes or pixelwise segmentations to locate objects of interest. However, this type of manual labeling is time consuming, error prone and it has been shown that manual segmentations are not necessarily the optimal spatial enclosure for object classifiers. This paper proposes a weakly-supervised system for multi-label image classification. In this setting, training images are annotated with a set of keywords describing their contents, but the visual concepts are not explicitly segmented in the images. We formulate the weakly-supervised image classification as a low-rank matrix completion problem. Compared to previous work, our proposed framework has three advantages: (1) Unlike existing solutions based on multiple-instance learning methods, our model is convex. We propose two alternative algorithms for matrix completion specifically tailored to visual data, and prove their convergence. (2) Unlike existing discriminative methods, our algorithm is robust to labeling errors, background noise and partial occlusions. (3) Our method can potentially be used for semantic segmentation. Experimental validation on several data sets shows that our method outperforms state-of-the-art classification algorithms, while effectively capturing each class appearance.},
  doi      = {10.1109/TPAMI.2014.2343234},
  keywords = {Multi-label image classification, Nuclear norm, Rank minimization, Segmentation, Weakly-supervised learning},
}

@Article{cao2015restricted,
  author   = {Cao, Peng and Liu, Xiaoli and Bao, Hang and Yang, Jinzhu and Zhao, Dazhe},
  title    = {Restricted {Boltzmann} machines based oversampling and semi-supervised learning for false positive reduction in breast {CAD}.},
  journal  = {Bio-medical materials and engineering},
  year     = {2015},
  volume   = {26 Suppl 1},
  pages    = {S1541--7},
  abstract = {The false-positive reduction (FPR) is a crucial step in the computer aided detection system for the breast. The issues of imbalanced data distribution and the limitation of labeled samples complicate the classification procedure. To overcome these challenges, we propose oversampling and semi-supervised learning methods based on the restricted Boltzmann machines (RBMs) to solve the classification of imbalanced data with a few labeled samples. To evaluate the proposed method, we conducted a comprehensive performance study and compared its results with the commonly used techniques. Experiments on benchmark dataset of DDSM demonstrate the effectiveness of the RBMs based oversampling and semi-supervised learning method in terms of geometric mean (G-mean) for false positive reduction in Breast CAD.},
  doi      = {10.3233/BME-151453},
  keywords = {Algorithms, Automated, Breast Neoplasms, Computer-Assist, Computer Simulation, Data Interpretation, False Positive Reactions, Female, Humans, methods, Models, Neural Networks (Computer), Pattern Recognition, Radiographic Image Enhancement, Radiographic Image Interpretation, radiography, Reproducibility of Results, Sample Size, Sensitivity and Specificity, Statistical, Stochastic Processes, Supervised Machine Learning},
  language = {eng},
}

@InProceedings{carbonneau2016witness,
  author    = {Carbonneau, Marc-André and Granger, Eric and Gagnon, Ghyslain},
  title     = {Witness {Identification} in {Multiple} {Instance} {Learning} {Using} {Random} {Subspaces}},
  booktitle = {Proceedings of the 23rd {International} {Conference} on {Pattern} {Recognition}},
  year      = {2016},
  file      = {carbonneau2016witness.pdf:carbonneau2016witness.pdf:PDF},
  groups    = {Veni},
}

@Article{castaldi2013distinct,
  author   = {Castaldi, Peter J. and Estépar, Raúl San José and Mendoza, Carlos S. and Hersh, Craig P. and Laird, Nan and Crapo, James D. and Lynch, David a. and Silverman, Edwin K. and Washko, George R.},
  title    = {Distinct quantitative computed tomography emphysema patterns are associated with physiology and function in smokers},
  journal  = {American Journal of Respiratory and Critical Care Medicine},
  year     = {2013},
  volume   = {188},
  pages    = {1083--1090},
  abstract = {RATIONALE: Emphysema occurs in distinct pathologic patterns, but little is known about the epidemiologic associations of these patterns. Standard quantitative measures of emphysema from computed tomography (CT) do not distinguish between distinct patterns of parenchymal destruction.{\textbackslash}n{\textbackslash}nOBJECTIVES: To study the epidemiologic associations of distinct emphysema patterns with measures of lung-related physiology, function, and health care use in smokers.{\textbackslash}n{\textbackslash}nMETHODS: Using a local histogram-based assessment of lung density, we quantified distinct patterns of low attenuation in 9,313 smokers in the COPDGene Study. To determine if such patterns provide novel insights into chronic obstructive pulmonary disease epidemiology, we tested for their association with measures of physiology, function, and health care use.{\textbackslash}n{\textbackslash}nMEASUREMENTS AND MAIN RESULTS: Compared with percentage of low-attenuation area less than -950 Hounsfield units (\%LAA-950), local histogram-based measures of distinct CT low-attenuation patterns are more predictive of measures of lung function, dyspnea, quality of life, and health care use. These patterns are strongly associated with a wide array of measures of respiratory physiology and function, and most of these associations remain highly significant (P {\textless} 0.005) after adjusting for \%LAA-950. In smokers without evidence of chronic obstructive pulmonary disease, the mild centrilobular disease pattern is associated with lower FEV1 and worse functional status (P {\textless} 0.005).{\textbackslash}n{\textbackslash}nCONCLUSIONS: Measures of distinct CT emphysema patterns provide novel information about the relationship between emphysema and key measures of physiology, physical function, and health care use. Measures of mild emphysema in smokers with preserved lung function can be extracted from CT scans and are significantly associated with functional measures.},
  doi      = {10.1164/rccm.201305-0873OC},
  file     = {castaldi2013distinct.pdf:castaldi2013distinct.pdf:PDF},
  keywords = {Chronic obstructive pulmonary disease, Emphysema, Epidemiology, Spiral computed tomography},
}

@Article{felix2015metalearning,
  author = {Felix, Catarina and Soares, Carlos},
  title  = {Metalearning for multiple-domain {Transfer} {Learning}},
  year   = {2015},
}

@Article{cha2002measuring,
  author   = {Cha, Sung Hyuk and Srihari, Sargur N.},
  title    = {On measuring the distance between histograms},
  journal  = {Pattern Recognition},
  year     = {2002},
  volume   = {35},
  number   = {6},
  pages    = {1355--1370},
  issn     = {0031-3203},
  abstract = {A distance measure between two histograms has applications in feature selection, image indexing and retrieval, pattern classification and clustering, etc. We propose a distance between sets of measurement values as a measure of dissimilarity of two histograms. The proposed measure has the advantage over the traditional distance measures regarding the overlap between two distributions; it takes the similarity of the non-overlapping parts into account as well as that of overlapping parts. We consider three versions of the univariate histogram, corresponding to whether the type of measurements is nominal, ordinal, and modulo and their computational time complexities are ??(b), ??(b) and O(b2) for each type of measurements, respectively, where b is the number of levels in histograms. ?? 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.},
  doi      = {10.1016/S0031-3203(01)00118-2},
  file     = {cha2002measuring.pdf:cha2002measuring.pdf:PDF},
  keywords = {Distance measure, Histogram, Modulo, Nominal, Ordinal},
}

@Article{chai2017multiple,
  author   = {Chai, Jing and Chen, Bo and Liu, Fan and Chen, Zehua and Ding, Xinghao},
  title    = {Multiple-{Instance} feature extraction at the bag and instance levels using the maximum trace-difference criterion},
  journal  = {Information Sciences},
  year     = {2017},
  volume   = {385},
  pages    = {353--377},
  abstract = {Multiple-Instance Learning (MIL) refers to the problem wherein each object is a bag consisting of multiple instances and only the bags' labels are provided. MIL data can contain irrelevant, redundant, and noisy components, which makes feature-extraction preprocessing essential for performance improvement. In this paper, we propose a Multiple-Instance Feature Extraction (MIFE) framework to design algorithms at both the bag and instance levels based on the Maximum Trace-Difference criterion, which simultaneously maximizes between-class scattering and minimizes within-class scattering. MIFE not only treats the existing Multiple-Instance Discriminant Analysis algorithm as an instance-level realization but also enables us to adopt different bag-level distances to design corresponding bag-level algorithms. In particular, we introduce the Class-to-Bag (C2B) and Bag-to-Bag (B2B) distances into the MIFE framework and obtain the MIFE-C2B and MIFE-B2B algorithms, respectively. The experimental results show that both MIFE-C2B and MIFE-B2B obtain competitive classification performance, and MIFE-B2B obtains the best performance on most tested datasets. The dimensionality reduction results show that both MIFE-C2B and MIFE-B2B obtain their best performance with no more than approximately 30\% of the original dimensions on most tested datasets.},
  doi      = {10.1016/j.ins.2016.12.042},
}

@Article{chan1995comparative,
  author  = {Chan, Philip K and Stolfo, Salvatore J},
  title   = {A {Comparative} {Evaluation} of {Voting} and {Meta}- learning on {Partitioned} {Data} on {Partitioned} {Data}},
  journal = {Science},
  year    = {1995},
  number  = {MAY},
  issn    = {9781558603776},
  doi     = {10.1016/B978-1-55860-377-6.50020-7},
  file    = {chan1995comparative.pdf:chan1995comparative.pdf:PDF},
}

@Article{chen2015standard,
  author   = {Chen, Hao and Ni, Dong and Qin, Jing and Li, Shengli and Yang, Xin and Wang, Tianfu and Heng, Pheng Ann},
  title    = {Standard {Plane} {Localization} in {Fetal} {Ultrasound} via {Domain} {Transferred} {Deep} {Neural} {Networks}.},
  journal  = {IEEE journal of biomedical and health informatics},
  year     = {2015},
  volume   = {19},
  number   = {5},
  pages    = {1627--1636},
  abstract = {Automatic localization of the standard plane containing complicated anatomical structures in ultrasound (US) videos remains a challenging problem. In this paper, we present a learning-based approach to locate the fetal abdominal standard plane (FASP) in US videos by constructing a domain transferred deep convolutional neural network (CNN). Compared with previous works based on low-level features, our approach is able to represent the complicated appearance of the FASP and hence achieve better classification performance. More importantly, in order to reduce the overfitting problem caused by the small amount of training samples, we propose a transfer learning strategy, which transfers the knowledge in the low layers of a base CNN trained from a large database of natural images to our task-specific CNN. Extensive experiments demonstrate that our approach outperforms the state-of-the-art method for the FASP localization as well as the CNN only trained on the limited US training samples. The proposed approach can be easily extended to other similar medical image computing problems, which often suffer from the insufficient training samples when exploiting the deep CNN to represent high-level features.},
  doi2     = {10.1109/JBHI.2015.2425041},
  groups   = {Not-so-supervised papers},
  keywords = {Abdomen, Computer-Assisted, Female, Fetus, Humans, Image Processing, methods, Neural Networks (Computer), physiology, Pregnancy, Prenatal, ROC Curve, Ultrasonography},
  language = {eng},
}

@InProceedings{chen2013neil,
  author    = {Chen, Xinlei and Shrivastava, Abhinav and Gupta, Abhinav},
  title     = {{NEIL}: {Extracting} visual knowledge from web data},
  booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Computer} {Vision}},
  year      = {2013},
  pages     = {1409--1416},
  abstract  = {We propose NEIL (Never Ending Image Learner), a computer program that runs 24 hours per day and 7 days per week to automatically extract visual knowledge from Internet data. NEIL uses a semi-supervised learning algorithm that jointly discovers common...},
  doi       = {10.1109/ICCV.2013.178},
  isbn      = {978-1-4799-2839-2},
  keywords  = {attributes, common sense relationships, macro vision, never ending learning, object detection, scene classification, semi-supervised learning, visual knowledge base},
}

@Article{chen2016mentoring,
  author  = {Chen, Yan},
  title   = {Mentoring female assistant professors enhances their success},
  journal = {Communications of the ACM},
  year    = {2016},
  volume  = {59},
  number  = {12},
  pages   = {40--42},
  doi     = {10.1145/3012425},
  file    = {chen2016mentoring.pdf:chen2016mentoring.pdf:PDF},
  url     = {http://dl.acm.org/citation.cfm?doid=3022085.3012425},
}

@Article{cheng2015domain,
  author   = {Cheng, Bo and Liu, Mingxia and Zhang, Daoqiang and Munsell, Brent C},
  title    = {Domain Transfer Learning for {MCI} Coversion Prediction},
  journal  = {Ieee Transaction on Biomedical Engineering},
  year     = {2015},
  volume   = {62},
  number   = {7},
  pages    = {1805--1817},
  month    = jul,
  abstract = {Machine learning methods have successfully been used to predict the conversion of mild cognitive impairment (MCI) to Alzheimer's disease (AD), by classifying MCi converters (MCI-C) from MCI nonconverters (MCI-NC). However, most existing methods construct classifiers using data from one particular target domain (e.g., MCI), and ignore data in other related domains (e.g., AD and normal control (NC)) that may provide valuable information to improve MCI conversion prediction performance. To address is limitation, we develop a novel domain transfer learning method for MCI coversion prediction, which can use data from both the target domain (i.e., MCI) and auxiliary domains (i.e., AB and NC). Specially, the proposed method consists of three key components: 1) a domain transfer feature selection component that selects the most informative feature-subset from both trget domain and auxilary domains from different imaging modalities; 2) a domain transfer sample selection component that selects the most informative sample-subset from the same target and auxiliary domains from different data modalities; and 3) a domain transfer supprot vector machine classification comnent that fuses the selected features and samples to seperate MCI-C and MCI-NC patients. We evaluate our method on 202 subjects from the Alzheimer's Diease Neuroimaging initiative (ADNI) that have MRI, FDG-PET, and CSF data. The experimental resulats show the proposed method can classify MCI-C patients from MCI-NC patients with an accuracy of 79.4\%, with the aid of additional domain knowledge learned from AD and NC.},
  doi2     = {10.1109/TBME.2015.2404809},
  groups   = {Not-so-supervised papers},
  issn2    = {978-3-642-33414-6},
  keywords = {Alzheimer's disease (AD), domain transfer learning, feature selection, mild cognitive impairment converters (MCI-C), Sample selection},
  language = {eng},
}

@InCollection{chevaleyre2003framework,
  author    = {Chevaleyre, Yann and Zucker, Jean-Daniel},
  title     = {A {Framework} for {Learning} {Rules} from {Multiple} {Instance} {Data}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2003},
  pages     = {49--60},
  note      = {DOI: 10.1007/3-540-44795-4\_5},
  url       = {http://link.springer.com/10.1007/3-540-44795-4_5},
}

@Article{comaniciu2016shaping,
  author   = {Comaniciu, Dorin and Engel, Klaus and Georgescu, Bogdan and Mansi, Tommaso},
  title    = {Shaping the future through innovations: {From} medical imaging to precision medicine},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {19--26},
  note     = {DOI: 10.1016/j.media.2016.06.016},
  abstract = {Medical images constitute a source of information essential for disease diagnosis, treatment and follow-up. In addition, due to its patient-specific nature, imaging information represents a critical component required for advancing precision medicine into clinical practice. This manuscript describes recently developed technologies for better handling of image information: photorealistic visualization of medical images with Cinematic Rendering, artificial agents for in-depth image understanding, support for minimally invasive procedures, and patient-specific computational models with enhanced predictive power. Throughout the manuscript we will analyze the capabilities of such technologies and extrapolate on their potential impact to advance the quality of medical care, while reducing its cost.},
  keywords = {Artificial intelligence for image parsing, Computational modelling, Heart valves modelling, Photorealistic rendering},
  url      = {http://dx.doi.org/10.1016/j.media.2016.06.016},
}

@Article{computing201620th,
  author  = {Computing, Medical Image and Intervention, Computer Assisted},
  title   = {20th anniversary of the {Medical} {Image} {Analysis} journal ({MedIA})},
  journal = {Medical Image Analysis},
  year    = {2016},
  volume  = {33},
  pages   = {1--3},
  doi     = {10.1016/j.media.2016.07.004},
}

@Article{cosatto2013automated,
  author   = {Cosatto, Eric and Laquerre, Pierre-Francois and Malon, Christopher and Graf, Hans-Peter and Saito, Akira and Kiyuna, Tomoharu and Marugame, Atsushi and Kamijo, Ken'ichi},
  title    = {Automated gastric cancer diagnosis on {H}\&{E}-stained sections; ltraining a classifier on a large scale with multiple instance machine learning},
  year     = {2013},
  volume   = {8676},
  pages    = {867605--867605},
  month    = mar,
  issn     = {16057422 (ISSN); 9780819494504 (ISBN)},
  abstract = {We present a system that detects cancer on slides of gastric tissue sections stained with hematoxylin and eosin (H\&E). At its heart is a classifier trained using the semi-supervised multi-instance learning framework (MIL) where each tissue is represented by a set of regions-of-interest (ROI) and a single label. Such labels are readily obtained because pathologists diagnose each tissue independently as part of the normal clinical work flow. From a large dataset of over 26K gastric tissue sections from over 12K patients obtained from a clinical load spanning several months, we train a MIL classifier on a patient-level partition of the dataset (2/3 of the patients) and obtain a very high performance of 96\% (AUC), tested on the remaining 1/3 never-seen before patients (over 8K tissues). We show this level of performance to match the more costly supervised approach where individual ROIs need to be labeled manually. The large amount of data used to train this system gives us confidence in its robustness and that it can be safely used in a clinical setting. We demonstrate how it can improve the clinical workflow when used for pre-screening or quality control. For pre-screening, the system can diagnose 47\% of the tissues with a very low likelihood ({\textless} 1\%) of missing cancers, thus halving the clinicians' caseload. For quality control, compared to random rechecking of 33\% of the cases, the system achieves a three-fold increase in the likelihood of catching cancers missed by pathologists. The system is currently in regular use at independent pathology labs in Japan where it is used to double-check clinician's diagnoses. At the end of 2012 it will have analyzed over 80,000 slides of gastric and colorectal samples (200,000 tissues). © 2013 SPIE.},
  doi      = {10.1117/12.2007047},
  editor   = {Gurcan, Metin N. and Madabhushi, Anant},
  keywords = {computer-assisted diagnosis, gastric cancer, histo-pathology, image analysis, machine learning, multi-instance learning, semi-supervised learning, whole-slide imaging},
  url      = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2007047},
}

@Article{criminisi2016machine,
  author   = {Criminisi, A.},
  title    = {Machine learning for medical images analysis},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {91--93},
  note     = {DOI: 10.1016/j.media.2016.06.002},
  abstract = {This article discusses the application of machine learning for the analysis of medical images. Specifically: (i) We show how a special type of learning models can be thought of as automatically optimized, hierarchically-structured, rule-based algorithms, and (ii) We discuss how the issue of collecting large labelled datasets applies to both conventional algorithms as well as machine learning techniques. The size of the training database is a function of model complexity rather than a characteristic of machine learning methods.},
  keywords = {Decision forests, machine learning, Training data},
  url      = {http://dx.doi.org/10.1016/j.media.2016.06.002},
}

@InProceedings{cruz2015method,
  author    = {Cruz-Roa, Angel and Arévalo, John and Judkins, Alexander and Madabhushi, Anant and González, Fabio},
  title     = {A method for medulloblastoma tumor differentiation based on convolutional neural networks and transfer learning},
  year      = {2015},
  editor    = {Romero, Eduardo and Lepore, Natasha and García-Arteaga, Juan D. and Brieva, Jorge},
  pages     = {968103--968103},
  month     = dec,
  publisher = {International Society for Optics and Photonics},
  doi       = {10.1117/12.2208825},
  groups    = {Not-so-supervised papers},
  keywords  = {Breast cancer, Computer vision technology, Neural networks},
  url       = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2208825},
}

@InProceedings{dai2015metric,
  author    = {Dai, Dengxin and Kroeger, Till and Timofte, Radu and van Gool, Luc},
  title     = {Metric imitation by manifold transfer for efficient vision applications},
  booktitle = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
  year      = {2015},
  pages     = {3527--3536},
  file      = {dai2015metric.pdf:dai2015metric.pdf:PDF},
}

@Book{dan2006multiple,
  title  = {Multiple {Instance} {Learning}},
  year   = {2006},
  author = {Dan, Zhang},
  isbn   = {978-3-319-47758-9},
}

@Article{darrellmachine,
  author   = {Darrell, Trevor and Kloft, Marius and Pontil, Massimiliano and Rätsch, Gunnar and Rodner, Erik},
  title    = {Machine {Learning} with {Interdependent} and {Non}-identically {Distributed} {Data} {Edited} by},
  volume   = {5},
  number   = {4},
  pages    = {18--55},
  keywords = {4, 5, 18, 4230, and phrases machine learning, computational biology, computer vision, dagrep, digital object identifier 10, domain adaptation, ing, transfer learn-},
}

@Article{davatzikos2016computational,
  author   = {Davatzikos, Christos},
  title    = {Computational neuroanatomy using brain deformations: {From} brain parcellation to multivariate pattern analysis and machine learning},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {149--154},
  note     = {DOI: 10.1016/j.media.2016.06.026},
  abstract = {The past 20 years have seen a mushrooming growth of the field of computational neuroanatomy. Much of this work has been enabled by the development and refinement of powerful, high-dimensional image warping methods, which have enabled detailed brain parcellation, voxel-based morphometric analyses, and multivariate pattern analyses using machine learning approaches. The evolution of these 3 types of analyses over the years has overcome many challenges. We present the evolution of our work in these 3 directions, which largely follows the evolution of this field. We discuss the progression from single-atlas, single-registration brain parcellation work to current ensemble-based parcellation; from relatively basic mass-univariate t-tests to optimized regional pattern analyses combining deformations and residuals; and from basic application of support vector machines to generative-discriminative formulations of multivariate pattern analyses, and to methods dealing with heterogeneity of neuroanatomical patterns. We conclude with discussion of some of the future directions and challenges.},
  keywords = {Brain image analysis, Computational neuroanatomy, machine learning, Pattern analysis},
  url      = {http://dx.doi.org/10.1016/j.media.2016.06.026},
}

@Article{bruijne2016machine,
  author   = {de Bruijne, Marleen},
  title    = {Machine learning approaches in medical image analysis: {From} detection to diagnosis},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {94--97},
  month    = oct,
  note     = {DOI: 10.1016/j.media.2016.06.032},
  abstract = {Machine learning approaches are increasingly successful in image-based diagnosis, disease prognosis, and risk assessment. This paper highlights new research directions and discusses three main challenges related to machine learning in medical imaging: coping with variation in imaging protocols, learning from weak labels, and interpretation and evaluation of results.},
  keywords = {Classification, Computer aided diagnosis, machine learning, Transfer learning},
  language = {eng},
}

@InCollection{bruijne2004shape,
  author    = {de Bruijne, Marleen and Nielsen, Mads},
  title     = {Shape {Particle} {Filtering} for {Image} {Segmentation}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2004},
  pages     = {168--175},
  note      = {DOI: 10.1007/978-3-540-30135-6\_21},
  url       = {http://link.springer.com/10.1007/978-3-540-30135-6_21},
}

@Article{dellamea2014preliminary,
  author   = {Della Mea, Vincenzo and Maddalena, Eddy and Mizzaro, Stefano and Machin, Piernicola and Beltrami, Carlo A},
  title    = {Preliminary results from a crowdsourcing experiment in immunohistochemistry.},
  journal  = {Diagnostic pathology},
  year     = {2014},
  volume   = {9 Suppl 1},
  number   = {Suppl 1},
  pages    = {S6--S6},
  issn     = {1746-1596 (Electronic){\textbackslash}r1746-1596 (Linking)},
  abstract = {BACKGROUND: Crowdsourcing, i.e., the outsourcing of tasks typically performed by a few experts to a large crowd as an open call, has been shown to be reasonably effective in many cases, like Wikipedia, the Chess match of Kasparov against the world in 1999, and several others. The aim of the present paper is to describe the setup of an experimentation of crowdsourcing techniques applied to the quantification of immunohistochemistry.{\textbackslash}n{\textbackslash}nMETHODS: Fourteen Images from MIB1-stained breast specimens were first manually counted by a pathologist, then submitted to a crowdsourcing platform through a specifically developed application. 10 positivity evaluations for each image have been collected and summarized using their median. The positivity values have been then compared to the gold standard provided by the pathologist by means of Spearman correlation.{\textbackslash}n{\textbackslash}nRESULTS: Contributors were in total 28, and evaluated 4.64 images each on average. Spearman correlation between gold and crowdsourced positivity percentages is 0.946 (p {\textless} 0.001).{\textbackslash}n{\textbackslash}nCONCLUSIONS: Aim of the experiment was to understand how to use crowdsourcing for an image analysis task that is currently time-consuming when done by human experts. Crowdsourced work can be used in various ways, in particular statistically agregating data to reduce identification errors. However, in this preliminary experimentation we just considered the most basic indicator, that is the median positivity percentage, which provided overall good results. This method might be more aimed to research than routine: when a large number of images are in need of ad-hoc evaluation, crowdsourcing may represent a quick answer to the need.},
  doi      = {10.1186/1746-1596-9-S1-S6},
  url      = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4305976&tool=pmcentrez&rendertype=abstract},
}

@Article{dempere-marco2002use,
  author   = {Dempere-Marco, Laura and Hu, Xiao Peng and MacDonald, Sharyn L S and Ellis, Stephen M and Hansell, David M and Yang, Guang Zhong},
  title    = {The use of visual search for knowledge gathering in image decision support},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2002},
  volume   = {21},
  number   = {7},
  pages    = {741--754},
  month    = jul,
  issn     = {0278-0062 (Print)},
  abstract = {This paper presents a new method of knowledge gathering for decision support in image understanding based on information extracted from the dynamics of saccadic eye movements. The framework involves the construction of a generic image feature extraction library, from which the feature extractors that are most relevant to the visual assessment by domain experts are determined automatically through factor analysis. The dynamics of the visual search are analyzed by using the Markov model for providing training information to novices on how and where to look for image features. The validity of the framework has been evaluated in a clinical scenario whereby the pulmonary vascular distribution on Computed Tomography images was assessed by experienced radiologists as a potential indicator of heart failure. The performance of the system has been demonstrated by training four novices to follow the visual assessment behavior of two experienced observers. In all cases, the accuracy of the students improved from near random decision making (33\%) to accuracies ranging from 50\% to 68\%.},
  doi      = {10.1109/TMI.2002.801153},
  keywords = {Eye movements, Factor analysis, Knowledge gathering, Markov models},
  url      = {http://www.ncbi.nlm.nih.gov/pubmed/12374312},
}

@Article{depeursinge2011lung,
  author   = {Depeursinge, Adrien and Foncubierta-Rodriguez, Antonio and Van De Ville, Dimitri and Müller, Henning},
  title    = {Lung texture classification using locally-oriented riesz components},
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year     = {2011},
  volume   = {6893 LNCS},
  pages    = {231--238},
  issn     = {9783642236259},
  abstract = {We develop a texture analysis framework to assist radiologists in interpreting high-resolution computed tomography (HRCT) images of the lungs of patients affected with interstitial lung diseases (ILD). Novel texture descriptors based on the Riesz transform are proposed to analyze lung texture without any assumption on prevailing scales and orientations. A global classification accuracy of 78.3\% among five lung tissue types is achieved using locally-oriented Riesz components. Comparative performance analysis with features derived from optimized grey-level co-occurrence matrices showed an absolute gain of 6.1\% in classification accuracy. The adaptability of the Riesz features is demonstrated by reconstructing templates according to the first principal components of the lung textures. The balanced performance achieved among the various lung textures suggest that the proposed methods can complement human observers in HRCT interpretation, and opens interesting perspectives for future research.},
  doi      = {10.1007/978-3-642-23626-6_29},
  keywords = {computer-aided diagnosis, high-resolution computed tomography, interstitial lung diseases, Riesz transform, texture analysis},
}

@Article{deriche2016computational,
  author   = {Deriche, Rachid},
  title    = {Computational brain connectivity mapping: {A} core health and scientific challenge},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {122--126},
  note     = {DOI: 10.1016/j.media.2016.06.003},
  abstract = {One third of the burden of all the diseases in Europe is due to problems caused by diseases affecting brain. Although exceptional progress have been obtained for exploring the brain during the past decades, it is still terra-incognita and calls for specific efforts in research to better understand its architecture and functioning. To take up this great challenge of modern science and to solve the limited view of the brain provided just by one imaging modality, this article advocates the idea developed in my research group of a global approach involving new generation of models for brain connectivity mapping and strong interactions between structural and functional connectivities. Capitalizing on the strengths of integrated and complementary non invasive imaging modalities such as diffusion Magnetic Resonance Imaging (dMRI) and Electro \& Magneto-Encephalography (EEG \& MEG) will contribute to achieve new frontiers for identifying and characterizing structural and functional brain connectivities and to provide a detailed mapping of the brain connectivity, both in space and time. Thus leading to an added clinical value for high impact diseases with new perspectives in computational neuro-imaging and cognitive neuroscience.},
  keywords = {Brain mapping, Diffusion MRI, EEG, MEG, Networks, Structural and functional brain connectivity},
}

@Article{dietterich1998approximate,
  author   = {Dietterich, Thomas G.},
  title    = {Approximate {Statistical} {Tests} for {Comparing} {Supervised} {Classi} cation {Learning} {Algorithms}},
  journal  = {Neural Computation},
  year     = {1998},
  volume   = {10},
  number   = {7},
  pages    = {1895--1923},
  month    = oct,
  issn     = {0899-7667},
  abstract = {This article reviews ve approximate statistical tests for determining whether one learning algorithm outperforms another on a particular learn- ing task. These tests are compared experimentally to determine their prob- ability of incorrectly detecting a difference when no difference exists (type I error). Two widely used statistical tests are shown to have high probability of type I error in certain situations and should never be used: a test for the difference of two proportions and a paired-differences t test based on taking several random train-test splits. A third test, a paired- differences t test based on 10-fold cross-validation, exhibits somewhat elevated probability of type I error. A fourth test, McNemar?s test, is shown to have low type I error. The fth test is a new test, 5 £ 2 cv, based on ve iterations of twofold cross-validation. Experiments show that this test also has acceptable type I error. The article also measures the power (ability to detect algorithm differences when they do exist) of these tests. The cross-validated t test is the most powerful. The 5 £2 cv test is shown to be slightly more powerful than McNemar?s test. The choice of the best test is determined by the computational cost of running the learning algorithm. For algorithms that can be executed only once, Mc- Nemar?s test is the only test with acceptable type I error. For algorithms that can be executed 10 times, the 5 £ 2 cv test is recommended, because it is slightly more powerful and because it directly measures variation due to the choice of training set.},
  doi      = {10.1162/089976698300017197},
  url      = {http://www.mitpressjournals.org/doi/abs/10.1162/089976698300017197},
}

@Article{dinh2013fidos,
  author   = {Dinh, Cuong V. and Duin, Robert P W and Piqueras-Salazar, Ignacio and Loog, Marco},
  title    = {{FIDOS}: {A} generalized {Fisher} based feature extraction method for domain shift},
  journal  = {Pattern Recognition},
  year     = {2013},
  volume   = {46},
  number   = {9},
  pages    = {2510--2518},
  issn     = {0031-3203},
  abstract = {Traditional pattern recognition techniques often assume that the data sets used for training and testing follow the same distribution. However, this assumption is usually not true for many real world problems as data from the same classes but different domains, e.g., data are collected under different conditions, may show different characteristics. We introduce FIDOS, a generalized FIsher based method for DOmain Shift problem, that aims at learning invariant features across domains in a supervised manner. Different from classical Fisher feature extraction, FIDOS aims to minimize not only the within-class scatter but also the difference in distributions between domains. Therefore, the subspace constructed by FIDOS reduces the drift in distributions among different domains and at the same time preserves the discriminants across classes. Another advantage of FIDOS over classical Fisher is that FIDOS extracts more features when multiple source domains are available in the training set; this is essential for a good classification especially when the number of classes is small. Experimental results on both artificial and real data and comparisons with other methods demonstrate the efficiency of our method in classifying objects under domain shift situations. © 2013 Elsevier Ltd. All rights reserved.},
  doi      = {10.1016/j.patcog.2013.02.011},
  file     = {dinh2013fidos.pdf:dinh2013fidos.pdf:PDF},
  keywords = {domain adaptation, Domain shift, Fisher feature extraction, Invariant features, Multiple source domain adaptation},
  url      = {http://dx.doi.org/10.1016/j.patcog.2013.02.011},
}

@Article{dollar2013structured,
  author = {Dollar, Piotr and Zitnick, C. L.},
  title  = {Structured {Forests} for {Fast} {Edge} {Detection}},
  year   = {2013},
  pages  = {1841--1848},
}

@InProceedings{donner2009weakly,
  author    = {Donner, Rene and Wildenauer, Horst and Bischof, Horst and Langs, Georg},
  title     = {Weakly supervised group-wise model learning based on discrete optimization.},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year      = {2009},
  volume    = {12},
  number    = {Pt 2},
  pages     = {860--868},
  abstract  = {In this paper we propose a method for the weakly supervised learning of sparse appearance models from medical image data based on Markov random fields (MRF). The models are learnt from a single annotated example and additional training samples without annotations. The approach formulates the model learning as solving a set of MRFs. Both the model training and the resulting model are able to cope with complex and repetitive structures. The weakly supervised model learning yields sparse MRF appearance models that perform equally well as those trained with manual annotations, thereby eliminating the need for tedious manual training supervision. Evaluation results are reported for hand radiographs and cardiac MRI slices.},
  groups    = {Not-so-supervised papers},
  keywords  = {Algorithms, Artificial Intelligence, Automated, Computer-Assisted, Humans, Image Enhancement, Image Interpretation, methods, Pattern Recognition, Reproducibility of Results, Sensitivity and Specificity},
  language  = {eng},
}

@Article{dredze2012becoming,
  author = {Dredze, Mark and Hopkins, Johns},
  title  = {Becoming a {PhD} {Student} {You} and {Your} {Advisor}},
  year   = {2012},
}

@Article{dredze2010multi,
  author   = {Dredze, Mark and Kulesza, Alex and Crammer, Koby},
  title    = {Multi-domain learning by confidence-weighted parameter combination},
  journal  = {Machine Learning},
  year     = {2010},
  volume   = {79},
  number   = {1-2},
  pages    = {123--149},
  month    = oct,
  abstract = {State-of-the-art statistical NLP systems for a variety of tasks learn from{\textbackslash}nlabeled training data that is often domain specific. However, there may be{\textbackslash}nmultiple domains or sources of interest on which the system must perform. For{\textbackslash}nexample, a spam filtering system must give high quality predictions for many{\textbackslash}nusers, each of whom receives emails from different sources and may make slightly{\textbackslash}ndifferent decisions about what is or is not spam. Rather than learning separate{\textbackslash}nmodels for each domain, we explore systems that learn across multiple domains.{\textbackslash}nWe develop a new multi-domain online learning framework based on parameter{\textbackslash}ncombination from multiple classifiers. Our algorithms draw from multi-task{\textbackslash}nlearning and domain adaptation to adapt multiple source domain classifiers to a{\textbackslash}nnew target domain, learn across multiple similar domains, and learn across a{\textbackslash}nlarge number of disparate domains. We evaluate our algorithms on two popular NLP{\textbackslash}ndomain adaptation tasks: sentiment classification and spam filtering. Keywords{\textbackslash}nOnline learning Domain adaptation Classifier combination Transfer learning{\textbackslash}nMulti-task learning},
  doi      = {10.1007/s10994-009-5148-0},
  keywords = {Classifier combination, domain adaptation, Multi-task learning, online learning, Transfer learning},
  url      = {http://link.springer.com/10.1007/s10994-009-5148-0},
}

@Article{duan2009domain,
  author   = {Duan, Lixin and Tsang, Ivor W. and Xu, Dong and Chua, Tat-Seng},
  title    = {Domain {Adaptation} from {Multiple} {Domain} adaptation from multiple sources via auxiliary classifiers},
  journal  = {26th International Conference on Machine Learning},
  year     = {2009},
  pages    = {289--296},
  issn     = {9781605585161},
  abstract = {We propose a multiple source domain adaptation method, referred to as Domain Adaptation Machine (DAM), to learn a robust decision function (referred to as target classifier) for label prediction of patterns from the target domain by leveraging a set of pre-computed classifiers (referred to as auxiliary/source classifiers) independently learned with the labeled patterns from multiple source domains. We introduce a new datadependent regularizer based on smoothness assumption into Least-Squares SVM (LS-SVM), which enforces that the target classifier shares similar decision values with the auxiliary classifiers from relevant source domains on the unlabeled patterns of the target domain. In addition, we employ a sparsity regularizer to learn a sparse target classifier. Comprehensive experiments on the challenging TRECVID 2005 corpus demonstrate that DAM outperforms the existing multiple source domain adaptation methods for video concept detection in terms of effectiveness and efficiency.},
  doi      = {10.1145/1553374.1553411},
  file     = {duan2009domain.pdf:duan2009domain.pdf:PDF},
}

@Article{duin2015dissimilarity,
  author   = {Duin, Robert P W},
  title    = {The dissimilarity representation for finding universals from particulars by an anti-essentialist approach},
  journal  = {Pattern Recognition Letters},
  year     = {2015},
  volume   = {64},
  pages    = {37--43},
  abstract = {Abstract The dissimilarity representation for designing pattern recognition systems is analyzed for its ability to build new knowledge from examples using an anti-essentialist approach. It is argued that it may find universals (pattern classifiers) from particulars (training set of examples) but that the resulting knowledge can just be applied but not accessed. Consequently, its use for a conscious human decision maker is limited.},
  doi      = {10.1016/j.patrec.2015.04.015},
  file     = {duin2015dissimilarity.pdf:duin2015dissimilarity.pdf:PDF},
  keywords = {Anti-essentialism, Generalization, Nearest Neighbor Rule, Representation},
  url      = {http://dx.doi.org/10.1016/j.patrec.2015.04.015},
}

@Article{dumitrache2013dr,
  author   = {Dumitrache, Anca and Aroyo, Lora and Welty, Chris and Sips, Robert Jan and Levas, Anthony},
  title    = {"{Dr}. {Detective}": {Combining} gamification techniques and crowdsourcing to create a gold standard in medical text},
  journal  = {CEUR Workshop Proceedings},
  year     = {2013},
  volume   = {1030},
  pages    = {16--31},
  issn     = {16130073 (ISSN)},
  abstract = {This paper proposes a design for a gamified crowdsourcing workflow to extract annotation from medical text. Developed in the context of a general crowdsourcing platform, Dr. Detective is a game with a purpose that engages medical experts into solving annotation tasks on medical case reports, tailored to capture disagreement between annotators. It incorporates incentives such as learning features, to motivate a continuous involvement of the expert crowd. The game was designed to identify expressions valuable for training NLP tools, and interpret their relation in the context of medical diagnosing. In this way, we can resolve the main problem in gathering ground truth from experts - that the low inter-annotator agreement is typically caused by different interpretations of the text. We report on the results of a pilot study assessing the usefulness of this game. The results show that the quality of the annotations by the expert crowd are comparable to those of an NLP parser. Furthermore, we observed that allowing game users to access each others' answers increases agreement between annotators.},
  file     = {dumitrache2013dr.pdf:dumitrache2013dr.pdf:PDF},
  keywords = {crowdsourcing, Games with a purpose, Gold standard, Information extraction, Natural language processing},
}

@InProceedings{dundar2010multiple,
  author    = {Dundar, M. Murat and Badve, Sunil and Raykar, Vikas C. and Jain, Rohit K. and Sertel, Olcay and Gurca, Metin N.},
  title     = {A Multiple Instance Learning Approach toward Optimal Classification of Pathology Slides},
  booktitle = {{International} {Conference} on {Pattern} Recognition (ICPR)},
  year      = {2010},
  pages     = {2732--2735},
  publisher = {IEEE},
  abstract  = {Pathology slides are diagnosed based on the histological descriptors extracted from regions of interest (ROIs) identified on each slide by the pathologists. A slide usually contains multiple regions of interest and a positive (cancer) diagnosis is confirmed when at least one of the ROIs in the slide is identified as positive. For a negative diagnosis the pathologist has to rule out cancer for each and every ROI available. Our research is motivated toward computer-assisted classification of digitized slides. The objective in this study is to develop a classifier to optimize classification accuracy at the slide level. Traditional supervised training techniques which are trained to optimize classifier performance at the ROI level yield suboptimal performance in this problem. We propose a multiple instance learning approach based on the implementation of the large margin principle with different loss functions defined for positive and negative samples. We consider the classification of intraductal breast lesions as a case study, and perform experimental studies comparing our approach against the state-of-the-art.},
  doi2      = {10.1109/ICPR.2010.669},
  isbn2     = {978-1-4244-7542-1},
  keywords  = {computer-as, ROI level yield suboptimal performance},
  url2      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5596023},
}

@Article{edwardstowards,
  author   = {Edwards, Harrison and Storkey, Amos},
  title    = {Towards a {Neural} {Statistician}},
  abstract = {An efficient learner is one who reuses what they already know to tackle a new problem. For a machine learner, this means understanding the similarities amongst datasets. In order to do this, one must take seriously the idea of working with datasets, rather than datapoints, as the key objects to model. Towards this goal, we demonstrate an extension of a variational autoencoder that can learn a method for computing representations, or statistics, of datasets in an unsupervised fashion. The network is trained to produce statistics that encapsulate a generative model for each dataset. Hence the network enables efficient learning from new datasets for both unsupervised and supervised tasks. We show that we are able to learn statistics that can be used for: clustering datasets, transferring generative models to new datasets, selecting representative samples of datasets and classifying previously unseen classes.},
}

@Article{epifanio2013h,
  author   = {Epifanio, Irene},
  title    = {H-plots for displaying nonmetric dissimilarity matrices},
  journal  = {Statistical Analysis and Data Mining},
  year     = {2013},
  volume   = {6},
  number   = {2},
  pages    = {136--143},
  month    = apr,
  abstract = {Nonmetric pairwise data with violations of symmetry, reflexivity, or triangle inequality appear in fields such as image matching, web mining, or cognitive psychology. When data are inherently nonmetric, we should not enforce metricity as real information could be lost. The multidimensional scaling problem is addressed from a new perspective. I propose a method based on the h-plot, which naturally handles asymmetric proximity data. Pairwise proximities between the objects are defined, though I do not embed these objects, but rather the variables that give the proximity to or from each object. The method is very simple to implement. The representation goodness can be easily assessed. The methodology is illustrated through several small examples and applied to the analysis of digital images of human corneal endothelia. Comparisons with well-known methods show its good behavior, especially with nonmetric pairwise data, which motivate my methodology. Other databases and methods are analyzed in the supporting information. © 2013 Wiley Periodicals, Inc.},
  doi      = {10.1002/sam.11177},
  keywords = {Embedding, Multidimensional scaling, Non-Euclidean pairwise data, Proximity data, Visualization},
  url      = {http://doi.wiley.com/10.1002/sam.11177},
}

@Article{esteva2017dermatologist,
  author  = {Esteva, Andre and Kuprel, Brett and Novoa, Roberto A. and Ko, Justin and Swetter, Susan M. and Blau, Helen M. and Thrun, Sebastian},
  title   = {Dermatologist-level classification of skin cancer with deep neural networks},
  journal = {Nature},
  year    = {2017},
  month   = jan,
  doi     = {10.1038/nature21056},
  url     = {http://www.nature.com/doifinder/10.1038/nature21056},
}

@Article{fan2008knowledge,
  author = {Fan, Wei},
  title  = {Knowledge {Transfer} {Via} {Multiple} {Model} {Local} {Structure} {Mapping} {Knowledge} {Transfer} via {Multiple} {Model}},
  year   = {2008},
  pages  = {283--291},
  issn   = {9781605581934},
}

@Article{feng2011geometric,
  author   = {Feng, Jiashi and Ni, Bingbing and Tian, Qi and Yan, Shuicheng},
  title    = {Geometric lp-norm {Feature} {Pooling} for {Image} {Classification}},
  journal  = {IEEE Computer Vision and Pattern Recognition},
  year     = {2011},
  pages    = {2697--2704},
  month    = jun,
  issn     = {978-1-4577-0394-2},
  abstract = {Modern visual classification models generally include a feature pooling step, which aggregates local features over the region of interest into a statistic through a certain spatial pooling operation. Two commonly used operations are the average and max poolings. However, recent theoretical analysis has indicated that neither of these two pooling techniques may be qualified to be optimal. Besides, we further reveal in this work that more severe limitations of these two pooling methods are from the unrecoverable loss of the spatial information during the statistical summarization and the underlying over-simplified assumption about the feature distribution. We aim to address these inherent issues in this work and generalize previous pooling methods as follows. We define a weighted ?p-norm spatial pooling function tailored for the class-specific feature spatial distribution. Moreover, a sensible prior for the feature spatial correlation is incorporated. Optimizing such pooling function towards optimal class separability yields a so-called geometric ?p-norm pooling (GLP) method. The described GLP method is capable of preserving the class-specific spatial/geometric information in the pooled features and significantly boosts the discriminating capability of the resultant features for image classification. Comprehensive evaluations on several image benchmarks demonstrate that the proposed GLP method can boost the image classification performance with a single type of feature to outperform or be comparable with the state-of-the-arts.},
  doi      = {10.1109/CVPR.2011.5995370},
  file     = {feng2011geometric.pdf:feng2011geometric.pdf:PDF},
  url      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5995370},
}

@Article{fernandez-delgado2014do,
  author   = {Fernández-Delgado, Manuel and Cernadas, Eva and Barro, Senén and Amorim, Dinani and Amorim Fernández-Delgado, Dinani},
  title    = {Do we {Need} {Hundreds} of {Classifiers} to {Solve} {Real} {World} {Classification} {Problems}?},
  journal  = {Journal of Machine Learning Research},
  year     = {2014},
  volume   = {15},
  pages    = {3133--3181},
  issn     = {1532-4435},
  abstract = {We evaluate 179 classifiers arising from 17 families (discriminant analysis, Bayesian, neural networks, support vector machines, decision trees, rule-based classifiers, boosting, bagging, stacking, random forests and other ensembles, generalized linear models, nearest-neighbors, partial least squares and principal component regression, logistic and multino-mial regression, multiple adaptive regression splines and other methods), implemented in Weka, R (with and without the caret package), C and Matlab, including all the relevant classifiers available today. We use 121 data sets, which represent the whole UCI data base (excluding the large-scale problems) and other own real problems, in order to achieve significant conclusions about the classifier behavior, not dependent on the data set col-lection. The classifiers most likely to be the bests are the random forest (RF) versions, the best of which (implemented in R and accessed via caret) achieves 94.1\% of the maximum accuracy overcoming 90\% in the 84.3\% of the data sets. However, the dif-ference is not statistically significant with the second best, the SVM with Gaussian kernel implemented in C using LibSVM, which achieves 92.3\% of the maximum accuracy. A few models are clearly better than the remaining ones: random forest, SVM with Gaussian and polynomial kernels, extreme learning machine with Gaussian kernel, C5.0 and avNNet (a committee of multi-layer perceptrons implemented in R with the caret package). The random forest is clearly the best family of classifiers (3 out of 5 bests classifiers are RF), followed by SVM (4 classifiers in the top-10), neural networks and boosting ensembles (5 and 3 members in the top-20, respectively).},
  keywords = {Bayesian classifiers, Classification, decision trees, Discriminant analysis, ensembles, generalized linear models, logistic and multinomial regression, multiple adaptive regression splines, nearest-neighbors, Neural networks, random forest, rule-based classifiers, Support Vector Machine, UCI data base},
}

@Article{fernandosubspace,
  author = {Fernando, Basura and Habrard, Amaury and Sebban, Marc and Tuytelaars, Tinne and Lyon, De},
  title  = {Subspace {Alignment} {For} {Domain} {Adaptation}},
}

@Article{frangi2016precision,
  author   = {Frangi, Alejandro F. and Taylor, Zeike A. and Gooya, Ali},
  title    = {Precision {Imaging}: more descriptive, predictive and integrative imaging},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {27--32},
  note     = {DOI: 10.1016/j.media.2016.06.024},
  abstract = {Medical image analysis has grown into a matured field challenged by progress made across all medical imaging technologies and more recent breakthroughs in biological imaging. The cross-fertilisation between medical image analysis, biomedical imaging physics and technology, and domain knowledge from medicine and biology has spurred a truly interdisciplinary effort that stretched outside the original boundaries of the disciplines that gave birth to this field and created stimulating and enriching synergies. Consideration on how the field has evolved and the experience of the work carried out over the last 15 years in our centre, has led us to envision a future emphasis of medical imaging in Precision Imaging. Precision Imaging is not a new discipline but rather a distinct emphasis in medical imaging borne at the cross-roads between, and unifying the efforts behind mechanistic and phenomenological model-based imaging. It captures three main directions in the effort to deal with the information deluge in imaging sciences, and thus achieve wisdom from data, information, and knowledge. Precision Imaging is finally characterised by being descriptive, predictive and integrative about the imaged object. This paper provides a brief and personal perspective on how the field has evolved, summarises and formalises our vision of Precision Imaging for Precision Medicine, and highlights some connections with past research and current trends in the field.},
  keywords = {Image-based modelling, Mechanistic modeling, Model-based imaging, Phenomenological modeling, Precision Imaging, Precision Medicine},
}

@Article{freitas2013comprehensible,
  author   = {Freitas, Alex A},
  title    = {Comprehensible {Classification} {Models} ? a position paper},
  journal  = {ACM SIGKDD Explorations Newsletter},
  year     = {2013},
  volume   = {15},
  number   = {1},
  pages    = {1--10},
  issn     = {1931-0145},
  abstract = {The vast majority of the literature evaluates the performance of classification models using only the criterion of predictive accuracy. This paper reviews the case for considering also the comprehensibility (interpretability) of classification models, and discusses the interpretability of five types of classification models, namely decision trees, classification rules, decision tables, nearest neighbors and Bayesian network classifiers. We discuss both interpretability issues which are specific to each of those model types and more generic interpretability issues, namely the drawbacks of using model size as the only criterion to evaluate the comprehensibility of a model, and the use of monotonicity constraints to improve the comprehensibility and acceptance of classification models by users.},
  doi      = {10.1145/2594473.2594475},
  keywords = {bayesian network classifiers, decision table, decision tree, monotonicity constraint, nearest neighbors, rule induction},
  url      = {http://dl.acm.org.miman.bib.bth.se/citation.cfm?id=2594475},
}

@InCollection{fuchs2008weakly,
  author    = {Fuchs, Thomas J. and Lange, Tilman and Wild, Peter J. and Moch, Holger and Buhmann, Joachim M.},
  title     = {Weakly {Supervised} {Cell} {Nuclei} {Detection} and {Segmentation} on {Tissue} {Microarrays} of {Renal} {Clear} {Cell} {Carcinoma}},
  booktitle = {Pattern {Recognition}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2008},
  pages     = {173--182},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-69320-8},
  note      = {DOI: 10.1007/978-3-540-69321-5\_18},
  url       = {http://link.springer.com/10.1007/978-3-540-69321-5_18},
}

@TechReport{fyfe2016academic,
  author = {Fyfe, Aileen and De Moortel, Ineke and Ashbrokk, Sharon},
  title  = {Academic {Women} {Now}: experiences of mid-career academic women in {Scotland}},
  year   = {2016},
  pages  = {72--72},
  url    = {http://www.youngacademyofscotland.org.uk/images/Documents/AcademicWomenNow2016FINAL.pdf},
}

@Article{gaoholistic,
  author   = {Gao, Mingchen and Xu, Ziyue and Lu, Le and Member, Senior and Harrison, Adam P and Summers, Ronald M and Mollura, Daniel J},
  title    = {Holistic {Interstitial} {Lung} {Disease} {Detection} using {Deep} {Convolutional} {Neural} {Networks} : {Multi}-label {Learning} and {Unordered} {Pooling}},
  pages    = {1--10},
  issn     = {978-3-319-24887-5},
  doi      = {10.1007/978-3-319-24888-2},
  keywords = {convolutional neural, fisher vector, interstitial lung disease detection, multi-label deep regression, network, unordered pooling},
}

@InProceedings{gao2015mci,
  author    = {Gao, Yue and Wee, Chong Yaw and Kim, Minjeong and Giannakopoulos, Panteleimon and Montandon, Marie Louise and Haller, Sven and Shen, Dinggang},
  title     = {{MCI} identification by joint learning on multiple {MRI} data},
  booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
  year      = {2015},
  volume    = {9350},
  pages     = {78--85},
  month     = oct,
  abstract  = {The identification of subtle brain changes that are associated with mild cognitive impairment (MCI), the at-risk stage of Alzheimer's disease, is still a challenging task. Different from existing works, which employ multimodal data (e.g., MRI, PET or CSF) to identify MCI subjects from normal elderly controls, we use four MRI sequences, including T1-weighted MRI (T1), Diffusion Tensor Imaging (DTI), Resting-State functional MRI (RS-fMRI) and Arterial Spin Labeling (ASL) perfusion imaging. Since these MRI sequences simultaneously capture various aspects of brain structure and function during clinical routine scan, it simplifies finding the relationship between subjects by incorporating the mutual information among them. To this end, we devise a hypergraph-based semi-supervised learning algorithm. In particular, we first construct a hypergraph for each of MRI sequences separately using a star expansion method with both the training and testing data. A centralized learning is then performed to model the optimal relevance between subjects by incorporating mutual information between different MRI sequences. We then combine all centralized hypergraphs by learning the optimal weight of each hypergraph based on the minimum Laplacian. We apply our proposed method on a cohort of 41 consecutive MCI subjects and 63 age-and-gender matched controls with four MRI sequences. Our method achieves at least a 7.61\% improvement in classification accuracy compared to state-of-the-art methods using multiple MRI data.},
  doi       = {10.1007/978-3-319-24571-3_10},
  isbn      = {978-3-319-24570-6},
  language  = {ENG},
}

@Article{gao2015structure,
  author   = {Gao, Zhen and Ruan, Jianhua},
  title    = {A structure-based {Multiple}-{Instance} {Learning} approach to predicting in vitro transcription factor-{DNA} interaction},
  journal  = {BMC Genomics},
  year     = {2015},
  volume   = {16},
  number   = {Suppl 4},
  pages    = {S3--S3},
  issn     = {1471-2164 (Electronic) 1471-2164 (Linking)},
  abstract = {BACKGROUND:Understanding the mechanism of transcriptional regulation remains an inspiring stage of molecular biology. Recently, in vitro protein-binding microarray experiments have greatly improved the understanding of transcription factor-DNA interaction. We present a method - MIL3D - which predicts in vitro transcription factor binding by multiple-instance learning with structural properties of DNA.RESULTS:Evaluation on in vitro data of twenty mouse transcription factors shows that our method outperforms a method based on simple-instance learning with DNA structural properties, and the widely used k-mer counting method, for nineteen out of twenty of the transcription factors. Our analysis showed that the MIL3D approach can utilize subtle structural similarities when a strong sequence consensus is not available.CONCLUSION:Combining multiple-instance learning and structural properties of DNA has promising potential for studying biological regulatory networks.},
  doi      = {10.1186/1471-2164-16-S4-S3},
  url      = {http://www.biomedcentral.com/1471-2164/16/S4/S3},
}

@Article{garcia2012prototype,
  author   = {García, Salvador and Derrac, Joaquín and Cano, José Ramón and Herrera, Francisco},
  title    = {Prototype selection for nearest neighbor classification: {Taxonomy} and empirical study},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year     = {2012},
  volume   = {34},
  number   = {3},
  pages    = {417--435},
  month    = mar,
  issn     = {0162-8828},
  abstract = {The nearest neighbor classifier is one of the most used and well-known techniques for performing recognition tasks. It has also demonstrated itself to be one of the most useful algorithms in data mining in spite of its simplicity. However, the nearest neighbor classifier suffers from several drawbacks such as high storage requirements, low efficiency in classification response, and low noise tolerance. These weaknesses have been the subject of study for many researchers and many solutions have been proposed. Among them, one of the most promising solutions consists of reducing the data used for establishing a classification rule (training data) by means of selecting relevant prototypes. Many prototype selection methods exist in the literature and the research in this area is still advancing. Different properties could be observed in the definition of them, but no formal categorization has been established yet. This paper provides a survey of the prototype selection methods proposed in the literature from a theoretical and empirical point of view. Considering a theoretical point of view, we propose a taxonomy based on the main characteristics presented in prototype selection and we analyze their advantages and drawbacks. Empirically, we conduct an experimental study involving different sizes of data sets for measuring their performance in terms of accuracy, reduction capabilities, and runtime. The results obtained by all the methods studied have been verified by nonparametric statistical tests. Several remarks, guidelines, and recommendations are made for the use of prototype selection for nearest neighbor classification.},
  doi      = {10.1109/TPAMI.2011.142},
  keywords = {Classification, condensation, edition, nearest neighbor, Prototype selection, taxonomy},
  url      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6136515},
}

@InProceedings{garcia-garcia2012classifier,
  author    = {García-Garcia, Dario and Santos-Rodriguez, Raul and Parrado-Hernández, Emilio},
  title     = {Classifier-based affinities for clustering sets of vectors},
  booktitle = {{IEEE} {International} {Workshop} on {Machine} {Learning} for {Signal} {Processing}, {MLSP}},
  year      = {2012},
  pages     = {1--6},
  month     = sep,
  publisher = {IEEE},
  doi       = {10.1109/MLSP.2012.6349760},
  isbn      = {978-1-4673-1026-0},
  keywords  = {Sequence clustering, sets of vectors, speaker clustering},
  url       = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6349760},
}

@Article{garcia-lorenzo2013review,
  author   = {García-Lorenzo, Daniel and Francis, Simon and Narayanan, Sridar and Arnold, Douglas L. and Collins, D. Louis},
  title    = {Review of automatic segmentation methods of multiple sclerosis white matter lesions on conventional magnetic resonance imaging},
  journal  = {Medical Image Analysis},
  year     = {2013},
  volume   = {17},
  number   = {1},
  pages    = {1--18},
  issn     = {1361-8415},
  abstract = {Magnetic resonance (MR) imaging is often used to characterize and quantify multiple sclerosis (MS) lesions in the brain and spinal cord. The number and volume of lesions have been used to evaluate MS disease burden, to track the progression of the disease and to evaluate the effect of new pharmaceuticals in clinical trials. Accurate identification of MS lesions in MR images is extremely difficult due to variability in lesion location, size and shape in addition to anatomical variability between subjects. Since manual segmentation requires expert knowledge, is time consuming and is subject to intra- and inter-expert variability, many methods have been proposed to automatically segment lesions.The objective of this study was to carry out a systematic review of the literature to evaluate the state of the art in automated multiple sclerosis lesion segmentation. From 1240. hits found initially with PubMed and Google scholar, our selection criteria identified 80 papers that described an automatic lesion segmentation procedure applied to MS. Only 47 of these included quantitative validation with at least one realistic image. In this paper, we describe the complexity of lesion segmentation, classify the automatic MS lesion segmentation methods found, and review the validation methods applied in each of the papers reviewed. Although many segmentation solutions have been proposed, including some with promising results using MRI data obtained on small groups of patients, no single method is widely employed due to performance issues related to the high variability of MS lesion appearance and differences in image acquisition. The challenge remains to provide segmentation techniques that work in all cases regardless of the type of MS, duration of the disease, or MRI protocol, and this within a comprehensive, standardized validation framework. MS lesion segmentation remains an open problem. © 2012 Elsevier B.V.},
  doi      = {10.1016/j.media.2012.09.004},
  keywords = {automatic segmentation, Focal lesions, Magnetic resonance imaging, Multiple sclerosis},
}

@InProceedings{gerber2011manifold,
  author    = {Gerber, Tolga {and} Joshi, Sarang {and} Whitaker, Ross, Samuel {and} Tasdizen},
  title     = {On the {Manifold} {Structure} of the {Space} of {Brain} {Images}},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year      = {2011},
  volume    = {29},
  number    = {0 1},
  pages     = {305--312},
  doi       = {10.1126/scisignal.2001449.Engineering},
  issn      = {2122633255},
}

@Article{gerig2016longitudinal,
  author   = {Gerig, Guido and Fishbaugh, James and Sadeghi, Neda},
  title    = {Longitudinal modeling of appearance and shape and its potential for clinical use},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {114--121},
  note     = {DOI: 10.1016/j.media.2016.06.014},
  abstract = {Clinical assessment routinely uses terms such as development, growth trajectory, degeneration, disease progression, recovery or prediction. This terminology inherently carries the aspect of dynamic processes, suggesting that single measurements in time and cross-sectional comparison may not sufficiently describe spatiotemporal changes. In view of medical imaging, such tasks encourage subject-specific longitudinal imaging. Whereas follow-up, monitoring and prediction are natural tasks in clinical diagnosis of disease progression and of assessment of therapeutic intervention, translation of methodologies for calculation of temporal profiles from longitudinal data to clinical routine still requires significant research and development efforts. Rapid advances in image acquisition technology with significantly reduced acquisition times and with increase of patient comfort favor repeated imaging over the observation period. In view of serial imaging ranging over multiple years, image acquisition faces the challenging issue of scanner standardization and calibration which is crucial for successful spatiotemporal analysis. Longitudinal 3D data, represented as 4D images, capture time-varying anatomy and function. Such data benefits from dedicated analysis methods and tools that make use of the inherent correlation and causality of repeated acquisitions of the same subject. Availability of such data spawned progress in the development of advanced 4D image analysis methodologies that carry the notion of linear and nonlinear regression, now applied to complex, high-dimensional data such as images, image-derived shapes and structures, or a combination thereof. This paper provides examples of recently developed analysis methodologies for 4D image data, primarily focusing on progress in areas of core expertise of the authors. These include spatiotemporal shape modeling and growth trajectories of white matter fiber tracts demonstrated with examples from ongoing longitudinal clinical neuroimaging studies such as analysis of early brain growth in subjects at risk for mental illness and neurodegeneration in Huntington's disease (HD). We will discuss broader aspects of current limitations and need for future research in view of data consistency and analysis methodologies.},
  keywords = {Longitudinal imaging, Mixed-effects modeling, Shape analysis, Shape regression},
  url      = {http://dx.doi.org/10.1016/j.media.2016.06.014},
}

@Article{gernsbacher2015why,
  author   = {Gernsbacher, Morton Ann},
  title    = {Why internet-based education?},
  journal  = {Frontiers in Psychology},
  year     = {2015},
  volume   = {6},
  number   = {JAN},
  pages    = {1--19},
  doi      = {10.3389/fpsyg.2015.00530},
  keywords = {Asynchronous learning, Depth of processing, Higher education, Internet-based learning, online learning, Optimal time of day, Writing skills},
}

@Article{gietema2007monitoring,
  author   = {Gietema, Hester A. and Schilham, Arnold M. and Ginneken, Bram van and Klaveren, Rob J. van and Lammers, Jan Willem J. and Prokop, Mathias},
  title    = {Monitoring of {Smoking}-induced {Emphysema} with {CT} in a {Lung} {Cancer} {Screening} {Setting}: {Detection} of {Real} {Increase} in {Extent} of {Emphysema}1},
  journal  = {http://dx.doi.org/10.1148/radiol.2443061330},
  year     = {2007},
  abstract = {Purpose:To retrospectively establish the minimum increase in emphysema score (ES) required for detection of real increased extent of emphysema with 95\% confidence by using multi?detector row computed tomography (CT) in a lung cancer screening setting. Materials and Methods: The study was a substudy of the NELSON project that was approved by the Dutch Ministry of Health and the ethics committee of each participating hospital, with patient informed consent. For this substudy, original approval and informed consent allowed use of data for future research. Among 1684 men screened with low-dose multi?detector row CT (30 mAs, 16 detector rows, 0.75-mm section thickness) between April 2004 and March 2005, only participants who underwent repeat multi?detector row CT with the same scanner after 3 months because of an indeterminate pulmonary nodule were included. Extent of emphysema was considered to remain stable in this short period. Extent of low-attenuation areas representing emphysema was computed for repeat a...},
  keywords = {ES = emphysema score, FEV1= forced expiratory volume in 1 second},
}

@Article{ginsburg2012automated,
  author   = {Ginsburg, Shoshana B. and Lynch, David a. and Bowler, Russell P. and Schroeder, Joyce D.},
  title    = {Automated {Texture}-based {Quantification} of {Centrilobular} {Nodularity} and {Centrilobular} {Emphysema} in {Chest} {CT} {Images}},
  journal  = {Academic Radiology},
  year     = {2012},
  volume   = {19},
  number   = {10},
  pages    = {1241--1251},
  issn     = {1878-4046 (Electronic) 1076-6332 (Linking)},
  abstract = {Rationale and Objectives: Characterization of smoking-related lung disease typically consists of visual assessment of chest computed tomographic (CT) images for the presence and extent of emphysema and centrilobular nodularity (CN). Quantitative analysis of emphysema and CN may improve the accuracy, reproducibility, and efficiency of chest CT scoring. The purpose of this study was to develop a fully automated texture-based system for the detection and quantification of centrilobular emphysema (CLE) and CN in chest CT images. Materials and Methods: A novel approach was used to prepare regions of interest (ROIs) within the lung parenchyma for representation by texture features associated with the gray-level run-length and gray-level gap-length methods. These texture features were used to train a multiple logistic regression classifier to discriminate between normal lung tissue, CN or " smoker's lung," and CLE. This classifier was trained and evaluated on 24 and 71 chest CT scans, respectively. Results: During training, the classifier correctly classified 89\% of ROIs depicting normal lung tissue, 74\% of ROIs depicting CN, and 95\% of ROIs manifesting CLE. When the performance of the classifier in quantifying extent of CN and CLE was evaluated on 71 chest CT scans, 65\% of ROIs in smokers without CLE were classified as CN, compared to 31\% in nonsmokers (P {\textless} .001) and 28\% in smokers with CLE (P {\textless} .001). Conclusions: The texture-based framework described herein facilitates successful discrimination among normal lung tissue, CN, and CLE and can be used for the automated quantification of smoking-related lung disease. © 2012 AUR.},
  doi      = {10.1016/j.acra.2012.04.020},
  file     = {ginsburg2012automated.pdf:ginsburg2012automated.pdf:PDF},
  keywords = {Centrilobular nodularity, computer-aided diagnosis, Emphysema, texture analysis},
}

@Article{glocker2016s,
  author = {Glocker, Ben},
  title  = {S c p d o},
  year   = {2016},
}

@Article{goetz2014learning,
  author = {Goetz, Michael and Stieltjes, Bram and Weber, Christian and Maier-Hein, Klaus H.},
  title  = {Learning from {Small} {Amounts} of {Labeled} {Data} in a {Brain} {Tumor} {Classification} {Task}},
  year   = {2014},
  number = {Mic},
  pages  = {1--5},
  file   = {goetz2014learning.pdf:goetz2014learning.pdf:PDF},
}

@Article{gomescrowdclustering,
  author   = {Gomes, Ryan and Peter, Caltech and Caltech, Welinder and Krause, Andreas and Caltech, Pietro Perona},
  title    = {Crowdclustering},
  abstract = {Is it possible to crowdsource categorization? Amongst the challenges: (a) each worker has only a partial view of the data, (b) different workers may have differ-ent clustering criteria and may produce different numbers of categories, (c) the underlying category structure may be hierarchical. We propose a Bayesian model of how workers may approach clustering and show how one may infer clusters / categories, as well as worker parameters, using this model. Our experiments, carried out on large collections of images, suggest that Bayesian crowdclustering works well and may be superior to single-expert annotations.},
}

@Article{gonzalez2014mismatched,
  author   = {Gonzalez, C and {Abu-Mostafa}},
  title    = {Mismatched {Training} and {Test} {Distributions} {Can} {Outperform} {Matched} {Ones}},
  journal  = {Neural computation},
  year     = {2014},
  volume   = {1872},
  pages    = {1840--1872},
  month    = dec,
  issn     = {0899-7667},
  abstract = {In learning theory, the training and test sets are assumed to be drawn from the same probability distribution. This assumption is also followed in practical situations,where matching the training and test distributions is considered desirable. Contrary to conventionalwisdom, we show that mismatched training and test distributions in supervised learning can in factoutperformmatcheddistributions intermsof thebottomline, theout- of-sample performance, independent of the target function in question. This surprising result has theoretical and algorithmic ramifications that we discuss. 1},
  doi      = {10.1162/NECO},
  language = {en},
  url      = {http://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00697},
}

@InProceedings{wilson2015human,
  author    = {Wilson, Andrew G and Dann, Christoph and Lucas, Chris and Xing, Eric P},
  title     = {The human kernel},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2015},
  pages     = {2854--2862},
}

@Article{gou2009transfer,
  author = {Gou, Shuiping and Yao, Yao and Jiao, Licheng},
  title  = {Transfer learning for kernel matching pursuit on computer-aided diagnoses},
  year   = {2009},
  number = {July},
  pages  = {749722--749722},
  issn   = {9780819478085},
  doi    = {10.1117/12.832265},
  file   = {gou2009transfer.pdf:gou2009transfer.pdf:PDF},
  groups = {Not-so-supervised papers},
  url    = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.832265},
}

@Article{gregorutti2016correlation,
  author   = {Gregorutti, Baptiste and Michel, Bertrand and Saint-Pierre, Philippe},
  title    = {Correlation and variable importance in random forests},
  journal  = {Statistics and Computing},
  year     = {2016},
  pages    = {1--20},
  note     = {DOI: 10.1007/s11222-016-9646-1},
  abstract = {This paper is about variable selection with the random forests algorithm in presence of correlated predictors. In high-dimensional regression or classification frameworks, variable selection is a difficult task, that becomes even more challenging in the presence of highly correlated predictors. Firstly we provide a theoretical study of the permutation importance measure for an additive regression model. This allows us to describe how the correlation between predictors impacts the permutation importance. Our results motivate the use of the Recursive Feature Elimination (RFE) algorithm for variable selection in this context. This algorithm recursively eliminates the variables using permutation importance measure as a ranking criterion. Next various simulation experiments illustrate the efficiency of the RFE algorithm for selecting a small number of variables together with a good prediction error. Finally, this selection algorithm is tested on the Landsat Satellite data from the UCI Machine Learning Repository.},
  keywords = {Random forests, Supervised learning, Variable importance, Variable selection},
}

@InProceedings{guillaumin2010multiple,
  author    = {Guillaumin, Matthieu and Verbeek, Jakob and Schmid, Cordelia},
  title     = {Multiple instance metric learning from automatically labeled bags of faces},
  booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
  year      = {2010},
  volume    = {6311 LNCS},
  pages     = {634--647},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Metric learning aims at finding a distance that approximates a task-specific notion of semantic similarity. Typically, a Mahalanobis distance is learned from pairs of data labeled as being semantically similar or not. In this paper, we learn such metrics in a weakly supervised setting where "bags" of instances are labeled with "bags" of labels. We formulate the problem as a multiple instance learning (MIL) problem over pairs of bags. If two bags share at least one label, we label the pair positive, and negative otherwise. We propose to learn a metric using those labeled pairs of bags, leading to MildML, for multiple instance logistic discriminant metric learning. MildML iterates between updates of the metric and selection of putative positive pairs of examples from positive pairs of bags. To evaluate our approach, we introduce a large and challenging data set, Labeled Yahoo! News, which we have manually annotated and contains 31147 detected faces of 5873 different people in 20071 images. We group the faces detected in an image into a bag, and group the names detected in the caption into a corresponding set of labels. When the labels come from manual annotation, we find that MildML using the bag-level annotation performs as well as fully supervised metric learning using instance-level annotation. We also consider performance in the case of automatically extracted labels for the bags, where some of the bag labels do not correspond to any example in the bag. In this case MildML works substantially better than relying on noisy instance-level annotations derived from the bag-level annotation by resolving face-name associations in images with their captions.},
  doi       = {10.1007/978-3-642-15549-9_46},
  file      = {guillaumin2010multiple.pdf:guillaumin2010multiple.pdf:PDF},
  isbn      = {3-642-15548-0},
  url       = {http://link.springer.com/10.1007/978-3-642-15549-9_46},
}

@Article{gulshan2016development,
  author   = {Gulshan, Varun and Peng, Lily and Coram, Marc and Stumpe, Martin C. and Wu, Derek and Narayanaswamy, Arunachalam and Venugopalan, Subhashini and Widner, Kasumi and Madams, Tom and Cuadros, Jorge and Kim, Ramasamy and Raman, Rajiv and Nelson, Philip C. and Mega, Jessica L. and Webster, Dale R. and X, Zhang and R, Raman and R, Chakrabarti and MD, Abràmoff and MRK, Mookiah and Y, LeCun and S, Ioffe and C, Szegedy and E, Decencière and G, Quellec and L, Giancardo and K, Solanki and G, Quellec and GH, Bresnick and J, Dean and O, Russakovsky and R, Caruana and A, Krizhevsky and CJ, Clopper and S, Philip and L, Verma and JG, Elmore and JG, Elmore},
  title    = {Development and {Validation} of a {Deep} {Learning} {Algorithm} for {Detection} of {Diabetic} {Retinopathy} in {Retinal} {Fundus} {Photographs}},
  journal  = {JAMA},
  year     = {2016},
  volume   = {304},
  number   = {6},
  pages    = {649--656},
  doi      = {10.1001/JAMA.2016.17216},
  file     = {gulshan2016development.pdf:gulshan2016development.pdf:PDF},
  keywords = {diabetic, diabetic retinopathy, fundus photography, machine learning, macular edema, Neural Networks (Computer)},
}

@InProceedings{gurari2016pull,
  author   = {Gurari, Danna and Jain, Suyog Dutt and Betke, Margrit and Grauman, Kristen},
  title    = {Pull the {Plug}? {Predicting} {If} {Computers} or {Humans} {Should} {Segment} {Images}},
  year     = {2016},
  pages    = {382--391},
  abstract = {Foreground object segmentation is a critical step for many image analysis tasks. While automated methods can produce high-quality results, their failures disappoint users in need of practical solutions. We propose a resource al-location framework for predicting how best to allocate a fixed budget of human annotation effort in order to collect higher quality segmentations for a given batch of images and automated methods. The framework is based on a pro-posed prediction module that estimates the quality of given algorithm-drawn segmentations. We demonstrate the value of the framework for two novel tasks related to " pulling the plug " on computer and human annotators. Specifically, we implement two systems that automatically decide, for a batch of images, when to replace 1) humans with com-puters to create coarse segmentations required to initialize segmentation tools and 2) computers with humans to create final, fine-grained segmentations. Experiments demonstrate the advantage of relying on a mix of human and computer efforts over relying on either resource alone for segmenting objects in three diverse datasets representing visible, phase contrast microscopy, and fluorescence microscopy images.},
  doi      = {10.1109/CVPR.2016.48},
  issn     = {9781467388511},
  journal  = {Computer Vision and Pattern Recognition},
}

@Article{gurari2016investigating,
  author  = {Gurari, Danna and Sameki, Mehrnoosh and Betke, Margrit},
  title   = {Investigating the influence of data familiarity to improve the design of a crowdsourcing image annotation system},
  journal = {Proc. HCOMP},
  year    = {2016},
}

@InProceedings{gurari2014how,
  author    = {Gurari, Danna and Theriault, Diane and Sameki, Mehrnoosh and Betke, Margrit},
  title     = {How to use level set methods to accurately find boundaries of cells in biomedical images? {Evaluation} of six methods paired with automated and crowdsourced initial contours},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year      = {2014},
  abstract  = {Level set methods are popular tools for automatically col-lecting accurate outlines of biological objects in biomedical images and videos. The two main challenges with successfully applying these meth-ods are identifying which among the many options will work well for a particular image set and choosing an initial contour that the method will successfully evolve to the desired final boundary. Little is known about the comparative performance resulting from different initial-contour method pairings. To examine the practical impact of this concern for biomedical applications, we compared six freely available level set methods with 12 different initializations on fluorescence and phase contrast images show-ing cells. The studies revealed that none of the initial-contour method pairings performed well for phase contrast images. These results mo-tivated us to suggest using internet workers to draw estimates of cell boundaries. These crowdsourced boundaries can then serve as initial boundaries for a level set method to produce results closer to the true boundaries. We found that pairing segmentation algorithms with crowd-sourced initial-contours yields over 50 percent points better performance than the other pairings for phase contrast images. Our results yield rec-ommendations for initial-contour method pairings based on image modal-ity and highlight the benefit of engaging non-expert internet workers to successfully leverage level set methods for biomedical images. We invite extensions of this work by sharing all code.},
}

@InProceedings{gurari2015how,
  author    = {Gurari, Danna and Theriault, Diane and Sameki, Mehrnoosh and Isenberg, Brett and Pham, Tuan A and Purwada, Alberto and Solski, Patricia and Walker, Matthew and Zhang, Chentian and Wong, Joyce Y and Betke, Margrit},
  title     = {How to collect segmentations for biomedical images? {A} benchmark evaluating the performance of experts, crowdsourced non-experts, and algorithms},
  booktitle = {Proceedings - 2015 {IEEE} {Winter} {Conference} on {Applications} of {Computer} {Vision}, {WACV} 2015},
  year      = {2015},
  pages     = {1169--1176},
  abstract  = {Analyses of biomedical images often rely on demarcat-ing the boundaries of biological structures (segmentation). While numerous approaches are adopted to address the segmentation problem including collecting annotations from domain-experts and automated algorithms, the lack of comparative benchmarking makes it challenging to determine the current state-of-art, recognize limitations of existing approaches, and identify relevant future research directions. To provide practical guidance, we evalu-ated and compared the performance of trained experts, crowdsourced non-experts, and algorithms for annotating 305 objects coming from six datasets that include phase contrast, fluorescence, and magnetic resonance images. Compared to the gold standard established by expert consensus, we found the best annotators were experts, fol-lowed by non-experts, and then algorithms. This analysis revealed that online paid crowdsourced workers without domain-specific backgrounds are reliable annotators to use as part of the laboratory protocol for segmenting biomedical images. We also found that fusing the seg-mentations created by crowdsourced internet workers and algorithms yielded improved segmentation results over segmentations created by single crowdsourced or algorithm annotations respectively. We invite extensions of our work by sharing our data sets and associated segmentation annotations (http://www.cs.bu.edu/?betke/ BiomedicalImageSegmentation).},
  doi       = {10.1109/WACV.2015.160},
  isbn      = {978-1-4799-6682-0},
}

@Article{guye2010graph,
  author   = {Guye, Maxime and Bettus, Gaelle and Bartolomei, Fabrice and Cozzone, Patrick J.},
  title    = {Graph theoretical analysis of structural and functional connectivity {MRI} in normal and pathological brain networks},
  journal  = {Magnetic Resonance Materials in Physics, Biology and Medicine},
  year     = {2010},
  volume   = {23},
  number   = {5-6},
  pages    = {409--421},
  month    = dec,
  issn     = {0968-5243},
  abstract = {Graph theoretical analysis of structural and functional connectivity MRI data (ie. diffusion tractography or cortical volume correlation and resting-state or task-related (effective) fMRI, respectively) has provided new measures of human brain organization in vivo. The most striking discovery is that the whole-brain network exhibits "small-world" properties shared with many other complex systems (social, technological, information, biological). This topology allows a high efficiency at different spatial and temporal scale with a very low wiring and energy cost. Its modular organization also allows for a high level of adaptation. In addition, degree distribution of brain networks demonstrates highly connected hubs that are crucial for the whole-network functioning. Many of these hubs have been identified in regions previously defined as belonging to the default-mode network (potentially explaining the high basal metabolism of this network) and the attentional networks. This could explain the crucial role of these hub regions in physiology (task-related fMRI data) as well as in pathophysiology. Indeed, such topological definition provides a reliable framework for predicting behavioral consequences of focal or multifocal lesions such as stroke, tumors or multiple sclerosis. It also brings new insights into a better understanding of pathophysiology of many neurological or psychiatric diseases affecting specific local or global brain networks such as epilepsy, Alzheimer's disease or schizophrenia. Graph theoretical analysis of connectivity MRI data provides an outstanding framework to merge anatomical and functional data in order to better understand brain pathologies.},
  doi      = {10.1007/s10334-010-0205-z},
  keywords = {Functional connectivity, Graph theory, Networks, Resting-state fMRI, Small-world, Structural connectivity, Tractography},
  url      = {http://link.springer.com/10.1007/s10334-010-0205-z},
}

@InProceedings{hamari2014does,
  author    = {Hamari, Juho and Koivisto, Jonna and Sarsa, Harri},
  title     = {Does gamification work? - {A} literature review of empirical studies on gamification},
  booktitle = {Hawaii International Conference on System Sciences (HICSS)},
  year      = {2014},
  pages     = {3025--3034},
  abstract  = {This paper reviews peer-reviewed empirical studies on gamification. We create a framework for examining the effects of gamification by drawing from the definitions of gamification and the discussion on motivational affordances. The literature review covers results, independent variables (examined motivational affordances), dependent variables (examined psychological/behavioral outcomes from gamification), the contexts of gamification, and types of studies performed on the gamified systems. The paper examines the state of current research on the topic and points out gaps in existing literature. The review indicates that gamification provides positive effects, however, the effects are greatly dependent on the context in which the gamification is being implemented, as well as on the users using it. The findings of the review provide insight for further studies as well as for the design of gamified systems.},
  doi       = {10.1109/HICSS.2014.377},
  file      = {hamari2014does.pdf:hamari2014does.pdf:PDF},
  issn      = {9781479925049},
}

@Article{hao2016cross,
  author   = {Hao, Tong and Yu, Ai Ling and Peng, Wei and Wang, Bin and Sun, Jin Sheng},
  title    = {Cross domain mitotic cell recognition},
  journal  = {Neurocomputing},
  year     = {2016},
  volume   = {195},
  pages    = {6--12},
  abstract = {Accurate and automated identification of mitosis is essential and challenging to many biomedical applications. To handle this challenge, we propose a novel mitotic cell recognition method by integrating heterogenous data in the framework of cross domain learning. First, we extract the discriminative feature to represent the local structure and textural saliency of individual cell sample. Second, the cell type-dependent classifiers are respectively trained on the target domain and the auxiliary domain and then fused in the framework of adaptive support vector machine for cross-domain learning. The achieved classifier can be implemented for mitotic cell recognition in the cross domain manner. The extensive experiments on two kinds of phase contrast microscopy image sequences (C3H10T1/2\& C2C12) show that the proposed method can leverage the datasets from multiple domains to boost the performance by effectively transferring the knowledge from the auxiliary domain to the target domain. Therefore, it can overcome the inconsistence of feature distributions in different domains.},
  doi      = {10.1016/j.neucom.2015.06.106},
  groups   = {Not-so-supervised papers},
  keywords = {Auxiliary domain, Cross-domain learning, Max margin principle, Mitotic cell, Target domain},
}

@Article{hardin2011clinical,
  author   = {Hardin, Megan and Silverman, Edwin K and Barr, R Graham and Hansel, Nadia N and Schroeder, Joyce D and Make, Barry J and Crapo, James D and Hersh, Craig P},
  title    = {The clinical features of the overlap between {COPD} and asthma},
  journal  = {Respiratory Research},
  year     = {2011},
  volume   = {12},
  number   = {1},
  pages    = {127--127},
  issn     = {1465-993X (Electronic){\textbackslash}r1465-9921 (Linking)},
  abstract = {BACKGROUND: The coexistence of COPD and asthma is widely recognized but has not been well described. This study characterizes clinical features, spirometry, and chest CT scans of smoking subjects with both COPD and asthma.{\textbackslash}n{\textbackslash}nMETHODS: We performed a cross-sectional study comparing subjects with COPD and asthma to subjects with COPD alone in the COPDGene Study.{\textbackslash}n{\textbackslash}nRESULTS: 119 (13\%) of 915 subjects with COPD reported a history of physician-diagnosed asthma. These subjects were younger (61.3 vs 64.7 years old, p=0.0001) with lower lifetime smoking intensity (43.7 vs 55.1 pack years, p=0.0001). More African-Americans reported a history of asthma (33.6\% vs 15.6\%, p{\textless}0.0001). Subjects with COPD and asthma demonstrated worse disease-related quality of life, were more likely to have had a severe COPD exacerbation in the past year, and were more likely to experience frequent exacerbations (OR 3.55 [2.19, 5.75], p{\textless}0.0001). Subjects with COPD and asthma demonstrated greater gas-trapping on chest CT. There were no differences in spirometry or CT measurements of emphysema or airway wall thickness.{\textbackslash}n{\textbackslash}nCONCLUSION: Subjects with COPD and asthma represent a relevant clinical population, with worse health-related quality of life. They experience more frequent and severe respiratory exacerbations despite younger age and reduced lifetime smoking history.{\textbackslash}n{\textbackslash}nTRIAL REGISTRATION: ClinicalTrials.gov: NCT00608764.},
  doi      = {10.1186/1465-9921-12-127},
  file     = {hardin2011clinical.pdf:hardin2011clinical.pdf:PDF},
  keywords = {airway hyperresponsiveness, asthma, Chronic obstructive pulmonary disease, Emphysema, exacerbation},
  url      = {http://respiratory-research.com/content/12/1/127},
}

@Article{harmouche2015probabilistic,
  author   = {Harmouche, Rola and Subbanna, Nagesh K and Collins, D Louis and Arnold, Douglas L and Arbel, Tal},
  title    = {Probabilistic multiple sclerosis lesion classification based on modeling regional intensity variability and local neighborhood {Information}},
  journal  = {IEEE Transactions on Biomedical Engineering},
  year     = {2015},
  volume   = {62},
  number   = {5},
  pages    = {1281--1292},
  month    = may,
  issn     = {0018-9294},
  abstract = {Goal: In this paper, a fully automatic probabilistic method for multiple sclerosis (MS) lesion classification is presented, whereby the posterior probability density function over healthy tissues and two types of lesions (T1-hypointense and T2-hyperintense) is generated at every voxel. Methods: During training, the system explicitly models the spatial variability of the intensity distributions throughout the brain by first segmenting it into distinct anatomical regions and then building regional likelihood distributions for each tissue class based on multimodal magnetic resonance image (MRI) intensities. Local class smoothness is ensured by incorporating neighboring voxel information in the prior probability through Markov random fields. The system is tested on two datasets from real multisite clinical trials consisting of multimodal MRIs from a total of 100 patients with MS. Lesion classification results based on the framework are compared with and without the regional information, as well as with other state-of-The-Art methods against the labels from expert manual raters. The metrics for comparison include Dice overlap, sensitivity, and positive predictive rates for both voxel and lesion classifications. Results: Statistically significant improvements in Dice values ( p {\textless} 0.01), for voxel-based and lesion-based sensitivity values (p {\textless} 0.001), and positive predictive rates (p {\textless} 0.001 and p {\textless} 0.01 respectively) are shown when the proposed method is compared to the method without regional information, and to a widely used method [1]. This holds particularly true in the posterior fossa, an area where classification is very challenging. Significance: The proposed method allows us to provide clinicians with accurate tissue labels for T1-hypointense and T2-hyperintense lesions, two types of lesions that differ in appearance and clinical ramifications, and with a confidence level in the classification, which helps clinicians assess the classification results.},
  doi      = {10.1109/TBME.2014.2385635},
  groups   = {Not-so-supervised papers},
  keywords = {Entropy, Markov random fields, maximum a posteriori, multiple sclerosis lesion classification, probabilistic classification, spatial information},
  url      = {http://www.ncbi.nlm.nih.gov/pubmed/25546852},
}

@Article{hassan2014scale,
  author = {Hassan, Ali and Riaz, Farhan and Shaukat, Arslan},
  title  = {Scale and {Rotation} {Invariant} {Texture} {Classi} fi cation {Using} {Covariate} {Shift} {Methodology}},
  year   = {2014},
  volume = {21},
  number = {3},
  pages  = {321--324},
  file   = {hassan2014scale.pdf:hassan2014scale.pdf:PDF},
}

@Article{hawkes2016clinical,
  author   = {Hawkes, David J.},
  title    = {From clinical imaging and computational models to personalised medicine and image guided interventions},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {50--55},
  note     = {DOI: 10.1016/j.media.2016.06.022},
  abstract = {This short paper describes the development of the UCL Centre for Medical Image Computing (CMIC) from 2006 to 2016, together with reference to historical developments of the Computational Imaging sciences Group (CISG) at Guy's Hospital. Key early work in automated image registration led to developments in image guided surgery and improved cancer diagnosis and therapy. The work is illustrated with examples from neurosurgery, laparoscopic liver and gastric surgery, diagnosis and treatment of prostate cancer and breast cancer, and image guided radiotherapy for lung cancer.},
  keywords = {Image guided interventions, Image registration, Medical image analysis},
}

@InProceedings{heimann2013learning,
  author    = {Heimann, Tobias and Mountney, Peter and John, Matthias and Ionasec, Razvan},
  title     = {Learning without labeling: {Domain} adaptation for ultrasound transducer localization},
  booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
  year      = {2013},
  volume    = {8151 LNCS},
  pages     = {49--56},
  abstract  = {The fusion of image data from trans-esophageal echography (TEE) and X-ray fluoroscopy is attracting increasing interest in minimally-invasive treatment of structural heart disease. In order to calculate the needed transform between both imaging systems, we employ a discriminative learning based approach to localize the TEE transducer in X-ray images. Instead of time-consuming manual labeling, we generate the required training data automatically from a single volumetric image of the transducer. In order to adapt this system to real X-ray data, we use unlabeled fluoroscopy images to estimate differences in feature space density and correct covariate shift by instance weighting. An evaluation on more than 1900 images reveals that our approach reduces detection failures by 95\% compared to cross validation on the test set and improves the localization error from 1.5 to 0.8 mm. Due to the automatic generation of training data, the proposed system is highly flexible and can be adapted to any medical device with minimal efforts.},
  doi2      = {10.1007/978-3-642-40760-4_7},
  isbn2     = {978-3-642-40759-8},
  keywords  = {Algorithms, Automated, Computer-Assisted, Fluoroscopy, Humans, Image Enhancement, Image Interpretation, instrumentation, Interventional, methods, Multimodal Imaging, Pattern Recognition, Reproducibility of Results, Sensitivity and Specificity, Staining and Labeling, Transducers, Ultrasonography},
  language  = {eng},
}

@InProceedings{hernandez-duranmetric,
  author   = {Hernandez-Duran, Mairelys and Plasencia-Calana, Yenisel and Mendez-Vazquez, Heydi},
  title    = {Metric learning in the dissimilarity space to improve low-resolution face recognition},
  pages    = {1--8},
  keywords = {dissimilarity space, face recog-, low-resolution, metric learning},
}

@Article{hernandez-gonzalez2016weak,
  author   = {Hernández-González, Jerónimo and Inza, Iñaki and Lozano, Jose A.},
  title    = {Weak supervision and other non-standard classification problems: {A} taxonomy},
  journal  = {Pattern Recognition Letters},
  year     = {2016},
  volume   = {69},
  pages    = {49--55},
  month    = jan,
  abstract = {In recent years, different researchers in the machine learning community have presented new classification frameworks which go beyond the standard supervised classification in different aspects. Specifically, a wide spectrum of novel frameworks that use partially labeled data in the construction of classifiers has been studied. With the objective of drawing up a description of the state-of-the-art, three identifying characteristics of these novel frameworks have been considered: (1) the relationship between instances and labels of a problem, which may be beyond the one-instance one-label standard, (2) the possible provision of partial class information for the training examples, and (3) the possible provision of partial class information also for the examples in the prediction stage. These three ideas have been formulated as axes of a comprehensive taxonomy that organizes the state-of-the-art. The proposed organization allows us both to understand similarities/differences among the different classification problems already presented in the literature as well as to discover unexplored frameworks that might be seen as further challenges and research opportunities. A representative set of state-of-the-art problems has been used to illustrate the novel taxonomy and support the discussion.},
  doi      = {10.1016/j.patrec.2015.10.008},
  keywords = {Degrees of supervision, Partially supervised classification, Weakly supervised classification},
  url      = {http://linkinghub.elsevier.com/retrieve/pii/S0167865515003505},
}

@Article{heussel2006quantification,
  author   = {Heussel, C P and Achenbach, T and Buschsieweke, C and Kuhnigk, J and Weinheimer, O and Hammer, G and Düber, C and Kauczor, H-U},
  title    = {[{Quantification} of pulmonary emphysema in multislice-{CT} using different software tools].},
  journal  = {RöFo : Fortschritte auf dem Gebiete der Röntgenstrahlen und der Nuklearmedizin},
  year     = {2006},
  volume   = {178},
  number   = {10},
  pages    = {987--98},
  month    = oct,
  abstract = {PURPOSE The data records of thin-section MSCT of the lung with approx. 300 images are difficult to use in manual evaluation. A computer-assisted pre-diagnosis can help with reporting. Furthermore, post-processing techniques, for instance, for quantification of emphysema on the basis of three-dimensional anatomical information might be improved and the workflow might be further automated. MATERIALS AND METHODS The results of 4 programs (Pulmo, Volume, YACTA and PulmoFUNC) for the quantitative analysis of emphysema (lung and emphysema volume, mean lung density and emphysema index) of 30 consecutive thin-section MSCT datasets with different emphysema severity levels were compared. The classification result of the YACTA program for different types of emphysema was also analyzed. RESULTS Pulmo and Volume have a median operating time of 105 and 59 minutes respectively due to the necessity for extensive manual correction of the lung segmentation. The programs PulmoFUNC and YACTA, which are automated to a large extent, have a median runtime of 26 and 16 minutes, respectively. The evaluation with Pulmo and Volume using 2 different datasets resulted in implausible values. PulmoFUNC crashed with 2 other datasets in a reproducible manner. Only with YACTA could all graphic datasets be evaluated. The lung volume, emphysema volume, emphysema index and mean lung density determined by YACTA and PulmoFUNC are significantly larger than the corresponding values of Volume and Pulmo (differences: Volume: 119 cm(3)/65 cm(3)/1 \%/17 HU, Pulmo: 60 cm(3)/96 cm(3)/1 \%/37 HU). Classification of the emphysema type was in agreement with that of the radiologist in 26 panlobular cases, in 22 paraseptalen cases and in 15 centrilobular emphysema cases. CONCLUSION The substantial expenditure of time obstructs the employment of quantitative emphysema analysis in the clinical routine. The results of YACTA and PulmoFUNC are affected by the dedicated exclusion of the tracheobronchial system. These fully automatic tools enable not only fast quantification without manual interaction, but also a reproducible measurement without user dependence.},
  doi      = {10.1055/s-2006-926823},
  url      = {http://www.ncbi.nlm.nih.gov/pubmed/17021978},
}

@Article{hofman2013rotterdam,
  author   = {Hofman, Albert and Murad, Sarwa Darwish and Van Duijn, Cornelia M. and Franco, Oscar H. and Goedegebure, André and Arfan Ikram, M. and Klaver, Caroline C W and Nijsten, Tamar E C and Peeters, Robin P. and Stricker, Bruno H Ch and Tiemeier, Henning W. and Uitterlinden, André G. and Vernooij, Meike W.},
  title    = {The rotterdam study: 2014 objectives and design update},
  journal  = {European Journal of Epidemiology},
  year     = {2013},
  volume   = {28},
  number   = {2013},
  pages    = {889--926},
  issn     = {1573-7284 (Electronic){\textbackslash}n0393-2990 (Linking)},
  abstract = {The Rotterdam Study is a prospective cohort study ongoing since 1990 in the city of Rotterdam in The Netherlands. The study targets cardiovascular, endocrine, hepatic, neurological, ophthalmic, psychiatric, dermatological, oncological, and respiratory diseases. As of 2008, 14,926 subjects aged 45 years or over comprise the Rotterdam Study cohort. The findings of the Rotterdam Study have been presented in over a 1,000 research articles and reports (see www.erasmus-epidemiology.nl/rotterdamstudy ). This article gives the rationale of the study and its design. It also presents a summary of the major findings and an update of the objectives and methods.},
  doi      = {10.1007/s10654-013-9866-z},
  file     = {hofman2013rotterdam.pdf:hofman2013rotterdam.pdf:PDF},
  keywords = {Cardiovascular diseases, Cohort study, Dermatological diseases, Endocrine diseases, Epidemiologic methods, Genetic epidemiology, Liver diseases, Neurological diseases, Ophthalmic diseases, Otolaryngological diseases, Pharmacoepidemiology, Psychiatric diseases, Respiratory diseases},
}

@Article{hogg2013small,
  author   = {Hogg, James C. and McDonough, John E. and Suzuki, Masaru},
  title    = {Small airway obstruction in {COPD}: {New} insights based on micro-{CT} imaging and {MRI} imaging},
  journal  = {Chest},
  year     = {2013},
  volume   = {143},
  pages    = {1436--1443},
  abstract = {The increase in total cross-sectional area in the distal airways of the human lung enhances the mixing of each tidal breath with end-expiratory gas volume by slowing bulk flow and increasing gas diffusion. However, this transition also favors the deposition of airborne particulates in this region because they diffuse 600 times slower than gases. Furthermore, the persistent deposition of toxic airborne particulates stimulates a chronic inflammatory immune cell infiltration and tissue repair and remodeling process that increases the resistance in airways {\textless}2 mm in diameter four to 40-fold in COPD. This increase was originally attributed to lumen narrowing because it increases resistance in proportion to the change in lumen radius raised to the fourth power. In contrast, removal of one-half the number of tubes arranged in parallel is required to double their resistance, and approximately 90\% need to be removed to explain the increase in resistance measured in COPD. However, recent reexamination of this problem based on micro-CT imaging indicates that terminal bronchioles are both narrowed and reduced to 10\% of the control values in the centrilobular and 25\% in the panlobular emphysematous phenotype of very severe (GOLD [Global Initiative for Chronic Obstructive Lung Disease] grade IV) COPD. These new data indicate that both narrowing and reduction in numbers of terminal bronchioles contribute to the rapid decline in FEV? that leads to severe airway obstruction in COPD. Moreover, the observation that terminal bronchiolar loss precedes the onset of emphysematous destruction suggests this destruction begins in the very early stages of COPD.},
  doi      = {10.1378/chest.12-1766},
}

@Article{holzinger2016interactive,
  author  = {Holzinger, Andreas},
  title   = {Interactive machine learning for health informatics: when do we need the human-in-the-loop?},
  journal = {Brain Informatics},
  year    = {2016},
  volume  = {3},
  number  = {2},
  pages   = {119--131},
  month   = jun,
  doi     = {10.1007/s40708-016-0042-6},
  url     = {http://link.springer.com/10.1007/s40708-016-0042-6},
}

@InCollection{hor2015scandent,
  author    = {Hor, Soheil and Moradi, Mehdi},
  title     = {Scandent tree: {A} random forest learning method for incomplete multimodal datasets},
  booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
  year      = {2015},
  isbn      = {978-3-319-24552-2},
  note      = {DOI: 10.1007/978-3-319-24553-9\_85},
  abstract  = {We propose a solution for training random forests on incom- plete multimodal datasets where many of the samples are non-randomly missing a large portion of the most discriminative features. For this goal, we present the novel concept of scandent trees. These are trees trained on the features common to all samples that mimic the feature space division structure of a supportdecision tree trained on all features.Weuse the forest resulting from ensembling these trees as a classification model.We evalu- ate the performance of our method for different multimodal sample sizes and singlemodal feature set sizes using a publicly available clinical dataset of heart disease patients and a prostate cancer dataset withMRI and gene expression modalities. The results show that the area under ROC curve of the proposed method is less sensitive to themultimodal dataset sample size, and that it outperforms the imputation methods especially when the ratio of multimodal data to all available data is small.},
}

@Article{hor2016learning,
  author   = {Hor, Soheil and Moradi, Mehdi},
  title    = {Learning in data-limited multimodal scenarios: scandent decision forests and tree-based features},
  journal  = {Medical Image Analysis},
  year     = {2016},
  pages    = {1--12},
  abstract = {Incomplete and inconsistent datasets often pose difficulties in multimodal studies. We introduce the concept of scandent decision trees to tackle these difficulties. Scandent trees are decision trees that optimally mimic the partitioning of the data determined by another decision tree, and crucially, use only a subset of the feature set. We show how scandent trees can be used to enhance the performance of decision forests trained on a small number of multimodal samples when we have access to larger datasets with vastly incomplete feature sets. Additionally, we introduce the concept of tree-based feature transforms in the decision forest paradigm. When combined with scandent trees, the tree-based feature transforms enable us to train a classifier on a rich multimodal dataset, and use it to classify samples with only a subset of features of the training data. Using this methodology, we build a model trained on MRI and PET images of the ADNI dataset, and then test it on cases with only MRI data. We show that this is significantly more effective in staging of cognitive impairments compared to a similar decision forest model trained and tested on MRI only, or one that uses other kinds of feature transform applied to the MRI data.},
  doi      = {10.1016/j.media.2016.07.012},
  keywords = {Incomplete data analysis, Multimodal data analysis},
}

@Article{hsiaooptimizing,
  author = {Hsiao, Cho-yi and Lo, Hung-yi and Yin, Tu-chun and Lin, Shou-de},
  title  = {Optimizing {Specificity} under {Perfect} {Sensitivity} for {Medical} {Data} {Classification}},
}

@InProceedings{huang2011ultrasonic,
  author    = {Huang, Jianhua and Hu, Cong and Zhang, Yingtao and Liu, Jiafeng and Tang, Xianglong},
  title     = {Ultrasonic classification of breast tumors based on multi-instance learning},
  year      = {2011},
  editor    = {Liu, Jianguo and Ding, Mingyue and Chen, Zhong},
  pages     = {80050R--80050R},
  month     = nov,
  publisher = {International Society for Optics and Photonics},
  doi       = {10.1117/12.900946},
  keywords  = {Algorithms, Breast, feature extraction, Ultrasonics, Ultrasonography},
  url       = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.900946},
}

@Article{huang2007correcting,
  author   = {Huang, Jiayuan and Smola, Alexander J and Gretton, Arthur and Borgwardt, Karsten M and Schölkopf, Bernhard},
  title    = {Correcting {Sample} {Selection} {Bias} by {Unlabeled} {Data}},
  journal  = {Nips},
  year     = {2007},
  pages    = {601--608},
  issn     = {1049-5258},
  abstract = {We consider the scenario where training and test data are drawn from{\textbackslash}ndifferent distributions, commonly referred to as sample selection{\textbackslash}nbias. Most algorithms for this setting try to first recover sampling{\textbackslash}ndistributions and then make appropriate corrections based on the{\textbackslash}ndistribution estimate. We present a nonparametric method which directly{\textbackslash}nproduces resampling weights without distribution estimation.Our method{\textbackslash}nworks by matching distributions between training and testing sets{\textbackslash}nin feature space. Experimental results demonstrate that our method{\textbackslash}nworks well in practice.},
  keywords = {domain-adaptation, sample-selection-bias},
  url      = {http://books.nips.cc/papers/files/nips19/NIPS2006_0915.pdf},
}

@Article{huang2009learning,
  author   = {Huang, Junzhou and Zhang, Tong and Metaxas, Dimitris},
  title    = {Learning with {Structured} {Sparsity}},
  journal  = {Computer},
  year     = {2009},
  volume   = {12},
  pages    = {1--30},
  issn     = {978-1-60558-516-1},
  abstract = {This paper investigates a new learning formulation called structured sparsity, which is a natural extension of the standard sparsity concept in statistical learning and compressive sensing. By allowing arbitrary structures{\textbackslash}non the feature set, this concept generalizes the group sparsity idea that has become popular in recent years. A general theory is developed for learning with{\textbackslash}nstructured sparsity, based on the notion of coding complexity associated with the structure. It is shown that if the coding complexity of the target signal is small, then one can achieve improved performance by using coding complexity regularization methods, which generalize the standard sparse regularization. Moreover, a structured greedy algorithm is proposed to efficiently solve the{\textbackslash}nstructured sparsity problem. It is shown that the greedy algorithm approximately solves the coding complexity optimization problem under appropriate conditions. Experiments are included to demonstrate the advantage{\textbackslash}nof structured sparsity over standard sparsity on some real applications.},
  doi      = {10.1145/1553374.1553429},
  keywords = {Methodology, Statistics},
  url      = {http://arxiv.org/abs/0903.3002v2},
}

@Article{husz2009mind,
  author = {Husz, Ferenc},
  title  = {Mind {Reading} by {Machine} {Learning} : {A} {Doubly} {Bayesian} {Method} for {Inferring} {Mental} {Representations}},
  year   = {2009},
  pages  = {2810--2815},
}

@Article{huynh2016digital,
  author   = {Huynh, Benjamin Q. and Giger, Maryellen L.},
  title    = {Digital mammographic tumor classification using transfer learning from deep convolutional neural networks},
  journal  = {Journal of Medical Imaging},
  year     = {2016},
  volume   = {3},
  number   = {3},
  pages    = {34501--34501},
  abstract = {Convolutional neural networks (CNNs) show potential for computer-aided diagnosis (CADx) by learning features directly from the image data instead of using analytically extracted features. However, CNNs are difficult to train from scratch for medical images due to small sample sizes and variations in tumor presentations. Instead, transfer learning can be used to extract tumor information from medical images via CNNs originally pretrained for nonmedical tasks, alleviating the need for large datasets. Our database includes 219 breast lesions (607 full-field digital mammographic images). We compared support vector machine classifiers based on the CNN-extracted image features and our prior computer-extracted tumor features in the task of distinguishing between benign and malignant breast lesions. Five-fold cross validation (by lesion) was conducted with the area under the receiver operating characteristic (ROC) curve as the performance metric. Results show that classifiers based on CNN-extracted features (with transfer learning) perform comparably to those using analytically extracted features [area under the ROC curve [Formula: see text]]. Further, the performance of ensemble classifiers based on both types was significantly better than that of either classifier type alone ([Formula: see text] versus 0.81, [Formula: see text]). We conclude that transfer learning can improve current CADx methods while also providing standalone classifiers without large datasets, facilitating machine-learning methods in radiomics and precision medicine.},
  doi2     = {10.1117/1.JMI.3.3.034501},
  keywords = {classification using transfer learning, from deep convolutional neural, ital mammographic tumor},
  language = {eng},
  url2     = {http://medicalimaging.spiedigitallibrary.org/article.aspx?doi=10.1117/1.JMI.3.3.034501},
}

@InProceedings{iglesias2010agreement,
  author    = {Iglesias, Juan Eugenio and Liu, Cheng-Yi and Thompson, Paul and Tu, Zhuowen},
  title     = {Agreement-based semi-supervised learning for skull stripping.},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year      = {2010},
  volume    = {13},
  number    = {Pt 3},
  pages     = {147--154},
  abstract  = {Learning-based approaches have become increasingly practical in medical imaging. For a supervised learning strategy, the quality of the trained algorithm (usually a classifier) is heavily dependent on the amount, as well as quality, of the available training data. It is often very time-consuming to obtain the ground truth manual delineations. In this paper, we propose a semi-supervised learning algorithm and show its application to skull stripping in brain MRI. The resulting method takes advantage of existing state-of-the-art systems, such as BET and FreeSurfer, to sample unlabeled data in an agreement-based framework. Using just two labeled and a set of unlabeled MRI scans, a voxel-based random forest classifier is trained to perform the skull stripping. Our system is practical, and it displays significant improvement over supervised approaches, BET and FreeSurfer in two datasets (60 test images).},
  groups    = {Not-so-supervised papers},
  keywords  = {Algorithms, anatomy \& histology, Artificial Intelligence, Automated, Brain, Computer-Assisted, Humans, Image Enhancement, Image Interpretation, Magnetic resonance imaging, methods, Pattern Recognition, Reproducibility of Results, Sensitivity and Specificity, Signal Processing, Skull, Subtraction Technique},
  language  = {eng},
}

@Article{irshad2015crowdsourcing,
  author   = {Irshad, H and Montaser-Kouhsari, L and Waltz, G and Bucur, O and Nowak, J A and Dong, F and Knoblauch, N W and Beck, A H},
  title    = {Crowdsourcing image annotation for nucleus detection and segmentation in computational pathology: evaluating experts, automated methods, and the crowd.},
  journal  = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
  year     = {2015},
  issn     = {2335-6936 (Print)},
  abstract = {The development of tools in computational pathology to assist physicians and biomedical scientists in the diagnosis of disease requires access to high-quality annotated images for algorithm learning and evaluation. Generating high-quality expert-derived annotations is time-consuming and expensive. We explore the use of crowdsourcing for rapidly obtaining annotations for two core tasks in com- putational pathology: nucleus detection and nucleus segmentation. We designed and implemented crowdsourcing experiments using the CrowdFlower platform, which provides access to a large set of labor channel partners that accesses and manages millions of contributors worldwide. We obtained annotations from four types of annotators and compared concordance across these groups. We obtained: crowdsourced annotations for nucleus detection and segmentation on a total of 810 images; annotations using automated methods on 810 images; annotations from research fellows for detection and segmentation on 477 and 455 images, respectively; and expert pathologist-derived annotations for detection and segmentation on 80 and 63 images, respectively. For the crowdsourced annotations, we evaluated performance across a range of contributor skill levels (1, 2, or 3). The crowdsourced annotations (4,860 images in total) were completed in only a fraction of the time and cost required for obtaining annotations using traditional methods. For the nucleus detection task, the research fellow-derived annotations showed the strongest concordance with the expert pathologist- derived annotations (F-M =93.68\%), followed by the crowd-sourced contributor levels 1,2, and 3 and the automated method, which showed relatively similar performance (F-M = 87.84\%, 88.49\%, 87.26\%, and 86.99\%, respectively). For the nucleus segmentation task, the crowdsourced contributor level 3-derived annotations, research fellow-derived annotations, and automated method showed the strongest concordance with the expert pathologist-derived annotations (F-M = 66.41\%, 65.93\%, and 65.36\%, respectively), followed by the contributor levels 2 and 1 (60.89\% and 60.87\%, respectively). When the research fellows were used as a gold-standard for the segmentation task, all three con- tributor levels of the crowdsourced annotations significantly outperformed the automated method (F-M = 62.21\%, 62.47\%, and 65.15\% vs. 51.92\%). Aggregating multiple annotations from the crowd to obtain a consensus annotation resulted in the strongest performance for the crowd-sourced segmentation. For both detection and segmentation, crowd-sourced performance is strongest with small images (400 × 400 pixels) and degrades significantly with the use of larger images (600 × 600 and 800 × 800 pixels). We conclude that crowdsourcing to non-experts can be used for large-scale labeling microtasks in computational pathology and offers a new approach for the rapid generation of labeled images for algorithm development and evaluation.},
  doi      = {10.1142/9789814644730_0029},
}

@Article{ivanovici2008optical,
  author   = {Ivanovici, M. and Scurtu, V.},
  title    = {Optical disc detection in retinal images},
  journal  = {11th International Conference on Optimization of Electrical and Electronic Equipment, OPTIM 2008},
  year     = {2008},
  pages    = {119--124},
  issn     = {1424415446},
  abstract = {Lasers are currently used for a wide spectrum of medical applications, including the treatment of eye disorders. When combined with digital image processing techniques, the issue of retinal image segmentation becomes of high importance. In this paper, our purpose is twofold: i) to identify and briefly present the existing approaches for the retinal image segmentation and ii) to test our hypothesis that the Viola-Jones algorithm-initially designed for face detection-can be suited as well for optical disc detection.},
  doi      = {10.1109/OPTIM.2008.4602510},
}

@Article{janssensranking,
  author   = {Janssens, Jeroen H M},
  title    = {Ranking {Images} on {Semantic} {Attributes} using {Human} {Computation}},
  abstract = {We investigate to what extent a large group of human workers is able to produce collaboratively a global ranking of images, based on a single semantic attribute. To this end, we have developed CollaboRank, which is a method that formulates and distributes tasks to human workers, and aggregates their personal rankings into a global ranking. Our results show that human workers can achieve a relatively high consensus, depending on the type of the semantic attribute.},
}

@Article{jenssen2006cauchyschwarz,
  author   = {Jenssen, Robert and Principe, Jose C. and Erdogmus, Deniz and Eltoft, Torbjørn},
  title    = {The {Cauchy}?{Schwarz} divergence and {Parzen} windowing: {Connections} to graph theory and {Mercer} kernels},
  journal  = {Journal of the Franklin Institute},
  year     = {2006},
  volume   = {343},
  number   = {6},
  pages    = {614--629},
  abstract = {This paper contributes a tutorial level discussion of some interesting properties of the recent Cauchy?Schwarz (CS) divergence measure between probability density functions. This measure brings together elements from several different machine learning fields, namely information theory, graph theory and Mercer kernel and spectral theory. These connections are revealed when estimating the CS divergence non-parametrically using the Parzen window technique for density estimation. An important consequence of these connections is that they enhance our understanding of the different machine learning schemes relative to each other.},
  doi      = {10.1016/j.jfranklin.2006.03.018},
}

@Article{jerebko2007robust,
  author   = {Jerebko, A K and Schmidt, G P and Zhou, X and Bi, J and Anand, V and Liu, J and Schoenberg, S and Schmuecking, I and Kiefer, B and Krishnan, A},
  title    = {Robust parametric modeling approach based on domain knowledge for computer aided detection of vertebrae column metastases in {MRI}.},
  journal  = {Information processing in medical imaging : proceedings of the ... conference},
  year     = {2007},
  volume   = {20},
  pages    = {713--724},
  abstract = {This study evaluates a robust parametric modeling approach for computer-aided detection (CAD) of vertebrae column metastases in whole-body MRI. Our method involves constructing a model based on geometric primitives from purely anatomical knowledge of organ shapes and rough variability limits. The basic intensity range of primary 'simple' objects in our models is derived from expert knowledge of image formation and appearance for certain tissue types. We formulated the classification problem as a multiple instance learning problem for which a novel algorithm is designed based on Fisher's linear discriminant analysis. Evaluation of metastases detection algorithm is done on a separate test set as well as on the training set via leave-one-patient-out approach.},
  keywords = {Algorithms, Artificial Intelligence, Automated, Biological, Cluster Analysis, Computer-Assisted, Computer Simulation, diagnosis, Humans, Image Enhancement, Image Interpretation, Imaging, Magnetic resonance imaging, methods, Models, Pattern Recognition, Reproducibility of Results, secondary, Sensitivity and Specificity, Spinal Neoplasms, Three-Dimensional, Whole Body Imaging},
  language = {eng},
}

@Article{jiang2013novel,
  author   = {Jiang, Huiyan and Zheng, Ruiping and Yi, Dehui and Zhao, Di},
  title    = {A novel multiinstance learning approach for liver cancer recognition on abdominal {CT} images based on {CPSO}-{SVM} and {IO}.},
  journal  = {Computational and mathematical methods in medicine},
  year     = {2013},
  volume   = {2013},
  pages    = {434969--434969},
  abstract = {A novel multi-instance learning (MIL) method is proposed to recognize liver cancer with abdominal CT images based on instance optimization (IO) and support vector machine with parameters optimized by a combination algorithm of particle swarm optimization and local optimization (CPSO-SVM). Introducing MIL into liver cancer recognition can solve the problem of multiple regions of interest classification. The images we use in the experiments are liver CT images extracted from abdominal CT images. The proposed method consists of two main steps: (1) obtaining the key instances through IO by texture features and a classification threshold in classification of instances with CPSO-SVM and (2) predicting unknown samples with the key instances and the classification threshold. By extracting the instances equally based on the entire image, the proposed method can ignore the procedure of tumor region segmentation and lower the demand of segmentation accuracy of liver region. The normal SVM method and two MIL algorithms, Citation-kNN algorithm and WEMISVM algorithm, have been chosen as comparing algorithms. The experimental results show that the proposed method can effectively recognize liver cancer images from two kinds of cancer CT images and greatly improve the recognition accuracy.},
  doi      = {10.1155/2013/434969},
  keywords = {Algorithms, Artifacts, Artificial Intelligence, Automated, Computer-Assisted, Databases, diagnosis, Factual, Humans, Liver Neoplasms, methods, Pathology, Pattern Recognition, radiography, Reproducibility of Results, Software, Support Vector Machine, Tomography, X-Ray Computed},
  language = {eng},
}

@Article{joskowicz2016computer,
  author   = {Joskowicz, Leo and Hazan, Eric J.},
  title    = {Computer {Aided} {Orthopaedic} {Surgery}: {Incremental} shift or paradigm change?},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {84--90},
  abstract = {Computer Aided Orthopaedic Surgery (CAOS) is now about 25 years old. Unlike Neurosurgery, Computer Aided Surgery has not become the standard of care in Orthopaedic Surgery. In this paper, we provide the technical and clinical context raised by this observation in an attempt to elucidate the reasons for this state of affairs. We start with a brief outline of the history of CAOS, review the main CAOS technologies, and describe how they are evaluated. We then identify some of the current publications in the field and present the opposing views on their clinical impact and their acceptance by the orthopaedic community worldwide. We focus on total knee replacement surgery as a case study and present current clinical results and contrasting opinions on CAOS technologies. We then discuss the challenges and opportunities for research in medical image analysis in CAOS and in musculoskeletal radiology. We conclude with a suggestion that while CAOS acceptance may be more moderate than that of other fields in surgery, it still has a place in the arsenal of useful tools available to orthopaedic surgeons.},
  doi      = {10.1016/j.media.2016.06.036},
  keywords = {Computer Aided Orthopaedic Surgery, Image guided surgery, Medical robotics, Review article for 20th anniversary issue},
  url      = {http://dx.doi.org/10.1016/j.media.2016.06.036},
}

@Article{joulin2015learning,
  author   = {Joulin, Armand and Maaten, Laurens van der and Jabri, Allan and Vasilache, Nicolas},
  title    = {Learning {Visual} {Features} from {Large} {Weakly} {Supervised} {Data}},
  year     = {2015},
  pages    = {8--8},
  abstract = {Convolutional networks trained on large supervised dataset produce visual features which form the basis for the state-of-the-art in many computer-vision problems. Fur- ther improvements of these visual features will likely require even larger manually labeled data sets, which severely lim- its the pace at which progress can be made. In this pa- per, we explore the potential of leveraging massive, weakly- labeled image collections for learning good visual features. We train convolutional networks on a dataset of 100 million Flickr photos and captions, and show that these networks produce features that perform well in a range of vision prob- lems. We also show that the networks appropriately capture word similarity, and learn correspondences between different languages.},
  file     = {joulin2015learning.pdf:joulin2015learning.pdf:PDF},
  url      = {http://arxiv.org/abs/1511.0225},
}

@Article{jozefowiczempirical,
  author   = {Jozefowicz, Rafal and Zaremba, Wojciech and Sutskever, Ilya},
  title    = {An {Empirical} {Exploration} of {Recurrent} {Network} {Architectures}},
  abstract = {The Recurrent Neural Network (RNN) is an ex-tremely powerful sequence model that is often difficult to train. The Long Short-Term Memory (LSTM) is a specific RNN architecture whose design makes it much easier to train. While wildly successful in practice, the LSTM's archi-tecture appears to be ad-hoc so it is not clear if it is optimal, and the significance of its individual components is unclear. In this work, we aim to determine whether the LSTM architecture is optimal or whether much better architectures exist. We conducted a thor-ough architecture search where we evaluated over ten thousand different RNN architectures, and identified an architecture that outperforms both the LSTM and the recently-introduced Gated Recurrent Unit (GRU) on some but not all tasks. We found that adding a bias of 1 to the LSTM's forget gate closes the gap between the LSTM and the GRU.},
}

@Article{kamnitsas2016efficient,
  author   = {Kamnitsas, Konstantinos and Ledig, Christian and Newcombe, Virginia F J and Simpson, Joanna P and Kane, Andrew D and Menon, David K and Rueckert, Daniel and Glocker, Ben},
  title    = {Efficient {Multi}-{Scale} 3D {CNN} with {Fully} {Connected} {CRF} for {Accurate} {Brain} {Lesion} {Segmentation}},
  journal  = {arXiv},
  year     = {2016},
  pages    = {1603.05959--1603.05959},
  abstract = {We propose a dual pathway, 11-layers deep, three-dimensional Convolutional Neural Network for the challenging task of brain lesion segmentation. The devised architecture is the result of an in-depth analysis of the limitations of current networks proposed for similar applications. To overcome the computational burden of processing 3D medical scans, we have developed an efficient and effective dense training scheme which automatically adapts to the inherent class imbalance present in the data. The training makes use of the notion of image segments which joins multiple patches from the same image into one pass through the network. Further, we analyze the development of deeper, thus more discriminative 3D CNNs. In order to incorporate both local and larger contextual information, we employ a dual pathway architecture that processes the input images at multiple scales simultaneously. For post-processing of the network's soft segmentation, we use a 3D fully connected Conditional Random Field which effectively removes false positives. Our pipeline is extensively evaluated on three challenging tasks of lesion segmentation in multi-channel MRI patient data with traumatic brain injuries, brain tumors, and ischemic stroke. We improve on the state-of-the-art for all three applications, with top ranking performance on the public benchmarks BRATS 2015 and ISLES 2015. Our method is computationally efficient and achieves a segmentation of a brain scan in less than six minutes. The source code of our implementation is made publicly available.},
  doi2     = {10.1109/TMI.2016.2553401},
  file     = {kamnitsas2016efficient.pdf:kamnitsas2016efficient.pdf:PDF},
  groups   = {Not-so-supervised papers},
  issn2    = {1662-4548 (Print){\textbackslash}r1662-453X (Linking)},
  url2     = {http://arxiv.org/abs/1603.05959},
}

@Article{kandaswamy2016high,
  author   = {Kandaswamy, Chetak and Silva, Luís M and Alexandre, Luís A and Santos, Jorge M},
  title    = {High-{Content} {Analysis} of {Breast} {Cancer} {Using} {Single}-{Cell} {Deep} {Transfer} {Learning}.},
  journal  = {Journal of biomolecular screening},
  year     = {2016},
  volume   = {21},
  number   = {3},
  pages    = {252--9},
  month    = mar,
  abstract = {High-content analysis has revolutionized cancer drug discovery by identifying substances that alter the phenotype of a cell, which prevents tumor growth and metastasis. The high-resolution biofluorescence images from assays allow precise quantitative measures enabling the distinction of small molecules of a host cell from a tumor. In this work, we are particularly interested in the application of deep neural networks (DNNs), a cutting-edge machine learning method, to the classification of compounds in chemical mechanisms of action (MOAs). Compound classification has been performed using image-based profiling methods sometimes combined with feature reduction methods such as principal component analysis or factor analysis. In this article, we map the input features of each cell to a particular MOA class without using any treatment-level profiles or feature reduction methods. To the best of our knowledge, this is the first application of DNN in this domain, leveraging single-cell information. Furthermore, we use deep transfer learning (DTL) to alleviate the intensive and computational demanding effort of searching the huge parameter's space of a DNN. Results show that using this approach, we obtain a 30\% speedup and a 2\% accuracy improvement.},
  doi      = {10.1177/1087057115623451},
  groups   = {Not-so-supervised papers},
  keywords = {cancer drug discovery, deep transfer learning, high-content screening, image analysis},
  url      = {http://www.ncbi.nlm.nih.gov/pubmed/26746583},
}

@Article{kandemirinstance,
  author   = {Kandemir, Melih and Hamprecht, Fred A},
  title    = {Instance {Label} {Prediction} by {Dirichlet} {Process} {Multiple} {Instance} {Learning}},
  abstract = {We propose a generative Bayesian model that predicts instance labels from weak (bag-level) supervision. We solve this problem by simulta-neously modeling class distributions by Gaussian mixture models and inferring the class labels of positive bag instances that satisfy the multiple in-stance constraints. We employ Dirichlet process priors on mixture weights to automate model se-lection, and efficiently infer model parameters and positive bag instances by a constrained varia-tional Bayes procedure. Our method improves on the state-of-the-art of instance classification from weak supervision on 20 benchmark text catego-rization data sets and one histopathology cancer diagnosis data set.},
  groups   = {Not-so-supervised papers},
}

@Article{kapur2016increasing,
  author   = {Kapur, Tina and Pieper, Steve and Fedorov, Andriy and Fillion-Robin, J. C. and Halle, Michael and O'Donnell, Lauren and Lasso, Andras and Ungi, Tamas and Pinter, Csaba and Finet, Julien and Pujol, Sonia and Jagadeesan, Jayender and Tokuda, Junichi and Norton, Isaiah and Estepar, Raul San Jose and Gering, David and Aerts, Hugo J W L and Jakab, Marianna and Hata, Nobuhiko and Ibanez, Luiz and Blezek, Daniel and Miller, Jim and Aylward, Stephen and Grimson, W. Eric L and Fichtinger, Gabor and Wells, William M. and Lorensen, William E. and Schroeder, Will and Kikinis, Ron},
  title    = {Increasing the impact of medical image computing using community-based open-access hackathons: {The} {NA}-{MIC} and 3D {Slicer} experience},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {176--180},
  note     = {DOI: 10.1016/j.media.2016.06.035},
  abstract = {The National Alliance for Medical Image Computing (NA-MIC) was launched in 2004 with the goal of investigating and developing an open source software infrastructure for the extraction of information and knowledge from medical images using computational methods. Several leading research and engineering groups participated in this effort that was funded by the US National Institutes of Health through a variety of infrastructure grants. This effort transformed 3D Slicer from an internal, Boston-based, academic research software application into a professionally maintained, robust, open source platform with an international leadership and developer and user communities. Critical improvements to the widely used underlying open source libraries and tools???VTK, ITK, CMake, CDash, DCMTK???were an additional consequence of this effort. This project has contributed to close to a thousand peer-reviewed publications and a growing portfolio of US and international funded efforts expanding the use of these tools in new medical computing applications every year. In this editorial, we discuss what we believe are gaps in the way medical image computing is pursued today; how a well-executed research platform can enable discovery, innovation and reproducible science (???Open Science???); and how our quest to build such a software platform has evolved into a productive and rewarding social engineering exercise in building an open-access community with a shared vision.},
  keywords = {3D Slicer, Hackathon, Medical image computing, NA-MIC, Open access, Open science, Open source, Project week, Reproducible research},
  url      = {http://dx.doi.org/10.1016/j.media.2016.06.035},
}

@Article{karri2017transfer,
  author   = {Karri, S. P. K. and Chakraborty, Debjani and Chatterjee, Jyotirmoy},
  title    = {Transfer learning based classification of optical coherence tomography images with diabetic macular edema and dry age-related macular degeneration},
  journal  = {Biomedical Optics Express},
  year     = {2017},
  volume   = {8},
  number   = {2},
  pages    = {579--579},
  month    = feb,
  abstract = {We present an algorithm for identifying retinal pathologies given retinal optical coherence tomography (OCT) images. Our approach fine-tunes a pre-trained convolutional neural network (CNN), GoogLeNet, to improve its prediction capability (compared to random initialization training) and identifies salient responses during prediction to understand learned filter characteristics. We considered a data set containing subjects with diabetic macular edema, or dry age-related macular degeneration, or no pathology. The fine-tuned CNN could effectively identify pathologies in comparison to classical learning. Our algorithm aims to demonstrate that models trained on non-medical images can be fine-tuned for classifying OCT images with limited training data.},
  doi      = {10.1364/BOE.8.000579},
  keywords = {Clinical applications, image analysis, Ophthalmology, Optical coherence tomography, Pattern Recognition},
  url      = {https://www.osapublishing.org/abstract.cfm?URI=boe-8-2-579},
}

@Article{kazantzi2014automated,
  author  = {Kazantzi, Alexandra and Costaridou, Lena and Skiadopoulos, Spyros and Korfiatis, Panayiotis and Karahaliou, Anna and Daoussis, Dimitris and Andonopoulos, Andreas and Kalogeropoulou, Christina},
  title   = {Automated 3D ?nterstitial {Lung} {Disease} ?xtent {Quantification}: {Performance} {Evaluation} and {Correlation} to {PFTs}},
  journal = {Journal of Digital Imaging},
  year    = {2014},
  volume  = {27},
  number  = {3},
  pages   = {380--391},
  month   = jun,
  doi     = {10.1007/s10278-013-9670-z},
  url     = {http://link.springer.com/10.1007/s10278-013-9670-z},
}

@Article{kempdiscovery,
  author   = {Kemp, Charles and Tenenbaum, Joshua B and Shiffrin, Richard M},
  title    = {The discovery of structural form},
  abstract = {Algorithms for finding structure in data have become increasingly important both as tools for scientific data analysis and as models of human learning, yet they suffer from a critical limitation. Scientists discover qualitatively new forms of structure in observed data: For instance, Linnaeus recognized the hierarchical organiza-tion of biological species, and Mendeleev recognized the periodic structure of the chemical elements. Analogous insights play a pivotal role in cognitive development: Children discover that object category labels can be organized into hierarchies, friendship net-works are organized into cliques, and comparative relations (e.g., ''bigger than'' or ''better than'') respect a transitive order. Stan-dard algorithms, however, can only learn structures of a single form that must be specified in advance: For instance, algorithms for hierarchical clustering create tree structures, whereas algorithms for dimensionality-reduction create low-dimensional spaces. Here, we present a computational model that learns structures of many different forms and that discovers which form is best for a given dataset. The model makes probabilistic inferences over a space of graph grammars representing trees, linear orders, multidimen-sional spaces, rings, dominance hierarchies, cliques, and other forms and successfully discovers the underlying structure of a variety of physical, biological, and social domains. Our approach brings structure learning methods closer to human abilities and may lead to a deeper computational understanding of cognitive development.},
}

@Article{khosla2012undoing,
  author   = {Khosla, Aditya and Zhou, Tinghui and Malisiewicz, Tomasz and Efros, Alexei A. and Torralba, Antonio},
  title    = {Undoing the damage of dataset bias},
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year     = {2012},
  volume   = {7572 LNCS},
  number   = {PART 1},
  pages    = {158--171},
  issn     = {9783642337178},
  abstract = {The presence of bias in existing object recognition datasets is now well-known in the computer vision community. While it remains in question whether creating an unbiased dataset is possible given limited resources, in this work we propose a discriminative framework that directly exploits dataset bias during training. In particular, our model learns two sets of weights: (1) bias vectors associated with each individual dataset, and (2) visual world weights that are common to all datasets, which are learned by undoing the associated bias from each dataset. The visual world weights are expected to be our best possible approximation to the object model trained on an unbiased dataset, and thus tend to have good generalization ability. We demonstrate the effectiveness of our model by applying the learned weights to a novel, unseen dataset, and report superior results for both classification and detection tasks compared to a classical SVM that does not account for the presence of bias. Overall, we find that it is beneficial to explicitly account for bias when combining multiple datasets.},
  doi      = {10.1007/978-3-642-33718-5_12},
  file     = {khosla2012undoing.pdf:khosla2012undoing.pdf:PDF},
  url      = {http://link.springer.com/10.1007/978-3-642-33718-5_12},
}

@Article{kim2013graph,
  author   = {Kim, Dokyoon and Kim, Sungeun and Risacher, Shannon L and Shen, Li and Ritchie, Marylyn D and Weiner, Michael W and Saykin, Andrew J and Nho, Kwangsik},
  title    = {A {Graph}-{Based} {Integration} of {Multimodal} {Brain} {Imaging} {Data} for the {Detection} of {Early} {Mild} {Cognitive} {Impairment} ({E}-{MCI}).},
  journal  = {MICCAI workshop on multimodal brain image analysis},
  year     = {2013},
  volume   = {8159},
  pages    = {159--169},
  abstract = {Alzheimer's disease (AD) is the most common cause of dementia in older adults. By the time an individual has been diagnosed with AD, it may be too late for potential disease modifying therapy to strongly influence outcome. Therefore, it is critical to develop better diagnostic tools that can recognize AD at early symptomatic and especially pre-symptomatic stages. Mild cognitive impairment (MCI), introduced to describe a prodromal stage of AD, is presently classified into early and late stages (E-MCI, L-MCI) based on severity. Using a graph-based semi-supervised learning (SSL) method to integrate multimodal brain imaging data and select valid imaging-based predictors for optimizing prediction accuracy, we developed a model to differentiate E-MCI from healthy controls (HC) for early detection of AD. Multimodal brain imaging scans (MRI and PET) of 174 E-MCI and 98 HC participants from the Alzheimer's Disease Neuroimaging Initiative (ADNI) cohort were used in this analysis. Mean targeted region-of-interest (ROI) values extracted from structural MRI (voxel-based morphometry (VBM) and FreeSurfer V5) and PET (FDG and Florbetapir) scans were used as features. Our results show that the graph-based SSL classifiers outperformed support vector machines for this task and the best performance was obtained with 66.8\% cross-validated AUC (area under the ROC curve) when FDG and FreeSurfer datasets were integrated. Valid imaging-based phenotypes selected from our approach included ROI values extracted from temporal lobe, hippocampus, and amygdala. Employing a graph-based SSL approach with multimodal brain imaging data appears to have substantial potential for detecting E-MCI for early detection of prodromal AD warranting further investigation.},
  doi      = {10.1007/978-3-319-02126-3_16},
  language = {ENG},
}

@Article{kim2010tree,
  author  = {Kim, Seyoung and Xing, Eric},
  title   = {Tree-{Guided} {Group} {Lasso} for {Multi}-{Task} {Regression} with {Structured} {Sparsity}},
  journal = {Proceedings of the 27th International Conference on Machine Learning},
  year    = {2010},
  url     = {http://repository.cmu.edu/machine_learning/237},
}

@Article{kleingame,
  author  = {Klein, A},
  title   = {A game for crowdsourcing the segmentation of {BigBrain} data},
  journal = {rio.pensoft.net},
  url     = {http://rio.pensoft.net/lib/ajax_srv/article_elements_srv.php?action=download_pdf&item_id=8816},
}

@Article{knutssonnormalized,
  author = {Knutsson, Hans and West, C},
  title  = {Normalized and {Differential} {Convolution}},
  number = {x},
}

@Article{kockelkorn2016optimization,
  author   = {Kockelkorn, Thessa T. J. P. and Ramos, Rui and Ramos, José and de Jong, Pim A. and Schaefer-Prokop, Cornelia M. and Wittenberg, Rianne and Tiehuis, Audrey M. and Grutters, Jan C. and Viergever, Max A. and van Ginneken, Bram},
  title    = {Optimization {Strategies} for {Interactive} {Classification} of {Interstitial} {Lung} {Disease} {Textures}},
  journal  = {Frontiers in ICT},
  year     = {2016},
  volume   = {3},
  pages    = {33--33},
  month    = dec,
  abstract = {For computerized analysis of textures in interstitial lung disease, manual annotations of lung tissue are necessary. Since making these annotations is labor-intensive, we previously proposed an interactive annotation framework. In this framework, observers iteratively trained a classifier to distinguish the different texture types by correcting its classification errors. In this work, we investigated three ways to extend this approach, in order to decrease the amount of user interaction required to annotate all lung tissue in a CT scan. First, we conducted automatic classification experiments to test how data from previously annotated scans can be used for classification of the scan under consideration. We compared the performance of a classifier trained on data from one observer, a classifier trained on data from multiple observers, a classifier trained on consensus training data, and an ensemble of classifiers, each trained on data from different sources. Experiments were conducted without and with texture selection. In the former case, training data from all 8 textures was used. In the latter, only training data from the texture types present in the scan were used, and the observer would have to indicate textures contained in the scan to be analyzed. Second, we simulated interactive annotation to test the effects of (1) asking observers to perform texture selection before the start of annotation, (2) the use of a classifier trained on data from previously annotated scans at the start of annotation, when the interactive classifier is untrained, and (3) allowing observers to choose which interactive or automatic classification results they wanted to correct. Finally, various strategies for selecting the classification results that were presented to the observer were considered. Classification accuracies for all possible interactive annotation scenarios were compared. Using the best performing protocol, in which observers select the textures that should be distinguished in the scan and in which they can choose which classification results to use for correction, a median accuracy of 88\% was reached. The results obtained using this protocol were significantly better than results obtained with other interactive or automatic classification protocols.},
  doi      = {10.3389/fict.2016.00033},
  keywords = {Classification, computer-aided diagnosis, Interactive annotation, Interstitial Lung Disease, texture},
  url      = {http://journal.frontiersin.org/article/10.3389/fict.2016.00033/full},
}

@Article{kohlbergerevaluating,
  author   = {Kohlberger, Timo and Singh, Vivek and Alvino, Chris and Bahlmann, Claus and Grady, Leo},
  title    = {Evaluating {Segmentation} {Error} {Without} {Ground} {Truth}},
  abstract = {The automatic delineation of the boundaries of organs and other anatomical structures is a key component of many medical image processing systems. In this paper we present a generic learning approach based on a novel space of segmentation features, which can be trained to predict the overlap error and Dice coefficient of an arbitrary organ segmentation without knowing the ground truth delineation. We show the regressor to be much stronger a predictor of these error metrics than the responses of Probabilistic Boosting Classifiers trained on the segmentation boundary. The presented approach not only allows us to build reliable confidence measures and fidelity checks, but also to rank several segmentation hypotheses against each other during online usage of the segmentation algorithm in clinical practice.},
}

@Article{kotzias2014deep,
  author   = {Kotzias, Dimitrios and Denil, Misha and Blunsom, Phil and de Freitas, Nando},
  title    = {Deep {Multi}-{Instance} {Transfer} {Learning}},
  year     = {2014},
  pages    = {1--9},
  month    = nov,
  abstract = {We present a new approach for transferring knowledge from groups to individuals that comprise them. We evaluate our method in text, by inferring the ratings of individual sentences using full-review ratings. This approach, which combines ideas from transfer learning, deep learning and multi-instance learning, reduces the need for laborious human labelling of fine-grained data when abundant labels are available at the group level.},
  file     = {kotzias2014deepmiltransfer.pdf:kotzias2014deepmiltransfer.pdf:PDF},
  url      = {http://arxiv.org/abs/1411.3128},
}

@Article{kraus2016classifying,
  author  = {Kraus, Oren Z. and Ba, Jimmy Lei and Frey, Brendan J.},
  title   = {Classifying and segmenting microscopy images with deep multiple instance learning},
  journal = {Bioinformatics},
  year    = {2016},
  volume  = {32},
  number  = {12},
  pages   = {i52--i59},
  month   = jun,
  doi     = {10.1093/bioinformatics/btw252},
  url     = {http://bioinformatics.oxfordjournals.org/lookup/doi/10.1093/bioinformatics/btw252},
}

@Article{kriegeskorte2013representational,
  author   = {Kriegeskorte, Nikolaus and Kievit, Rogier A.},
  title    = {Representational geometry: integrating cognition, computation, and the brain.},
  journal  = {Trends in cognitive sciences},
  year     = {2013},
  volume   = {17},
  number   = {8},
  pages    = {401--12},
  month    = aug,
  abstract = {The cognitive concept of representation plays a key role in theories of brain information processing. However, linking neuronal activity to representational content and cognitive theory remains challenging. Recent studies have characterized the representational geometry of neural population codes by means of representational distance matrices, enabling researchers to compare representations across stages of processing and to test cognitive and computational theories. Representational geometry provides a useful intermediate level of description, capturing both the information represented in a neuronal population code and the format in which it is represented. We review recent insights gained with this approach in perception, memory, cognition, and action. Analyses of representational geometry can compare representations between models and the brain, and promise to explain brain computation as transformation of representational similarity structure.},
  doi      = {10.1016/j.tics.2013.06.007},
  file     = {kriegeskorte2013representational.pdf:kriegeskorte2013representational.pdf:PDF},
  keywords = {Brain, Brain: physiology, Cognition, Cognition: physiology, Computer Simulation, Humans, Mathematics, Models, Neurological},
  url      = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3730178&tool=pmcentrez&rendertype=abstract},
}

@Article{kriegeskorte2009circular,
  author   = {Kriegeskorte, Nikolaus and Simmons, W Kyle and Bellgowan, Patrick S F and Baker, Chris I},
  title    = {Circular analysis in systems neuroscience: the dangers of double dipping.},
  journal  = {Nature neuroscience},
  year     = {2009},
  volume   = {12},
  number   = {5},
  pages    = {535--540},
  issn     = {1546-1726 (Electronic) 1097-6256 (Linking)},
  abstract = {A neuroscientific experiment typically generates a large amount of data, of which only a small fraction is analyzed in detail and presented in a publication. However, selection among noisy measurements can render circular an otherwise appropriate analysis and invalidate results. Here we argue that systems neuroscience needs to adjust some widespread practices to avoid the circularity that can arise from selection. In particular, 'double dipping', the use of the same dataset for selection and selective analysis, will give distorted descriptive statistics and invalid statistical inference whenever the results statistics are not inherently independent of the selection criteria under the null hypothesis. To demonstrate the problem, we apply widely used analyses to noise data known to not contain the experimental effects in question. Spurious effects can appear in the context of both univariate activation analysis and multivariate pattern-information analysis. We suggest a policy for avoiding circularity.},
  doi      = {10.1167/8.6.88},
}

@InCollection{krishnapuram2008multiple,
  author    = {Krishnapuram, Balaji and Stoeckel, Jonathan and Raykar, Vikas and Rao, Bharat and Bamberger, Philippe and Ratner, Eli and Merlet, Nicolas and Stainvas, Inna and Abramov, Menahem and Manevitch, Alexandra},
  title     = {Multiple-{Instance} {Learning} {Improves} {CAD} {Detection} of {Masses} in {Digital} {Mammography}},
  booktitle = {Digital {Mammography}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2008},
  pages     = {350--357},
  address   = {Berlin, Heidelberg},
  note      = {DOI: 10.1007/978-3-540-70538-3\_49},
  url       = {http://link.springer.com/10.1007/978-3-540-70538-3_49},
}

@Article{kruggel2008texture,
  author   = {Kruggel, Frithjof and Paul, Joseph Suresh and Gertz, Hermann-Josef},
  title    = {Texture-based segmentation of diffuse lesions of the brain?s white matter},
  journal  = {NeuroImage},
  year     = {2008},
  volume   = {39},
  number   = {3},
  pages    = {987--996},
  abstract = {Diffuse lesions of the white matter of the human brain are common pathological findings in magnetic resonance images of elderly subjects. These lesions are typically caused by small vessel diseases (e.g., due to hypertension, diabetes), and related to cognitive decline. Because these lesions are inhomogeneous, unsharp, and faint, but show an intensity pattern that is different from the adjacent healthy tissue, a segmentation based on texture properties is proposed here. This method was successfully applied to a set of 116 image data sets of elderly subjects. Quantitative measures for the lesion load are derived that compare well with results from experts that visually rated lesions on a semiquantitative scale. Texture-based segmentation can be considered as a general method for lesion segmentation, and an outline for adapting this method to similar problems is presented.},
  annote   = {WMLPreprocessing within-scan correction of intensity imhomogeneities and within-group normalization of image intensity and contrast116 subjects, same scannerCooc features and PCA. Gaussian mixture model, lesion probability mapHigh sensitivity, low specificity (false positives)Train/test unclear},
  doi      = {10.1016/j.neuroimage.2007.09.058},
}

@Article{krupinski2016special,
  author   = {Krupinski, Elizabeth A.},
  title    = {Special {Section} {Guest} {Editorial}: {Medical} {Image} {Perception}: {Understanding} {How} {Radiologists} {Understand} {Images}},
  journal  = {Journal of Medical Imaging},
  year     = {2016},
  volume   = {3},
  number   = {1},
  pages    = {011001--011001},
  month    = mar,
  doi      = {10.1117/1.JMI.3.1.011001},
  keywords = {Breast, Diffuse optical imaging, Image quality, Medicine, Visual system},
  url      = {http://medicalimaging.spiedigitallibrary.org/article.aspx?doi=10.1117/1.JMI.3.1.011001},
}

@Article{krupinski2010no,
  author   = {Krupinski, Elizabeth A.},
  title    = {No {Title}},
  year     = {2010},
  volume   = {72},
  number   = {5},
  pages    = {1205--1217},
  month    = jul,
  issn     = {1943-393X (Electronic){\textbackslash}r1943-3921 (Linking)},
  abstract = {Medical images constitute a core portion of the information a physician utilizes to render diagnostic and treatment decisions. At a fundamental level, this diagnostic process involves two basic processes: visually inspecting the image (visual perception) and rendering an interpretation (cognition). The likelihood of error in the interpretation of medical images is, unfortunately, not negligible. Errors do occur, and patients' lives are impacted, underscoring our need to understand how physicians interact with the information in an image during the interpretation process. With improved understanding, we can develop ways to further improve decision making and, thus, to improve patient care. The science of medical image perception is dedicated to understanding and improving the clinical interpretation process.},
  doi      = {10.3758/APP.72.5.1205},
  keywords = {Attention, Clinical Competence, Cognition, Decision Making, Diagnostic Errors, Diagnostic Imaging, Diagnostic Imaging: instrumentation, Diagnostic Imaging: psychology, Discrimination Learning, Fixation, Humans, Lung Neoplasms, Lung Neoplasms: radiography, Mammography, Mammography: instrumentation, Mental Fatigue, Mental Fatigue: psychology, Observer Variation, Ocular, orientation, Pattern Recognition, Radiographic Image Enhancement, ROC Curve, Saccades, Tomography, Visual, Visual Perception, Workload, Workload: psychology, X-Ray Computed, X-Ray Computed: instrumentation},
  url      = {http://www.springerlink.com/index/10.3758/APP.72.5.1205},
}

@Article{kulis2011what,
  author  = {Kulis, Brian and Saenko, Kate and Darrell, Trevor and Brian Kulis, {and} Trevor Darrell, Kate Saenko},
  title   = {What {You} {Saw} is {Not} {What} {You} {Get}: {Domain} {Adaptation} {Using} {Asymmetric}},
  journal = {Cvpr},
  year    = {2011},
  url     = {http://www.eecs.berkeley.edu/~kulis/pubs/cvpr_adapt.pdf},
}

@Article{kumar2010learning,
  author   = {Kumar, Abhishek and Daumé Iii, Hal},
  title    = {Learning {Task} {Grouping} and {Overlap} in {Multi}-{Task} {Learning}},
  year     = {2010},
  abstract = {In the paradigm of multi-task learning, mul-tiple related prediction tasks are learned jointly, sharing information across the tasks. We propose a framework for multi-task learn-ing that enables one to selectively share the information across the tasks. We assume that each task parameter vector is a linear com-bination of a finite number of underlying ba-sis tasks. The coefficients of the linear com-bination are sparse in nature and the over-lap in the sparsity patterns of two tasks con-trols the amount of sharing across these. Our model is based on the assumption that task parameters within a group lie in a low dimen-sional subspace but allows the tasks in differ-ent groups to overlap with each other in one or more bases. Experimental results on four datasets show that our approach outperforms competing methods.},
  keywords = {Multi-task learning, Sparsity},
}

@Article{kundu2014domain,
  author   = {Kundu, Gourab},
  title    = {Domain adaptation with minimal training},
  year     = {2014},
  file     = {kundu2014domain.pdf:kundu2014domain.pdf:PDF},
  keywords = {domain adaptation, Named Entity Recognition, Transfer learning},
  url      = {https://www.ideals.illinois.edu/handle/2142/72928},
}

@Article{kuo2016objective,
  author   = {Kuo, Wieying and Andrinopoulou, Eleni-Rosalina and Perez-Rovira, Adria and Ozturk, Hadiye and de Bruijne, Marleen and Tiddens, Harm A.W.M.},
  title    = {Objective airway artery dimensions compared to {CT} scoring methods assessing structural cystic fibrosis lung disease},
  journal  = {Journal of Cystic Fibrosis},
  year     = {2016},
  doi      = {10.1016/j.jcf.2016.05.015},
  file     = {kuo2016objective.pdf:kuo2016objective.pdf:PDF},
  keywords = {aa, abbreviations, aic, airway and artery, airway wall thickening, akaike information criterion, awt, be, Bronchiectasis, cf, cf-ct, Chest CT, Computed tomography, ct, cystic, Cystic fibrosis, cystic fi brosis, fibrosis computed tomography scorings, module, mp, Pediatrics, Scoring},
  url      = {http://dx.doi.org/10.1016/j.jcf.2016.05.015},
}

@InProceedings{kswgrers2014classification,
  author    = {{Kurogol S and Washko G R and Estepar R S}},
  title     = {Classification of emphysema patterns with a multi-class hierarchical approach},
  booktitle = {International Symposium on Biomedical Imaging (ISBI)},
  year      = {2014},
  pages     = {1031--1034},
  abstract  = {Emphysema has distinct and well-defined visually apparent CT patterns called centrilobular and panlobular emphysema. Existing studies concentrated on the classification of these patterns but they have not looked at the complete evolution of this disease as the destruction of lung parenchyma progresses from normal lung tissue to mild, moderate, and severe disease with complete effacement of the lung architecture. In this paper, we discretize this continuous process into five classes of increasing disease severity and construct a training set of 1161 CT patches. We exploit three solutions to this monotonic multi-class classification problem: a global rankSVM for ranking, hierarchical SVM for classification and a combination of these two, which we call a hierarchical rankSVM. Results showed that both hierarchical approaches were computationally efficient. The classification accuracies were slightly better for hierarchical SVM. However, in addition to classification, ranking approaches also provided a ranking of patterns, which can be utilized as a continuous disease progression score. In terms of the classification accuracy and ratio of pair-wise constraints satisfied, hierarchical rankSVM outperformed the global rankSVM.},
  doi       = {10.1109/ISBI.2014.6868049.RANKING},
  issn      = {9781467319614},
  keywords  = {COPD, Emphysema, multi-class classification, ranksvm},
  url       = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6868049},
}

@Article{kutsuna2012active,
  author  = {Kutsuna, Natsumaro and Higaki, Takumi and Matsunaga, Sachihiro and Otsuki, Tomoshi and Yamaguchi, Masayuki and Fujii, Hirofumi and Hasezawa, Seiichiro},
  title   = {Active learning framework with iterative clustering for bioimage classification},
  journal = {Nature Communications},
  year    = {2012},
  volume  = {3},
  pages   = {1032--1032},
  month   = aug,
  doi     = {10.1038/ncomms2030},
  url     = {http://www.nature.com/doifinder/10.1038/ncomms2030},
}

@Article{langone2016supervised,
  author   = {Langone, Rocco and Suykens, Johan A.K.},
  title    = {Supervised aggregated feature learning for multiple instance classification},
  journal  = {Information Sciences},
  year     = {2016},
  abstract = {This paper introduces a novel algorithm, called Supervised Aggregated FEature learning or SAFE, which combines both (local) instance level and (global) bag level information in a joint framework to address the multiple instance classification task. In this realm, the collective assumption is used to express the relationship between the instance labels and the bag labels, by means of taking the sum as aggregation rule. The proposed model is formulated within a least squares support vector machine setting, where an unsupervised core model (either kernel PCA or kernel spectral clustering) at the instance level is combined with a classification loss function at the bag level. The corresponding dual problem consists of solving a linear system, and the bag classifier is obtained by aggregating the instance scores. Synthetic experiments suggest that SAFE is advantageous when the instances from both positive and negative bags can be naturally grouped in the same cluster. Moreover, real-life experiments indicate that SAFE is competitive with the best state-of-the-art methods.},
  doi      = {10.1016/j.ins.2016.09.060},
}

@Article{lecun2015deep,
  author  = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  title   = {Deep learning},
  journal = {Nature},
  year    = {2015},
  volume  = {521},
  number  = {7553},
  pages   = {436--444},
  month   = may,
  doi     = {10.1038/nature14539},
  url     = {http://www.nature.com/doifinder/10.1038/nature14539},
}

@Article{levitin2016measuring,
  author   = {Levitin, Daniel J. and Grafton, Scott T.},
  title    = {Measuring the representational space of music with {fMRI}: a case study with {Sting}},
  journal  = {Neurocase},
  year     = {2016},
  volume   = {22},
  number   = {6},
  pages    = {548--557},
  month    = nov,
  abstract = {ABSTRACTFunctional brain imaging has revealed much about the neuroanatomical substrates of higher cognition, including music, language, learning, and memory. The technique lends itself to studying of groups of individuals. In contrast, the nature of expert performance is typically studied through the examination of exceptional individuals using behavioral case studies and retrospective biography. Here, we combined fMRI and the study of an individual who is a world-class expert musician and composer in order to better understand the neural underpinnings of his music perception and cognition, in particular, his mental representations for music. We used state of the art multivoxel pattern analysis (MVPA) and representational dissimilarity analysis (RDA) in a fixed set of brain regions to test three exploratory hypotheses with the musician Sting: (1) Composing would recruit neutral structures that are both unique and distinguishable from other creative acts, such as composing prose or visual art; (2) listenin...},
  doi      = {10.1080/13554794.2016.1216572},
  keywords = {case studies, mental imagery, Music cognition, MVPA, neuroimaging},
  url      = {https://www.tandfonline.com/doi/full/10.1080/13554794.2016.1216572},
}

@Article{li2010variable,
  author   = {Li, Caiyan and Li, Hongzhe},
  title    = {{VARIABLE} {SELECTION} {AND} {REGRESSION} {ANALYSIS} {FOR} {GRAPH}-{STRUCTURED} {COVARIATES} {WITH} {AN} {APPLICATION} {TO} {GENOMICS}.},
  journal  = {The annals of applied statistics},
  year     = {2010},
  volume   = {4},
  number   = {3},
  pages    = {1498--1516},
  month    = sep,
  abstract = {Graphs and networks are common ways of depicting information. In biology, many different biological processes are represented by graphs, such as regulatory networks, metabolic pathways and protein-protein interaction networks. This kind of a priori use of graphs is a useful supplement to the standard numerical data such as microarray gene expression data. In this paper, we consider the problem of regression analysis and variable selection when the covariates are linked on a graph. We study a graph-constrained regularization procedure and its theoretical properties for regression analysis to take into account the neighborhood information of the variables measured on a graph, where a smoothness penalty on the coefficients is defined as a quadratic form of the Laplacian matrix associated with the graph. We establish estimation and model selection consistency results and provide estimation bounds for both fixed and diverging numbers of parameters in regression models. We demonstrate by simulations and a real dataset that the proposed procedure can lead to better variable selection and prediction than existing methods that ignore the graph information associated with the covariates.},
  doi      = {10.1214/10-AOAS332},
  url      = {http://www.ncbi.nlm.nih.gov/pubmed/22916087},
}

@Article{li2015multiplea,
  author   = {Li, Chao and Shi, Cen and Zhang, Huan and Chen, Yazhu and Zhang, Su},
  title    = {Multiple instance learning for computer aided detection and diagnosis of gastric cancer with dual-energy {CT} imaging},
  journal  = {Journal of Biomedical Informatics},
  year     = {2015},
  volume   = {57},
  pages    = {358--368},
  month    = oct,
  abstract = {Multiple instance learning algorithms have been increasingly utilized in computer aided detection and diagnosis field. In this study, we propose a novel multiple instance learning method for the identification of tumor invasion depth of gastric cancer with dual-energy CT imaging. In the proposed scheme, two level features, bag-level features and instance-level features are extracted for subsequent processing and classification work. For instance-level features, there is some ambiguity in assigning labels to selected patches. An improved Citation-KNN method is presented to solve this problem. Compared with benchmarking state-of-the-art multiple instance learning algorithms using the same clinical dataset, the proposed algorithm can achieve improved results. The experimental evaluation is performed using leave-one-out cross validation with the total accuracy of 0.7692. The proposed multiple instance learning algorithm serves as an alternative method for computer aided diagnosis and identification of tumor invasion depth of gastric cancer with dual-energy CT imaging techniques.},
  doi      = {10.1016/j.jbi.2015.08.017},
  keywords = {Circular Gabor features, Computer aided diagnosis, Dual-energy CT, gastric cancer, multiple instance learning},
  language = {eng},
  url      = {http://dx.doi.org/10.1016/j.jbi.2015.08.017},
}

@Article{li2012breast,
  author   = {Li, Jun-Bao and Yu, Yang and Yang, Zhi-Ming and Tang, Lin-Lin},
  title    = {Breast tissue image classification based on {Semi}-supervised {Locality} {Discriminant} {Projection} with {Kernels}.},
  journal  = {Journal of medical systems},
  year     = {2012},
  volume   = {36},
  number   = {5},
  pages    = {2779--2786},
  month    = oct,
  abstract = {Breast tissue classification is an important and effective way for computer aided diagnosis of breast cancer. We present Semi-supervised Locality Discriminant Projections with Kernels for breast cancer classification. The contributions of this work lie in: 1) Semi-supervised learning is used into Locality Preserving Projections (LPP) to enhance its performance using side-information together with the unlabelled training samples, while current algorithms only consider the side-information but ignoring the unlabeled training samples. 2) Kernel trick is applied into Semi-supervised LPP to improve its ability in the nonlinear classification. 3) The framework of breast cancer classification with Semi-supervised LPP with kernels is presented. Many experiments are implemented on four breast tissue databases to testify and evaluate the feasibility and affectivity of the proposed scheme.},
  doi      = {10.1007/s10916-011-9754-6},
  keywords = {Algorithms, Artificial Intelligence, Breast Neoplasms, Classification, Computer-Assisted, diagnosis, Humans, Image Interpretation, Linear Models, methods, Principal Component Analysis, radiography},
  language = {eng},
}

@InCollection{li2015multiple,
  author    = {Li, Wenqi and Zhang, Jianguo and McKenna, Stephen J.},
  title     = {Multiple Instance Cancer Detection by Boosting Regularised Trees},
  publisher = {Springer International Publishing},
  year      = {2015},
  pages     = {645--652},
  note      = {DOI: 10.1007/978-3-319-24553-9\_79},
  file      = {li2015multiple.pdf:li2015multiple.pdf:PDF;li2015multiple2.pdf:li2015multiple2.pdf:PDF},
  url2      = {http://link.springer.com/10.1007/978-3-319-24553-9_79},
}

@Article{li2016pushing,
  author   = {Li, Wenyuan and Liu, Chun Chi and Kang, Shuli and Li, Jian Rong and Tseng, Yu Ting and Zhou, Xianghong Jasmine},
  title    = {Pushing the annotation of cellular activities to a higher resolution: {Predicting} functions at the isoform level},
  journal  = {Methods},
  year     = {2016},
  volume   = {93},
  pages    = {110--118},
  abstract = {In past decades, the experimental determination of protein functions was expensive and time-consuming, so numerous computational methods were developed to speed up and guide the process. However, most of these methods predict protein functions at the gene level and do not consider the fact that protein isoforms (translated from alternatively spliced transcripts), not genes, are the actual function carriers. Now, high-throughput RNA-seq technology is providing unprecedented opportunities to unravel protein functions at the isoform level. In this article, we review recent progress in the high-resolution functional annotations of protein isoforms, focusing on two methods developed by the authors. Both methods can integrate multiple RNA-seq datasets for comprehensively characterizing functions of protein isoforms.},
  doi      = {10.1016/j.ymeth.2015.07.016},
  keywords = {Isoform function prediction, multiple instance learning, RNA-seq data},
  url      = {http://dx.doi.org/10.1016/j.ymeth.2015.07.016},
}

@Article{lintott2008galaxy,
  author   = {Lintott, Chris J. and Schawinski, Kevin and Slosar, An?e and Land, Kate and Bamford, Steven and Thomas, Daniel and Raddick, M. Jordan and Nichol, Robert C. and Szalay, Alex and Andreescu, Dan and Murray, Phil and Vandenberg, Jan and Murray, P and Berg, J van den and Sullivan, BL and Wood, CL and Iliff, MJ and Bonney, RE and Fink, D and Kelling, S and Huss, JW and Orozco, C and Goodale, J and Wu, C and Batalov, S and Vickers, TJ and Valafar, F and Su, AI and Khatib, F and Cooper, S and Tyka, MD and Xu, K and Makedon, I and Popovic, Z and Baker, D and Players, F and McGonigal, J and Cooper, S and Khatib, F and Treuille, A and Barbero, J and Lee, J and Beenen, M and Leaver-Fay, A and Baker, D and Popovic, Z and Players, F and Khatib, F and Dimaio, F and Cooper, S and Kazmierczyk, M and Gilski, M and Krzywda, S and Zabranska, H and Pichova, I and Thompson, J and Popovic, Z and Jaskolski, M and Baker, D and Ahn, Lv and Dabbish, L and Ahn, Lv and Dabbish, L},
  title    = {Galaxy {Zoo}: morphologies derived from visual inspection of galaxies from the {Sloan} {Digital} {Sky} {Survey} ?},
  journal  = {Monthly Notices of the Royal Astronomical Society},
  year     = {2008},
  volume   = {389},
  number   = {3},
  pages    = {1179--1189},
  month    = sep,
  abstract = {The protein folding game Foldit shows that games are an effective way to recruit, engage and organize ordinary citizens to help solve difficult scientific problems.},
  doi      = {10.1111/j.1365-2966.2008.13689.x},
  groups   = {Veni},
  keywords = {Animal Genetics and Genomics, Bioinformatics, Evolutionary Biology, Human Genetics, Microbial Genetics and Genomics, Plant Genetics \& Genomics},
  url      = {http://mnras.oxfordjournals.org/cgi/doi/10.1111/j.1365-2966.2008.13689.x},
}

@InProceedings{liu2014iterated,
  author    = {Liu, Xiao and Shi, Jun and Zhou, Shichong and Lu, Minhua},
  title     = {An iterated {Laplacian} based semi-supervised dimensionality reduction for classification of breast cancer on ultrasound images.},
  booktitle = {International Conference of the IEEE Engineering in Medicine and Biology Society},
  year      = {2014},
  volume    = {2014},
  pages     = {4679--4682},
  abstract  = {The dimensionality reduction is an important step in ultrasound image based computer-aided diagnosis (CAD) for breast cancer. A newly proposed l2,1 regularized correntropy algorithm for robust feature selection (CRFS) has achieved good performance for noise corrupted data. Therefore, it has the potential to reduce the dimensions of ultrasound image features. However, in clinical practice, the collection of labeled instances is usually expensive and time costing, while it is relatively easy to acquire the unlabeled or undetermined instances. Therefore, the semi-supervised learning is very suitable for clinical CAD. The iterated Laplacian regularization (Iter-LR) is a new regularization method, which has been proved to outperform the traditional graph Laplacian regularization in semi-supervised classification and ranking. In this study, to augment the classification accuracy of the breast ultrasound CAD based on texture feature, we propose an Iter-LR-based semi-supervised CRFS (Iter-LR-CRFS) algorithm, and then apply it to reduce the feature dimensions of ultrasound images for breast CAD. We compared the Iter-LR-CRFS with LR-CRFS, original supervised CRFS, and principal component analysis. The experimental results indicate that the proposed Iter-LR-CRFS significantly outperforms all other algorithms.},
  doi       = {10.1109/EMBC.2014.6944668},
  groups    = {Not-so-supervised papers},
  keywords  = {Algorithms, Artificial Intelligence, Breast Neoplasms, Computer-Assisted, diagnosis, Female, Humans, Image Interpretation, Mammary, methods, Principal Component Analysis, Ultrasonography},
  language  = {eng},
}

@Article{livi2013graph,
  author  = {Livi, Lorenzo and Rizzi, Antonello},
  title   = {The graph matching problem},
  journal = {Pattern Analysis and Applications},
  year    = {2013},
  volume  = {16},
  number  = {3},
  pages   = {253--283},
  month   = aug,
  doi     = {10.1007/s10044-012-0284-8},
  url     = {http://link.springer.com/10.1007/s10044-012-0284-8},
}

@Article{loeve2012chest,
  author   = {Loeve, Martine and Hop, Wim C J and De Bruijne, Marleen and Van Hal, Peter T W and Robinson, Phil and Aitken, Moira L. and Dodd, Jonathan D. and Tiddens, Harm A W M},
  title    = {Chest computed tomography scores are predictive of survival in patients with cystic fibrosis awaiting lung transplantation},
  journal  = {American Journal of Respiratory and Critical Care Medicine},
  year     = {2012},
  volume   = {185},
  number   = {10},
  pages    = {1096--1103},
  issn     = {1535-4970 (Electronic){\textbackslash}n1073-449X (Linking)},
  abstract = {Up to one-third of patients with cystic fibrosis (CF) awaiting lung transplantation (LTX) die while waiting. Inclusion of computed tomography (CT) scores may improve survival prediction models such as the lung allocation score (LAS).},
  doi      = {10.1164/rccm.201111-2065OC},
  file     = {loeve2012chest.pdf:loeve2012chest.pdf:PDF},
  keywords = {Cystic fibrosis, Lung disease, Lung transplantation, Tomography X-ray computed, Waiting list survival},
}

@Article{long2013transfer,
  author   = {Long, Mingsheng and Wang, Jianmin and Ding, Guiguang and Sun, Jiaguang and Yu, Philip S.},
  title    = {Transfer feature learning with joint distribution adaptation},
  journal  = {Proceedings of the IEEE International Conference on Computer Vision},
  year     = {2013},
  pages    = {2200--2207},
  issn     = {9781479928392},
  abstract = {Transfer learning is established as an effective technology in {\textbackslash}ncomputer vision for leveraging rich labeled data in the source domain to build {\textbackslash}nan accurate classifier for the target domain. However, most prior methods have {\textbackslash}nnot simultaneously reduced the difference in both the marginal distribution and {\textbackslash}nconditional distribution between domains. In this paper, we put forward a novel {\textbackslash}ntransfer learning approach, referred to as Joint Distribution Adaptation (JDA). {\textbackslash}nSpecifically, JDA aims to jointly adapt both the marginal distribution and {\textbackslash}nconditional distribution in a principled dimensionality reduction procedure, and {\textbackslash}nconstruct new feature representation that is effective and robust for {\textbackslash}nsubstantial distribution difference. Extensive experiments verify that JDA can {\textbackslash}nsignificantly outperform several state-of-the-art methods on four types of {\textbackslash}ncross-domain image classification problems.},
  doi      = {10.1109/ICCV.2013.274},
  file     = {long2013transfer.pdf:long2013transfer.pdf:PDF},
  keywords = {feature learning, joint distribution adaptation, Transfer learning},
}

@Article{lu2015transfer,
  author   = {Lu, Jie and Behbood, Vahid and Hao, Peng and Zuo, Hua and Xue, Shan and Zhang, Guangquan},
  title    = {Transfer learning using computational intelligence: {A} survey},
  journal  = {Knowledge-Based Systems},
  year     = {2015},
  volume   = {80},
  number   = {January},
  pages    = {14--23},
  abstract = {Transfer learning aims to provide a framework to utilize previously-acquired knowledge to solve new but similar problems much more quickly and effectively. In contrast to classical machine learning methods, transfer learning methods exploit the knowledge accumulated from data in auxiliary domains to facilitate predictive modeling consisting of different data patterns in the current domain. To improve the performance of existing transfer learning methods and handle the knowledge transfer process in real-world systems, computational intelligence has recently been applied in transfer learning. This paper systematically examines computational intelligence-based transfer learning techniques and clusters related technique developments into four main categories: (a) neural network-based transfer learning; (b) Bayes-based transfer learning; (c) fuzzy transfer learning, and (d) applications of computational intelligence-based transfer learning. By providing state-of-the-art knowledge, this survey will directly support researchers and practice-based professionals to understand the developments in computational intelligence-based transfer learning research and applications.},
  doi      = {10.1016/j.knosys.2015.01.010},
  file     = {lu2015transfer.pdf:lu2015transfer.pdf:PDF},
  keywords = {Bayes, Computational intelligence, Fuzzy sets and systems, Genetic algorithm, Neural network, Transfer learning},
  url      = {http://dx.doi.org/10.1016/j.knosys.2015.01.010},
}

@Article{lyer1997using,
  author   = {Lyer, Rukmini and Ostendorf, Mari and Gish, Herb},
  title    = {Using out-of-domain data to improve in-domain language models},
  journal  = {IEEE Signal Processing Letters},
  year     = {1997},
  volume   = {4},
  number   = {8},
  pages    = {221--223},
  abstract = {Standard statistical language modeling techniques suffer from sparse data problems when applied to real tasks in speech recognition, where large amounts of domain-dependent text are not available. We investigate new approaches to improve sparse application-specific language models by combining domain dependent and out-of-domain data, including a back-off scheme that effectively leads to context-dependent multiple interpolation weights, and a likelihood-based similarity weighting scheme to discriminatively use data to train a task-specific language model. Experiments with both approaches on a spontaneous speech recognition task (switchboard), lead to reduced word error rate over a domain-specific n-gram language model, giving a larger gain than that obtained with previous brute-force data combination approaches},
  doi      = {10.1109/97.611282},
  keywords = {Lanugage modeling, Out-of-domain training},
}

@Article{maas2016concept,
  author   = {Maas, Anne H. and van der Molen, Pieta and van de Vijver, Reinier and Chen, Wei and van Pul, Carola and Cottaar, Eduardus J.E. and van Riel, Natal A.W. and Hilbers, Peter A.J. and Haak, Harm R.},
  title    = {Concept {Development} of the {Eindhoven} {Diabetes} {Education} {Simulator} {Project}},
  journal  = {Games for Health Journal},
  year     = {2016},
  volume   = {5},
  number   = {2},
  pages    = {120--127},
  issn     = {9783658028961},
  abstract = {Recent studies suggest that Serious Games (SG) are interesting and innovative tools useful to influence attitudes, beliefs and behaviors. SG use entertainment technology to teach, train, or change the behavior, encouraging active engagement and processing of information from the users. Games for health are games with a focus on health care, physical and mental fitness, and their popular application areas are nutrition, physical training, education, and prevention. The game-based learning principles target intrinsic motivation, learning through fun, authenticity, self- reliance/autonomy, and experiential learning. The mechanisms adopted include rules, clear but challenging goals, fantasy, progressive levels of difficulty, interactivity, player control, uncertainty, feedback and a social element. Active videogames seem to be effective in increasing energy expenditure and promoting physical activity. It has been shown that playing video games can promote extrinsic motivation and foster positive emotion with possible very important effects on health behavior. Therefore, SG can be promising tools that seek to entertain the user while attempting to elicit some form of change in behavior. Our recent studies show that an original Web Game called ''Gustavo in Gnam's Planet'' increases knowledge about healthy food and improves healthy lifestyle habits; our SG ''could be an important useful mean and an auspicious tool for prevention programs within a multidimensional educational program''. Video games seem to be persuasive instruments for education in different interventions, and it is known the potential of using video games and gamification to promote healthy habits and better self-management of chronic diseases and diabetes in pregnancy.},
  doi      = {10.1089/g4h.2015.0037},
  file     = {maas2016concept.pdf:maas2016concept.pdf:PDF},
  keywords = {*diabetes mellitus, *health, *technology, astronomy, chronic disease, education, emotion, energy expenditure, experiential learning, fantasy, feedback system, food, habit, health behavior, health care, learning, lifestyle, mental capacity, mental performance, motivation, nutrition, physical activity, Pregnancy, prevention, processing, recreation, self care, Training},
  url      = {http://eef.colorado.edu/2009FallMini/Ananthanarayan_GamesForHealth.pdf%5Cnhttp://online.liebertpub.com/doi/10.1089/g4h.2015.0037},
}

@Article{madabhushi2016image,
  author   = {Madabhushi, Anant and Lee, George},
  title    = {Image analysis and machine learning in digital pathology: {Challenges} and opportunities},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {170--175},
  issn     = {1361-8423 (Electronic) 1361-8415 (Linking)},
  note     = {DOI: 10.1016/j.media.2016.06.037},
  abstract = {With the rise in whole slide scanner technology, large numbers of tissue slides are being scanned and represented and archived digitally. While digital pathology has substantial implications for telepathology, second opinions, and education there are also huge research opportunities in image computing with this new source of ???big data???. It is well known that there is fundamental prognostic data embedded in pathology images. The ability to mine ???sub-visual??? image features from digital pathology slide images, features that may not be visually discernible by a pathologist, offers the opportunity for better quantitative modeling of disease appearance and hence possibly improved prediction of disease aggressiveness and patient outcome. However the compelling opportunities in precision medicine offered by big digital pathology data come with their own set of computational challenges. Image analysis and computer assisted detection and diagnosis tools previously developed in the context of radiographic images are woefully inadequate to deal with the data density in high resolution digitized whole slide images. Additionally there has been recent substantial interest in combining and fusing radiologic imaging and proteomics and genomics based measurements with features extracted from digital pathology images for better prognostic prediction of disease aggressiveness and patient outcome. Again there is a paucity of powerful tools for combining disease specific features that manifest across multiple different length scales. The purpose of this review is to discuss developments in computational image analysis tools for predictive modeling of digital pathology images from a detection, segmentation, feature extraction, and tissue classification perspective. We discuss the emergence of new handcrafted feature approaches for improved predictive modeling of tissue appearance and also review the emergence of deep learning schemes for both object detection and tissue classification. We also briefly review some of the state of the art in fusion of radiology and pathology images and also combining digital pathology derived image measurements with molecular ???omics??? features for better predictive modeling. The review ends with a brief discussion of some of the technical and computational challenges to be overcome and reflects on future opportunities for the quantitation of histopathology.},
  keywords = {deep learning, Digital pathology, Omics, Radiology},
}

@Article{mahapatra2016active,
  author   = {Mahapatra, Dwarikanath and Vos, Franciscus M and Buhmann, Joachim M},
  title    = {Active learning based segmentation of {Crohns} disease from abdominal {MRI}},
  journal  = {Computer methods and programs in biomedicine},
  year     = {2016},
  volume   = {128},
  pages    = {75--85},
  abstract = {This paper proposes a novel active learning (AL) framework, and combines it with  semi supervised learning (SSL) for segmenting Crohns disease (CD) tissues from abdominal magnetic resonance (MR) images. Robust fully supervised learning (FSL) based classifiers require lots of labeled data of different disease severities. Obtaining such data is time consuming and requires considerable expertise. SSL methods use a few labeled samples, and leverage the information from many unlabeled samples to train an accurate classifier. AL queries labels of most informative samples and maximizes gain from the labeling effort. Our primary contribution is in designing a query strategy that combines novel context information with classification uncertainty and feature similarity. Combining SSL and AL gives a robust segmentation method that: (1) optimally uses few labeled samples and many unlabeled samples; and (2) requires lower training time. Experimental results show our method achieves higher segmentation accuracy than FSL methods with fewer samples and reduced training effort.},
  doi2     = {10.1016/j.cmpb.2016.01.014},
  language = {eng},
}

@Article{maiora2014random,
  author   = {Maiora, Josu and Ayerdi, Borja and Graña, Manuel},
  title    = {Random forest active learning for {AAA} thrombus segmentation in computed tomography angiography images},
  journal  = {Neurocomputing},
  year     = {2014},
  volume   = {126},
  pages    = {71--77},
  abstract = {Image segmentation of 3D Computed Tomography Angiography (CTA) is affected by a variety of noise conditions that may render ineffective image segmentation procedures that have been developed and validated on a collection of training CTA data when applied on new CTA data. The approach followed in this paper to tackle this problem is to provide an Active Learning based interactive image segmentation system which will allow quick volume segmentation, with minimal intervention of a human operator. Image segmentation is achieved by a Random forest (RF) classifier applied on a set of image features extracted from each voxel and its neighborhood. An initial set of labeled voxels is required to start the process, training an initial RF. The most uncertain unlabeled voxels are shown to the human operator to select some of them for inclusion in the training set, retraining the RF classifier. The approach is applied to the segmentation of the thrombus of Abdominal Aortic Aneurysm (AAA) in CTA data (of patients), showing that the CTA volume can be accurately segmented after few iterations requiring a small labeled data sample. © 2013 Elsevier B.V.},
  doi      = {10.1016/j.neucom.2013.01.051},
  keywords = {Abdominal aortic aneurysm segmentation, Active learning, CTA image segmentation, Random forests},
}

@Article{malpani2015study,
  author   = {Malpani, Anand and Vedula, S Swaroop and Chen, Chi Chiung Grace and Hager, Gregory D},
  title    = {A study of crowdsourced segment-level surgical skill assessment using pairwise rankings.},
  journal  = {International journal of computer assisted radiology and surgery},
  year     = {2015},
  volume   = {10},
  number   = {9},
  pages    = {1435--47},
  month    = sep,
  abstract = {PURPOSE Currently available methods for surgical skills assessment are either subjective or only provide global evaluations for the overall task. Such global evaluations do not inform trainees about where in the task they need to perform better. In this study, we investigated the reliability and validity of a framework to generate objective skill assessments for segments within a task, and compared assessments from our framework using crowdsourced segment ratings from surgically untrained individuals and expert surgeons against manually assigned global rating scores. METHODS Our framework includes (1) a binary classifier trained to generate preferences for pairs of task segments (i.e., given a pair of segments, specification of which one was performed better), (2) computing segment-level percentile scores based on the preferences, and (3) predicting task-level scores using the segment-level scores. We conducted a crowdsourcing user study to obtain manual preferences for segments within a suturing and knot-tying task from a crowd of surgically untrained individuals and a group of experts. We analyzed the inter-rater reliability of preferences obtained from the crowd and experts, and investigated the validity of task-level scores obtained using our framework. In addition, we compared accuracy of the crowd and expert preference classifiers, as well as the segment- and task-level scores obtained from the classifiers. RESULTS We observed moderate inter-rater reliability within the crowd (Fleiss' kappa, ? = 0.41) and experts (? = 0.55). For both the crowd and experts, the accuracy of an automated classifier trained using all the task segments was above par as compared to the inter-rater agreement [crowd classifier 85 \% (SE 2 \%), expert classifier 89 \% (SE 3 \%)]. We predicted the overall global rating scores (GRS) for the task with a root-mean-squared error that was lower than one standard deviation of the ground-truth GRS. We observed a high correlation between segment-level scores (? ? 0.86) obtained using the crowd and expert preference classifiers. The task-level scores obtained using the crowd and expert preference classifier were also highly correlated with each other (? ? 0.84), and statistically equivalent within a margin of two points (for a score ranging from 6 to 30). Our analyses, however, did not demonstrate statistical significance in equivalence of accuracy between the crowd and expert classifiers within a 10 \% margin. CONCLUSIONS Our framework implemented using crowdsourced pairwise comparisons leads to valid objective surgical skill assessment for segments within a task, and for the task overall. Crowdsourcing yields reliable pairwise comparisons of skill for segments within a task with high efficiency. Our framework may be deployed within surgical training programs for objective, automated, and standardized evaluation of technical skills.},
  doi      = {10.1007/s11548-015-1238-6},
  url      = {http://www.ncbi.nlm.nih.gov/pubmed/26133652},
}

@Article{mangin2016spatial,
  author   = {Mangin, J. F. and Lebenberg, J. and Lefranc, S. and Labra, N. and Auzias, G. and Labit, M. and Guevara, M. and Mohlberg, H. and Roca, P. and Guevara, P. and Dubois, J. and Leroy, F. and Dehaene-Lambertz, G. and Cachia, A. and Dickscheid, T. and Coulon, O. and Poupon, C. and Rivi??re, D. and Amunts, K. and Sun, Z. Y.},
  title    = {Spatial normalization of brain images and beyond},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {127--133},
  note     = {DOI: 10.1016/j.media.2016.06.008},
  abstract = {The deformable atlas paradigm has been at the core of computational anatomy during the last two decades. Spatial normalization is the variant endowing the atlas with a coordinate system used for voxel-based aggregation of images across subjects and studies. This framework has largely contributed to the success of brain mapping. Brain spatial normalization, however, is still ill-posed because of the complexity of the human brain architecture and the lack of architectural landmarks in standard morphological MRI. Multi-atlas strategies have been developed during the last decade to overcome some difficulties in the context of segmentation. A new generation of registration algorithms embedding architectural features inferred for instance from diffusion or functional MRI is on the verge to improve the architectural value of spatial normalization. A better understanding of the architectural meaning of the cortical folding pattern will lead to use some sulci as complementary constraints. Improving the architectural compliance of spatial normalization may impose to relax the diffeomorphic constraint usually underlying atlas warping. A two-level strategy could be designed: in each region, a dictionary of templates of incompatible folding patterns would be collected and matched in a way or another using rare architectural information, while individual subjects would be aligned using diffeomorphisms to the closest template. Manifold learning could help to aggregate subjects according to their morphology. Connectivity-based strategies could emerge as an alternative to deformation-based alignment leading to match the connectomes of the subjects rather than images.},
  keywords = {Connectome, Cortical folding pattern, Diffeomorphism, Spatial normalization},
  url      = {http://dx.doi.org/10.1016/j.media.2016.06.008},
}

@Article{mansourrevisiting,
  author  = {Mansour, Rh and Refaei, N and Gamon, M},
  title   = {Revisiting {The} {Old} {Kitchen} {Sink}: {Do} {We} {Need} {Sentiment} {Domain} {Adaptation}?},
  journal = {Aclweb.Org},
  url     = {https://www.aclweb.org/anthology/R/R13/R13-1055.pdf},
}

@Article{mansourdomain,
  author = {Mansour, Yishay},
  title  = {Domain {Adaptation} with {Multiple} {Sources}},
  pages  = {1--8},
}

@Article{markatopouloudynamic,
  author   = {Markatopoulou, Fotini and Tsoumakas, Grigorios and Vlahavas, Ioannis},
  title    = {Dynamic {Ensemble} {Pruning} {Based} on {Multi}-{Label} {Classification}},
  keywords = {dynamic classifier fusion, ensemble pruning, ensemble selection, multi-label classification},
}

@Article{marquez2014postdoc,
  author   = {Marquez, Stefanie B},
  title    = {A {Postdoc} ? s {Guide} to {Being} a {Postdoc}},
  journal  = {Journal of Postdoctoral Research},
  year     = {2014},
  volume   = {2},
  number   = {6},
  pages    = {39--45},
  abstract = {If you have recently accepted a postdoctoral position and have begun working as a postdoc, or are planning to pursue a second postdoc, there are many opportunities to improve your skills both within and outside of academics and your specific field of study. The suggestions offered in this paper are not all-inclusive by any means, and are meant to serve as guidelines to show postdocs what they can do, not necessarily what they should do. This is my perspective as a third-year postdoctoral researcher in the medical sciences.},
  keywords = {Academia, career development, Networking, postdoctoral mentoring},
}

@Article{marx2013neuroscience,
  author   = {Marx, Vivien},
  title    = {Neuroscience waves to the crowd},
  journal  = {Nature Methods},
  year     = {2013},
  volume   = {10},
  number   = {11},
  pages    = {1069--1074},
  abstract = {Researchers scale up how to crowdsource the mapping of neural circuits. These projects entice crowds by tapping into their spirit of play.},
  doi      = {10.1038/nmeth.2695},
  file     = {marx2013neuroscience.pdf:marx2013neuroscience.pdf:PDF},
  keywords = {Citizen science, Games},
  url      = {http://www.nature.com/nmeth/journal/v10/n11/abs/nmeth.2695.html},
}

@Article{mavandadi2012distributed,
  author   = {Mavandadi, Sam and Dimitrov, Stoyan and Feng, Steve and Yu, Frank and Sikora, Uzair and Yaglidere, Oguzhan and Padmanabhan, Swati and Nielsen, Karin and Ozcan, Aydogan},
  title    = {Distributed medical image analysis and diagnosis through crowd-sourced games: {A} malaria case study},
  journal  = {PLoS ONE},
  year     = {2012},
  volume   = {7},
  number   = {5},
  issn     = {1932-6203; 1932-6203},
  abstract = {In this work we investigate whether the innate visual recognition and learning capabilities of untrained humans can be used in conducting reliable microscopic analysis of biomedical samples toward diagnosis. For this purpose, we designed entertaining digital games that are interfaced with artificial learning and processing back-ends to demonstrate that in the case of binary medical diagnostics decisions (e.g., infected vs. uninfected), with the use of crowd-sourced games it is possible to approach the accuracy of medical experts in making such diagnoses. Specifically, using non-expert gamers we report diagnosis of malaria infected red blood cells with an accuracy that is within 1.25\% of the diagnostics decisions made by a trained medical professional.},
  doi      = {10.1371/journal.pone.0037245},
  file     = {mavandadi2012distributed.pdf:mavandadi2012distributed.pdf:PDF},
}

@Article{mccann2012automated,
  author   = {McCann, Michael T and Bhagavatula, Ramamurthy and Fickus, Matthew C and Ozolek, John A and Kovacevic, Jelena},
  title    = {Automated colitis detection from endoscopic biopsies as a tissue screening tool in diagnostic pathology},
  journal  = {International Conference on Image Processing (ICIP)},
  year     = {2012},
  volume   = {2012},
  pages    = {2809--2812},
  abstract = {We present a method for identifying colitis in colon biopsies as an extension of  our framework for the automated identification of tissues in histology images. Histology is a critical tool in both clinical and research applications, yet even mundane histological analysis, such as the screening of colon biopsies, must be carried out by highly-trained pathologists at a high cost per hour, indicating a niche for potential automation. To this end, we build upon our previous work by extending the histopathology vocabulary (a set of features based on visual cues used by pathologists) with new features driven by the colitis application. We use the multiple-instance learning framework to allow our pixel-level classifier to learn from image-level training labels. The new system achieves accuracy comparable to state-of-the-art biological image classifiers with fewer and more intuitive features.},
  doi2     = {10.1109/ICIP.2012.6467483},
  groups   = {Not-so-supervised papers},
  language = {ENG},
}

@Article{mcgovernidentifying,
  author   = {Mcgovern, Amy and Jensen, David},
  title    = {Identifying {Predictive} {Structures} in {Relational} {Data} {Using} {Multiple} {Instance} {Learning}},
  abstract = {This paper introduces an approach for identify-ing predictive structures in relational data using the multiple-instance framework. By a predictive structure, we mean a structure that can explain a given labeling of the data and can predict labels of unseen data. Multiple-instance learning has previously only been applied to flat, or proposi-tional, data and we present a modification to the framework that allows multiple-instance tech-niques to be used on relational data. We present experimental results using a relational modifica-tion of the diverse density method (Maron, 1998; Maron \& Lozano-Pérez, 1998) and of a method based on the chi-squared statistic (McGovern \& Jensen, 2003). We demonstrate that multiple-instance learning can be used to identify predic-tive structures on both a small illustrative data set and the Internet Movie Database. We compare the classification results to a k-nearest neighbor approach.},
}

@Article{meeds2014mlitb,
  author   = {Meeds, Edward and Hendriks, Remco and Faraby, Said Al and Bruntink, Magiel and Welling, Max},
  title    = {{MLitB}: {Machine} {Learning} in the {Browser}},
  year     = {2014},
  pages    = {1--18},
  abstract = {With few exceptions, the field of Machine Learning (ML) research has largely ignored the browser as a computational engine. Beyond an educational resource for ML, the browser has vast potential to not only improve the state-of-the-art in ML research, but also, inexpensively and on a massive scale, to bring sophisticated ML learning and prediction to the public at large. This paper introduces MLitB, a prototype ML framework written entirely in Javascript, capable of performing large-scale distributed computing with heterogeneous classes of devices. The development of MLitB has been driven by several underlying objectives whose aim is to make ML learning and usage ubiquitous (by using ubiquitous compute devices), cheap and effortlessly distributed, and collaborative. This is achieved by allowing every internet capable device to run training algorithms and predictive models with no software installation and by saving models in universally readable formats. Our prototype library is capable of training deep neural networks (DNNs) with synchronized, distributed stochastic gradient descent (SGD). MLitB offers several important opportunities for novel ML research, including: development of distributed learning algorithms, advancement of web GPU algorithms, novel field and mobile applications, privacy preserving computing, and green grid-computing. MLitB is available as open source software.},
  doi      = {10.7717/peerj-cs.11},
  url      = {http://arxiv.org/abs/1412.2432},
}

@InProceedings{meier2014patient,
  author    = {Meier, Raphael and Bauer, Stefan and Slotboom, Johannes and Wiest, Roland and Reyes, Mauricio},
  title     = {Patient-specific semi-supervised learning for postoperative brain tumor segmentation.},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year      = {2014},
  volume    = {17},
  number    = {Pt 1},
  pages     = {714--721},
  abstract  = {In contrast to preoperative brain tumor segmentation, the problem of postoperative brain tumor segmentation has been rarely approached so far. We present a fully-automatic segmentation method using multimodal magnetic resonance image data and patient-specific semi-supervised learning. The idea behind our semi-supervised approach is to effectively fuse information from both pre- and postoperative image data of the same patient to improve segmentation of the postoperative image. We pose image segmentation as a classification problem and solve it by adopting a semi-supervised decision forest. The method is evaluated on a cohort of 10 high-grade glioma patients, with segmentation performance and computation time comparable or superior to a state-of-the-art brain tumor segmentation method. Moreover, our results confirm that the inclusion of preoperative MR images lead to a better performance regarding postoperative brain tumor segmentation.},
  groups    = {Not-so-supervised papers},
  keywords  = {adverse effects, Algorithms, Automated, Brain Neoplasms, complications, Computer-Assisted, diagnosis, Differential, etiology, Glioma, Humans, Image Enhancement, Image Interpretation, methods, Neurosurgical Procedures, Pathology, Pattern Recognition, Postoperative Care, Postoperative Hemorrhage, Reproducibility of Results, Sensitivity and Specificity, surgery, Treatment Outcome},
  language  = {eng},
}

@Article{mendez2015multiview,
  author   = {Méndez, C. Andrés and Summers, Paul and Menegaz, Gloria},
  title    = {Multiview cluster ensembles for multimodal {MRI} segmentation},
  journal  = {International Journal of Imaging Systems and Technology},
  year     = {2015},
  volume   = {25},
  number   = {1},
  pages    = {56--67},
  doi      = {10.1002/ima.22121},
  file     = {mendez2015multiview.pdf:mendez2015multiview.pdf:PDF},
  keywords = {clustering, DCE-MRI, Diffusion MRI, DTI-MRI, Multimodal MRI, non-supervised classification, Segmentation},
}

@Article{menegola2016towards,
  author   = {Menegola, Afonso and Fornaciali, Michel and Pires, Ramon and Avila, Sandra and Valle, Eduardo},
  title    = {Towards Automated Melanoma Screening: Exploring Transfer Learning Schemes},
  journal  = {arXiv preprint arXiv:1609.01228},
  year     = {2016},
  abstract = {Deep learning is the current bet for image classification. Its greed for huge amounts of annotated data limits its usage in medical imaging context. In this scenario transfer learning appears as a prominent solution. In this report we aim to clarify how transfer learning schemes may influence classification results. We are particularly focused in the automated melanoma screening problem, a case of medical imaging in which transfer learning is still not widely used. We explored transfer with and without fine-tuning, sequential transfers and usage of pre-trained models in general and specific datasets. Although some issues remain open, our findings may drive future researches.},
  groups   = {Not-so-supervised papers},
  url2     = {http://arxiv.org/abs/1609.01228},
}

@InProceedings{mercan2016multi,
  author    = {Mercan, Caner and Mercan, Ezgi and Aksoy, Selim and Shapiro, Linda G. and Weaver, Donald L. and Elmore, Joann G.},
  title     = {Multi-instance multi-label learning for whole slide breast histopathology},
  year      = {2016},
  editor    = {Gurcan, Metin N. and Madabhushi, Anant},
  pages     = {979108--979108},
  month     = mar,
  publisher = {International Society for Optics and Photonics},
  doi2      = {10.1117/12.2216458},
  groups    = {Not-so-supervised papers},
  keywords  = {Algorithms, Biopsy, Breast, computer-aided diagnosis, image analysis, Imaging technologies, Zoom lenses},
  url2      = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2216458},
}

@Article{merz1999using,
  author   = {Merz, Cj},
  title    = {Using {Correspondence} {Analysis} to {Combine} {Classifiers}},
  journal  = {Machine Learning},
  year     = {1999},
  volume   = {36},
  pages    = {33--58},
  abstract = {Several effective methods have been developed recently for improving predictive performance by generating and combining multiple learned models. The general approach is to create a set of learned models either by applying an algorithm repeatedly to different versions of the training data, or by applying different learning algorithms to the same data. The predictions of the models are then combined according to a voting scheme. This paper focuses on the task of combining the predictions of a set of learned models. The method described uses the strategies of stacking and Correspondence Analysis to model the relationship between the learning examples and their classification by a collection of learned models. A nearest neighbor method is then applied within the resulting representation to classify previously unseen examples. The new algorithm does not perform worse than, and frequently performs significantly better than other combining techniques on a suite of data sets.},
  doi      = {10.1023/A:1007559205422},
  file     = {merz1999using.pdf:merz1999using.pdf:PDF},
  keywords = {Classification, combining estimates, correspondence analysis, multiple models},
  url      = {http://link.springer.com/article/10.1023/A:1007559205422},
}

@InProceedings{michel2010supervised,
  author    = {Michel, Vincent and Eger, Evelyn and Keribin, Christine and Poline, Jean-Baptiste and Thirion, Bertrand},
  title     = {A supervised clustering approach for extracting predictive information from brain activation images},
  booktitle = {2010 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} - {Workshops}},
  year      = {2010},
  pages     = {7--14},
  month     = jun,
  publisher = {IEEE},
  doi       = {10.1109/CVPRW.2010.5543435},
  isbn      = {978-1-4244-7029-7},
  keywords  = {Analysis of Variance, Biomarkers, Biomedical imaging, biomedical MRI, Brain, brain activation images, computational complexity, Data mining, Decoding, face expression, feature extraction, fmri, functional magnetic resonance imaging, image coding, image information, Image Interpretation, images encoding, learning (artificial intelligence), Magnetic resonance imaging, medical image processing, medical images, neuroimaging, pattern clustering, predictive information extraction, Predictive models, spatial configurations, spatial connectivity, spatial structure, supervised clustering approach},
  url       = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5543435},
}

@Book{mitchell2007multi,
  title    = {Multi-{Sensor} {Data} {Fusion}: an introduction},
  year     = {2007},
  author   = {Mitchell, H. B.},
  isbn     = {978-3-540-71463-7},
  note     = {DOI: 10.2481/dsj.4.127},
  abstract = {This textbook provides a comprehensive introduction to the theories and techniques of multi-sensor data fusion. It is aimed at advanced undergraduate and first-year graduate students in electrical engineering and computer science, as well as researchers and professional engineers. The book is intended to be self-contained. No previous knowledge of multi-sensor data fusion is assumed, although some familiarity with the basic tools of linear algebra, calculus and simple probability theory is recommended. Although conceptually simple, the study of multi-sensor data fusion presents challenges that are unique within the education of the electrical engineer or computer scientist. To become competent in the field the student must become familiar with tools taken from a wide range of diverse subjects including: neural networks, signal processing, statistical estimation, tracking algorithms, computer vision and control theory. All too often the student views multi-sensor data fusion as a miscellaneous assortment of different processes which bear no relationship to each other. In this book the processes are described using a common statistical framework. As a consequence, the underlying pattern of relationships that exists between the different methodologies is made evident. The book is illustrated with many real-life applications and contains an extensive list of modern references. It is accompanied by a webpage from which supplementary material may be obtained, including support for course instructors and links to relevant matlab code},
}

@Article{mittal2016unsupervised,
  author   = {Mittal, Ayush and Raj, Anant and Namboodiri, Vinay P. and Tuytelaars, Tinne},
  title    = {Unsupervised {Domain} {Adaptation} in the {Wild}: {Dealing} with {Asymmetric} {Label} {Sets}},
  year     = {2016},
  month    = mar,
  abstract = {The goal of domain adaptation is to adapt models learned on a source domain to a particular target domain. Most methods for unsupervised domain adaptation proposed in the literature to date, assume that the set of classes present in the target domain is identical to the set of classes present in the source domain. This is a restrictive assumption that limits the practical applicability of unsupervised domain adaptation techniques in real world settings ("in the wild"). Therefore, we relax this constraint and propose a technique that allows the set of target classes to be a subset of the source classes. This way, large publicly available annotated datasets with a wide variety of classes can be used as source, even if the actual set of classes in target can be more limited and, maybe most importantly, unknown beforehand. To this end, we propose an algorithm that orders a set of source subspaces that are relevant to the target classification problem. Our method then chooses a restricted set from this ordered set of source subspaces. As an extension, even starting from multiple source datasets with varied sets of categories, this method automatically selects an appropriate subset of source categories relevant to a target dataset. Empirical analysis on a number of source and target domain datasets shows that restricting the source subspace to only a subset of categories does indeed substantially improve the eventual target classification accuracy over the baseline that considers all source classes.},
  url      = {http://arxiv.org/abs/1603.08105},
}

@InCollection{mokbel2012how,
  author    = {Mokbel, Bassam and Gross, Sebastian and Lux, Markus and Pinkwart, Niels and Hammer, Barbara},
  title     = {How to {Quantitatively} {Compare} {Data} {Dissimilarities} for {Unsupervised} {Machine} {Learning}?},
  publisher = {Springer Berlin Heidelberg},
  year      = {2012},
  pages     = {1--13},
  note      = {DOI: 10.1007/978-3-642-33212-8\_1},
  url       = {http://link.springer.com/10.1007/978-3-642-33212-8_1},
}

@InCollection{montillo2011entangled,
  author    = {Montillo, Albert and Shotton, Jamie and Winn, John and Iglesias, Juan Eugenio and Metaxas, Dimitri and Criminisi, Antonio},
  title     = {Entangled {Decision} {Forests} and {Their} {Application} for {Semantic} {Segmentation} of {CT} {Images}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2011},
  pages     = {184--196},
  note      = {DOI: 10.1007/978-3-642-22092-0\_16},
  url       = {http://link.springer.com/10.1007/978-3-642-22092-0_16},
}

@Article{moradi2015machine,
  author   = {Moradi, Elaheh and Pepe, Antonietta and Gaser, Christian and Huttunen, Heikki and Tohka, Jussi},
  title    = {Machine learning framework for early {MRI}-based {Alzheimer}'s conversion prediction in {MCI} subjects.},
  journal  = {NeuroImage},
  year     = {2015},
  volume   = {104},
  pages    = {398--412},
  abstract = {Mild cognitive impairment (MCI) is a transitional stage between age-related cognitive decline and Alzheimer's disease (AD). For the effective treatment of AD, it would be important to identify MCI patients at high risk for conversion to AD. In this study, we present a novel magnetic resonance imaging (MRI)-based method for predicting the MCI-to-AD conversion from one to three years before the clinical diagnosis. First, we developed a novel MRI biomarker of MCI-to-AD conversion using semi-supervised learning and then integrated it with age and cognitive measures about the subjects using a supervised learning algorithm resulting in what we call the aggregate biomarker. The novel characteristics of the methods for learning the biomarkers are as follows: 1) We used a semi-supervised learning method (low density separation) for the construction of MRI biomarker as opposed to more typical supervised methods; 2) We performed a feature selection on MRI data from AD subjects and normal controls without using data from MCI subjects via regularized logistic regression; 3) We removed the aging effects from the MRI data before the classifier training to prevent possible confounding between AD and age related atrophies; and 4) We constructed the aggregate biomarker by first learning a separate MRI biomarker and then combining it with age and cognitive measures about the MCI subjects at the baseline by applying a random forest classifier. We experimentally demonstrated the added value of these novel characteristics in predicting the MCI-to-AD conversion on data obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. With the ADNI data, the MRI biomarker achieved a 10-fold cross-validated area under the receiver operating characteristic curve (AUC) of 0.7661 in discriminating progressive MCI patients (pMCI) from stable MCI patients (sMCI). Our aggregate biomarker based on MRI data together with baseline cognitive measurements and age achieved a 10-fold cross-validated AUC score of 0.9020 in discriminating pMCI from sMCI. The results presented in this study demonstrate the potential of the suggested approach for early AD diagnosis and an important role of MRI in the MCI-to-AD conversion prediction. However, it is evident based on our results that combining MRI data with cognitive test results improved the accuracy of the MCI-to-AD conversion prediction.},
  doi2     = {10.1016/j.neuroimage.2014.10.002},
  groups   = {Not-so-supervised papers},
  keywords = {Aged, Aged, 80 and over, Alzheimer Disease, Biomarkers, Brain, Databases, Factual, Female, Humans, Image Interpretation, Computer-Assisted, machine learning, Magnetic resonance imaging, Male, methods, Middle Aged, Mild Cognitive Impairment, Pathology, Risk Factors},
  language = {eng},
}

@Article{moreno-torres2013repairing,
  author   = {Moreno-Torres, Jose G. and Llor??, Xavier and Goldberg, David E. and Bhargava, Rohit},
  title    = {Repairing fractures between data using genetic programming-based feature extraction: {A} case study in cancer diagnosis},
  journal  = {Information Sciences},
  year     = {2013},
  volume   = {222},
  pages    = {805--823},
  abstract = {There is an underlying assumption on most model building processes: given a learned classifier, it should be usable to explain unseen data from the same given problem. Despite this seemingly reasonable assumption, when dealing with biological data it tends to fail; where classifiers built out of data generated using the same protocols in two different laboratories can lead to two different, non-interchangeable, classifiers. There are usually too many uncontrollable variables in the process of generating data in the lab and biological variations, and small differences can lead to very different data distributions, with a fracture between data. This paper presents a genetics-based machine learning approach that performs feature extraction on data from a lab to help increase the classification performance of an existing classifier that was built using the data from a different laboratory which uses the same protocols, while learning about the shape of the fractures between data that motivated the bad behavior. The experimental analysis over benchmark problems together with a real-world problem on prostate cancer diagnosis show the good behavior of the proposed algorithm. ?? 2012 Elsevier Inc. All rights reserved.},
  doi      = {10.1016/j.ins.2010.09.018},
  keywords = {Biological data, Cancer diagnosis, Different laboratories, feature extraction, Fractures between data, Genetic programming},
  url      = {http://dx.doi.org/10.1016/j.ins.2010.09.018},
}

@Article{mori2016macro,
  author   = {Mori, Kensaku},
  title    = {From macro-scale to micro-scale computational anatomy: a perspective on the next 20 years},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {159--164},
  abstract = {This paper gives our perspective on the next two decades of computational anatomy, which has made great strides in the recognition and understanding of human anatomy from conventional clinical images. The results from this field are now used in a variety of medical applications, including quantitative analysis of organ shapes, interventional assistance, surgical navigation, and population analysis. Several anatomical models have also been used in computational anatomy, and these mainly target millimeter-scale shapes. For example, liver-shape models are almost completely modeled at the millimeter scale, and shape variations are described at such scales. Most clinical 3D scanning devices have had just under 1 or 0.5 mm per voxel resolution for over 25 years, and this resolution has not changed drastically in that time. Although Z-axis (head-to-tail direction) resolution has been drastically improved by the introduction of multi-detector CT scanning devices, in-plane resolutions have not changed very much either. When we look at human anatomy, we can see different anatomical structures at different scales. For example, pulmonary blood vessels and lung lobes can be observed in millimeter-scale images. If we take 10-??m-scale images of a lung specimen, the alveoli and bronchiole regions can be located in them. Most work in millimeter-scale computational anatomy has been done by the medical-image analysis community. In the next two decades, we encourage our community to focus on micro-scale computational anatomy. In this perspective paper, we briefly review the achievements of computational anatomy and its impacts on clinical applications; furthermore, we show several possibilities from the viewpoint of microscopic computational anatomy by discussing experimental results from our recent research activities.},
  doi      = {10.1016/j.media.2016.06.034},
  keywords = {Micro-computational anatomy, Micro-CT, Micro-structure analysis, Virtual navigation},
  url      = {http://dx.doi.org/10.1016/j.media.2016.06.034},
}

@Article{nan2012biomarker,
  author   = {Nan, Xiaofei and Wang, Nan and Gong, Ping and Zhang, Chaoyang and Chen, Yixin and Wilkins, Dawn},
  title    = {Biomarker discovery using 1-norm regularization for multiclass earthworm microarray gene expression data},
  journal  = {Neurocomputing},
  year     = {2012},
  volume   = {92},
  pages    = {36--43},
  abstract = {Novel biomarkers can be discovered through mining high dimensional microarray datasets using machine learning techniques. Here we propose a novel recursive gene selection method which can handle the multiclass setting effectively and efficiently. The selection is performed iteratively. In each iteration, a linear multiclass classifier is trained using 1-norm regularization, which leads to sparse weight vectors, i.e., many feature weights are exactly zero. Those zero-weight features are eliminated in the next iteration. The empirical results demonstrate that the selected features (genes) have very competitive discriminative power. In addition, the selection process has fast rate of convergence.},
  doi      = {10.1016/j.neucom.2011.09.035},
}

@InProceedings{nappi2016deep,
  author    = {Nappi, Janne J. and Hironaka, Toru and Regge, Daniele and Yoshida, Hiroyuki},
  title     = {Deep transfer learning of virtual endoluminal views for the detection of polyps in {CT} colonography},
  year      = {2016},
  editor    = {Tourassi, Georgia D. and Armato, Samuel G.},
  pages     = {97852B--97852B},
  month     = mar,
  publisher = {International Society for Optics and Photonics},
  doi2      = {10.1117/12.2217260},
  groups    = {Not-so-supervised papers},
  keywords  = {computer-aided diagnosis, Databases, Neural networks, Virtual colonoscopy},
  url2      = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2217260},
}

@Article{narasimhan2015consistent,
  author = {Narasimhan, Harikrishna},
  title  = {Consistent {Multiclass} {Algorithms} for {Complex} {Performance} {Measures}},
  year   = {2015},
  volume = {37},
}

@Article{nardelli2015optimizing,
  author   = {Nardelli, Pietro and Khan, Kashif A and Corvò, Alberto and Moore, Niamh and Murphy, Mary J and Twomey, Maria and O'Connor, Owen J and Kennedy, Marcus P and Estépar, Raúl San José and Maher, Michael M and Cantillon-Murphy, Pádraig and O?Connor, Owen J and Kennedy, Marcus P and Estépar, Raúl San José and Maher, Michael M and Cantillon-Murphy, Pádraig and Coxson, HO and Rogers, RM and Sluimer, Ingrid and Schilham, A and Prokop, M and Ginneken, B and Aberle, DR and Adams, AM and Berg, CD and Black, WC and Clapp, JD and Fagerstrom, RM and Zopf, DA and Hollister, SJ and Nelson, ME and Ohye, RG and Green, GE and Kitasaka, T and Mori, K and Suenaga, Y and Hasegawa, J and Toriwaki, J and Schlathölter, T and Lorenz, C and Carlsen, IC and Renisch, S and Deschamps, T and Tschirren, J and Yavarna, T and Reinhardt, JM and Lo, P and Sporring, J and Ashraf, H and Pedersen, JJH and Bruijne, M and Kiraly, AP and Higgins, WE and McLennan, G and Hoffman, A and Reinhardt, JM and Salito, C and Barazzetti, L and Woods, JC and Aliverti, A and Gibbs, JD and Graham, MW and Higgins, WE and Graham, MW and Gibbs, JD and Cornish, DC and Higgins, WE and Gibbs, JD and Graham, MW and Higgins, WE and Rizi, FY and Ahmadian, A and Rezaie, N and Iranmanesh, SA and Lo, P and Ginneken, B and Reinhardt, JM and Bruijne, M and Fedorov, A and Beichel, R and Kalpathy-Cramer, J and Finet, J and Fillion-Robin, JC and Pujol, S and Nunzio, G and Tommasi, E and Agrusti, A and Cataldo, R and Mitri, I and Favetta, M},
  title    = {Optimizing parameters of an open-source airway segmentation algorithm using different {CT} images.},
  journal  = {Biomedical engineering online},
  year     = {2015},
  volume   = {14},
  number   = {1},
  pages    = {62--62},
  month    = dec,
  abstract = {BACKGROUND: Computed tomography (CT) helps physicians locate and diagnose pathological conditions. In some conditions, having an airway segmentation method which facilitates reconstruction of the airway from chest CT images can help hugely in the assessment of lung diseases. Many efforts have been made to develop airway segmentation algorithms, but methods are usually not optimized to be reliable across different CT scan parameters.{\textbackslash}n{\textbackslash}nMETHODS: In this paper, we present a simple and reliable semi-automatic algorithm which can segment tracheal and bronchial anatomy using the open-source 3D Slicer platform. The method is based on a region growing approach where trachea, right and left bronchi are cropped and segmented independently using three different thresholds. The algorithm and its parameters have been optimized to be efficient across different CT scan acquisition parameters. The performance of the proposed method has been evaluated on EXACT'09 cases and local clinical cases as well as on a breathing pig lung phantom using multiple scans and changing parameters. In particular, to investigate multiple scan parameters reconstruction kernel, radiation dose and slice thickness have been considered. Volume, branch count, branch length and leakage presence have been evaluated. A new method for leakage evaluation has been developed and correlation between segmentation metrics and CT acquisition parameters has been considered.{\textbackslash}n{\textbackslash}nRESULTS: All the considered cases have been segmented successfully with good results in terms of leakage presence. Results on clinical data are comparable to other teams' methods, as obtained by evaluation against the EXACT09 challenge, whereas results obtained from the phantom prove the reliability of the method across multiple CT platforms and acquisition parameters. As expected, slice thickness is the parameter affecting the results the most, whereas reconstruction kernel and radiation dose seem not to particularly affect airway segmentation.{\textbackslash}n{\textbackslash}nCONCLUSION: The system represents the first open-source airway segmentation platform. The quantitative evaluation approach presented represents the first repeatable system evaluation tool for like-for-like comparison between different airway segmentation platforms. Results suggest that the algorithm can be considered stable across multiple CT platforms and acquisition parameters and can be considered as a starting point for the development of a complete airway segmentation algorithm.},
  doi      = {10.1186/s12938-015-0060-2},
  file     = {nardelli2015optimizing.pdf:nardelli2015optimizing.pdf:PDF},
  keywords = {3D Slicer, Airway segmentation, Computed tomography (CT), Image Processing, ITK, lung, Region growing},
  url      = {http://www.biomedical-engineering-online.com/content/14/1/62},
}

@Article{navab2016personalized,
  author   = {Navab, Nassir and Fellow, Miccai and Hennersperger, Christoph and Frisch, Benjamin and F??rst, Bernhard},
  title    = {Personalized, relevance-based {Multimodal} {Robotic} {Imaging} and augmented reality for {Computer} {Assisted} {Interventions}},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {64--71},
  issn     = {1361-8415},
  abstract = {In the last decade, many researchers in medical image computing and computer assisted interventions across the world focused on the development of the Virtual Physiological Human (VPH), aiming at changing the practice of medicine from classification and treatment of diseases to that of modeling and treating patients. These projects resulted in major advancements in segmentation, registration, morphological, physiological and biomechanical modeling based on state of art medical imaging as well as other sensory data. However, a major issue which has not yet come into the focus is personalizing intra-operative imaging, allowing for optimal treatment. In this paper, we discuss the personalization of imaging and visualization process with particular focus on satisfying the challenging requirements of computer assisted interventions. We discuss such requirements and review a series of scientific contributions made by our research team to tackle some of these major challenges.},
  doi      = {10.1016/j.media.2016.06.021},
  keywords = {Augmented reality, Computer assisted interventions, Multimodal imaging and visualization, Robotic imaging},
  url      = {http://dx.doi.org/10.1016/j.media.2016.06.021},
}

@Article{nayakmultiple,
  author   = {Nayak, Guruprasad and Mithal, Varun and Kumar, Vipin},
  title    = {Multiple {Instance} {Learning} for bags with {Ordered} instances},
  abstract = {Multiple Instance Learning (MIL) algorithms are designed for problems where labels are available for groups of in-stances, commonly referred to as bags. In this paper, we con-sider a new MIL problem setting where instances in a bag are not exchangeable, and a bijection exists between every pair of bags. We propose a neural network based MIL algo-rithm (MILOrd) that leverages the existence of such a bijec-tion when learning to discriminate bags. MILOrd has an input node for each instance in the bag, an output node that captures the bag level prediction, and a hidden layer that captures the output from an instance level classifier for each instance in the bag. The bag level prediction is obtained by combining these hidden layer values using a function that models the impor-tance of each instance, unlike the traditional schemes where each instance is considered equal. We demonstrate the utility of the proposed algorithm on the problem of burned area map-ping using yearly bags composed of multispectral reflectance data for different time steps in the year. Our experiments show that MILOrd outperforms traditional MIL schemes that don't account for the presence of a bijection, on the performance of both bag label and instance label prediction.},
}

@InCollection{ng2012novel,
  author    = {Ng, Bernard and Varoquaux, Gaël and Poline, Jean-Baptiste and Thirion, Bertrand},
  title     = {A {Novel} {Sparse} {Graphical} {Approach} for {Multimodal} {Brain} {Connectivity} {Inference}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2012},
  pages     = {707--714},
  note      = {DOI: 10.1007/978-3-642-33415-3\_87},
  url       = {http://link.springer.com/10.1007/978-3-642-33415-3_87},
}

@Article{niessen2016mr,
  author   = {Niessen, Wiro J.},
  title    = {{MR} brain image analysis in dementia: {From} quantitative imaging biomarkers to ageing brain models and imaging genetics},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {107--113},
  issn     = {1361-8423 (Electronic){\textbackslash}r1361-8415 (Linking)},
  abstract = {MR brain image analysis has constantly been a hot topic research area in medical image analysis over the past two decades. In this article, it is discussed how the field developed from the construction of tools for automatic quantification of brain morphology, function, connectivity and pathology, to creating models of the ageing brain in normal ageing and disease, and tools for integrated analysis of imaging and genetic data. The current and future role of the field in improved understanding of the development of neurodegenerative disease is discussed, and its potential for aiding in early and differential diagnosis and prognosis of different types of dementia. For the latter, the use of reference imaging data and reference models derived from large clinical and population imaging studies, and the application of machine learning techniques on these reference data, are expected to play a key role.},
  doi      = {10.1016/j.media.2016.06.029},
  keywords = {Ageing brain models, Computer aided diagnosis, Dementia, Imaging genetics, machine learning, Population imaging, Quantitative imaging biomarker},
}

@Article{nishio2017computer,
  author   = {Nishio, Mizuho and Nagashima, Chihiro},
  title    = {Computer-aided {Diagnosis} for {Lung} {Cancer}: {Usefulness} of {Nodule} {Heterogeneity}},
  journal  = {Academic Radiology},
  year     = {2017},
  abstract = {RATIONALE AND OBJECTIVES
To develop a computer-aided diagnosis system to differentiate between malignant and benign nodules.

MATERIALS AND METHODS
Seventy-three lung nodules revealed on 60 sets of computed tomography (CT) images were analyzed. Contrast-enhanced CT was performed in 46 CT examinations. The images were provided by the LUNGx Challenge, and the ground truth of the lung nodules was unavailable; a surrogate ground truth was, therefore, constructed by radiological evaluation. Our proposed method involved novel patch-based feature extraction using principal component analysis, image convolution, and pooling operations. This method was compared to three other systems for the extraction of nodule features: histogram of CT density, local binary pattern on three orthogonal planes, and three-dimensional random local binary pattern. The probabilistic outputs of the systems and surrogate ground truth were analyzed using receiver operating characteristic analysis and area under the curve. The LUNGx Challenge team also calculated the area under the curve of our proposed method based on the actual ground truth of their dataset.

RESULTS
Based on the surrogate ground truth, the areas under the curve were as follows: histogram of CT density, 0.640; local binary pattern on three orthogonal planes, 0.688; three-dimensional random local binary pattern, 0.725; and the proposed method, 0.837. Based on the actual ground truth, the area under the curve of the proposed method was 0.81.

CONCLUSIONS
The proposed method could capture discriminative characteristics of lung nodules and was useful for the differentiation between malignant and benign nodules.},
  doi      = {10.1016/j.acra.2016.11.007},
}

@InCollection{noelle2003distribution,
  author    = {Nölle, Michael},
  title     = {Distribution {Distance} {Measures} {Applied} to 3-{D} {Object} {Recognition} ? {A} {Case} {Study}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2003},
  pages     = {84--91},
  note      = {DOI: 10.1007/978-3-540-45243-0\_12},
  url       = {http://link.springer.com/10.1007/978-3-540-45243-0_12},
}

@Article{obuchowski2014statistical,
  author   = {Obuchowski, Nancy A and Barnhart, Huiman X and Buckler, Andrew J and Pennello, Gene and Wang, Xiao-Feng and Kalpathy-Cramer, Jayashree and Kim, Hyun J Grace and Reeves, Anthony P},
  title    = {Statistical issues in the comparison of quantitative imaging biomarker algorithms using pulmonary nodule volume as an example.},
  journal  = {Statistical methods in medical research},
  year     = {2014},
  volume   = {24},
  number   = {1},
  pages    = {107--140},
  issn     = {0962-2802},
  abstract = {Quantitative imaging biomarkers are being used increasingly in medicine to diagnose and monitor patients' disease. The computer algorithms that measure quantitative imaging biomarkers have different technical performance characteristics. In this paper we illustrate the appropriate statistical methods for assessing and comparing the bias, precision, and agreement of computer algorithms. We use data from three studies of pulmonary nodules. The first study is a small phantom study used to illustrate metrics for assessing repeatability. The second study is a large phantom study allowing assessment of four algorithms' bias and reproducibility for measuring tumor volume and the change in tumor volume. The third study is a small clinical study of patients whose tumors were measured on two occasions. This study allows a direct assessment of six algorithms' performance for measuring tumor change. With these three examples we compare and contrast study designs and performance metrics, and we illustrate the advantages and limitations of various common statistical methods for quantitative imaging biomarker studies.},
  doi      = {10.1177/0962280214537392},
  file     = {obuchowski2014statistical.pdf:obuchowski2014statistical.pdf:PDF},
  keywords = {agreement, bias, correlation coefficient, coverage probability, intraclass, limits of agreement, repeatability, Reproducibility},
  url      = {http://www.ncbi.nlm.nih.gov/pubmed/24919828},
}

@Article{olivetti2011supervised,
  author = {Olivetti, Emanuele and Avesani, Paolo},
  title  = {Supervised {Segmentation} of {Fiber} {Tracts} {Motivation} : {Brain} {Connectivity}},
  year   = {2011},
  file   = {olivetti2011supervised.pdf:olivetti2011supervised.pdf:PDF},
}

@Article{orru2012using,
  author   = {Orrù, Graziella and Pettersson-Yeo, William and Marquand, Andre F. and Sartori, Giuseppe and Mechelli, Andrea},
  title    = {Using {Support} {Vector} {Machine} to identify imaging biomarkers of neurological and psychiatric disease: {A} critical review},
  journal  = {Neuroscience \& Biobehavioral Reviews},
  year     = {2012},
  volume   = {36},
  number   = {4},
  pages    = {1140--1152},
  abstract = {Standard univariate analysis of neuroimaging data has revealed a host of neuroanatomical and functional differences between healthy individuals and patients suffering a wide range of neurological and psychiatric disorders. Significant only at group level however these findings have had limited clinical translation, and recent attention has turned toward alternative forms of analysis, including Support-Vector-Machine (SVM). A type of machine learning, SVM allows categorisation of an individual's previously unseen data into a predefined group using a classification algorithm, developed on a training data set. In recent years, SVM has been successfully applied in the context of disease diagnosis, transition prediction and treatment prognosis, using both structural and functional neuroimaging data. Here we provide a brief overview of the method and review those studies that applied it to the investigation of Alzheimer's disease, schizophrenia, major depression, bipolar disorder, presymptomatic Huntington's disease, Parkinson's disease and autistic spectrum disorder. We conclude by discussing the main theoretical and practical challenges associated with the implementation of this method into the clinic and possible future directions.},
  doi      = {10.1016/j.neubiorev.2012.01.004},
}

@Article{ortega-martorell2013novel,
  author   = {Ortega-Martorell, Sandra and Ruiz, Hector and Vellido, Alfredo and Olier, Ivan and Romero, Enrique and Julia-Sape, Margarida and Martin, Jose D and Jarman, Ian H and Arus, Carles and Lisboa, Paulo J G},
  title    = {A novel semi-supervised methodology for extracting tumor type-specific {MRS} sources in human brain data.},
  journal  = {PloS one},
  year     = {2013},
  volume   = {8},
  number   = {12},
  pages    = {e83773--e83773},
  abstract = {BACKGROUND: The clinical investigation of human brain tumors often starts with a non-invasive imaging study, providing information about the tumor extent and location, but little insight into the biochemistry of the analyzed tissue. Magnetic Resonance Spectroscopy can complement imaging by supplying a metabolic fingerprint of the tissue. This study analyzes single-voxel magnetic resonance spectra, which represent signal information in the frequency domain. Given that a single voxel may contain a heterogeneous mix of tissues, signal source identification is a relevant challenge for the problem of tumor type classification from the spectroscopic signal. METHODOLOGY/PRINCIPAL FINDINGS: Non-negative matrix factorization techniques have recently shown their potential for the identification of meaningful sources from brain tissue spectroscopy data. In this study, we use a convex variant of these methods that is capable of handling negatively-valued data and generating sources that can be interpreted as tumor class prototypes. A novel approach to convex non-negative matrix factorization is proposed, in which prior knowledge about class information is utilized in model optimization. Class-specific information is integrated into this semi-supervised process by setting the metric of a latent variable space where the matrix factorization is carried out. The reported experimental study comprises 196 cases from different tumor types drawn from two international, multi-center databases. The results indicate that the proposed approach outperforms a purely unsupervised process by achieving near perfect correlation of the extracted sources with the mean spectra of the tumor types. It also improves tissue type classification. CONCLUSIONS/SIGNIFICANCE: We show that source extraction by unsupervised matrix factorization benefits from the integration of the available class information, so operating in a semi-supervised learning manner, for discriminative source identification and brain tumor labeling from single-voxel spectroscopy data. We are confident that the proposed methodology has wider applicability for biomedical signal processing.},
  doi      = {10.1371/journal.pone.0083773},
  groups   = {Not-so-supervised papers},
  keywords = {Algorithms, Brain, Brain Neoplasms, diagnosis, Humans, Magnetic Resonance Spectroscopy, methods, Pathology, Statistics as Topic},
  language = {eng},
}

@Article{ourselin2016computer,
  author   = {Ourselin, S??bastien and Emberton, Mark and Vercauteren, Tom},
  title    = {From computer-assisted intervention research to clinical impact: {The} need for a holistic approach},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {72--78},
  abstract = {The early days of the field of medical image computing (MIC) and computer-assisted intervention (CAI), when publishing a strong self-contained methodological algorithm was enough to produce impact, are over. As a community, we now have substantial responsibility to translate our scientific progresses into improved patient care. In the field of computer-assisted interventions, the emphasis is also shifting from the mere use of well-known established imaging modalities and position trackers to the design and combination of innovative sensing, elaborate computational models and fine-grained clinical workflow analysis to create devices with unprecedented capabilities. The barriers to translating such devices in the complex and understandably heavily regulated surgical and interventional environment can seem daunting. Whether we leave the translation task mostly to our industrial partners or welcome, as researchers, an important share of it is up to us. We argue that embracing the complexity of surgical and interventional sciences is mandatory to the evolution of the field. Being able to do so requires large-scale infrastructure and a critical mass of expertise that very few research centres have. In this paper, we emphasise the need for a holistic approach to computer-assisted interventions where clinical, scientific, engineering and regulatory expertise are combined as a means of moving towards clinical impact. To ensure that the breadth of infrastructure and expertise required for translational computer-assisted intervention research does not lead to a situation where the field advances only thanks to a handful of exceptionally large research centres, we also advocate that solutions need to be designed to lower the barriers to entry. Inspired by fields such as particle physics and astronomy, we claim that centralised very large innovation centres with state of the art technology and health technology assessment capabilities backed by core support staff and open interoperability standards need to be accessible to the wider computer-assisted intervention research community.},
  doi      = {10.1016/j.media.2016.06.018},
  keywords = {Computer-assisted intervention, Health technology assessment, Medical devices, Valley of death},
}

@Article{panwar2016genome,
  author   = {Panwar, Bharat and Menon, Rajasree and Eksi, Ridvan and Li, Hong-Dong and Omenn, Gilbert S and Guan, Yuanfang},
  title    = {Genome-{Wide} {Functional} {Annotation} of {Human} {Protein}-{Coding} {Splice} {Variants} {Using} {Multiple} {Instance} {Learning}.},
  journal  = {Journal of proteome research},
  year     = {2016},
  volume   = {15},
  number   = {6},
  pages    = {1747--53},
  month    = jun,
  abstract = {The vast majority of human multiexon genes undergo alternative splicing and produce a variety of splice variant transcripts and proteins, which can perform different functions. These protein-coding splice variants (PCSVs) greatly increase the functional diversity of proteins. Most functional annotation algorithms have been developed at the gene level; the lack of isoform-level gold standards is an important intellectual limitation for currently available machine learning algorithms. The accumulation of a large amount of RNA-seq data in the public domain greatly increases our ability to examine the functional annotation of genes at isoform level. In the present study, we used a multiple instance learning (MIL)-based approach for predicting the function of PCSVs. We used transcript-level expression values and gene-level functional associations from the Gene Ontology database. A support vector machine (SVM)-based 5-fold cross-validation technique was applied. Comparatively, genes with multiple PCSVs performed better than single PCSV genes, and performance also improved when more examples were available to train the models. We demonstrated our predictions using literature evidence of ADAM15, LMNA/C, and DMXL2 genes. All predictions have been implemented in a web resource called "IsoFunc", which is freely available for the global scientific community through http://guanlab.ccmb.med.umich.edu/isofunc .},
  doi      = {10.1021/acs.jproteome.5b00883},
  keywords = {ADAM15, alternative splicing, DMXL2, functional annotation, gene ontology (GO), IsoFunc, LMNA/C, multiple instance learning (MIL), protein-coding splice variant (PCSV), RNA-seq, support vector machine (SVM)},
  url      = {http://www.ncbi.nlm.nih.gov/pubmed/27142340},
}

@Article{paragios2016hyper,
  author   = {Paragios, Nikos and Ferrante, Enzo and Glocker, Ben and Komodakis, Nikos and Parisot, Sarah and Zacharaki, Evangelia I.},
  title    = {({Hyper})-graphical models in biomedical image analysis},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {102--106},
  abstract = {Computational vision, visual computing and biomedical image analysis have made tremendous progress over the past two decades. This is mostly due the development of efficient learning and inference algorithms which allow better and richer modeling of image and visual understanding tasks. Hyper-graph representations are among the most prominent tools to address such perception through the casting of perception as a graph optimization problem. In this paper, we briefly introduce the importance of such representations, discuss their strength and limitations, provide appropriate strategies for their inference and present their application to address a variety of problems in biomedical image analysis.},
  doi      = {10.1016/j.media.2016.06.028},
  keywords = {Graph cuts, (Hyper)graphs, Image segmentation, Linear programming, Message passing, Random fields, Shape \& volume registration},
}

@Article{park2014interactive,
  author   = {Park, Sang Hyun and Gao, Yaozong and Shi, Yinghuan and Shen, Dinggang},
  title    = {Interactive prostate segmentation using atlas-guided semi-supervised learning and adaptive feature selection},
  journal  = {Medical Physics},
  year     = {2014},
  volume   = {41},
  number   = {11},
  pages    = {111715--111715},
  abstract = {PURPOSE: Accurate prostate segmentation is necessary for maximizing the effectiveness of radiation therapy of prostate cancer. However, manual segmentation from 3D CT images is very time-consuming and often causes large intra- and interobserver variations across clinicians. Many segmentation methods have been proposed to automate this labor-intensive process, but tedious manual editing is still required due to the limited performance. In this paper, the authors propose a new interactive segmentation method that can (1) flexibly generate the editing result with a few scribbles or dots provided by a clinician, (2) fast deliver intermediate results to the clinician, and (3) sequentially correct the segmentations from any type of automatic or interactive segmentation methods. METHODS: The authors formulate the editing problem as a semisupervised learning problem which can utilize a priori knowledge of training data and also the valuable information from user interactions. Specifically, from a region of interest near the given user interactions, the appropriate training labels, which are well matched with the user interactions, can be locally searched from a training set. With voting from the selected training labels, both confident prostate and background voxels, as well as unconfident voxels can be estimated. To reflect informative relationship between voxels, location-adaptive features are selected from the confident voxels by using regression forest and Fisher separation criterion. Then, the manifold configuration computed in the derived feature space is enforced into the semisupervised learning algorithm. The labels of unconfident voxels are then predicted by regularizing semisupervised learning algorithm. RESULTS: The proposed interactive segmentation method was applied to correct automatic segmentation results of 30 challenging CT images. The correction was conducted three times with different user interactions performed at different time periods, in order to evaluate both the efficiency and the robustness. The automatic segmentation results with the original average Dice similarity coefficient of 0.78 were improved to 0.865-0.872 after conducting 55-59 interactions by using the proposed method, where each editing procedure took less than 3 s. In addition, the proposed method obtained the most consistent editing results with respect to different user interactions, compared to other methods. CONCLUSIONS: The proposed method obtains robust editing results with few interactions for various wrong segmentation cases, by selecting the location-adaptive features and further imposing the manifold regularization. The authors expect the proposed method to largely reduce the laborious burdens of manual editing, as well as both the intra- and interobserver variability across clinicians.},
  doi2     = {10.1118/1.4898200},
  groups   = {Not-so-supervised papers},
  keywords = {Algorithms, Automated, Automation, Computer Simulation, Humans, Imaging, Male, methods, Observer Variation, Pathology, Pattern Recognition, Prostate, Prostatic Neoplasms, radiography, Radiotherapy, regression analysis, Three-Dimensional, Tomography, X-Ray Computed},
  language = {eng},
}

@Article{partridge2011forty,
  author   = {Partridge, Craig},
  title    = {Forty data communications research questions},
  journal  = {ACM SIGCOMM Computer Communication Review},
  year     = {2011},
  volume   = {41},
  number   = {5},
  pages    = {24--24},
  abstract = {About ten years ago, Bob Lucky asked me for a list of open research questions in networking. I didn?t have a ready list and reacted it would be good to have one. This essay is my (long belated) reply.},
  doi      = {10.1145/2043165.2043170},
  file     = {partridge2011forty.pdf:partridge2011forty.pdf:PDF},
  url      = {http://dl.acm.org/citation.cfm?doid=2043165.2043170},
}

@Article{patel2015visual,
  author   = {Patel, Vishal M. and Gopalan, Raghuraman and Li, Ruonan and Chellappa, Rama},
  title    = {Visual {Domain} {Adaptation}: {A} survey of recent advances},
  journal  = {IEEE Signal Processing Magazine},
  year     = {2015},
  volume   = {32},
  number   = {3},
  pages    = {53--69},
  abstract = {In pattern recognition and computer vision, one is often faced with scenarios where the training data used to learn a model have different distribution from the data on which the model is applied. Regardless of the cause, any distributional change that occurs after learning a classifier can degrade its performance at test time. Domain adaptation tries to mitigate this degradation. In this article, we provide a survey of domain adaptation methods for visual recognition. We discuss the merits and drawbacks of existing domain adaptation approaches and identify promising avenues for research in this rapidly evolving field.},
  doi      = {10.1109/MSP.2014.2347059},
  file     = {patel2015visual.pdf:patel2015visual.pdf:PDF},
}

@Article{patterson2012sun,
  author   = {Patterson, Genevieve and Hays, James},
  title    = {{SUN} attribute database: {Discovering}, annotating, and recognizing scene attributes},
  journal  = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  year     = {2012},
  pages    = {2751--2758},
  issn     = {9781467312264},
  abstract = {In this paper we present the first large-scale scene attribute database. First, we perform crowd-sourced human studies to find a taxonomy of 102 discriminative attributes. Next, we build the ?SUN attribute database? on top of the diverse SUN categorical database. Our attribute database spans more than 700 categories and 14,000 images and has potential for use in high-level scene understanding and fine-grained scene recognition. We use our dataset to train attribute classifiers and evaluate how well these relatively simple classifiers can recognize a variety of attributes related to materials, surface properties, lighting, functions and affordances, and spatial envelope properties.},
  doi      = {10.1109/CVPR.2012.6247998},
  file     = {patterson2012sun.pdf:patterson2012sun.pdf:PDF},
}

@Article{paul2016deep,
  author   = {Paul, Rahul and Hawkins, Samuel H and Balagurunathan, Yoganand and Schabath, Matthew B and Gillies, Robert J and Hall, Lawrence O and Goldgof, Dmitry B},
  title    = {Deep {Feature} {Transfer} {Learning} in {Combination} with {Traditional} {Features} {Predicts} {Survival} {Among} {Patients} with {Lung} {Adenocarcinoma}},
  abstract = {Abbreviations: Convolutional neural network (CNN), area under the curve (AUC), computed tomography (CT), artificial neural networks (ANN), rectified linear unit (ReLU) Lung cancer is the most common cause of cancer-related deaths in the USA. It can be detected and diag-nosed using computed tomography images. For an automated classifier, identifying predictive features from medical images is a key concern. Deep feature extraction using pretrained convolutional neural networks (CNNs) has recently been successfully applied in some image domains. Here, we applied a pretrained CNN to extract deep features from 40 computed tomography images, with contrast, of non-small cell adeno-carcinoma lung cancer, and combined deep features with traditional image features and trained classifiers to predict short-and long-term survivors. We experimented with several pretrained CNNs and several fea-ture selection strategies. The best previously reported accuracy when using traditional quantitative features was 77.5\% (area under the curve [AUC], 0.712), which was achieved by a decision tree classifier. The best reported accuracy from transfer learning and deep features was 77.5\% (AUC, 0.713) using a decision tree classifier. When extracted deep neural network features were combined with traditional quantitative features, we obtained an accuracy of 90\% (AUC, 0.935) with the 5 best post-rectified linear unit features extracted from a vgg-f pretrained CNN and the 5 best traditional features. The best results were achieved with the symmetric uncertainty feature ranking algorithm followed by a random forests classifier. INTRODUCTION Lung cancer is the most common cause of cancer-related deaths in the USA (1). Early detection of cancer results in improved patient outcomes. Radiological imaging modalities, such as com-puted tomography (CT) and magnetic resonance imaging, can help in early detection, diagnosis, and management of cancer. Ra-diomics (33) is a process of extracting quantitative features for computer-aided image analysis on high-quality medical images (eg, magnetic resonance imaging, CT). The process involves extraction of various quantitative features from a region of interest (2) (intensity, shape, or texture) and use of those (and potentially other) features to provide actionable information. Traditional quantitative features (30, 31, 32, 36, 37) may be insufficient for tumor classification; therefore, features extracted from a deep neural network may prove helpful. Recently, deep feature extraction from a convolutional neural network (CNN) has},
  doi2     = {10.18383/j.tom.2016.00211},
  keywords = {adenocarcinoma, Computed tomography, deep features, deep neural network, lung cancer, pre-trained CNN, symmet-ric uncertainty, Transfer learning},
}

@Article{perez2016automatic,
  author   = {Perez-rovira, Adria and Kuo, Wieying and Petersen, Jens and Tiddens, Harm A. W. M. and de Bruijne, Marleen},
  title    = {Automatic airway-artery analysis on lung {CT} to quantify airway wall thickening and bronchiectasis},
  journal  = {Medical Physics},
  year     = {2016},
  number   = {submitted},
  pages    = {1--10},
  doi      = {10.1118/1.4963214},
  file     = {perez2016automatic.pdf:perez2016automatic.pdf:PDF},
  keywords = {airway, artery, Bronchiectasis, ct, quantification},
}

@Article{peters2016image,
  author   = {Peters, Terry M. and Linte, Cristian A.},
  title    = {Image-guided interventions and computer-integrated therapy: {Quo} vadis?},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {56--63},
  abstract = {Significant efforts have been dedicated to minimizing invasiveness associated with surgical interventions, most of which have been possible thanks to the developments in medical imaging, surgical navigation, visualization and display technologies. Image-guided interventions have promised to dramatically change the way therapies are delivered to many organs. However, in spite of the development of many sophisticated technologies over the past two decades, other than some isolated examples of successful implementations, minimally invasive therapy is far from enjoying the wide acceptance once envisioned. This paper provides a large-scale overview of the state-of-the-art developments, identifies several barriers thought to have hampered the wider adoption of image-guided navigation, and suggests areas of research that may potentially advance the field.},
  doi      = {10.1016/j.media.2016.06.004},
  keywords = {Image-guided interventions, Navigation, Surgical workflow, Tracking, Virtual reality, Visualization},
}

@Article{pevny2016using,
  author   = {Pevny, Tomas and Somol, Petr},
  title    = {Using {Neural} {Network} {Formalism} to {Solve} {Multiple}-{Instance} {Problems}},
  year     = {2016},
  number   = {Mil},
  abstract = {Many objects in the real world are difficult to describe by a single numerical vector of a fixed length, whereas describing them by a set of vectors is more natural. Therefore, Multiple instance learning (MIL) techniques have been constantly gaining on importance throughout last years. MIL formalism represents each object (sample) by a set (bag) of feature vectors (instances) of fixed length where knowledge about objects (e.g., class label) is available on bag level but not necessarily on instance level. Many standard tools including supervised classifiers have been already adapted to MIL setting since the problem got formalized in late nineties. In this work we propose a neural network (NN) based formalism that intuitively bridges the gap between MIL problem definition and the vast existing knowledge-base of standard models and classifiers. We show that the proposed NN formalism is effectively optimizable by a modified back-propagation algorithm and can reveal unknown patterns inside bags. Comparison to eight types of classifiers from the prior art on a set of 14 publicly available benchmark datasets confirms the advantages and accuracy of the proposed solution.},
  file     = {pevny2016using.pdf:pevny2016using.pdf:PDF},
  url      = {http://arxiv.org/abs/1609.07257},
}

@InCollection{pfeifer2008multiple,
  author    = {Pfeifer, Nico and Kohlbacher, Oliver},
  title     = {Multiple {Instance} {Learning} {Allows} {MHC} {Class} {II} {Epitope} {Predictions} {Across} {Alleles}},
  booktitle = {Algorithms in {Bioinformatics}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2008},
  pages     = {210--221},
  address   = {Berlin, Heidelberg},
  note      = {DOI: 10.1007/978-3-540-87361-7\_18},
  annote    = {Predicting binding of peptide (bag) to MHCII alleles. There are different alleles, for some of which binding / non-binding peptides are available, and for others this is not the case.Peptide = chain of amino acids (instances). Unknown which part (amino acid)? binds to the allele.Each peptide is represented by a bag of substrings of length 9, which have a particular type of amino acid at position 1. The label is the binding affinity of the peptide (real-valued)Normalized set kernel is usedBag level prediction, collective assumption},
  file      = {pfeifer2008multiple.pdf:pfeifer2008multiple.pdf:PDF},
  url       = {http://link.springer.com/10.1007/978-3-540-87361-7_18},
}

@InProceedings{phan2016transfer,
  author    = {Phan, Ha Tran Hong and Kumar, Ashnil and Kim, Jinman and Feng, Dagan},
  title     = {Transfer learning of a convolutional neural network for {HEp}-2 cell image classification},
  booktitle = {International Symposium on Biomedical Imaging (ISBI)},
  year      = {2016},
  pages     = {1208--1211},
  month     = apr,
  publisher = {IEEE},
  doi2      = {10.1109/ISBI.2016.7493483},
  groups    = {Not-so-supervised papers},
  isbn2     = {978-1-4799-2349-6},
  url2      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7493483},
}

@InCollection{ping2011famer,
  author    = {Ping, Wei and Xu, Ye and Wang, Jianyong and Hua, Xian-Sheng},
  title     = {{FAMER}: {Making} {Multi}-{Instance} {Learning} {Better} and {Faster}},
  booktitle = {Proceedings of the 2011 {SIAM} {International} {Conference} on {Data} {Mining}},
  publisher = {Society for Industrial and Applied Mathematics},
  year      = {2011},
  pages     = {594--605},
  address   = {Philadelphia, PA},
  month     = apr,
  note      = {DOI: 10.1137/1.9781611972818.51},
  url       = {http://epubs.siam.org/doi/abs/10.1137/1.9781611972818.51},
}

@Article{prescott1997gender,
  author   = {Prescott, E. and Bjerg, A. M. and Andersen, P. K. and Lange, P. and Vestbo, J.},
  title    = {Gender difference in smoking effects on lung function and risk of hospitalization for {COPD}: {Results} front a {Danish} longitudinal population study},
  journal  = {European Respiratory Journal},
  year     = {1997},
  volume   = {10},
  number   = {4},
  pages    = {822--827},
  abstract = {Recent findings suggest that females may be more susceptible than males to the deleterious influence of tobacco smoking in developing chronic obstructive pulmonary disease (COPD). This paper studies the interaction of gender and smoking on development of COPD as assessed by lung function and hospital admission. A total of 13,897 subjects, born after 1920, from two population studies, 9,083 from the Copenhagen City Heart Study (CCHS) and 4,814 from the Glostrup Population Studies (GPS), were followed for 7-16 yrs. Data were linked with information on hospital admissions caused by COPD. Based on cross-sectional data, in the CCHS the estimated excess loss of forced expiratory volume in one second (FEV1) per pack-year of smoking was 7.4 mL in female smokers who inhaled and 6.3 mL in male smokers who inhaled. In the GPS, the corresponding excess loss of FEV1 was 10.5 and 8.4 mL in females and males, respectively. Two hundred and eighteen subjects in the CCHS and 23 in the GPS were hospitalized during follow-up. Risk associated with pack-years was higher in females than in males (relative risks (RRs) for 1-20, 20-40 and {\textgreater}40 pack-years were 7.0 (3.5-14.1), 9.8 (4.9-19.6) and 23.3 (10.7-50.9) in females, and 3.2 (1.1-9.1), 5.7 (2.2-14.3) and 8.4 (3.3-21.6) in males) but the interaction term gender x pack-years did not reach significance (p=0.08). Results were similar in the GPS. After adjusting for smoking in more detail, females in both cohorts had an increased risk of hospitalization for COPD compared to males with a RR of 1.5 (1.2-2.1) in the CCHS and 3.6 (1.4-9.0) in the GPS. This was not likely to be caused by a generally increased rate of hospital admission for females. Results were similar when including deaths from COPD as endpoint. In two independent population samples, smoking had greater impact on the lung function of females than males, and after adjusting for smoking females subsequently suffered a higher risk of being admitted to hospital for COPD. Results suggest that adverse effects of smoking on lung function may be greater in females than in males.},
  doi      = {10.1183/09031936.97.10040822},
  file     = {prescott1997gender.pdf:prescott1997gender.pdf:PDF},
  keywords = {Chronic obstructive pulmonary disease, Epidemiology, Females, Forced expiratory volume in one second},
}

@Article{pye2015gender,
  author   = {Pye, David J},
  title    = {Gender {Bias} in the {Diagnosis} of {COPD} *},
  year     = {2015},
  pages    = {1691--1695},
  file     = {pye2015gender.pdf:pye2015gender.pdf:PDF},
  keywords = {asthma, death, misdiagnosis, most common cause of, opd is the fourth, physician decision making, spirometry, underdiagnosis},
}

@InProceedings{quantification2013nih,
  author    = {Quantification, Emphysema and Hrct, I N A Multi-scanner and Using, Cohort and Intensity, Local},
  title     = {{NIH} {Public} {Access}},
  booktitle = {International Symposium on Biomedical Imaging (ISBI)},
  year      = {2013},
  doi       = {10.1109/ISBI.2012.6235587.EMPHYSEMA},
  keywords  = {COPD, densitometry, Emphysema, texture analysis, tissue classification},
}

@InProceedings{quellec2012weakly,
  author    = {Quellec, G. and Laniard, M. and Cazuguel, G. and Abramoff, M. D. and Cochener, B. and Roux, Ch.},
  title     = {Weakly supervised classification of medical images},
  booktitle = {International Symposium on Biomedical Imaging (ISBI)},
  year      = {2012},
  pages     = {110--113},
  month     = may,
  publisher = {IEEE},
  doi       = {10.1109/ISBI.2012.6235496},
  isbn      = {978-1-4577-1858-8},
  keywords  = {biomedical optical imaging, Diabetes, diabetic retinopathy, diabetic retinopathy detection, diseases, Equations, eye, image classification, Image color analysis, Image resolution, medical image processing, medical images, relevant pattern detection, retinal image dataset, Retinopathy, Training, Vectors, weakly supervised image classification, weak supervision},
  url       = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6235496},
}

@Article{quellec2016automatic,
  author   = {Quellec, Gwenolé and Lamard, Mathieu and Erginay, Ali and Chabouis, Agnès and Massin, Pascale and Cochener, Béatrice and Cazuguel, Guy},
  title    = {Automatic detection of referral patients due to retinal pathologies through data mining},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {29},
  pages    = {47--64},
  abstract = {With the increased prevalence of retinal pathologies, automating the detection of these pathologies is becoming more and more relevant. In the past few years, many algorithms have been developed for the automated detection of a specific pathology, typically diabetic retinopathy, using eye fundus photography. No matter how good these algorithms are, we believe many clinicians would not use automatic detection tools focusing on a single pathology and ignoring any other pathology present in the patient's retinas. To solve this issue, an algorithm for characterizing the appearance of abnormal retinas, as well as the appearance of the normal ones, is presented. This algorithm does not focus on individual images: it considers examination records consisting of multiple photographs of each retina, together with contextual information about the patient. Specifically, it relies on data mining in order to learn diagnosis rules from characterizations of fundus examination records. The main novelty is that the content of examination records (images and context) is characterized at multiple levels of spatial and lexical granularity: 1) spatial flexibility is ensured by an adaptive decomposition of composite retinal images into a cascade of regions, 2) lexical granularity is ensured by an adaptive decomposition of the feature space into a cascade of visual words. This multigranular representation allows for great flexibility in automatically characterizing normality and abnormality: it is possible to generate diagnosis rules whose precision and generalization ability can be traded off depending on data availability. A variation on usual data mining algorithms, originally designed to mine static data, is proposed so that contextual and visual data at adaptive granularity levels can be mined. This framework was evaluated in e-ophtha, a dataset of 25,702 examination records from the OPHDIAT screening network, as well as in the publicly-available Messidor dataset. It was successfully applied to the detection of patients that should be referred to an ophthalmologist and also to the specific detection of several pathologies.},
  doi2     = {10.1016/j.media.2015.12.006},
  keywords = {anomaly detection, Bag of Visual Words model, Data mining, Retinal pathologies},
}

@Article{raddick2010citizen,
  author   = {Raddick, M Jordan and Bracey, Georgia and Carney, Karen and Gyuk, Geza},
  title    = {Citizen science: status and research directions for the coming decade},
  journal  = {AGB Stars and Related Phenomonastro 2010: The Astronomy and Astrophysics Decadal Survey},
  year     = {2010},
  pages    = {46--46},
  issn     = {9780874216561},
  abstract = {Imagine a world where participating in science is as accepted a part of everyday life as participation in a sport is today. Many people would participate in science at various levels, each making genuine contributions to scientific knowledge. How much more knowledge could we discover? How many more people could learn about the way that science works and make scientific habits of mind a part of their everyday lives? Such a world is starting to become a reality through Citizen Science. Citizen Science involves volunteers from the general public in scientific investigations as data collectors or analysts. A number of existing Citizen Science projects in astronomy have been highly successful in terms of scientific productivity and number of people reached. Citizen Science has a number of benefits for four separate communities. For scientific researchers, it allows projects that were previously impossible to be done quickly and easily. For volunteers, it can provide fun, a sense of community, and the ability to contribute to science. For STEM educators, it can offer the opportunity for increased learning, a window into the process of science, and a chance to promote the idea that I can do science. For society at large, it can build a closer connection between scientists and the public, and can result in a public with increased knowledge about science and scientific habits of mind. We strongly recommend that the astronomical community recognize the value added by Citizen Science to astronomy, in terms of both its scientific merit and its broader impacts. We recommend that developers of Citizen Science projects collaborate to share tools and lessons learned, as well as engage in formal research studies to quantify characteristics of successful Citizen Science projects as measured by all stakeholders.},
  doi      = {10.1007/s13398-014-0173-7.2},
}

@Article{rajan2006exploiting,
  author   = {Rajan, Suju and Ghosh, Joydeep and Crawford, Melba M.},
  title    = {Exploiting class hierarchies for knowledge transfer in hyperspectral data},
  journal  = {IEEE Transactions on Geoscience and Remote Sensing},
  year     = {2006},
  volume   = {44},
  number   = {11},
  pages    = {3408--3417},
  issn     = {0196-2892},
  abstract = {Obtaining ground truth for classification of remotely sensed data is time consuming and expensive, resulting in poorly represented signatures over large areas. In addition, the spectral signatures of a given class vary with location and/or time. Therefore, successful adaptation of a classifier designed from the available labeled data to classify new hyperspectral images acquired over other geographic locations or subsequent times is difficult, if minimal additional labeled data are available. In this paper, the binary hierarchical classifier is used to propose a knowledge transfer framework that leverages the information extracted from the existing labeled data to classify spatially separate and multitemporal test data. Experimental results show that in the absence of any labeled data in the new area, the approach is better than a direct application of the original classifier on the new data. Moreover, when small amounts of the labeled data are available from the new area, the framework offers further improvements through semisupervised learning mechanisms and compares favorably with previously proposed methods},
  doi      = {10.1109/TGRS.2006.878442},
  file     = {rajan2006exploiting.pdf:rajan2006exploiting.pdf:PDF},
  keywords = {Hierarchical classifier, Knowledge transfer, Multitemporal data, Semisupervised classifiers, Spatially separate data},
}

@Article{ramos2013learning,
  author   = {Ramos, José and Kockelkorn, Thessa and van Ginneken, Bram and Viergever, Max A and Grutters, Jan and Ramos, Rui and Campilho, Aurélio},
  title    = {Learning {Interstitial} {Lung} {Diseases} \{{CT}\} {Patterns} from {Reports} {Keywords}},
  journal  = {The Fifth International Workshop on Pulmonary Image Analysis},
  year     = {2013},
  pages    = {21--32},
  abstract = {The interpretation of CT exams from patients with interstitial lung{\textbackslash}ndiseases depends on the correct assessment of associated CT patterns.{\textbackslash}nComputer aided diagnosis systems often study the automatic identification{\textbackslash}nof CT patterns, using the division of the lung in volumes of interest{\textbackslash}nand the use of supervised classification. Despite moderate success,{\textbackslash}nthis approach has been hampered by the shortage of medical annotations{\textbackslash}navailable to research groups. We propose a new method that collects{\textbackslash}nexams that contain CT patterns through the presence of keywords{\textbackslash}n{\textbackslash}nin radiology reports, to learn pattern models using a multiple instance{\textbackslash}nlearning algorithm. We compared our approach to the traditional use{\textbackslash}nof volumes of interest annotations for six interstitial lung diseases{\textbackslash}npatterns. The results show our approach performed comparatively in{\textbackslash}nfour of the studied patterns, and poorly for the other two. The results{\textbackslash}nsuggest that under certain conditions learning CT patterns from radiology{\textbackslash}nreports is possible, which could foster developments in computer{\textbackslash}naided diagnosis systems.},
  file     = {ramos2013learning.pdf:ramos2013learning.pdf:PDF},
}

@Article{rao2009mining,
  author   = {Rao, R Bharat and Fung, Glenn and Krishnapuram, Balaji and Bi, Jinbo and Dundar, Murat and Raykar, Vikas and Yu, Shipeng and Krishnan, Sriram and Zhou, Xiang and Krishnan, Arun and Salganicoff, Marcos and Bogoni, Luca and Wolf, Matthias and Jerebko, Anna and Stoeckel, Jonathan},
  title    = {Mining {Medical} {Images}},
  journal  = {Proceedings of the Third Workshop on Data Mining Case Studies and Practice Prize, Fifteenth Annual SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2009).},
  year     = {2009},
  volume   = {1895},
  number   = {Stanton},
  abstract = {Advances in medical technology have greatly increased information density for imaging studies. This may result from increased spatial resolution facilitating greater anatomical detail, increased contrast resolution allowing evaluation of more subtle structures than previously possible, or increased temporal image acquisition rate. However, such technological advances, while potentially improving the diagnostic benefits of a study, may result in ?data overload? while processing this information. This often manifests as increased total study time, defined as the combination of acquisition, processing and interpretation times; even more critically, the vast increase in data does not always translate to improved diagnosis/treatment selection. This paper describes a related series of clinically motivated data mining products that extract the key, actionable information from the vast amount of imaging data in order to ensure an improvement in patient care (via more accurate/early diagnosis) and a simultaneous reduction in total study time. Several thousand units of the products described in this paper have been commercially deployed in hospitals around the world since 2004 1 . While each application targets a specific clinical task, they share the common methodology of transforming raw imaging data, through knowledge-based data mining algorithms, into clinically relevant information. This enables users to spend less time interacting with an image volume to extract the clinical information it contains, while supporting improved diagnostic accuracy. Although image processing plays an equally critical role in these software, this paper focuses primarily on the data mining challenges involved in developing commercial products.},
  keywords = {Computer aided diagnosis, Data mining, exploratory surgery, from, has all but vanished, Image Processing, the term},
}

@Article{ross2016bayesian,
  author = {Ross, James C and Castaldi, Peter J and Cho, Michael H and Chen, Junxiang and Chang, Yale and Dy, Jennifer G and Edwin, K and Washko, George R},
  title  = {A {Bayesian} {Nonparametric} {Model} for {Disease} {Subtyping} : {Application} to {Emphysema} {Phenotypes}},
  year   = {2016},
  volume = {X},
  number = {X},
  pages  = {1--11},
  doi    = {10.1109/TMI.2016.2608782},
}

@Article{rubinov2013fledgling,
  author   = {Rubinov, Mikail and Bullmore, Ed},
  title    = {Fledgling pathoconnectomics of psychiatric disorders},
  journal  = {Trends in Cognitive Sciences},
  year     = {2013},
  volume   = {17},
  number   = {12},
  pages    = {641--647},
  abstract = {Pathoconnectomics, the mapping of abnormal brain networks, is a popular current framework for the study of brain dysfunction in psychiatric disorders. In this review we evaluate the conceptual foundations of this framework, describe the construction and analysis of empirical models of brain networks or connectomes, and summarize recent reports of the large-scale whole-brain connectome organization of two candidate brain-network disorders, schizophrenia and autism. We consider the evidence for the abnormal brain-network nature of psychiatric disorders and find it inconclusive. For instance, although there is some evidence for more random whole-brain network organization in schizophrenia and autism, future studies need to determine if these and other observed brain-network abnormalities represent sufficient phenotypes of psychiatric disorders, in order to validate pathoconnectomics as a scientific and clinical framework.},
  doi      = {10.1016/j.tics.2013.10.007},
}

@Article{rueckert2016learning,
  author   = {Rueckert, Daniel and Glocker, Ben and Kainz, Bernhard},
  title    = {Learning clinically useful information from images: {Past}, present and future},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {1339--1351},
  abstract = {Over the last decade, research in medical imaging has made significant progress in addressing challenging tasks such as image registration and image segmentation. In particular, the use of model-based approaches has been key in numerous, successful advances in methodology. The advantage of model-based approaches is that they allow the incorporation of prior knowledge acting as a regularisation that favours plausible solutions over implausible ones. More recently, medical imaging has moved away from hand-crafted, and often explicitly designed models towards data-driven, implicit models that are constructed using machine learning techniques. This has led to major improvements in all stages of the medical imaging pipeline, from acquisition and reconstruction to analysis and interpretation. As more and more imaging data is becoming available, e.g., from large population studies, this trend is likely to continue and accelerate. At the same time new developments in machine learning, e.g., deep learning, as well as significant improvements in computing power, e.g., parallelisation on graphics hardware, offer new potential for data-driven, semantic and intelligent medical imaging. This article outlines the work of the BioMedIA group in this area and highlights some of the challenges and opportunities for future work.},
  doi      = {10.1016/j.media.2016.06.009},
  keywords = {Intelligent imaging, machine learning, Semantic imaging},
  url      = {http://dx.doi.org/10.1016/j.media.2016.06.009},
}

@Article{rusk2015deep,
  author   = {Rusk, Nicole},
  title    = {Deep learning},
  journal  = {Nature Methods},
  year     = {2015},
  volume   = {13},
  number   = {1},
  pages    = {35--35},
  issn     = {9780521835688},
  abstract = {NATURE METHODS {\textbar} VOL.13 NO.1 {\textbar} JANUARY 2016 {\textbar} 35 METHODS TO WATCH {\textbar} SPECIAL FEATURE and high computational costs are being tackled. Researchers in academic settings as well as in startup companies such as Deep Genomics, launched July 22, 2015, by some of the authors of DeepBind, will increasingly apply deep learning to genome analysis and precision medicine. The goal is to predict the effect of genetic variants? both naturally occurring and introduced by genome editing?on a cell's regulatory landscape and how this in turn affects dis-ease development. Nicole Rusk ??Deep learning New computational tools learn complex motifs from large sequence data sets. A powerful form of machine learning that enables computers to solve perceptual problems such as image and speech rec-ognition is increasingly making an entry into the biological sciences. These deep-learning methods, such as deep artificial neural networks, use multiple processing layers to discover patterns and structure in very large data sets. Each layer learns a concept from the data that subsequent lay-ers build on; the higher the level, the more abstract the concepts that are learned. Deep learning does not depend on prior data processing and automatically extracts features. To use a simple example, a deep neural network tasked with interpreting shapes would learn to recognize simple edges in the first layer and then add recog-nition of the more complex shapes com-posed of those edges in subsequent lay-ers. There is no hard and fast rule for how many layers are needed to constitute deep learning, but most experts agree that more than two are required. Recent examples show the power of deep learning to derive regulatory fea-tures in genomes from DNA sequence alone: DeepSEA (Nat. Methods 12, 931? 934, 2015) uses genomic sequence as input, trains on chromatin profiles from large consortia such as ENCODE and the Epigenomics Roadmap, and predicts the effect of single-nucleotide variants on reg-ulatory regions such as DNase hypersen-sitive sites, transcription factor?binding sites and histone marks. Basset (bioRxiv, doi:10.1101/028399, 2015) uses similar deep neural networks to predict the effect of single-nucleotide polymorphisms on chromatin accessibility. DeepBind (Nat. Biotechnol. 33, 831?838, 2015) finds protein-binding sites on RNA and DNA and predicts the effects of mutations. Deep learning will be invaluable in the context of big data, as it extracts high-level information from very large volumes of data. As it gains traction in genome analy-sis, initial challenges such as overfitting due to rare dependencies in the training data},
  doi      = {10.1038/nmeth.3707},
  url      = {http://www.nature.com/doifinder/10.1038/nature14539%5Cnhttp://www.nature.com/doifinder/10.1038/nmeth.3707},
}

@Article{salperwycklearning,
  author   = {Salperwyck, Christophe and Lemaire, Vincent},
  title    = {Learning with few examples: an empirical study on leading classifiers},
  abstract = {? Learning algorithms proved their ability to deal with large amount of data. Most of the statistical approaches use defined size learning sets and produce static models. However in specific situations: active or incremental learning, the learning task starts with only very few data. In that case, looking for algorithms able to produce models with only few examples becomes necessary. The literature's classifiers are generally evaluated with criterion such as: accuracy, ability to order data (ranking)... But this classifiers' taxonomy can dramatically change if the focus is on the ability to learn with just few examples. To our knowledge, just few studies were performed on this problem. The study presented in this paper aims to study a larger panel of both algorithms (9 different kinds) and data sets (17 UCI bases).},
}

@Article{samala2016mass,
  author   = {Samala, Ravi K. and Chan, Heang-Ping and Hadjiiski, Lubomir and Helvie, Mark A. and Wei, Jun and Cha, Kenny},
  title    = {Mass detection in digital breast tomosynthesis: {Deep} convolutional neural network with transfer learning from mammography},
  journal  = {Medical Physics},
  year     = {2016},
  volume   = {43},
  number   = {12},
  pages    = {6654--6666},
  month    = dec,
  doi2     = {10.1118/1.4967345},
  groups   = {Not-so-supervised papers},
  keywords = {Analysis of texture, Artificial neural networks, Biological material, Cancer, computer?aided detection, convolutional neural network, Data sets, deep?learning, digital breast tomosynthesis, Digital tomosynthesis mammography, e.g. blood, feature extraction, Film mammography, Haemocytometers, image classification, Image data processing or generation, Image detection systems, Image segmentation, image texture, Inference methods or devices, in general, learning, learning (artificial intelligence), Learning machines, Mammography, mass, medical image processing, neural nets, Radiology, Segmentation, specially adapted for specific applications, Testing procedures, Transfer learning, tumours, urine},
  url2     = {http://scitation.aip.org/content/aapm/journal/medphys/43/12/10.1118/1.4967345},
}

@Article{samekiicord,
  author   = {Sameki, Mehrnoosh and Gurari, Danna and Betke, Margrit},
  title    = {{ICORD}: {Intelligent} {Collection} of {Redundant} {Data} ? {A} {Dynamic} {System} for {Crowdsourcing} {Cell} {Segmentations} {Accurately} and {Efficiently}},
  abstract = {Segmentation is a fundamental step in analyzing biolog-ical structures in microscopy images. When state-of-the-art automated methods are found to produce inaccurate bound-aries, interactive segmentation can be effective. Since the inclusion of domain experts is typically expensive and does not scale, crowdsourcing has been considered. Due to con-cerns about the quality of crowd work, quality control meth-ods that rely on a fixed number of redundant annotations have been used. We here introduce a collection strategy that dynamically assesses the quality of crowd work. We propose ICORD (Intelligent Collection Of Redundant an-notation Data), a system that predicts the accuracy of a segmented region from analysis of (1) its geometric and intensity-based features and (2) the crowd worker's behav-ioral features. Based on this score, ICORD dynamically determines if the annotation accuracy is satisfactory or if a higher-quality annotation should be sought out in another round of crowdsourcing. We tested ICORD on phase con-trast and fluorescence images of 270 cells. We compared the performance of ICORD and a popular baseline method for which we aggregated 1,350 crowd-drawn cell segmen-tations. Our results show that ICORD collects annotations both accurately and efficiently. Accuracy levels are within 3 percentage points of those of the baseline. More impor-tantly, due to its dynamic nature, ICORD vastly outperforms the baseline method with respect to efficiency. ICORD only uses between 27\% and 50\% of the resources, i.e., collection time and cost, that the baseline method requires.},
}

@Article{sameki2015predicting,
  author = {Sameki, Mehrnoosh and Gurari, Danna and Betke, Margrit},
  title  = {Predicting {Quality} of {Crowdsourced} {Image} {Segmentations} from {Crowd} {Behavior}},
  year   = {2015},
}

@InProceedings{rosa2015multiple,
  author    = {Sanchez de la Rosa, Ruben and Lamard, Mathieu and Cazuguel, Guy and Coatrieux, Gouenou and Cozic, Michel and Quellec, Gwenole},
  title     = {Multiple-instance learning for breast cancer detection in mammograms.},
  booktitle = {International Conference of the IEEE Engineering in Medicine and Biology Society},
  year      = {2015},
  volume    = {2015},
  pages     = {7055--7058},
  abstract  = {This paper describes an experimental computer-aided detection and diagnosis system for breast cancer, the most common form of cancer among women, using mammography. The system relies on the Multiple-Instance Learning (MIL) paradigm, which has proven useful for medical decision support in previous works from our team. In the proposed framework, the breasts are first partitioned adaptively into regions. Then, either textural features, or features derived from the detection of masses and microcalcifications, are extracted from each region. Finally, feature vectors extracted from each region are combined using an MIL algorithm (Citation k-NN or mi-Graph), in order to recognize "normal" mammography examinations or to categorize examinations as "normal", "benign" or "cancer". An accuracy of 91.1\% (respectively 62.1\%) was achieved for normality recognition (respectively three-class categorization) in a subset of 720 mammograms from the DDSM dataset. The paper also discusses future improvements, that will make the most of the MIL paradigm, in order to improve "benign" versus "cancer" discrimination in particular.},
  doi2      = {10.1109/EMBC.2015.7320017},
  groups    = {Not-so-supervised papers},
  keywords  = {Algorithms, Breast, Breast Neoplasms, Calcinosis, Databases as Topic, Female, Humans, Mammography, methods, Pathology, radiography},
  language  = {eng},
}

@Article{sardelis2016not,
  author  = {Sardelis, Stephanie and Drew, Joshua A.},
  title   = {Not "pulling up the ladder": {Women} who organize conference symposia provide greater opportunities for women to speak at conservation conferences},
  journal = {PLoS ONE},
  year    = {2016},
  volume  = {11},
  number  = {7},
  pages   = {1--20},
  issn    = {1932-6203},
  doi     = {10.1371/journal.pone.0160015},
}

@Article{saul2013implicit,
  author   = {Saul, Jennifer},
  title    = {Implicit bias, stereotype threat, and women in philosophy},
  journal  = {Women in philosophy: What needs to change?},
  year     = {2013},
  pages    = {39--60},
  issn     = {0199325618},
  abstract = {There is by now a well-established body of research in psychology showing that human beings are strongly influenced by a range of unconscious biases and dispositions related to categories like race, sex, age, disability, sexual orientation, etc. So far, there has been little to no empirical work on whether philosophers are influenced by these biases. But given that philosophers are human beings, it seems very likely that they are. This paper explores the effects these biases may be having in philosophy with respect to women, and proposes and explores some remedies philosophers could implement.},
  doi      = {10.1093/acprof:oso/9780199325603.003.0003},
  keywords = {Implicit bias, responsibility, stereotype threat},
}

@Article{scheirer2014good,
  author   = {Scheirer, Walter J. and Wilber, Michael J. and Eckmann, Michael and Boult, Terrance E.},
  title    = {Good {Recognition} is {Non}-{Metric}},
  year     = {2014},
  pages    = {9--9},
  month    = feb,
  abstract = {Recognition is the fundamental task of visual cognition, yet how to formalize the general recognition problem for computer vision remains an open issue. The problem is sometimes reduced to the simplest case of recognizing matching pairs, often structured to allow for metric constraints. However, visual recognition is broader than just pair matching -- especially when we consider multi-class training data and large sets of features in a learning context. What we learn and how we learn it has important implications for effective algorithms. In this paper, we reconsider the assumption of recognition as a pair matching test, and introduce a new formal definition that captures the broader context of the problem. Through a meta-analysis and an experimental assessment of the top algorithms on popular data sets, we gain a sense of how often metric properties are violated by good recognition algorithms. By studying these violations, useful insights come to light: we make the case that locally metric algorithms should leverage outside information to solve the general recognition problem.},
  file     = {scheirer2013good.pdf:scheirer2013good.pdf:PDF},
  url      = {http://arxiv.org/abs/1302.4673},
}

@Article{schilham2006local,
  author   = {Schilham, Arnold M R and Van Ginneken, Bram and Gietema, Hester and Prokop, Mathias},
  title    = {Local noise weighted filtering for emphysema scoring of low-dose {CT} images},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2006},
  volume   = {25},
  number   = {4},
  pages    = {451--463},
  issn     = {0278-0062 (Print){\textbackslash}r0278-0062 (Linking)},
  abstract = {Computed tomography (CT) has become the new reference standard for quantification of emphysema. The most popular measure of emphysema derived from CT is the pixel index (PI), which expresses the fraction of the lung volume with abnormally low intensity values. As PI is calculated from a single, fixed threshold on intensity, this measure is strongly influenced by noise. This effect shows up clearly when comparing the PI score of a high-dose scan to the PI score of a low-dose (i.e., noisy) scan of the same subject. In this paper, the noise variance (NOVA) filter is presented: a general framework for (iterative) nonlinear filtering, which uses an estimate of the spatially dependent noise variance in an image. The NOVA filter iteratively estimates the local image noise and filters the image. For the specific purpose of emphysema quantification of low-dose CT images, a dedicated, noniterative NOVA filter is constructed by using prior knowledge of the data to obtain a good estimate of the spatially dependent noise in an image. The performance of the NOVA filter is assessed by comparing characteristics of pairs of high-dose and low-dose scans. The compared characteristics are the PI scores for different thresholds and the size distributions of emphysema bullae. After filtering, the PI scores of high-dose and low-dose images agree to within 2\%-3\% points. The reproducibility of the high-dose bullae size distribution is also strongly improved. NOVA filtering of a CT image of typically 400 x 512 x 512 voxels takes only a couple of minutes which makes it suitable for routine use in clinical practice.},
  doi      = {10.1109/TMI.2006.871545},
  file     = {schilham2006local.pdf:schilham2006local.pdf:PDF},
  keywords = {Denoising, Emphysema quantification, Low-dose CT images, Nonlinear filtering.},
}

@InCollection{schlegl2015predicting,
  author    = {Schlegl, Thomas and Waldstein, Sebastian M. and Vogl, Wolf-Dieter and Schmidt-Erfurth, Ursula and Langs, Georg},
  title     = {Predicting Semantic Descriptions from Medical Images with Convolutional Neural Networks},
  booktitle = {Information Processing in Medical Imaging (IPMI)},
  publisher = {Springer International Publishing},
  year      = {2015},
  pages     = {437--448},
  note2     = {DOI: 10.1007/978-3-319-19992-4\_34},
  url2      = {http://link.springer.com/10.1007/978-3-319-19992-4_34},
}

@Article{schnabel2016advances,
  author   = {Schnabel, Julia A. and Heinrich, Mattias P. and Papie??, Bart??omiej W. and Brady, Sir J Michael},
  title    = {Advances and challenges in deformable image registration: {From} image fusion to complex motion modelling},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {145--148},
  abstract = {Over the past 20 years, the field of medical image registration has significantly advanced from multi-modal image fusion to highly non-linear, deformable image registration for a wide range of medical applications and imaging modalities, involving the compensation and analysis of physiological organ motion or of tissue changes due to growth or disease patterns. While the original focus of image registration has predominantly been on correcting for rigid-body motion of brain image volumes acquired at different scanning sessions, often with different modalities, the advent of dedicated longitudinal and cross-sectional brain studies soon necessitated the development of more sophisticated methods that are able to detect and measure local structural or functional changes, or group differences. Moving outside of the brain, cine imaging and dynamic imaging required the development of deformable image registration to directly measure or compensate for local tissue motion. Since then, deformable image registration has become a general enabling technology. In this work we will present our own contributions to the state-of-the-art in deformable multi-modal fusion and complex motion modelling, and then discuss remaining challenges and provide future perspectives to the field.},
  doi      = {10.1016/j.media.2016.06.031},
  keywords = {Demons, Discrete optimization, Multi-modality, Registration uncertainty, Sliding motion, Supervoxels},
}

@Article{schneider2012equivalence,
  author   = {Schneider, E. and Nevitt, M. and McCulloch, C. and Cicuttini, F. M. and Duryea, J. and Eckstein, F. and Tamez-Pena, J.},
  title    = {Equivalence and precision of knee cartilage morphometry between different segmentation teams, cartilage regions, and {MR} acquisitions},
  journal  = {Osteoarthritis and Cartilage},
  year     = {2012},
  volume   = {20},
  number   = {8},
  pages    = {869--879},
  abstract = {Objective: To compare precision and evaluate equivalence of femorotibial cartilage volume (VC) and mean cartilage thickness over total area of bone (ThCtAB.Me) from independent segmentation teams using identical Magnetic Resonance (MR) images from three series: sagittal 3D Dual Echo in the Steady State (DESS), coronal multi-planar reformat (DESS-MPR) of DESS and coronal 3D Fast Low Angle SHot (FLASH). Design: Nineteen subjects underwent test-retest MR imaging at 3 T. Four teams segmented the cartilage using prospectively defined plate regions and rules. Mixed models analysis of the pooled data were used to evaluate the effect of acquisition, team and plate on precision and Pearson correlations and mixed models were used to evaluate equivalence. Results: Segmentation team differences dominated measurement variability in most cartilage regions for all image series. Precision of VC and ThCtAB.Me differed significantly by team and cartilage plate, but not between FLASH and DESS. Mean values of VC and ThCtAB.Me differed by team (P {\textless} 0.05) for DESS, FLASH and DESS-MPR. FLASH VC was 4-6\% larger than DESS in the medial tibia and lateral central femur, and FLASH ThCtAB.Me was 5-6\% larger in the medial tibia, but 4-8\% smaller in the medial central femur. Correlations between DESS and FLASH for VC and ThCtAB.Me were high (r = 0.90-0.97), except for DESS vs FLASH medial central femur ThCtAB.Me (r = 0.81-0.83). Conclusions: Cartilage morphology metrics from different image contrasts had similar precision, were generally equivalent, and may be combined for cross-sectional analyses if potential systematic offsets are accounted for. Data from different teams should not be pooled unless equivalence is demonstrated for cartilage metrics of interest. ?? 2012 Osteoarthritis Research Society International.},
  doi      = {10.1016/j.joca.2012.04.005},
  file     = {schneider2012equivalence.pdf:schneider2012equivalence.pdf:PDF},
  keywords = {Cartilage, Knee, Magnetic resonance, Morphometry, Osteoarthritis, Quantitation},
  url      = {http://dx.doi.org/10.1016/j.joca.2012.04.005},
}

@InProceedings{schwartz2012improving,
  author    = {Schwartz, Yannick and Varoquaux, Gael Gaël and Pallier, Christophe and Pinel, Philippe and Poline, Jean-Baptiste and Thirion, Bertrand},
  title     = {Improving accuracy and power with transfer learning using a meta-analytic database.},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year      = {2012},
  volume    = {15},
  number    = {Pt 3},
  pages     = {248--255},
  abstract  = {Typical cohorts in brain imaging studies are not large enough for systematic testing of all the information contained in the images. To build testable working hypotheses, investigators thus rely on analysis of previous work, sometimes formalized in a so-called meta-analysis. In brain imaging, this approach underlies the specification of regions of interest (ROIs) that are usually selected on the basis of the coordinates of previously detected effects. In this paper, we propose to use a database of images, rather than coordinates, and frame the problem as transfer learning: learning a discriminant model on a reference task to apply it to a different but related new task. To facilitate statistical analysis of small cohorts, we use a sparse discriminant model that selects predictive voxels on the reference task and thus provides a principled procedure to define ROIs. The benefits of our approach are twofold. First it uses the reference database for prediction, i.e., to provide potential biomarkers in a clinical setting. Second it increases statistical power on the new task. We demonstrate on a set of 18 pairs of functional MRI experimental conditions that our approach gives good prediction. In addition, on a specific transfer situation involving different scanners at different locations, we show that voxel selection based on transfer learning leads to higher detection power on small cohorts.},
  file      = {schwartz2012improving.pdf:schwartz2012improving.pdf:PDF},
  groups    = {Not-so-supervised papers},
  keywords  = {Algorithms, Automated, Automated: methods, Brain, Brain mapping, Brain: physiology, Computer-Assisted, Computer-Assisted: methods, Databases, Factual, Humans, Image Enhancement, Image Enhancement: methods, Image Interpretation, Information Storage and Retrieval, Magnetic resonance imaging, Magnetic Resonance Imaging: methods, Meta-Analysis as Topic, methods, Pattern Recognition, physiology, Reproducibility of Results, Sensitivity and Specificity},
  language  = {eng},
  url       = {http://www.ncbi.nlm.nih.gov/pubmed/23286137},
}

@Article{scornetconsistency,
  author   = {Scornet, Erwan and Biau, Gérard and Vert, Jean-Philippe},
  title    = {{CONSISTENCY} {OF} {RANDOM} {FORESTS}},
  abstract = {Random forests are a learning algorithm proposed by Breiman (2001) that combines several randomized decision trees and aggregates their predictions by averaging. Despite its wide usage and outstanding practical performance, little is known about the math-ematical properties of the procedure. This disparity between theory and practice originates in the difficulty to simultaneously analyze both the randomization process and the highly data-dependent tree structure. In the present paper, we take a step forward in forest explo-ration by proving a consistency result for Breiman's (2001) original algorithm in the context of additive regression models. Our analysis also sheds an interesting light on how random forests can nicely adapt to sparsity.},
}

@Book{seeger2004gaussian,
  title    = {Gaussian processes for machine learning.},
  year     = {2004},
  author   = {Seeger, Matthias},
  volume   = {14},
  isbn     = {0-262-18253-X},
  note     = {DOI: 10.1142/S0129065704001899},
  abstract = {Gaussian processes (GPs) are natural generalisations of multivariate Gaussian random variables to infinite (countably or continuous) index sets. GPs have been applied in a large number of fields to a diverse range of ends, and very many deep theoretical analyses of various properties are available. This paper gives an introduction to Gaussian processes on a fairly elementary level with special emphasis on characteristics relevant in machine learning. It draws explicit connections to branches such as spline smoothing models and support vector machines in which similar ideas have been investigated. Gaussian process models are routinely used to solve hard machine learning problems. They are attractive because of their flexible non-parametric nature and computational simplicity. Treated within a Bayesian framework, very powerful statistical methods can be implemented which offer valid estimates of uncertainties in our predictions and generic model selection procedures cast as nonlinear optimization problems. Their main drawback of heavy computational scaling has recently been alleviated by the introduction of generic sparse approximations.13,78,31 The mathematical literature on GPs is large and often uses deep concepts which are not required to fully understand most machine learning applications. In this tutorial paper, we aim to present characteristics of GPs relevant to machine learning and to show up precise connections to other "kernel machines" popular in the community. Our focus is on a simple presentation, but references to more detailed sources are provided.},
  keywords = {2006, c, c 2006 massachusetts institute, e, gaussianprocess, gaussian processes for machine, gpml, i, isbn 026218253x, k, learning, of technology, org, rasmussen, the mit press, williams, www},
  url      = {http://www.gaussianprocess.org/gpml/chapters/RW.pdf},
}

@Article{segev2015learn,
  author   = {Segev, Noam and Harel, Maayan and Mannor, Shie and Crammer, Koby and El-Yaniv, Ran},
  title    = {Learn on {Source}, {Refine} on {Target}:{A} {Model} {Transfer} {Learning} {Framework} with {Random} {Forests}},
  year     = {2015},
  pages    = {1--14},
  abstract = {We propose novel model transfer-learning methods that refine a decision forest model M learned within a "source" domain using a training set sampled from a "target" domain, assumed to be a variation of the source. We present two random forest transfer algorithms. The first algorithm searches greedily for locally optimal modifications of each tree structure by trying to locally expand or reduce the tree around individual nodes. The second algorithm does not modify structure, but only the parameter (thresholds) associated with decision nodes. We also propose to combine both methods by considering an ensemble that contains the union of the two forests. The proposed methods exhibit impressive experimental results over a range of problems.},
  file     = {segev2015learn.pdf:segev2015learn.pdf:PDF},
  url      = {http://arxiv.org/abs/1511.01258},
}

@Article{seymour2010maximizing,
  author  = {Seymour, Benjamin},
  title   = {Maximizing the {Usefulness} of {Data} {Gathered} {Though} {Crowdsourcing} {Methods} {Using} {Gamification}},
  journal = {Cs.Auckland.Ac.Nz},
  year    = {2010},
  file    = {seymour2010maximizing.pdf:seymour2010maximizing.pdf:PDF},
}

@Article{shah2014double,
  author   = {Shah, Nihar B. and Zhou, Dengyong},
  title    = {Double or {Nothing} : {Multiplicative} {Incentive} {Mechanisms} for {Crowdsourcing}},
  journal  = {arXiv preprint arXiv:1408.1387},
  year     = {2014},
  pages    = {19--21},
  issn     = {MSR-TR-2014-117},
  abstract = {Many fields of science and engineering, ranging from predicting protein structures to building machine translation systems, require large amounts of labeled data. These labeling tasks have traditionally been performed by experts; the limited pool of experts would limit the size of the datasets, and make the process slow and expensive. In recent years, there is a rapidly increasing interest in using crowds of semi-skilled workers recruited through the Internet. While this ?crowdsourcing? can cheaply produce large amounts of labeled data in short times, it is typically plagued by the problem of low quality. To address this fundamental challenge in crowdsourcing, we design a novel reward mechanism for acquiring high-quality data, which incentivizes workers to censor their own low-quality data. Our main results are the mathematical proofs showing that surprisingly, under a natural and desirable ?no-free-lunch? requirement, this is the one and only mechanism that is incentive-compatible. The simplicity of the mechanism is an additional attractive property. In preliminary experiments involving over 900 worker-tasks, we observe upto a three-fold drop in the error rates under this unique incentive mechanism.},
  file     = {shah2014double.pdf:shah2014double.pdf:PDF},
}

@Article{shahbazi2016similarity,
  author   = {Shahbazi, Reza and Raizada, Rajeev and Edelman, Shimon},
  title    = {Similarity, kernels, and the fundamental constraints on cognition},
  journal  = {Journal of Mathematical Psychology},
  year     = {2016},
  volume   = {70},
  pages    = {21--34},
  abstract = {Kernel-based methods, and in particular the so-called kernel trick, which is used in statistical learning theory as a means of avoiding expensive high-dimensional computations, have broad and constructive implications for the cognitive and brain sciences. An equivalent and complementary view of kernels as a measure of similarity highlights their effectiveness in low-dimensional and low-complexity learning and generalization ? tasks that are indispensable in cognitive information processing. In this survey, we seek (i) to highlight some parallels between kernels in machine learning on the one hand and similarity in psychology and neuroscience on the other hand, (ii) to sketch out new research directions arising from these parallels, and (iii) to clarify some aspects of the way kernels are presented and discussed in the literature that may have affected their perceived relevance to cognition. In particular, we aim to resolve the tension between the view of kernels as a method of raising the dimensionality, and the various requirements of reducing dimensionality for cognitive purposes. We identify four fundamental constraints that apply to any cognitive system that is charged with learning from the statistics of its world, and argue that kernel-like neural computation is particularly suited to serving such learning and decision making needs, while simultaneously satisfying these constraints.},
  doi      = {10.1016/j.jmp.2015.11.004},
}

@InCollection{shen2016learning,
  author    = {Shen, Wei and Zhou, Mu and Yang, Feng and Dong, Di and Yang, Caiyun and Zang, Yali and Tian, Jie},
  title     = {Learning from Experts: Developing Transferable Deep Features for Patient-Level Lung Cancer Prediction},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  publisher = {Springer International Publishing},
  year      = {2016},
  pages     = {124--131},
  groups    = {Not-so-supervised papers},
  note2     = {DOI: 10.1007/978-3-319-46723-8\_15},
  url2      = {http://link.springer.com/10.1007/978-3-319-46723-8_15},
}

@InCollection{shi2012transductive,
  author    = {Shi, Yinghuan and Liao, Shu and Gao, Yaozong and Zhang, Daoqiang and Gao, Yang and Shen, Dinggang},
  title     = {Transductive {Prostate} {Segmentation} for {CT} {Image} {Guided} {Radiotherapy}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2012},
  pages     = {1--9},
  note      = {DOI: 10.1007/978-3-642-35428-1\_1},
  groups    = {Not-so-supervised papers},
  url       = {http://link.springer.com/10.1007/978-3-642-35428-1_1},
}

@Article{shin2013stacked,
  author   = {Shin, Hoo-chang Chang and Orton, Matthew R. and Collins, David J. and Doran, Simon J. and Leach, Martin O.},
  title    = {Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4D patient data},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year     = {2013},
  volume   = {35},
  number   = {8},
  pages    = {1930--1943},
  issn     = {0162-8828},
  abstract = {Medical image analysis remains a challenging application area for artificial intelligence. When applying machine learning, obtaining ground-truth labels for supervised learning is more difficult than in many more common applications of machine learning. This is especially so for datasets with abnormalities, as tissue types and the shapes of the organs in these datasets differ widely. However, organ detection in such an abnormal dataset may have many promising potential real-world applications, such as automatic diagnosis, automated radiotherapy planning, and medical image retrieval, where new multimodal medical images provide more information about the imaged tissues for diagnosis. Here, we test the application of deep learning methods to organ identification in magnetic resonance medical images, with visual and temporal hierarchical features learned to categorize object classes from an unlabeled multimodal DCE-MRI dataset so that only a weakly supervised training is required for a classifier. A probabilistic patch-based method was employed for multiple organ detection, with the features learned from the deep learning model. This shows the potential of the deep learning model for application to medical images, despite the difficulty of obtaining libraries of correctly labeled training datasets and despite the intrinsic abnormalities present in patient datasets.},
  doi      = {10.1109/TPAMI.2012.277},
  groups   = {Not-so-supervised papers},
  keywords = {biomedical image processing, Edge and feature detection, machine learning, object recognition, pixel classification},
  url      = {http://www.ncbi.nlm.nih.gov/pubmed/23787345},
}

@Article{shin2014coupling,
  author   = {Shin, Hyunjung and Nam, Yonghyun},
  title    = {A coupling approach of a predictor and a descriptor for breast cancer prognosis.},
  journal  = {BMC medical genomics},
  year     = {2014},
  volume   = {7 Suppl 1},
  pages    = {S4--S4},
  abstract = {BACKGROUND: In cancer prognosis research, diverse machine learning models have applied to the problems of cancer susceptibility (risk assessment), cancer recurrence (redevelopment of cancer after resolution), and cancer survivability, regarding an accuracy (or an AUC--the area under the ROC curve) as a primary measurement for the performance evaluation of the models. However, in order to help medical specialists to establish a treatment plan by using the predicted output of a model, it is more pragmatic to elucidate which variables (markers) have most significantly influenced to the resulting outcome of cancer or which patients show similar patterns. METHODS: In this study, a coupling approach of two sub-modules--a predictor and a descriptor--is proposed. The predictor module generates the predicted output for the cancer outcome. Semi-supervised learning co-training algorithm is employed as a predictor. On the other hand, the descriptor module post-processes the results of the predictor module, mainly focusing on which variables are more highly or less significantly ranked when describing the results of the prediction, and how patients are segmented into several groups according to the trait of common patterns among them. Decision trees are used as a descriptor. RESULTS: The proposed approach, 'predictor-descriptor,' was tested on the breast cancer survivability problem based on the surveillance, epidemiology, and end results database for breast cancer (SEER). The results present the performance comparison among the established machine leaning algorithms, the ranks of the prognosis elements for breast cancer, and patient segmentation. In the performance comparison among the predictor candidates, Semi-supervised learning co-training algorithm showed best performance, producing an average AUC of 0.81. Later, the descriptor module found the top-tier prognosis markers which significantly affect to the classification results on survived/dead patients: 'lymph node involvement', 'stage', 'site-specific surgery', 'number of positive node examined', and 'tumor size', etc. Also, a typical example of patient-segmentation was provided: the patients classified as dead were grouped into two segments depending on difference in prognostic profiles, ones with serious results with respect to the pathologic exams and the others with the feebleness of age.},
  doi      = {10.1186/1755-8794-7-S1-S4},
  keywords = {Algorithms, Artificial Intelligence, Breast Neoplasms, computational biology, diagnosis, Humans, Lymphatic Metastasis, methods, Pathology, Prognosis},
  language = {eng},
}

@Article{situ2010boosting,
  author   = {Situ, Ning and Yuan, Xiaojing and Zouridakis, George},
  title    = {Boosting instance prototypes to detect local dermoscopic features.},
  journal  = {International Conference of the IEEE Engineering in Medicine and Biology Society},
  year     = {2010},
  volume   = {2010},
  pages    = {5561--5564},
  abstract = {Local dermoscopic features are useful in many dermoscopic criteria for skin cancer detection. We address the problem of detecting local dermoscopic features from epiluminescence (ELM) microscopy skin lesion images. We formulate the recognition of local dermoscopic features as a multi-instance learning (MIL) problem. We employ the method of diverse density (DD) and evidence confidence (EC) function to convert MIL to a single-instance learning (SIL) problem. We apply Adaboost to improve the classification performance with support vector machines (SVMs) as the base classifier. We also propose to boost the selection of instance prototypes through changing the data weights in the DD function. We validate the methods on detecting ten local dermoscopic features from a dataset with 360 images. We compare the performance of the MIL approach, its boosting version, and a baseline method without using MIL. Our results show that boosting can provide performance improvement compared to the other two methods.},
  doi2     = {10.1109/IEMBS.2010.5626776},
  groups   = {Not-so-supervised papers},
  keywords = {Algorithms, Area Under Curve, Computer-Assisted, Dermoscopy, diagnosis, Humans, Image Interpretation, methods, Pathology, Skin Neoplasms},
  language = {eng},
}

@Article{skibba2016women,
  author  = {Skibba, Ramin},
  title   = {Women postdocs less likely than men to get a glowing reference},
  journal = {Nature},
  year    = {2016},
  month   = oct,
  doi     = {10.1038/nature.2016.20715},
  url     = {http://www.nature.com/doifinder/10.1038/nature.2016.20715},
}

@Article{sluimer2006computer,
  author   = {Sluimer, Ingrid and Schilham, Arnold and Prokop, Mathias and Van Ginneken, Bram},
  title    = {Computer analysis of computed tomography scans of the lung: {A} survey},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2006},
  volume   = {25},
  number   = {4},
  pages    = {385--405},
  issn     = {0278-0062},
  abstract = {Current computed tomography (CT) technology allows for near isotropic, submillimeter resolution acquisition of the complete chest in a single breath hold. These thin-slice chest scans have become indispensable in thoracic radiology, but have also substantially increased the data load for radiologists. Automating the analysis of such data is, therefore, a necessity and this has created a rapidly developing research area in medical imaging. This paper presents a review of the literature on computer analysis of the lungs in CT scans and addresses segmentation of various pulmonary structures, registration of chest scans, and applications aimed at detection, classification and quantification of chest abnormalities. In addition, research trends and challenges are identified and directions for future research are discussed.},
  doi      = {10.1109/TMI.2005.862753},
  file     = {sluimer2006computer.pdf:sluimer2006computer.pdf:PDF},
  keywords = {Airway disease, Chest, computer-aided diagnosis, ct, Emphysema quantification, Interstitial Lung Disease, Literature review, Literature survey, lung cancer, Nodule characterization, Nodule detection, Nodule size measurements, Pulmonary embolism, Registration},
}

@Misc{small2012postdoc,
  author   = {Small, Gaston},
  title    = {The postdoc dilemma},
  month    = mar,
  year     = {2012},
  note     = {DOI: 10.1038/nj7388-235a},
  abstract = {As a graduate student, I overheard a faculty member advise a colleague to include funding in a grant proposal for a graduate student rather than a postdoctoral fellow. The reason??Postdocs spend all their time writing papers from their dissertation work,? she ... {\textbackslash}n},
  pages    = {235},
  url      = {http://www.nature.com/doifinder/10.1038/nj7388-235a},
  volume   = {483},
}

@Article{smithmodel,
  author   = {Smith, John R},
  title    = {Model-{Shared} {Subspace} {Boosting} for {Multi}-label},
  issn     = {9781595936097},
  keywords = {boost-, multi-label classification, random subspace methods},
}

@Article{sokootiaccuracy,
  author   = {Sokooti, Hessam and Saygili, Gorkem and Glocker, Ben and Lelieveldt, Boudewijn P F and Staring, Marius},
  title    = {Accuracy {Estimation} for {Medical} {Image} {Registration} {Using} {Regression} {Forests}},
  abstract = {This paper reports a new automatic algorithm to estimate the misregistration in a quantitative manner. A random regression forest is constructed, predicting the local registration error. The forest is built using local and modality independent features related to the registra-tion precision, the transformation model and intensity-based similarity after registration. The forest is trained and tested using manually anno-tated corresponding points between pairs of chest CT scans. The results show that the mean absolute error of regression is 0.72 ± 0.96 mm and the accuracy of classification in three classes (correct, poor and wrong registration) is 93.4\%, comparing favorably to a competing method. In conclusion, a method was proposed that for the first time shows the fea-sibility of automatic registration assessment by means of regression, and promising results were obtained.},
  keywords = {Image registration, registration accuracy, regression forests, uncertainty esti-mation},
}

@Article{solutions2014gamification,
  author = {Solutions, Media and Rotterdam, C E},
  title  = {Gamification as a {Solution}},
  year   = {2014},
  volume = {31},
  number = {september},
  pages  = {0--11},
}

@Article{song2013feature,
  author   = {Song, Yang and Cai, Weidong and Zhou, Yun and Feng, David Dagan},
  title    = {Feature-based image patch approximation for lung tissue classification},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2013},
  volume   = {32},
  number   = {4},
  pages    = {797--808},
  issn     = {0278-0062 VO - 32},
  abstract = {In this paper, we propose a new classification method for five categories of lung tissues in high-resolution computed tomography (HRCT) images, with feature-based image patch approximation. We design two new feature descriptors for higher feature descriptiveness, namely the rotation-invariant Gabor-local binary patterns (RGLBP) texture descriptor and multi-coordinate histogram of oriented gradients (MCHOG) gradient descriptor. Together with intensity features, each image patch is then labeled based on its feature approximation from reference image patches. And a new patch-adaptive sparse approximation (PASA) method is designed with the following main components: minimum discrepancy criteria for sparse-based classification, patch-specific adaptation for discriminative approximation, and feature-space weighting for distance computation. The patch-wise labelings are then accumulated as probabilistic estimations for region-level classification. The proposed method is evaluated on a publicly available ILD database, showing encouraging performance improvements over the state-of-the-arts.},
  doi      = {10.1109/TMI.2013.2241448},
  file     = {song2013feature.pdf:song2013feature.pdf:PDF},
  keywords = {Adaptive, gradient, reference, texture},
}

@Article{sonka2016quantitative,
  author   = {Sonka, Milan and Abr??moff, Michael D.},
  title    = {Quantitative analysis of retinal {OCT}},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {165--169},
  abstract = {Clinical acceptance of 3-D OCT retinal imaging brought rapid development of quantitative 3-D analysis of retinal layers, vasculature, retinal lesions as well as facilitated new research in retinal diseases. One of the cornerstones of many such analyses is segmentation and thickness quantification of retinal layers and the choroid, with an inherently 3-D simultaneous multi-layer LOGISMOS (Layered Optimal Graph Image Segmentation for Multiple Objects and Surfaces) segmentation approach being extremely well suited for the task. Once retinal layers are segmented, regional thickness, brightness, or texture-based indices of individual layers can be easily determined and thus contribute to our understanding of retinal or optic nerve head (ONH) disease processes and can be employed for determination of disease status, treatment responses, visual function, etc. Out of many applications, examples provided in this paper focus on image-guided therapy and outcome prediction in age-related macular degeneration and on assessing visual function from retinal layer structure in glaucoma.},
  doi      = {10.1016/j.media.2016.06.001},
  keywords = {Choroid, LOGISMOS, Optical coherence tomography (OCT), Quantitative medical imaging, retina, Visual function},
  url      = {http://dx.doi.org/10.1016/j.media.2016.06.001},
}

@Article{sonoyama2016transfer,
  author   = {Sonoyama, Shoji and Tamaki, Toru and Hirakawa, Tsubasa and Raytchev, Bisser and Kaneda, Kazufumi and Koide, Tetsushi and Yoshida, Shigeto and Mieno, Hiroshi and Tanaka, Shinji},
  title    = {Transfer {Learning} for {Endoscopic} {Image} {Classification}},
  year     = {2016},
  month    = aug,
  abstract = {In this paper we propose a method for transfer learning of endoscopic images. For transferring between features obtained from images taken by different (old and new) endoscopes, we extend the Max-Margin Domain Transfer (MMDT) proposed by Hoffman et al. in order to use L2 distance constraints as regularization, called Max-Margin Domain Transfer with L2 Distance Constraints (MMDTL2). Furthermore, we develop the dual formulation of the optimization problem in order to reduce the computation cost. Experimental results demonstrate that the proposed MMDTL2 outperforms MMDT for real data sets taken by different endoscopes.},
  groups   = {Not-so-supervised papers},
  url      = {http://arxiv.org/abs/1608.06713},
}

@Article{sorensen2011texture,
  author  = {Sørensen, L and Gangeh, M J and Shaker, S B and de Bruijne, M},
  title   = {Texture {Classification} in {Pulmonary} \{{CT}\}},
  journal = {Lung Imaging and Computer Aided Diagnosis},
  year    = {2011},
  number  = {c},
  pages   = {343--367},
}

@Article{sorensen2010quantitative,
  author   = {Sørensen, Lauge and Shaker, Saher B and De Bruijne, Marleen},
  title    = {Quantitative analysis of pulmonary emphysema using local binary patterns},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2010},
  volume   = {29},
  number   = {2},
  pages    = {559--569},
  month    = feb,
  issn     = {1558-254X (Electronic){\textbackslash}r0278-0062 (Linking)},
  abstract = {We aim at improving quantitative measures of emphysema in computed tomography (CT) images of the lungs. Current standard measures, such as the relative area of emphysema (RA), rely on a single intensity threshold on individual pixels, thus ignoring any interrelations between pixels. Texture analysis allows for a much richer representation that also takes the local structure around pixels into account. This paper presents a texture classification-based system for emphysema quantification in CT images. Measures of emphysema severity are obtained by fusing pixel posterior probabilities output by a classifier. Local binary patterns (LBP) are used as texture features, and joint LBP and intensity histograms are used for characterizing regions of interest (ROIs). Classification is then performed using a k nearest neighbor classifier with a histogram dissimilarity measure as distance. A 95.2\% classification accuracy was achieved on a set of 168 manually annotated ROIs, comprising the three classes: normal tissue, centrilobular emphysema, and paraseptal emphysema. The measured emphysema severity was in good agreement with a pulmonary function test (PFT) achieving correlation coefficients of up to {\textbar}r{\textbar} = 0.79 in 39 subjects. The results were compared to RA and to a Gaussian filter bank, and the texture-based measures correlated significantly better with PFT than did RA.},
  doi      = {10.1109/TMI.2009.2038575},
  keywords = {Emphysema, Local binary patterns (LBPs), Quantitative computed tomography (CT), texture analysis, tissue classification},
  url      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5405641},
}

@Article{sroges1966curiosity,
  author   = {Sroges, Richard W and Glickman, Stephen E},
  title    = {Curiosity in {Zoo} {Animals}},
  journal  = {Behaviour},
  year     = {1966},
  volume   = {26},
  number   = {1},
  pages    = {151--187},
  issn     = {00057959},
  abstract = {The reactions of more than 200 zoo animals to a standardized set of novel objects were recorded and quantified. Our results indicated significant differences among various taxonomic groups, both in the quantity and form of object manipulation. Our major quantitative findings were as follows: A. Primates and Carnivores exhibited more investigatory behavior than Rodents or a group of "primitive" mammals. B. A sample of 20 reptiles showed very little response, with the exception of a single Orinoco crocodile. C. There were no significant overall sex differences among 53 mature pairs of mammals drawn from different orders. D. A sample of subadult mammals tended to be more reactive than adult members of the same species. E. Within the Old World monkeys, there was considerable variation between the two subfamilies: The Cercopithecinae indulged in more investigatory behavior than the Colobinae, while the latter exhibited a greater percentage of purely visual "orienting" responses. F. Among the Cercopithecinae, the baboons and macaques demonstrated more investigatory behavior than the guenons and patas monkeys, although the latter genera displayed a larger percentage of visual orienting responses. G. The limited sample of Prosimians did not differ significantly from the highly evolved Colobinae in total reactivity. H. There were no significant differences among the families of carnivores within our sample, although the smaller cats comprising the genus Felis were less reactive as a group than the larger cats of the genus Panthera. In addition, there was some hint that the meerkats, which constituted the only representatives of the Vivveridae, were less immediately reactive than the remaining carnivorous species. I. Among a relatively small sample of Rodents, the members of the suborder Hystricomorpha exhibited more reactivity than those in the suborder Myomorpha, with the Sciuromorpha in an intermediate position. In terms of the forms (motor sequences) of reaction, chewing constituted the primary contact response within all groups. However, the following additional reactions were noted: A. Primates were characterized by grasping with the forepaws, visual inspection, and manipulation of objects. The latter was particularly evident in the baboons and macaques where many "individualistic" patterns appeared. These, in turn, contrasted with the Prosimian group where such diverse manipulatory behavior was rarely, if ever, recorded. Indications of fear were observed in 19/100 adults. B. Carnivores showed a vigorous, relatively fearless, approach to the objects which approximated the patterns that might normally be used in the capture and consumption of prey: swatting with the paws, stalking, chasing, biting, "worrying," and tugging against the paws. C. Rodent reactions were generally limited to gnawing, although there appeared to be differences in the aggressiveness of approach among the three suborders. There were also some hoarding responses, (depositing objects in a particular part of the cage, or burying them in the sawdust). D. Some possibly species-characteristic techniques of object manipulation were noted, e.g., the use of the tongue and snout by the giant anteater, the tail by the spider monkey, and the lips by the guanaco. A preliminary attempt was made to interpret our results in relation to feeding patterns and danger from predators in the natural habitats of the species that we tested. The possible significance of species differences in reactivity for brain-behavior correlations, and contemporary behavioristic theory, was also briefly considered.},
  doi      = {10.1163/156853966X00074},
  url      = {http://booksandjournals.brillonline.com/content/10.1163/156853966x00074},
}

@Article{stainvas2010cancer,
  author = {Stainvas, Inna and Manevitch, Alexandra and Leichter, Isaac},
  title  = {Cancer {Detection} with {Multiple} {Radiologists} via {Soft} {Multiple} {Instance} {Logistic} {Regression} and {L} 1 {Regularization}},
  year   = {2010},
  pages  = {1--20},
  groups = {Not-so-supervised papers},
}

@Article{stonnington2008interpreting,
  author   = {Stonnington, Cynthia M. and Tan, Geoffrey and Kl??ppel, Stefan and Chu, Carlton and Draganski, Bogdan and Jack, Clifford R. and Chen, Kewei and Ashburner, John and Frackowiak, Richard S J},
  title    = {Interpreting scan data acquired from multiple scanners: {A} study with {Alzheimer}'s disease},
  journal  = {NeuroImage},
  year     = {2008},
  volume   = {39},
  number   = {3},
  pages    = {1180--1185},
  issn     = {1053-8119 (Print){\textbackslash}r1053-8119 (Linking)},
  abstract = {Large, multi-site studies utilizing MRI-derived measures from multiple scanners present an opportunity to advance research by pooling data. On the other hand, it remains unclear whether or not the potential confound introduced by different scanners and upgrades will devalue the integrity of any results. Although there are studies of scanner differences for the purpose of calibration and quality control, the current literature is devoid of studies that describe the analysis of multi-scanner data with regard to the interaction of scanner(s) with effects of interest. We investigated a data-set of 136 subjects, 62 patients with mild to moderate Alzheimer's disease and 74 cognitively normal elderly controls, with MRI scans from one center that were acquired over 10??years with 6 different scanners and multiple upgrades over time. We used a whole-brain voxel-wise analysis to evaluate the effect of scanner, effect of disease, and the interaction of scanner and disease for the 6 different scanners. The effect of disease in patients showed the expected significant reduction of grey matter in the medial temporal lobe. Scanner differences were substantially less than the group differences and only significant in the thalamus. There was no significant interaction of scanner with disease group. We describe the rationale for concluding that our results were not confounded by scanner differences. Similar analyses in other multi-scanner data-sets could be used to justify the pooling of data when needed, such as in studies of rare disorders or in multi-center designs. ?? 2007 Elsevier Inc. All rights reserved.},
  doi      = {10.1016/j.neuroimage.2007.09.066},
  file     = {stonnington2008interpreting.pdf:stonnington2008interpreting.pdf:PDF},
  groups   = {Not-so-supervised papers},
  keywords = {Alzheimer's Disease, Magnetic resonance imaging (MRI), Multi-scanner, Voxel based morphometry},
}

@Article{storkey2009when,
  author   = {Storkey, Amos J},
  title    = {When training and test sets are different: characterising learning transfer},
  journal  = {Dataset Shift in Machine Learning},
  year     = {2009},
  pages    = {1--28},
  issn     = {9780262170055},
  abstract = {A number of common forms of dataset shift are introduced, and each{\textbackslash}nis related to a particular form of causal probabilistic model. Examples{\textbackslash}nare given for the different types of shift, and some corresponding{\textbackslash}nmodelling approaches. By characterising dataset shift in this way,{\textbackslash}nthere is potential for the development of models which capture the{\textbackslash}nspecific types of variations, combine different modes of variation,{\textbackslash}nor do model selection to assess whether dataset shift is an issue{\textbackslash}nin particular circumstances. As an example of how such models can{\textbackslash}nbe developed, an illustration is provided for one approach to adapting{\textbackslash}nGaussian process methods for a particular type of dataset shift called{\textbackslash}nMixture Component Shift.},
  keywords = {LIT-DRIFTMODELS},
}

@Article{su2013cell,
  author   = {Su, Hang and Yin, Zhaozheng and Huh, Seungil and Kanade, Takeo},
  title    = {Cell segmentation in phase contrast microscopy images via semi-supervised classification over optics-related features.},
  journal  = {Medical image analysis},
  year     = {2013},
  volume   = {17},
  number   = {7},
  pages    = {746--765},
  month    = oct,
  abstract = {Phase-contrast microscopy is one of the most common and convenient imaging modalities to observe long-term multi-cellular processes, which generates images by the interference of lights passing through transparent specimens and background medium with different retarded phases. Despite many years of study, computer-aided phase contrast microscopy analysis on cell behavior is challenged by image qualities and artifacts caused by phase contrast optics. Addressing the unsolved challenges, the authors propose (1) a phase contrast microscopy image restoration method that produces phase retardation features, which are intrinsic features of phase contrast microscopy, and (2) a semi-supervised learning based algorithm for cell segmentation, which is a fundamental task for various cell behavior analysis. Specifically, the image formation process of phase contrast microscopy images is first computationally modeled with a dictionary of diffraction patterns; as a result, each pixel of a phase contrast microscopy image is represented by a linear combination of the bases, which we call phase retardation features. Images are then partitioned into phase-homogeneous atoms by clustering neighboring pixels with similar phase retardation features. Consequently, cell segmentation is performed via a semi-supervised classification technique over the phase-homogeneous atoms. Experiments demonstrate that the proposed approach produces quality segmentation of individual cells and outperforms previous approaches.},
  doi      = {10.1016/j.media.2013.04.004},
  groups   = {Not-so-supervised papers},
  keywords = {Algorithms, Artifacts, Artificial Intelligence, Automated, Cell Tracking, Computer-Assisted, Image Enhancement, Image Interpretation, methods, microscopy, Pattern Recognition, Phase-Contrast, Reproducibility of Results, Sensitivity and Specificity},
  language = {eng},
}

@Article{suinesiaputra2016cardiac,
  author   = {Suinesiaputra, Avan and McCulloch, Andrew D. and Nash, Martyn P. and Pontre, Beau and Young, Alistair A.},
  title    = {Cardiac image modelling: {Breadth} and depth in heart disease},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {1339--1351},
  abstract = {With the advent of large-scale imaging studies and big health data, and the corresponding growth in analytics, machine learning and computational image analysis methods, there are now exciting opportunities for deepening our understanding of the mechanisms and characteristics of heart disease. Two emerging fields are computational analysis of cardiac remodelling (shape and motion changes due to disease) and computational analysis of physiology and mechanics to estimate biophysical properties from non-invasive imaging. Many large cohort studies now underway around the world have been specifically designed based on non-invasive imaging technologies in order to gain new information about the development of heart disease from asymptomatic to clinical manifestations. These give an unprecedented breadth to the quantification of population variation and disease development. Also, for the individual patient, it is now possible to determine biophysical properties of myocardial tissue in health and disease by interpreting detailed imaging data using computational modelling. For these population and patient-specific computational modelling methods to develop further, we need open benchmarks for algorithm comparison and validation, open sharing of data and algorithms, and demonstration of clinical efficacy in patient management and care. The combination of population and patient-specific modelling will give new insights into the mechanisms of cardiac disease, in particular the development of heart failure, congenital heart disease, myocardial infarction, contractile dysfunction and diastolic dysfunction.},
  doi      = {10.1016/j.media.2016.06.027},
  keywords = {Biomechanics, Cardiac atlases, Computational modelling},
  url      = {http://dx.doi.org/10.1016/j.media.2016.06.027},
}

@Article{summers2003road,
  author   = {Summers, Ronald M.},
  title    = {Road {Maps} for {Advancement} of {Radiologic} {Computer}-aided {Detection} in the 21st {Century}1},
  journal  = {http://dx.doi.org/10.1148/radiol.2291030010},
  year     = {2003},
  keywords = {Computers, diagnostic aid, Diagnostic radiology, Editorials, Picture archiving and communication system (PACS), Quality assurance},
}

@Article{sun2008listed,
  author   = {Sun, Jie and Li, Hui},
  title    = {Listed companies' financial distress prediction based on weighted majority voting combination of multiple classifiers},
  journal  = {Expert Systems with Applications},
  year     = {2008},
  volume   = {35},
  number   = {3},
  pages    = {818--827},
  issn     = {0957-4174},
  abstract = {How to effectively predict financial distress is an important problem in corporate financial management. Though much attention has been paid to financial distress prediction methods based on single classifier, its limitation of uncertainty and benefit of multiple classifier combination for financial distress prediction has also been neglected. This paper puts forward a financial distress prediction method based on weighted majority voting combination of multiple classifiers. The framework of multiple classifier combination system, model of weighted majority voting combination, basic classifiers' voting weight model and basic classifiers' selection principles are discussed in detail. Empirical experiment with Chinese listed companies' real world data indicates that this method can greatly improve the average prediction accuracy and stability, and it is more suitable for financial distress prediction than single classifiers. © 2007 Elsevier Ltd. All rights reserved.},
  doi      = {10.1016/j.eswa.2007.07.045},
  file     = {sun2008listed.pdf:sun2008listed.pdf:PDF},
  keywords = {Financial distress prediction, Multiple classifier combination, Weighted majority voting},
}

@Article{sun2017enhancing,
  author   = {Sun, Wenqing and Tseng, Tzu-Liang Bill and Zhang, Jianying and Qian, Wei},
  title    = {Enhancing deep convolutional neural network scheme for breast cancer diagnosis with unlabeled data.},
  journal  = {Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society},
  year     = {2017},
  volume   = {57},
  pages    = {4--9},
  month    = jul,
  abstract = {In this study we developed a graph based semi-supervised learning (SSL) scheme using deep convolutional neural network (CNN) for breast cancer diagnosis. CNN usually needs a large amount of labeled data for training and fine tuning the parameters, and our proposed scheme only requires a small portion of labeled data in training set. Four modules were included in the diagnosis system: data weighing, feature selection, dividing co-training data labeling, and CNN. 3158 region of interests (ROIs) with each containing a mass extracted from 1874 pairs of mammogram images were used for this study. Among them 100 ROIs were treated as labeled data while the rest were treated as unlabeled. The area under the curve (AUC) observed in our study was 0.8818, and the accuracy of CNN is 0.8243 using the mixed labeled and unlabeled data.},
  doi      = {10.1016/j.compmedimag.2016.07.004},
  groups   = {Not-so-supervised papers},
  language = {ENG},
}

@Article{sun2016computerized,
  author   = {Sun, Wenqing and Tseng, Tzu-Liang Bill and Zhang, Jianying and Qian, Wei},
  title    = {Computerized breast cancer analysis system using three stage semi-supervised learning method},
  journal  = {Computer methods and programs in biomedicine},
  year     = {2016},
  volume   = {135},
  pages    = {77--88},
  abstract = {BACKGROUND AND OBJECTIVE: A large number of labeled medical image data is usually a requirement to train a well-performed computer-aided detection (CAD) system. But the process of data labeling is time consuming, and potential ethical and logistical problems may also present complications. As a result, incorporating unlabeled data into CAD system can be a feasible way to combat these obstacles. METHODS: In this study we developed a three stage semi-supervised learning (SSL) scheme that combines a small amount of labeled data and larger amount of unlabeled data. The scheme was modified on our existing CAD system using the following three stages: data weighing, feature selection, and newly proposed dividing co-training data labeling algorithm. Global density asymmetry features were incorporated to the feature pool to reduce the false positive rate. Area under the curve (AUC) and accuracy were computed using 10 fold cross validation method to evaluate the performance of our CAD system. The image dataset includes mammograms from 400 women who underwent routine screening examinations, and each pair contains either two cranio-caudal (CC) or two mediolateral-oblique (MLO) view mammograms from the right and the left breasts. From these mammograms 512 regions were extracted and used in this study, and among them 90 regions were treated as labeled while the rest were treated as unlabeled. RESULTS: Using our proposed scheme, the highest AUC observed in our research was 0.841, which included the 90 labeled data and all the unlabeled data. It was 7.4\% higher than using labeled data only. With the increasing amount of labeled data, AUC difference between using mixed data and using labeled data only reached its peak when the amount of labeled data was around 60. CONCLUSIONS: This study demonstrated that our proposed three stage semi-supervised learning can improve the CAD performance by incorporating unlabeled data. Using unlabeled data is promising in computerized cancer research and may have a significant impact for future CAD system applications.},
  doi2     = {10.1016/j.cmpb.2016.07.017},
  groups   = {Not-so-supervised papers},
  language = {eng},
}

@Article{tan2013automatic,
  author = {Tan, Robby T},
  title  = {Automatic coronary calcium scoring in multi-center lung cancer screening trial},
  year   = {2013},
  number = {3759512},
  file   = {tan2013automatic.pdf:tan2013automatic.pdf:PDF},
}

@InProceedings{tomas-fernandez2011new,
  author    = {Tomas-Fernandez, X. and Warfield, Simon K.},
  title     = {A new classifier feature space for an improved multiple sclerosis lesion segmentation},
  booktitle = {International Symposium on Biomedical Imaging (ISBI)},
  year      = {2011},
  pages     = {1492--1495},
  month     = mar,
  publisher = {IEEE},
  annote    = {Motivation: usually distribution of intensities modeled as Gaussian mixture, but lesions and normal voxels overlap. Propose to compare intensity of voxels to intensity distribution of voxels in healthy subjects, at the same location (Mahalanobis distance)Aligned T1w, T2w, FLAIR imagesTrained on 15 healthy subjectsValidation on MS Lesion challengeHigh PPV, low sensitivity},
  doi       = {10.1109/ISBI.2011.5872683},
  isbn      = {978-1-4244-4127-3},
  keywords  = {biological tissues, biomedical MRI, Brain, brain tissue, classifier feature space, contrast, image classification, image noise, Image segmentation, intensity based classification, Lesions, Magnetic resonance imaging, medical image processing, Multiple sclerosis, multiple sclerosis lesion segmentation, Segmentation, spatial locations},
  url       = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5872683},
}

@Article{tommasi2013dataset,
  author   = {Tommasi, Tatiana and Quadrianto, Novi and Caputo, Barbara and Lampert, Christoph H.},
  title    = {Beyond dataset bias: {Multi}-task unaligned shared knowledge transfer},
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year     = {2013},
  volume   = {7724 LNCS},
  number   = {PART 1},
  pages    = {1--15},
  issn     = {9783642373305},
  abstract = {Many visual datasets are traditionally used to analyze the performance of different learning techniques. The evaluation is usually done within each dataset, therefore it is questionable if such results are a reliable indicator of true generalization ability. We propose here an algorithm to exploit the existing data resources when learning on a new multiclass problem. Our main idea is to identify an image representation that decomposes orthogonally into two subspaces: a part specific to each dataset, and a part generic to, and therefore shared between, all the considered source sets. This allows us to use the generic representation as un-biased reference knowledge for a novel classification task. By casting the method in the multi-view setting, we also make it possible to use different features for different databases. We call the algorithm MUST, Multitask Unaligned Shared knowledge Transfer. Through extensive experiments on five public datasets, we show that MUST consistently improves the cross-datasets generalization performance.},
  doi      = {10.1007/978-3-642-37331-2_1},
}

@Article{torralba2011unbiased,
  author   = {Torralba, Antonio and Efros, Alexei A.},
  title    = {Unbiased {Look} at {Dataset} {Bias}},
  journal  = {CVPR 2011},
  year     = {2011},
  pages    = {1521--1528},
  month    = jun,
  issn     = {978-1-4577-0394-2},
  abstract = {Datasets are an integral part of contemporary object recognition research. They have been the chief reason for the considerable progress in the field, not just as source of large amounts of training data, but also as means of measuring and comparing performance of competing algo-rithms. At the same time, datasets have often been blamed for narrowing the focus of object recognition research, re-ducing it to a single benchmark performance number. In-deed, some datasets, that started out as data capture efforts aimed at representing the visual world, have become closed worlds unto themselves (e.g. the Corel world, the Caltech-101 world, the PASCAL VOC world). With the focus on beating the latest benchmark numbers on the latest dataset, have we perhaps lost sight of the original purpose? The goal of this paper is to take stock of the current state of recognition datasets. We present a comparison study us-ing a set of popular datasets, evaluated based on a number of criteria including: relative data bias, cross-dataset gen-eralization, effects of closed-world assumption, and sample value. The experimental results, some rather surprising, suggest directions that can improve dataset collection as well as algorithm evaluation protocols. But more broadly, the hope is to stimulate discussion in the community regard-ing this very important, but largely neglected issue.},
  doi      = {10.1109/CVPR.2011.5995347},
  keywords = {algorithm evaluation protocols, closed world assumption effects, Communities, contemporary object recognition, cross dataset generalization, data capture, Internet, object recognition, recognition datasets, relative data bias, sample value, Support vector machines, Testing, Training, visual databases, Visualization},
  url      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5995347},
}

@Article{tuia2015multiclass,
  author   = {Tuia, Devis and Courty, Nicolas and Tuia, Devis and Courty, Nicolas},
  title    = {Multiclass feature learning for hyperspectral image classification : sparse and hierarchical solutions {To} cite this version :},
  year     = {2015},
  keywords = {active set, deep learning, feature selection, hierarchical feature extraction, hyperspectral imaging, multimodal},
}

@Article{tulder2014learning,
  author = {Tulder, Gijs Van and Bruijne, Marleen De},
  title  = {Learning {Features} for {Tissue} {Classification} with the {Classification} {Restricted}},
  year   = {2014},
  pages  = {47--58},
  issn   = {9783319139722},
  file   = {tulder2014learning.pdf:tulder2014learning.pdf:PDF},
}

@Article{tumer1999linear,
  author   = {Tumer, Kagan and Ghosh, Joydeep},
  title    = {Linear and {Order} {Statistics} {Combiners} for {Pattern} {Classification}},
  year     = {1999},
  pages    = {31--31},
  abstract = {Several researchers have experimentally shown that substantial improvements can be obtained in difficult pattern recognition problems by combining or integrating the outputs of multiple classifiers. This chapter provides an analytical framework to quantify the improvements in classification results due to combining. The results apply to both linear combiners and order statistics combiners. We first show that to a first order approximation, the error rate obtained over and above the Bayes error rate, is directly proportional to the variance of the actual decision boundaries around the Bayes optimum boundary. Combining classifiers in output space reduces this variance, and hence reduces the "added" error. If N unbiased classifiers are combined by simple averaging, the added error rate can be reduced by a factor of N if the individual errors in approximating the decision boundaries are uncorrelated. Expressions are then derived for linear combiners which are biased or correlated, and the effect of output correlations on ensemble performance is quantified. For order statistics based non-linear combiners, we derive expressions that indicate how much the median, the maximum and in general the ith order statistic can improve classifier performance. The analysis presented here facilitates the understanding of the relationships among error rates, classifier boundary distributions, and combining in output space. Experimental results on several public domain data sets are provided to illustrate the benefits of combining and to support the analytical results.},
  file     = {tumer1999linear.pdf:tumer1999linear.pdf:PDF},
  url      = {http://arxiv.org/abs/cs/9905012},
}

@Article{ungi2016open,
  author   = {Ungi, Tamas and Lasso, Andras and Fichtinger, Gabor},
  title    = {Open-source platforms for navigated image-guided interventions},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {181--186},
  abstract = {Navigation technology is changing the clinical standards in medical interventions by making existing procedures more accurate, and new procedures possible. Navigation is based on preoperative or intraoperative imaging combined with 3-dimensional position tracking of interventional tools registered to the images. Research of navigation technology in medical interventions requires significant engineering efforts. The difficulty of developing such complex systems has been limiting the clinical translation of new methods and ideas. A key to the future success of this field is to provide researchers with platforms that allow rapid implementation of applications with minimal resources spent on reimplementing existing system features. A number of platforms have been already developed that can share data in real time through standard interfaces. Complete navigation systems can be built using these platforms using a layered software architecture. In this paper, we review the most popular platforms, and show an effective way to take advantage of them through an example surgical navigation application.},
  doi      = {10.1016/j.media.2016.06.011},
  keywords = {Image-guided therapy, Interventions, Opensource, Surgical navigation},
}

@Article{vaid2016v,
  author  = {Vaid, J. and Geraci, L.},
  title   = {V. {An} examination of women's professional visibility in cognitive psychology},
  journal = {Feminism \& Psychology},
  year    = {2016},
  volume  = {26},
  number  = {3},
  pages   = {292--319},
  month   = aug,
  doi     = {10.1177/0959353516641139},
  url     = {http://fap.sagepub.com/cgi/doi/10.1177/0959353516641139},
}

@Article{scheer2014benefits,
  author   = {Van Der Scheer, Lieke and Garcia, Elisa and Van Der Laan, Anna Laura and Van Der Burg, Simone and Boenink, Marianne},
  title    = {The {Benefits} of {Patient} {Involvement} for {Translational} {Research}},
  journal  = {Health Care Analysis},
  year     = {2014},
  number   = {December},
  issn     = {1573-3394 (Electronic){\textbackslash}r1065-3058 (Linking)},
  abstract = {The question we raise in this paper is, whether patient involvement might be a beneficial way to help determine and achieve the aims of translational (TR) research and, if so, how to proceed. TR is said to ensure a more effective movement ('translation') of basic scientific findings to relevant and useful clinical applications. In view of the fact that patients are supposed to be the primary beneficiaries of such translation and also have relevant knowledge based on their experience, listening to their voice early on in the innovation process might very well increase the effectiveness of the translation. After explaining how the concept of TR emerged and what it entails, this paper shows through a literature review which arguments have been put forward to promote patient involvement in health care research in a more general sense. We examine whether, and if so how, these arguments are relevant for the discourse on TR and we identify pitfalls and dilemmas. Ultimately, we conclude that it may be worthwhile to experiment with patient involvement in TR but that the design of such involvement requires careful consideration.},
  doi      = {10.1007/s10728-014-0289-0},
  keywords = {Patient experiential knowledge, Patient involvement, Patient involvement in research, Patient participation, Patient participation in science, Translational research},
}

@InCollection{weken2003using,
  author    = {Van der Weken, Dietrich and Nachtegael, Mike and Kerre, Etienne},
  title     = {Using {Similarity} {Measures} for {Histogram} {Comparison}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2003},
  pages     = {396--403},
  note      = {DOI: 10.1007/3-540-44967-1\_47},
  url       = {http://link.springer.com/10.1007/3-540-44967-1_47},
}

@Article{ginneken3d,
  author   = {Van Ginneken, Bram and Heimann, Tobias and Styner, Martin},
  title    = {3D {Segmentation} in the {Clinic}: {A} {Grand} {Challenge}},
  abstract = {This paper describes the set-up of a segmentation competi-tion for automatic and semi-automatic extraction of the liver from com-puted tomography scans and the caudate nucleus from brain MRI data. This competition was held in the form of a workshop at the 2007 Medical Image Computing and Computer Assisted Intervention conference. The rationale for organizing the competition is discussed, the training and test data sets for both segmentation tasks are described and the scoring system used to evaluate the segmentation is presented.},
}

@Article{ginneken2009computer,
  author   = {van Ginneken, Bram and Hogeweg, Laurens and Prokop, Mathias},
  title    = {Computer-aided diagnosis in chest radiography: {Beyond} nodules},
  journal  = {European Journal of Radiology},
  year     = {2009},
  volume   = {72},
  number   = {2},
  pages    = {226--230},
  abstract = {Chest radiographs are the most common exam in radiology. They are essential for the management of various diseases associated with high mortality and morbidity and display a wide range of findings, many of them subtle. In this survey we identify a number of areas beyond pulmonary nodules that could benefit from computer-aided detection and diagnosis (CAD) in chest radiography. These include interstitial infiltrates, catheter tip detection, size measurements, detection of pneumothorax and detection and quantification of emphysema. Recent work in these areas is surveyed, but we conclude that the amount of research devoted to these topics is modest. Reasons for the slow pace of CAD development in chest radiography beyond nodules are discussed.},
  doi      = {10.1016/j.ejrad.2009.05.061},
}

@Article{opbroek2013transfer,
  author  = {van Opbroek, Annegreet and Ikram, M. Arfan and Vernooij, Meike W. and De Bruijne, Marleen},
  title   = {A transfer-learning approach to image segmentation across scanners by maximizing distribution similarity},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year    = {2013},
  volume  = {8184 LNCS},
  pages   = {49--56},
  doi2    = {10.1007/978-3-319-02267-3_7},
  file    = {opbroek2013transfer.pdf:opbroek2013transfer.pdf:PDF},
  issn2   = {9783319022666},
}

@Article{rikxoort2009automatic,
  author   = {van Rikxoort, Eva M. and de Hoop, Bartjan and Viergever, Max A. and Prokop, Mathias and van Ginneken, Bram},
  title    = {Automatic lung segmentation from thoracic computed tomography scans using a hybrid approach with error detection},
  journal  = {Medical Physics},
  year     = {2009},
  volume   = {36},
  number   = {7},
  pages    = {2934--2934},
  abstract = {Lung segmentation is a prerequisite for automated analysis of chest CT scans. Conventional lung segmentation methods rely on large attenuation differences between lung parenchyma and surrounding tissue. These methods fail in scans where dense abnormalities are present, which often occurs in clinical data. Some methods to handle these situations have been proposed, but they are too time consuming or too specialized to be used in clinical practice. In this article, a new hybrid lung segmentation method is presented that automatically detects failures of a conventional algorithm and, when needed, resorts to a more complex algorithm, which is expected to produce better results in abnormal cases. In a large quantitative evaluation on a database of 150 scans from different sources, the hybrid method is shown to perform substantially better than a conventional approach at a relatively low increase in computational cost.},
  doi      = {10.1118/1.3147146},
  url      = {http://scitation.aip.org/content/aapm/journal/medphys/36/7/10.1118/1.3147146},
}

@Article{vedaldi2016understanding,
  author = {Vedaldi, Andrea},
  title  = {Understanding {CNNs} using visualisation and transformation analysis},
  year   = {2016},
  number = {August},
}

@Article{vilalta2002perspective,
  author   = {Vilalta, Ricardo and Drissi, Youssef},
  title    = {A {Perspective} {View} and {Survey} of {Meta}-{Learning}},
  journal  = {Artificial Intelligence Review},
  year     = {2002},
  volume   = {18},
  pages    = {77--95},
  abstract = {Different researchers hold different views of what the term meta-learning exactly means. The first part of this paper provides our own perspective view in which the goal is to build self-adaptive learners (i.e. learning algorithms that improve their bias dynamically through experience by accumulating meta-knowledge). The second part provides a survey of meta-learning as reported by the machine-learning literature. We find that, despite different views and research lines, a question remains constant: how can we exploit knowledge about learning (i.e. meta-knowledge) to improve the performance of learning algorithms? Clearly the answer to this question is key to the advancement of the field and continues being the subject of intensive research.},
  keywords = {Classification, inductive learning, meta-knowledge},
}

@Article{vissers2012brain,
  author   = {Vissers, Marlies E. and X Cohen, Michael and Geurts, Hilde M.},
  title    = {Brain connectivity and high functioning autism: {A} promising path of research that needs refined models, methodological convergence, and stronger behavioral links},
  journal  = {Neuroscience \& Biobehavioral Reviews},
  year     = {2012},
  volume   = {36},
  number   = {1},
  pages    = {604--625},
  abstract = {Here we review findings from studies investigating functional and structural brain connectivity in high functioning individuals with autism spectrum disorders (ASDs). The dominant theory regarding brain connectivity in people with ASD is that there is long distance under-connectivity and local over-connectivity of the frontal cortex. Consistent with this theory, long-range cortico-cortical functional and structural connectivity appears to be weaker in people with ASD than in controls. However, in contrast to the theory, there is less evidence for local over-connectivity of the frontal cortex. Moreover, some patterns of abnormal functional connectivity in ASD are not captured by current theoretical models. Taken together, empirical findings measuring different forms of connectivity demonstrate complex patterns of abnormal connectivity in people with ASD. The frequently suggested pattern of long-range under-connectivity and local over-connectivity is in need of refinement.},
  doi      = {10.1016/j.neubiorev.2011.09.003},
}

@Article{vonbearnensquash2010paper,
  author   = {Von Bearnensquash, Carven},
  title    = {Paper {Gestalt}},
  journal  = {CVPR workshop},
  year     = {2010},
  pages    = {345--349},
  abstract = {Peer reviews of conference paper submissions is an in- tegral part of the research cycle, though it has unknown origins. For the computer vision community, this process has become significantly more difficult in recent years due to the volume of submissions. For example, the number of submissions to the CVPR conference has tripled in the last ten years. For this reason, the community has been forced to reach out to a less than ideal pool of reviewers, which un- fortunately includes uninformed junior graduate students, disgruntled senior graduate students, and tenured faculty. In this work we take the simple intuition that the quality of a paper can be estimated by merely glancing through the general layout, and use this intuition to build a system that employs basic computer vision techniques to predict if the paper should be accepted or rejected. This system can then be used as a first cascade layer during the review pro- cess. Our results show that while rejecting 15\% of good papers, we can cut down the number of bad papers by more than 50\%, saving valuable time of reviewers. Finally, we fed this very paper into our system and are happy to report that it received a posterior probability of 88.4\% of being good. 1. Introduction Peer reviews of conference paper submissions},
}

@InProceedings{wang20144d,
  author    = {Wang, Bo and Liu, Wei and Prastawa, Marcel and Irimia, Andrei and Vespa, Paul M and van Horn, John D and Fletcher, P Thomas and Gerig, Guido},
  title     = {{4D} Active Cut: An Interactive Tool for Pathological Anatomy Modeling},
  booktitle = {International Symposium on Biomedical Imaging (ISBI)},
  year      = {2014},
  volume    = {2014},
  pages     = {529--532},
  abstract  = {4D pathological anatomy modeling is key to understanding complex pathological brain images. It is a challenging problem due to the difficulties in detecting multiple appearing and disappearing lesions across time points and estimating dynamic changes and deformations between them. We propose a novel semi-supervised method, called 4D active cut, for lesion recognition and deformation estimation. Existing interactive segmentation methods passively wait for user to refine the segmentations which is a difficult task in 3D images that change over time. 4D active cut instead actively selects candidate regions for querying the user, and obtains the most informative user feedback. A user simply answers 'yes' or 'no' to a candidate object without having to refine the segmentation slice by slice. Compared to single-object detection of the existing methods, our method also detects multiple lesions with spatial coherence using Markov random fields constraints. Results show improvement on the lesion detection, which subsequently improves deformation estimation.},
  doi2      = {10.1109/ISBI.2014.6867925},
  groups    = {Not-so-supervised papers},
  language  = {ENG},
}

@Article{wang2013modeling,
  author   = {Wang, Bo and Prastawa, Marcel and Saha, Avishek and Awate, Suyash P and Irimia, Andrei and Chambers, Micah C and Vespa, Paul M and Van Horn, John D and Pascucci, Valerio and Gerig, Guido},
  title    = {Modeling {4D} Changes in Pathological Anatomy using Domain Adaptation: Analysis of {TBI} Imaging using a Tumor Database},
  journal  = {MICCAI workshop on Multimodal brain image analysis},
  year     = {2013},
  volume   = {8159},
  pages    = {31--39},
  abstract = {Analysis of 4D medical images presenting pathology (i.e., lesions) is significantly challenging due to the presence of complex changes over time. Image analysis methods for 4D images with lesions need to account for changes in brain structures due to deformation, as well as the formation and deletion of new structures (e.g., edema, bleeding) due to the physiological processes associated with damage, intervention, and recovery. We propose a novel framework that models 4D changes in pathological anatomy across time, and provides explicit mapping from a healthy template to subjects with pathology. Moreover, our framework uses transfer learning to leverage rich information from a known source domain, where we have a collection of completely segmented images, to yield effective appearance models for the input target domain. The automatic 4D segmentation method uses a novel domain adaptation technique for generative kernel density models to transfer information between different domains, resulting in a fully automatic method that requires no user interaction. We demonstrate the effectiveness of our novel approach with the analysis of 4D images of traumatic brain injury (TBI), using a synthetic tumor database as the source domain.},
  doi2     = {10.1007/978-3-319-02126-3_4},
  groups   = {Not-so-supervised papers},
  language = {ENG},
  url2     = {http://www.ncbi.nlm.nih.gov/pubmed/25346953},
}

@Article{wangmaximum,
  author   = {Wang, Hua and Huang, Heng and Kamangar, Farhad and Nie, Feiping and Ding, Chris},
  title    = {Maximum {Margin} {Multi}-{Instance} {Learning}},
  abstract = {Multi-instance learning (MIL) considers input as bags of instances, in which la-bels are assigned to the bags. MIL is useful in many real-world applications. For example, in image categorization semantic meanings (labels) of an image mostly arise from its regions (instances) instead of the entire image (bag). Existing MIL methods typically build their models using the Bag-to-Bag (B2B) distance, which are often computationally expensive and may not truly reflect the semantic sim-ilarities. To tackle this, in this paper we approach MIL problems from a new perspective using the Class-to-Bag (C2B) distance, which directly assesses the relationships between the classes and the bags. Taking into account the two ma-jor challenges in MIL, high heterogeneity on data and weak label association, we propose a novel Maximum Margin Multi-Instance Learning (M 3 I) approach to parameterize the C2B distance by introducing the class specific distance metrics and the locally adaptive significance coefficients. We apply our new approach to the automatic image categorization tasks on three (one single-label and two multi-label) benchmark data sets. Extensive experiments have demonstrated promising results that validate the proposed method.},
}

@Article{wang2015links,
  author   = {Wang, Li and Gao, Yaozong and Shi, Feng and Li, Gang and Gilmore, John H. and Lin, Weili and Shen, Dinggang},
  title    = {{LINKS}: {Learning}-based multi-source {IntegratioN} {frameworK} for {Segmentation} of infant brain images},
  journal  = {NeuroImage},
  year     = {2015},
  volume   = {108},
  pages    = {160--172},
  issn     = {9783319139715},
  abstract = {Segmentation of infant brain MR images is challenging due to insufficient image quality, severe partial volume effect, and ongoing maturation and myelination processes. In the first year of life, the image contrast between white and gray matters of the infant brain undergoes dramatic changes. In particular, the image contrast is inverted around 6-8. months of age, and the white and gray matter tissues are isointense in both T1- and T2-weighted MR images and thus exhibit the extremely low tissue contrast, which poses significant challenges for automated segmentation. Most previous studies used multi-atlas label fusion strategy, which has the limitation of equally treating the different available image modalities and is often computationally expensive. To cope with these limitations, in this paper, we propose a novel learning-based multi-source integration framework for segmentation of infant brain images. Specifically, we employ the random forest technique to effectively integrate features from multi-source images together for tissue segmentation. Here, the multi-source images include initially only the multi-modality (T1, T2 and FA) images and later also the iteratively estimated and refined tissue probability maps of gray matter, white matter, and cerebrospinal fluid. Experimental results on 119 infants show that the proposed method achieves better performance than other state-of-the-art automated segmentation methods. Further validation was performed on the MICCAI grand challenge and the proposed method was ranked top among all competing methods. Moreover, to alleviate the possible anatomical errors, our method can also be combined with an anatomically-constrained multi-atlas labeling approach for further improving the segmentation accuracy.},
  doi      = {10.1016/j.neuroimage.2014.12.042},
  keywords = {Context feature, Infant brain images, Isointense stage, Multi-modality, random forest, Tissue segmentation},
  url      = {http://dx.doi.org/10.1016/j.neuroimage.2014.12.042},
}

@Article{wang2015optimizing,
  author   = {Wang, Shijun and Li, Diana and Petrick, Nicholas and Sahiner, Berkman and Linguraru, Marius George and Summers, Ronald M},
  title    = {Optimizing area under the {ROC} curve using semi-supervised learning.},
  journal  = {Pattern Recognition},
  year     = {2015},
  volume   = {48},
  number   = {1},
  pages    = {276--287},
  abstract = {Receiver operating characteristic (ROC) analysis is a standard methodology to evaluate the performance of a binary classification system. The area under the ROC curve (AUC) is a performance metric that summarizes how well a classifier separates two classes. Traditional AUC optimization techniques are supervised learning methods that utilize only labeled data (i.e., the true class is known for all data) to train the classifiers. In this work, inspired by semi-supervised and transductive learning, we propose two new AUC optimization algorithms hereby referred to as semi-supervised learning receiver operating characteristic (SSLROC) algorithms, which utilize unlabeled test samples in classifier training to maximize AUC. Unlabeled samples are incorporated into the AUC optimization process, and their ranking relationships to labeled positive and negative training samples are considered as optimization constraints. The introduced test samples will cause the learned decision boundary in a multidimensional feature space to adapt not only to the distribution of labeled training data, but also to the distribution of unlabeled test data. We formulate the semi-supervised AUC optimization problem as a semi-definite programming problem based on the margin maximization theory. The proposed methods SSLROC1 (1-norm) and SSLROC2 (2-norm) were evaluated using 34 (determined by power analysis) randomly selected datasets from the University of California, Irvine machine learning repository. Wilcoxon signed rank tests showed that the proposed methods achieved significant improvement compared with state-of-the-art methods. The proposed methods were also applied to a CT colonography dataset for colonic polyp classification and showed promising results.},
  doi2     = {10.1016/j.patcog.2014.07.025},
  groups   = {Not-so-supervised papers},
  language = {ENG},
}

@Article{wang2012machine,
  author   = {Wang, Shijun and Summers, Ronald M.},
  title    = {Machine learning and radiology},
  journal  = {Medical Image Analysis},
  year     = {2012},
  volume   = {16},
  number   = {5},
  pages    = {933--951},
  abstract = {In this paper, we give a short introduction to machine learning and survey its applications in radiology. We focused on six categories of applications in radiology: medical image segmentation, registration, computer aided detection and diagnosis, brain function or activity analysis and neurological disease diagnosis from fMR images, content-based image retrieval systems for CT or MRI images, and text analysis of radiology reports using natural language processing (NLP) and natural language understanding (NLU). This survey shows that machine learning plays a key role in many radiology applications. Machine learning identifies complex patterns automatically and helps radiologists make intelligent decisions on radiology data such as conventional radiographs, CT, MRI, and PET images and radiology reports. In many applications, the performance of machine learning-based automatic detection and diagnosis systems has shown to be comparable to that of a well-trained and experienced radiologist. Technology development in machine learning and radiology will benefit from each other in the long run. Key contributions and common characteristics of machine learning techniques in radiology are discussed. We also discuss the problem of translating machine learning applications to the radiology clinical setting, including advantages and potential barriers.},
  doi      = {10.1016/j.media.2012.02.005},
}

@InProceedings{wang2015computer,
  author    = {Wang, Shuai and Cong, Yang and Fan, Huijie and Yang, Yunsheng and Tang, Yandong and Zhao, Huaici},
  title     = {Computer aided endoscope diagnosis via weakly labeled data mining},
  booktitle = {International Conference on Image Processing (ICIP)},
  year      = {2015},
  pages     = {3072--3076},
  publisher = {IEEE},
  doi2      = {10.1109/ICIP.2015.7351368},
  groups    = {Not-so-supervised papers},
  isbn2     = {978-1-4799-8339-1},
  keywords  = {Bismuth, Computer aided diagnosis (CAD), computer aided endoscope diagnosis, computers, Data mining, Endoscopes, frame-level classification problem, gastroscopic image dataset, image classification, Image color analysis, image representation, learning (artificial intelligence), Lesions, medical image processing, MIL issue, multiple instance learning issue, multiple instance learning (MIL), pixel-wise groundtruth, pixel-wise label information mining, positive bags, positive instance, standard supervised learning problem, superpixel, Training, Transforms, weak frame-level labels, weakly labeled data mining, weakly labeled endoscope images},
  url2      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7351368},
}

@Article{wang2013max,
  author   = {Wang, Xinggang and Wang, Baoyuan and Bai, Xiang and Liu, Wenyu and Tu, Zhuowen},
  title    = {Max-{Margin} {Multiple}-{Instance} {Dictionary} {Learning}},
  journal  = {Icml},
  year     = {2013},
  abstract = {Dictionary learning has became an increas- ingly important task in machine learning, as it is fundamental to the representation problem. A number of emerging techniques specifically include a codebook learning step, in which a critical knowledge abstraction process is carried out. Existing approach- es in dictionary (codebook) learning are ei- ther generative (unsupervised e.g. k-means) or discriminative (supervised e.g. extreme- ly randomized forests). In this paper, we propose a multiple instance learning (MIL) strategy (along the line of weakly supervised learning) for dictionary learning. Each code is represented by a classifier, such as a linear SVM, which naturally performs metric fusion for multi-channel features. We design a for- mulation to simultaneously learn mixtures of codes by maximizing classification margins in MIL. State-of-the-art results are observed in image classification benchmarks based on the learned codebooks, which observe both com- pactness and effectiveness},
}

@InCollection{warrell2011multiple,
  author    = {Warrell, Jonathan and Torr, Philip H. S.},
  title     = {Multiple-{Instance} {Learning} with {Structured} {Bag} {Models}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2011},
  pages     = {369--384},
  note      = {DOI: 10.1007/978-3-642-23094-3\_27},
  file      = {warrell2011multiple.pdf:warrell2011multiple.pdf:PDF},
  url       = {http://link.springer.com/10.1007/978-3-642-23094-3_27},
}

@InCollection{watanabe2016label,
  author    = {Watanabe, Takanori and Tunc, Birkan and Parker, Drew and Kim, Junghoon and Verma, Ragini},
  title     = {Label-{Informed} {Non}-negative {Matrix} {Factorization} with {Manifold} {Regularization} for {Discriminative} {Subnetwork} {Detection}},
  publisher = {Springer International Publishing},
  year      = {2016},
  pages     = {166--174},
  note      = {DOI: 10.1007/978-3-319-46720-7\_20},
  url       = {http://link.springer.com/10.1007/978-3-319-46720-7_20},
}

@Article{wei2016empirical,
  author  = {Wei, Xiu-Shen and Zhou, Zhi-Hua},
  title   = {An empirical study on image bag generators for multi-instance learning},
  journal = {Machine Learning},
  year    = {2016},
  pages   = {1--44},
  month   = mar,
  doi     = {10.1007/s10994-016-5560-1},
  url     = {http://link.springer.com/10.1007/s10994-016-5560-1},
}

@Article{wells2016medical,
  author   = {Wells, William M.},
  title    = {Medical {Image} {Analysis} ??? past, present, and future},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {1339--1351},
  abstract = {In this editorial I summarize, against the backdrop of the research disciplines, meetings and journals of the time, the emergence in the early 1990s of the field that is eponymous with the present journal. I briefly summarize the current status of the field, and outline some possible future directions.},
  doi      = {10.1016/j.media.2016.06.013},
  keywords = {Analysis, Editorial, Image, Medical},
}

@Article{wierciochprobability,
  author = {Wiercioch, Magdalena and Smieja, Marek and Tabor, Jacek},
  title  = {Probability {Index} of {Metric} {Correspondence} as a measure of visualization reliability {In} this section we introduce a measure for visualization assessment called {Probability} {Index} of {Metric}},
}

@InProceedings{wilber2016learning,
  author    = {Wilber, Michael J. and Kwak, Iljung S. and Kriegman, David and Belongie, Serge},
  title     = {Learning concept embeddings with combined human-machine expertise},
  booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Computer} {Vision}},
  year      = {2016},
  abstract  = {This paper presents our work on "SNaCK," a low-dimensional concept embedding algorithm that combines human expertise with automatic machine similarity kernels. Both parts are complimentary: human insight can capture relationships that are not apparent from the object's visual similarity and the machine can help relieve the human from having to exhaustively specify many constraints. We show that our SNaCK embeddings are useful in several tasks: distinguishing prime and nonprime numbers on MNIST, discovering labeling mistakes in the Caltech UCSD Birds (CUB) dataset with the help of deep-learned features, creating training datasets for bird classifiers, capturing subjective human taste on a new dataset of 10,000 foods, and qualitatively exploring an unstructured set of pictographic characters. Comparisons with the state-of-the-art in these tasks show that SNaCK produces better concept embeddings that require less human supervision than the leading methods.},
  doi       = {10.1109/ICCV.2015.118},
  isbn      = {978-1-4673-8391-2},
}

@InCollection{woznica2010new,
  author    = {Woznica, Adam and Kalousis, Alexandros},
  title     = {A {New} {Framework} for {Dissimilarity} and {Similarity} {Learning}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2010},
  pages     = {386--397},
  note      = {DOI: 10.1007/978-3-642-13672-6\_38},
  url       = {http://link.springer.com/10.1007/978-3-642-13672-6_38},
}

@InProceedings{woznica2006distances,
  author    = {Woznica, Adam and Kalousis, Alexandros and Hilario, Melanie},
  title     = {Distances and ({Indefinite}) {Kernels} for {Sets} of {Objects}},
  booktitle = {Sixth {International} {Conference} on {Data} {Mining} ({ICDM}'06)},
  year      = {2006},
  pages     = {1151--1156},
  month     = dec,
  publisher = {IEEE},
  doi       = {10.1109/ICDM.2006.60},
  file      = {woznica2006distances.pdf:woznica2006distances.pdf:PDF},
  isbn      = {0-7695-2701-7},
  keywords  = {Buildings, Computer science, Density measurement, Gaussian processes, Kernel, learning (artificial intelligence), machine learning, Power measurement, Probability density function, set kernels, set theory, Support vector machine classification, Support vector machines, Vectors},
  url       = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4053170},
}

@InProceedings{wu2015deep,
  author    = {Wu, Jiajun and Yinan Yu, Yinan and Chang Huang, Chang and Kai Yu, Kai},
  title     = {Deep multiple instance learning for image classification and auto-annotation},
  booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
  year      = {2015},
  pages     = {3460--3469},
  month     = jun,
  publisher = {IEEE},
  doi       = {10.1109/CVPR.2015.7298968},
  isbn      = {978-1-4673-6964-0},
  keywords  = {deep multiple instance learning, feature extraction, image annotation, image classification, learning (artificial intelligence), machine learning, MIL, Neural networks, Noise measurement, Proposals, supervised deep learning framework, Supervised learning, Visualization},
  url       = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7298968},
}

@Article{wu2014milcut,
  author   = {Wu, Jiajun and Zhao, Yibiao and Zhu, Jun-Yan and Luo, Siwei and Tu, Zhuowen},
  title    = {{MILCut}: {A} {Sweeping} {Line} {Multiple} {Instance} {Learning} {Paradigm} for {Interactive} {Image} {Segmentation}},
  journal  = {2014 IEEE Conference on Computer Vision and Pattern Recognition},
  year     = {2014},
  pages    = {256--263},
  issn     = {978-1-4799-5118-5},
  abstract = {Interactive segmentation, in which a user provides a bounding box to an object of interest for image segmentation, has been applied to a variety of applications in image editing, crowdsourcing, computer vision, and medical imaging. The challenge of this semi-automatic image segmentation task lies in dealing with the uncertainty of the foreground object within a bounding box. Here, we formulate the interactive segmentation problem as a multiple instance learning (MIL) task by generating positive bags from pixels of sweeping lines within a bounding box. We name this approach MILCut. We provide a justification to our formulation and develop an algorithm with significant performance and efficiency gain over existing state-of-the-art systems. Extensive experiments demonstrate the evident advantage of our approach.},
  doi      = {10.1109/CVPR.2014.40},
  file     = {wu2014milcut.pdf:wu2014milcut.pdf:PDF},
  url      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6909434},
}

@InProceedings{xiao2010smile,
  author    = {Xiao, Yanshan and Liu, Bo and Cao, Longbing and Yin, Jie and Wu, Xindong},
  title     = {{SMILE}: {A} {Similarity}-{Based} {Approach} for {Multiple} {Instance} {Learning}},
  booktitle = {2010 {IEEE} {International} {Conference} on {Data} {Mining}},
  year      = {2010},
  pages     = {589--598},
  month     = dec,
  publisher = {IEEE},
  doi       = {10.1109/ICDM.2010.126},
  isbn      = {978-1-4244-9131-5},
  keywords  = {generalisation (artificial intelligence), learning (artificial intelligence), MIL method, multiple instance learning, pattern classification, similarity-based multiple instance learning, SMILE, supervised learning generalization, Support vector machines, SVM-based predictive classifier},
  url       = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5694013},
}

@Article{xu2011survey,
  author   = {Xu, Qian and Yang, Qiang},
  title    = {A {Survey} of {Transfer} and {Multitask} {Learning} in {Bioinformatics}},
  journal  = {Journal of Computing Science and Engineering},
  year     = {2011},
  volume   = {5},
  number   = {3},
  pages    = {257--268},
  doi      = {10.5626/JCSE.2011.5.3.257},
  file     = {xu2011survey.pdf:xu2011survey.pdf:PDF},
  keywords = {Bioinformatics, Data mining, Transfer learning},
}

@Article{xu2014deep,
  author  = {Xu, Yan and Mo, Tao and Feng, Qiwei and Zhong, Peilin and Lai, Maode and Chang, Eric},
  title   = {Deep learning of feature representation with multiple instance learning for medical image analysis},
  journal = {ICASSP},
  year    = {2014},
  groups  = {Not-so-supervised papers},
}

@InProceedings{xu2012context,
  author    = {Xu, Yan and Zhang, Jianwen and Chang, Eric I-Chao and Lai, Maode and Tu, Zhuowen},
  title     = {Context-constrained multiple instance learning for histopathology image segmentation},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year      = {2012},
  volume    = {15},
  number    = {Pt 3},
  pages     = {623--630},
  abstract  = {Histopathology image segmentation plays a very important role in cancer diagnosis and therapeutic treatment. Existing supervised approaches for image segmentation require a large amount of high quality manual delineations (on pixels), which is often hard to obtain. In this paper, we propose a new algorithm along the line of weakly supervised learning; we introduce context constraints as a prior for multiple instance learning (ccMIL), which significantly reduces the ambiguity in weak supervision (a 20\% gain); our method utilizes image-level labels to learn an integrated model to perform histopathology cancer image segmentation, clustering, and classification. Experimental results on colon histopathology images demonstrate the great advantages of ccMIL.},
  doi       = {10.1007/978-3-642-33454-2_77},
  file      = {xu2012contexts.pdf:xu2012contexts.pdf:PDF},
  groups    = {Not-so-supervised papers},
  keywords  = {Algorithms, Artificial Intelligence, Automated, Colonic Neoplasms, Computer-Assisted, Humans, Image Enhancement, Image Interpretation, methods, microscopy, Pathology, Pattern Recognition, Reproducibility of Results, Sensitivity and Specificity},
  language  = {eng},
  url       = {http://link.springer.com/10.1007/978-3-642-33454-2_77},
}

@Article{yan2007model,
  author   = {Yan, Rong and Tesic, Jelena and Smith, John R.},
  title    = {Model-shared subspace boosting for multi-label classification},
  journal  = {Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '07},
  year     = {2007},
  pages    = {834--834},
  issn     = {9781595936097},
  abstract = {Typical approaches to the multi-label classification problem require{\textbackslash}nlearning an independent classifier for every label from all the examples{\textbackslash}nand features. This can become a computational bottleneck for sizeable{\textbackslash}ndatasets with a large label space. In this paper, we propose an efficient{\textbackslash}nand effective multi-label learning algorithm called model-shared{\textbackslash}nsubspace boosting (MSSBoost) as an attempt to reduce the information{\textbackslash}nredundancy in the learning process. This algorithm automatically{\textbackslash}nfinds, shares and combines a number of base models across multiple{\textbackslash}nlabels, where each model is learned from random feature subspace{\textbackslash}nand bootstrap data samples. The decision functions for each label{\textbackslash}nare jointly estimated and thus a small number of shared subspace{\textbackslash}nmodels can support the entire label space. Our experimental results{\textbackslash}non both synthetic data and real multimedia collections have demonstrated{\textbackslash}nthat the proposed algorithm can achieve better classification performance{\textbackslash}nthan the non-ensemble baseline classifiers with a significant speedup{\textbackslash}nin the learning and prediction processes. It can also use a smaller{\textbackslash}nnumber of base models to achieve the same classification performance{\textbackslash}nas its non-model-shared counterpart.},
  doi      = {10.1145/1281192.1281281},
  file     = {yan2007model.pdf:yan2007model.pdf:PDF},
  keywords = {multi-label classification, random subspace methods},
  url      = {http://dl.acm.org/citation.cfm?id=1281192.1281281},
}

@Article{yan2015bodypart,
  author   = {Yan, Zhennan and Zhan, Yiqiang and Peng, Zhigang and Liao, Shu and Shinagawa, Yoshihisa and Metaxas, Dimitris N and Zhou, Xiang Sean},
  title    = {Bodypart {Recognition} {Using} {Multi}-stage {Deep} {Learning}.},
  journal  = {Information processing in medical imaging : proceedings of the ... conference},
  year     = {2015},
  volume   = {24},
  pages    = {449--461},
  abstract = {Automatic medical image analysis systems often start from identifying the human body part contained in the image; Specifically, given a transversal slice, it is important to know which body part it comes from, namely "slice-based bodypart recognition". This problem has its unique characteristic--the body part of a slice is usually identified by local discriminative regions instead of global image context, e.g., a cardiac slice is differentiated from an aorta arch slice by the mediastinum region. To leverage this characteristic, we design a multi-stage deep learning framework that aims at: (1) discover the local regions that are discriminative to the bodypart recognition, and (2) learn a bodypart identifier based on these local regions. These two tasks are achieved by the two stages of our learning scheme, respectively. In the pre-train stage, a convolutional neural network (CNN) is learned in a multi-instance learning fashion to extract the most discriminative local patches from the training slices. In the boosting stage, the learned CNN is further boosted by these local patches for bodypart recognition. By exploiting the discriminative local appearances, the learned CNN becomes more accurate than global image context-based approaches. As a key hallmark, our method does not require manual annotations of the discriminative local patches. Instead, it automatically discovers them through multi-instance deep learning. We validate our method on a synthetic dataset and a large scale CT dataset (7000+ slices from wholebody CT scans). Our method achieves better performances than state-of-the-art approaches, including the standard CNN.},
  groups   = {Not-so-supervised papers},
  keywords = {80 and over, Adolescent, Adult, Aged, Algorithms, Artificial Intelligence, Automated, Child, Computer-Assisted, Female, Humans, Image Enhancement, Image Interpretation, Imaging, Infant, Male, methods, Middle Aged, Pattern Recognition, Preschool, Reproducibility of Results, Sensitivity and Specificity, Three-Dimensional, Tomography, Whole Body Imaging, X-Ray Computed, Young Adult},
  language = {eng},
}

@Article{yan2016multi,
  author   = {Yan, Zhennan and Zhan, Yiqiang and Peng, Zhigang and Liao, Shu and Shinagawa, Yoshihisa and Zhang, Shaoting and Metaxas, Dimitris N. and Zhou, Xiang Sean},
  title    = {Multi-Instance Deep Learning: Discover Discriminative Local Anatomies for Bodypart Recognition},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2016},
  volume   = {35},
  number   = {5},
  pages    = {1332--1343},
  abstract = {In general image recognition problems, discriminative information often lies in local image patches. For example, most human identity information exists in the image patches containing human faces. The same situation stays in medical images as well. "Bodypart identity" of a transversal slice - which bodypart the slice comes from - is often indicated by local image information, e.g. a cardiac slice and an aorta arch slice are only differentiated by the mediastinum region. In this work, we design a multi-stage deep learning framework for image classification and apply it on bodypart recognition. Specifically, the proposed framework aims at: 1) discover the local regions that are discriminative and non-informative to the image classification problem, and 2) learn a image-level classifier based on these local regions. We achieve these two tasks by the two stages of learning scheme, respectively. In the pre-train stage, a convolutional neural network (CNN) is learned in a multiinstance learning fashion to extract the most discriminative and and non-informative local patches from the training slices. In the boosting stage, the pre-learned CNN is further boosted by these local patches for image classification. The CNN learned by exploiting the discriminative local appearances becomes more accurate than those learned from global image context. The key hallmark of our method is that it automatically discovers the discriminative and non-informative local patches through multiinstance deep learning. Thus, no manual annotation is required. Our method is validated on a synthetic dataset and a large scale CT dataset. It achieves better performances than state-of-the-art approaches, including the standard deep CNN.},
  doi2     = {10.1109/TMI.2016.2524985},
  groups   = {Not-so-supervised papers},
  issn2    = {0278-0062},
  keywords = {CNN, discriminative local information discovery, multi-instance, multi-stage},
  url2     = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7398101},
}

@Article{yildiz2014multivariate,
  author   = {Yildiz, Olcay Taner and Alpaydin, Ethem},
  title    = {Multivariate {Comparison} of {Classification} {Algorithms}},
  year     = {2014},
  pages    = {1--15},
  abstract = {Statistical tests that compare classification algorithms are univariate and use a single performance measure, e.g., misclassification error, \$F\$ measure, AUC, and so on. In multivariate tests, comparison is done using multiple measures simultaneously. For example, error is the sum of false positives and false negatives and a univariate test on error cannot make a distinction between these two sources, but a 2-variate test can. Similarly, instead of combining precision and recall in \$F\$ measure, we can have a 2-variate test on (precision, recall). We use Hotelling's multivariate \$T{\textasciicircum}2\$ test for comparing two algorithms, and when we have three or more algorithms we use the multivariate analysis of variance (MANOVA) followed by pairwise post hoc tests. In our experiments, we see that multivariate tests have higher power than univariate tests, that is, they can detect differences that univariate tests cannot. We also discuss how multivariate analysis allows us to automatically extract performance measures that best distinguish the behavior of multiple algorithms.},
  keywords = {design of experiments, ethem alpayd?n 2, multivariate analysis, olcay taner y?ld?z 1, statistical tests},
  url      = {http://arxiv.org/abs/1409.4566},
}

@Article{yosinskihow,
  author   = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  title    = {How transferable are features in deep neural networks?},
  abstract = {Many deep neural networks trained on natural images exhibit a curious phe-nomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Trans-ferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to split-ting networks between co-adapted neurons, which was not expected. In an exam-ple network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of fea-tures decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset.},
}

@Article{zhang2013automated,
  author  = {Zhang, Gang and Yin, Jian and Li, Ziping and Su, Xiangyang and Li, Guozheng and Zhang, Honglai},
  title   = {Automated skin biopsy histopathological image annotation using multi-instance representation and learning},
  journal = {BMC Medical Genomics},
  year    = {2013},
  volume  = {6},
  number  = {Suppl 3},
  pages   = {S10--S10},
  doi2    = {10.1186/1755-8794-6-S3-S10},
  file    = {zhang2013automated.pdf:zhang2013automated.pdf:PDF},
  groups  = {Not-so-supervised papers},
  url2    = {http://bmcmedgenomics.biomedcentral.com/articles/10.1186/1755-8794-6-S3-S10},
}

@Article{zhang2016learning,
  author  = {Zhang, Jing and Wu, Xindong and Sheng, Victor S.},
  title   = {Learning from crowdsourced labeled data: a survey},
  journal = {Artificial Intelligence Review},
  year    = {2016},
  pages   = {1--34},
  month   = jul,
  doi     = {10.1007/s10462-016-9491-9},
  url     = {http://link.springer.com/10.1007/s10462-016-9491-9},
}

@Article{zhang2013domain,
  author  = {Zhang, Kun and Muandet, Krikamol and Wang, Zhikun and {Others}},
  title   = {Domain adaptation under target and conditional shift},
  journal = {Proceedings of the 30th International Conference on Machine Learning (ICML-13)},
  year    = {2013},
  volume  = {28},
  pages   = {819--827},
  file    = {zhang2013domain.pdf:zhang2013domain.pdf:PDF},
}

@Article{zhang2016statistical,
  author   = {Zhang, Miaomiao and Golland, Polina},
  title    = {Statistical shape analysis: {From} landmarks to diffeomorphisms},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {155--158},
  abstract = {We offer a blazingly brief review of evolution of shape analysis methods in medical imaging. As the representations and the statistical models grew more sophisticated, the problem of shape analysis has been gradually redefined to accept images rather than binary segmentations as a starting point. This transformation enabled shape analysis to take its rightful place in the arsenal of tools for extracting and understanding patterns in large clinical image sets. We speculate on the future developments in shape analysis and potential applications that would bring this mathematically rich area to bear on clinical practice.},
  doi      = {10.1016/j.media.2016.06.025},
  keywords = {Diffeomorphisms, Landmarks, Shape variability, Statistical shape analysis},
  url      = {http://dx.doi.org/10.1016/j.media.2016.06.025},
}

@Article{zhang2007classifier,
  author   = {Zhang, Peng and Zhu, Xingquan and Tan, Jianlong and Guo, Li},
  title    = {Classifier and {Cluster} {Ensembles} for {Mining} {Concept} {Drifting} {Data} {Streams}},
  year     = {2007},
  keywords = {-data stream mining, Classification, concept drifting, ensemble, learning},
}

@Article{zhang2016efficiency,
  author   = {Zhang, Qiantao and Lucey, Brian M. and Larkin, Charles James},
  title    = {An {Efficiency} {Analysis} of the {Three}-{Missionss} in {Irish} {Higher} {Education} {Institutions}},
  journal  = {SSRN Electronic Journal},
  year     = {2016},
  doi      = {10.2139/ssrn.2832715},
  keywords = {Efficiency analysis, Free Disposable Hull, Higher education institutions, Ireland},
  url      = {http://www.ssrn.com/abstract=2832715},
}

@Article{zhang2016large,
  author   = {Zhang, Shaoting and Metaxas, Dimitris},
  title    = {Large-{Scale} medical image analytics: {Recent} methodologies, applications and {Future} directions},
  journal  = {Medical Image Analysis},
  year     = {2016},
  volume   = {33},
  pages    = {98--101},
  issn     = {1361-8415},
  abstract = {Despite the ever-increasing amount and complexity of annotated medical image data, the development of large-scale medical image analysis algorithms has not kept pace with the need for methods that bridge the semantic gap between images and diagnoses. The goal of this position paper is to discuss and explore innovative and large-scale data science techniques in medical image analytics, which will benefit clinical decision-making and facilitate efficient medical data management. Particularly, we advocate that the scale of image retrieval systems should be significantly increased at which interactive systems can be effective for knowledge discovery in potentially large databases of medical images. For clinical relevance, such systems should return results in real-time, incorporate expert feedback, and be able to cope with the size, quality, and variety of the medical images and their associated metadata for a particular domain. The design, development, and testing of the such framework can significantly impact interactive mining in medical image databases that are growing rapidly in size and complexity and enable novel methods of analysis at much larger scales in an efficient, integrated fashion.},
  doi      = {10.1016/j.media.2016.06.010},
  keywords = {Image retrieval, Large-scale, Medical image analytics, Segmentation, Visual analytics},
  url      = {http://dx.doi.org/10.1016/j.media.2016.06.010},
}

@Article{zhengcross,
  author   = {Zheng, Yefeng},
  title    = {{CROSS}-{MODALITY} {MEDICAL} {IMAGE} {DETECTION} {AND} {SEGMENTATION} {BY} {TRANSFER} {LEARNING} {OF} {SHAPE} {PRIORS}},
  abstract = {Machine learning based methods have been widely used for detecting and segmenting various anatomical structures in dif-ferent medical imaging modalities. The robustness of such approaches is largely determined by the number of training samples. In practice it is often difficult to acquire sufficient training samples for a certain imaging modality. Since mul-tiple imaging modalities are often used for disease diagnosis or surgical planning, images of the same anatomical struc-ture may be available in a different modality. In this work we investigate the effectiveness of shape priors learned from a different modality (e.g., CT) to improve the segmentation accuracy on the target modality (e.g., MRI). The shape priors are exploited in the marginal space learning framework in sev-eral ways, e.g., increasing the pose hypothesis set, enriching the statistical shape model, and synthesizing new training im-ages with real shapes. Experiments show that the additional shape priors transferred from a different source can dramat-ically improve the segmentation accuracy when the training set is small (e.g., with 10 or 20 training images).},
}

@Article{zhou2015learning,
  author   = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
  title    = {Learning {Deep} {Features} for {Discriminative} {Localization}},
  year     = {2015},
  abstract = {In this work, we revisit the global average pooling layer proposed in [13], and shed light on how it explicitly enables the convolutional neural network to have remarkable local-ization ability despite being trained on image-level labels. While this technique was previously proposed as a means for regularizing training, we find that it actually builds a generic localizable deep representation that can be applied to a variety of tasks. Despite the apparent simplicity of global average pooling, we are able to achieve 37.1\% top-5 error for object localization on ILSVRC 2014, which is re-markably close to the 34.2\% top-5 error achieved by a fully supervised CNN approach. We demonstrate that our net-work is able to localize the discriminative image regions on a variety of tasks despite not being trained for them.},
}

@Article{zhou2014multiple,
  author   = {Zhou, Zhi-Hua Hua Z.-H. and Zhang, Min-Ling Ling and Jiang, K. and Li, M and Zhang, Xiaohang and Liu, Jiaqi and Du, Yu and Lv, Tingjie and Zhang, Min-Ling Ling and Zhou, Zhi-Hua Hua Z.-H. and Zhang, Dan and Wang, Fei and Si, Luo and Li, Tao and Science, Computer and Lafayette, West and Sciences, Information and Xu, Yan Y. and Zhu, Jun Yan and Chang, Eric and Tu, Zhuowen and Zhang, Jianwen and Eric, I and Chang, C and Lai, Maode and Tu, Zhuowen and Wijaya, Tri Kurniawan and Ganu, Tanuja and Chakraborty, Dipanjan and Aberer, Karl and Seetharam, Deva P. and Weidmann, Nils and Frank, Eibe and Pfahringer, Bernhard and Warren Liao, T. and Wang, Jun and Zucker, Jean-Daniel D. and Thalamuthu, Anbupalam and Mukhopadhyay, Indranil and Zheng, Xiaojing and Tseng, George C and Tax, D. M J and Hendriks, E. and Valstar, M. F. and Pantic, M. and Ruffo, G. and Renner, Stephan and Heinemann, Christoph and Räsänen, Teemu and Voukantsis, Dimitrios and Niska, Harri and Karatzas, Kostas and Kolehmainen, Mikko and Pei, Yuanli and Fern, Xiaoli Z. and Pao, H. T. and Chuang, S. C. and Xu, Yan Y. and Fu, H and Pakhira, Malay K and Bandyopadhyay, Sanghamitra and Maulik, Ujjwal and Oates, Tim and Firoiu, Laura and Cohen, Paul R and Mutanen, Antti and Ruska, Maija and Repo, Sami and Järventausta, Pertti and Mihaylov, Mihail and Jurado, Sergio and Avellana, Narcís and Razo-Zapata, Iván and Van Moffaert, Kristof and Arco, Leticia and Bezunartea, Maite and Grau, Isel and Cañadas, Adrian and Nowé, Ann and Maron, O. and Lozano-Perez, T. A and MacQueen, James and Losa, I and Nigris, Michele De M De and Van, Tvu and Liao, Bo and Li, Yun and Jiang, Yan and Cai, Lijun and Lee, T E and Haben, S A and Grindrod, P and Lavin, Alexander and Klabjan, Diego and Lai, Cheng-Ping and Chung, Pau-Choo and Tseng, Vincent S. and Kruse, R. and Döring, C. and Lesor, M.-J. and Kriegel, Hans-peter and Pryakhin, Alexey and Schubert, Matthias and Kohonen, Teuvo and {J. Wang} and Zucker, Jean-Daniel D. and Iglesias, Félix and Kastner, Wolfgang and Hübner, Michael and Prüggler, Natalie and Hossain, Jahangir and Kabir, A. N. M. Enamul and Rahman, Mostafizur and Kabir, Borhan and Islam, Rafiqul and Hollands, Robert G and Herman, G. and Ye, G. and Xu, J. and Zhang, B. and Gu, Z. and Mei, T. and Tang, J. and Wu, X. and Hua, X. and Giordano, Vincenzo and Gangale, Flavia and Jrc-ie, Gianluca Fulli and Sánchez, Manuel and Dg, Jiménez and Onyeji, Ijeoma and Colta, Alexandru and Papaioannou, Ioulia and Mengolini, Anna and Alecu, Corina and Ojala, Tauno and Maschio, Isabella and Gharavi-Alkhansari, Mohammad and Huang, Thomas S and Flath, Christoph and Nicolay, David and Conte, Tobias and Van Dinther, Clemens and Filipova-Neumann, Lilia and Figueiredo, V and Rodrigues, F and Vale, Z and Gouveia, J B and {European Commission} and Espinoza, Marcelo and Joye, C. and Belmans, R. and DeMoor, B. and Edgar, G. A. and Dunn, Joseph C and Dudoit, Sandrine and Fridlyand, Jane and Dietterich, T. G. and Lathrop, R. H. and Lozano-Perez, T. A and Dent, Ian and Aickelin, Uwe and Rodden, Tom and Davies, David L and Bouldin, Donald W and Chen, X. and Zhang, C. and Chen, S. and Rubin, S and Cao, Hong An and Beckel, Christian and Staake, Thorsten and Cali?ski, Tadeusz and Harabasz, Jerzy and Brunner, Helfried and Nigris, Michele De M De and Gallo, Angel Díaz and Herold, Irmgard and Hribernik, Wolfgang and Karg, Ludwig and Koivuranta, Kari and Papi?, Igor and Lopes, Joao Peças and Verboven, Peter and Brockwell, Peter J and Davis, Richard a and Boutell, M. R. and Luo, J. and Shen, X. and Brown, C. M. and Binh, Phan Thi Thanh and Ha, Nguyen Hong and Tuan, Tong Cong and Khoa, Le Dinh and Ball, Geoffrey H and Hall, David J and Ardakanian, Omid and Koochakzadeh, Negar and Singh, Rayman Preet and Golab, Lukasz and Keshav, S. and Andrews, S. and Hofmann, T. and Tsochantaridis, I. and Amar, R. A. and Dooly, D. R. and Goldman, S. A. and Zhang, Q. and Alzate, Carlos and Espinoza, Marcelo and Moor, Bart De and Suykens, Johan a K and Albert, Adrian and Rajagopal, Ram and Aghabozorgi, Saeed and Ying Wah, Teh and Herawan, Tutut and Jalab, Hamid a and Shaygan, Mohammad Amin and Jalali, Alireza and Saybani, Mahmoud Reza and Wah, Teh Ying},
  title    = {Multiple-instance learning of real-valued data},
  journal  = {Expert Systems with Applications},
  year     = {2014},
  volume   = {1},
  number   = {3},
  pages    = {31--71},
  issn     = {978-3-540-20121-2},
  abstract = {Cancer tissues in histopathology images exhibit abnormal patterns; it {\textbackslash}nis of great clinical importance to label a histopathology image as having {\textbackslash}ncancerous regions or not and perform the corresponding image segmentation. {\textbackslash}nHowever, the detailed annotation of cancer cells is often an ambiguous and {\textbackslash}nchallenging task. In this paper, we propose a new learning method, multiple {\textbackslash}nclustered instance learning (MCIL), to classify, segment and cluster cancer {\textbackslash}ncells in colon histopathology images. The proposed MCIL method simultaneously {\textbackslash}nperforms image-level classification (cancer vs. non-cancer image), pixel-level {\textbackslash}nsegmentation (cancer vs. non-cancer tissue), and patch-level clustering (cancer {\textbackslash}nsubclasses). We embed the clustering concept into the multiple instance learning {\textbackslash}n(MIL) setting and derive a principled solution to perform the above three tasks {\textbackslash}nin an integrated framework. Experimental results demonstrate the efficiency and {\textbackslash}neffectiveness of MCIL in analyzing colon cancers.},
  doi      = {10.1109/CVPR.2012.6247772},
  keywords = {2, and bernhard pfahringer 2, Bag constraints, Classification, clustering, Constrained clustering, Constructive induction, eibe frank 2, Ensemble learning, generalized, Instance clustering, Knowledge representation, learning from examples, machine learning, MIML, multi-instance learning, multi-instance problems, nils weidmann 1, Representation transformation, Spectral clustering, supervised learn-, Time series classification, wo-level learning method for},
  url      = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3951281&tool=pmcentrez&rendertype=abstract%5Cnhttp://www.sciencedirect.com/science/article/pii/S0167865513002572%5Cnhttp://www.springerlink.com/index/f6gt44f5rm4xtc0k.pdf%5Cnhttp://research.microso},
}

@InCollection{zhu2014reasoning,
  author    = {Zhu, Yuke and Fathi, Alireza and Fei-Fei, Li},
  title     = {Reasoning about {Object} {Affordances} in a {Knowledge} {Base} {Representation}},
  publisher = {Springer International Publishing},
  year      = {2014},
  pages     = {408--424},
  note      = {DOI: 10.1007/978-3-319-10605-2\_27},
  url       = {http://link.springer.com/10.1007/978-3-319-10605-2_27},
}

@Article{zikic2013atlas,
  author   = {Zikic, Darko and Glocker, Ben and Criminisi, Antonio},
  title    = {Atlas encoding by randomized forests for efficient label propagation},
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year     = {2013},
  volume   = {8151 LNCS},
  number   = {PART 3},
  pages    = {66--73},
  issn     = {9783642407598},
  abstract = {We propose a method for multi-atlas label propagation based on encoding the individual atlases by randomized classification forests. Most current approaches perform a non-linear registration between all atlases and the target image, followed by a sophisticated fusion scheme. While these approaches can achieve high accuracy, in general they do so at high computational cost. This negatively affects the scalability to large databases and experimentation. To tackle this issue, we propose to use a small and deep classification forest to encode each atlas individually in reference to an aligned probabilistic atlas, resulting in an Atlas Forest (AF). At test time, each AF yields a probabilistic label estimate, and fusion is done by averaging. Our scheme performs only one registration per target image, achieves good results with a simple fusion scheme, and allows for efficient experimentation. In contrast to standard forest schemes, incorporation of new scans is possible without retraining, and target-specific selection of atlases remains possible. The evaluation on three different databases shows accuracy at the level of the state of the art, at a significantly lower runtime.},
  doi      = {10.1007/978-3-642-40760-4_9},
  file     = {zikic2013atlasforest.pdf:zikic2013atlasforest.pdf:PDF},
}

@Article{zulueta-coarasa2011emphysema,
  author   = {Zulueta-Coarasa, Teresa and Kurugol, Sila and Ross, James C. and Washko, George G. and San Jose Estepar, Raul and {Zulueta}},
  title    = {Emphysema classification based on embedded probabilistic {PCA}},
  journal  = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
  year     = {2011},
  volume   = {4},
  number   = {164},
  pages    = {3969--3972},
  issn     = {9781457702167},
  abstract = {In this article we investigate the suitability of a manifold learning technique to classify different types of emphysema based on embedded Probabilistic PCA (PPCA). Our approach finds the most discriminant linear space for each emphysema pattern against the remaining patterns where lung CT image patches can be embedded. In this embedded space, we train a PPCA model for each pattern. The main novelty of our technique is that it is possible to compute the class membership posterior probability for each emphysema pattern rather than a hard assignment as it is typically done by other approaches. We tested our algorithm with six emphysema patterns using a data set of 1337 CT training patches. Using a 10-fold cross validation experiment, an average recall rate of 69\% is achieved when the posterior probability is greater than 75\%. A quantitative comparison with a texture-based approach based on Local Binary Patterns and with an approach based on local intensity distributions shows that our method is competitive. The analysis of full lungs using our approach shows a good visual agreement with the underlying emphysema types and a smooth spatial relation.},
  doi      = {10.1126/scisignal.2001449.Engineering},
}

@Misc{exploring,
  title = {Exploring deep features from brain tumor magnetic resonance images via transfer learning},
  url   = {http://ieeexplore.ieee.org/abstract/document/7727204/},
}

@Misc{learning,
  title = {Learning under {Concept} {Drift}: an {Overview}},
  url   = {file:///C:/Users/vcheplygina/Downloads/Zliobaite_CDoverview (1).pdf},
}

@PhdThesis{cheplygina2015dissimilarity,
  author = {Veronika Cheplygina},
  title  = {Dissimilarity-based multiple instance learning},
  year   = {2015},
  groups = {My papers},
}

@Book{duda1999pattern,
  title     = {Pattern classification},
  publisher = {John Wiley \& Sons},
  year      = {1999},
  author    = {Duda, Richard O and Hart, Peter E and Stork, David G},
}

@Article{bradley1997use,
  Title                    = {{The use of the area under the {ROC} curve in the evaluation of machine learning algorithms}},
  Author                   = {Bradley, A.P.},
  Journal                  = {Pattern Recognition},
  Year                     = {1997},
  Number                   = {7},
  Pages                    = {1145--1159},
  Volume                   = {30},

  Publisher                = {Elsevier}
}

@Article{demsar2006statistical,
  author  = {Dem{\v{s}}ar, J.},
  title   = {Statistical comparisons of classifiers over multiple data sets},
  journal = {The Journal of Machine Learning Research},
  year    = {2006},
  volume  = {7},
  pages   = {1--30},
  file    = {demsar2006statistical.pdf:demsar2006statistical.pdf:PDF},
}

@Article{dietterich1997solving,
  author    = {Dietterich, T.G. and Lathrop, R.H. and Lozano-P{\'e}rez, T.},
  title     = {Solving the multiple instance problem with axis-parallel rectangles},
  journal   = {Artificial Intelligence},
  year      = {1997},
  volume    = {89},
  number    = {1-2},
  pages     = {31--71},
  file      = {dietterich1997solving.pdf:dietterich1997solving.pdf:PDF},
  publisher = {Elsevier},
}

@Misc{duin2009dis,
  author    = {Duin, R. P. W. and Pekalska, E.},
  title     = {{Dis}-{T}ools},
  year      = {2009},
  publisher = {Delft University of Technology},
}

@Book{fukunaga1990introduction,
  title     = {Introduction to statistical pattern recognition},
  publisher = {Academic press},
  year      = {1990},
  author    = {Fukunaga, Keinosuke},
}

@Article{kuncheva2003measures,
  author    = {Kuncheva, Ludmila I and Whitaker, Christopher J},
  title     = {Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy},
  journal   = {Machine Learning},
  year      = {2003},
  volume    = {51},
  number    = {2},
  pages     = {181--207},
  file      = {kuncheva2003measures.pdf:kuncheva2003measures.pdf:PDF},
  publisher = {Springer},
}

@Article{sorensen2012texture,
  author  = {S{\o}rensen, Lauge and Nielsen, Mads and Lo, Pechin and Ashraf, Haseem and Pedersen, Jesper H and de Bruijne, Marleen},
  title   = {Texture-based analysis of {COPD}: a data-driven approach},
  journal = {IEEE Transactions on Medical Imaging},
  year    = {2012},
  volume  = {31},
  number  = {1},
  pages   = {70--78},
  groups  = {Not-so-supervised papers},
}

@Article{al-boukai2011prediction,
  author   = {Al-boukai, Ahmad a and Al-kassimi, Feisal a and Ibrahim, Gehan F and Shaik, Shaffi a},
  title    = {Prediction of {Pulmonary} {Hypertension} in {Patients} with or without {Interstitial} {Lung} {Disease}},
  journal  = {Radiology},
  year     = {2011},
  volume   = {260},
  number   = {3},
  pages    = {875--883},
  issn     = {1527-1315 (Electronic){\textbackslash}n0033-8419 (Linking)},
  abstract = {Purpose: To study the reliability of pulmonary vascular measurements based on computed tomography (CT) in the prediction of pulmonary hypertension (PH) in patients with advanced interstitial lung disease (ILD) compared with those with- out ILD. Materials and Methods: The study was approved by the Institutional Review Board. All patients gave written informed consent. A prospective study of 134 patients who underwent right-sided heart catheterization and chest CT scanning within 72 hours of admission was conducted. Patients were divided into two groups?one with ILD (group A, n = 100) and one without ILD (group B, n = 34). CT measurements of the main pulmonary artery diameter (PAD), the ratio of PAD to the ascending aorta diameter (AAD), right pulmonary artery diameter (RPAD), and left pulmonary artery diam- eter (LPAD) were obtained. Univariate logistic regression analysis was performed, and receiver operating charac- teristic curves were constructed to assess the predictive ability of vascular measurements obtained by using CT in the identifi cation of PH. Results: Main PAD was signifi cantly greater in patients with PH than in those without PH in both groups (group A, P = .008; group B, P = .02). A PAD greater than 25 mm in patients with ILD was predictive of PH, with a sensitivity of 86.4\% (32 of 37 ), a specifi city of 41.2\% (26 of 63), a positive predictive value of 46.3\% (32 of 69), and a negative pre- dictive value of 83.8\% (26 of 31). In patients without ILD, a PAD greater than 31.6 mm and an LPAD greater than 21.4 mm were predictive of PH (sensitivity, 47.3\% [nine of 19]; specifi city, 93.3\% [14 of 15]; positive predictive value, 90.0\% [nine of 10]; and negative predictive value, 58.3\% [14 of 24]). Conclusion: CT-derived vascular measurements were of limited utility in the prediction of PH in patients with ILD compared with those without ILD. ORIGINAL},
  doi      = {10.1148/radiol},
}

@Article{aljabar2009multi,
  author   = {Aljabar, P. and Heckemann, R. A. and Hammers, A. and Hajnal, J. V. and Rueckert, D.},
  title    = {Multi-atlas based segmentation of brain images: {Atlas} selection and its effect on accuracy},
  journal  = {NeuroImage},
  year     = {2009},
  volume   = {46},
  number   = {3},
  pages    = {726--738},
  issn     = {1095-9572 (Electronic){\textbackslash}n1053-8119 (Linking)},
  abstract = {Quantitative research in neuroimaging often relies on anatomical segmentation of human brain MR images. Recent multi-atlas based approaches provide highly accurate structural segmentations of the brain by propagating manual delineations from multiple atlases in a database to a query subject and combining them. The atlas databases which can be used for these purposes are growing steadily. We present a framework to address the consequent problems of scale in multi-atlas segmentation. We show that selecting a custom subset of atlases for each query subject provides more accurate subcortical segmentations than those given by non-selective combination of random atlas subsets. Using a database of 275 atlases, we tested an image-based similarity criterion as well as a demographic criterion (age) in a leave-one-out cross-validation study. Using a custom ranking of the database for each subject, we combined a varying number n of atlases from the top of the ranked list. The resulting segmentations were compared with manual reference segmentations using Dice overlap. Image-based selection provided better segmentations than random subsets (mean Dice overlap 0.854 vs. 0.811 for the estimated optimal subset size, n = 20). Age-based selection resulted in a similar marked improvement. We conclude that selecting atlases from large databases for atlas-based brain image segmentation improves the accuracy of the segmentations achieved. We show that image similarity is a suitable selection criterion and give results based on selecting atlases by age that demonstrate the value of meta-information for selection. © 2009 Elsevier Inc. All rights reserved.},
  doi      = {10.1016/j.neuroimage.2009.02.018},
  file     = {aljabar2009multi.pdf:aljabar2009multi.pdf:PDF},
  keywords = {Atlases, MRI, Registration, Segmentation, Selection},
}

@Article{aykac2003segmentation,
  author   = {Aykac, Deniz and Hoffman, Eric a and McLennan, Geoffrey and Reinhardt, Joseph M},
  title    = {Segmentation and analysis of the human airway tree from three-dimensional {X}-ray {CT} images.},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2003},
  volume   = {22},
  number   = {8},
  pages    = {940--950},
  issn     = {0278-0062 (Print){\textbackslash}r0278-0062 (Linking)},
  abstract = {The lungs exchange air with the external environment via the pulmonary airways. Computed tomography (CT) scanning can be used to obtain detailed images of the pulmonary anatomy, including the airways. These images have been used to measure airway geometry, study airway reactivity, and guide surgical interventions. Prior to these applications, airway segmentation can be used to identify the airway lumen in the CT images. Airway tree segmentation can be performed manually by an image analyst, but the complexity of the tree makes manual segmentation tedious and extremely time-consuming. We describe a fully automatic technique for segmenting the airway tree in three-dimensional (3-D) CT images of the thorax. We use grayscale morphological reconstruction to identify candidate airways on CT slices and then reconstruct a connected 3-D airway tree. After segmentation, we estimate airway branchpoints based on connectivity changes in the reconstructed tree. Compared to manual analysis on 3-mm-thick electron-beam CT images, the automatic approach has an overall airway branch detection sensitivity of approximately 73\%.},
  doi      = {10.1109/TMI.2003.815905},
  file     = {aykac2003segmentation.pdf:aykac2003segmentation.pdf:PDF},
  keywords = {Anatomy, Bronchography/*methods, Computer-Assist, Cross-Sectional/methods, Humans, Imaging, Lung/radiography, Pulmonary Alveoli/*radiography, Radiographic Image Enhancement/methods, Radiographic Image Interpretation, Three-Dimensional/*methods, Tomography, Trachea/*radiography, X-Ray Computed/*methods},
  url      = {http://www.ncbi.nlm.nih.gov/pubmed/12906248},
}

@Article{huang2015promises,
  author   = {Huang, Tao and Lan, Liang and Fang, Xuexian and An, Peng and Min, Junxia and Wang, Fudi},
  title    = {Promises and {Challenges} of {Big} {Data} {Computing} in {Health} {Sciences}},
  journal  = {Big Data Research},
  year     = {2015},
  volume   = {2},
  number   = {1},
  pages    = {2--11},
  issn     = {2214-5796},
  abstract = {With the development of smart devices and cloud computing, more and more public health data can be collected from various sources and can be analyzed in an unprecedented way. The huge social and academic impact of such developments caused a worldwide buzz for big data. In this review article, we summarized the latest applications of Big Data in health sciences, including the recommendation systems in healthcare, Internet-based epidemic surveillance, sensor-based health conditions and food safety monitoring, Genome-Wide Association Studies (GWAS) and expression Quantitative Trait Loci (eQTL), inferring air quality using big data and metabolomics and ionomics for nutritionists. We also reviewed the latest technologies of big data collection, storage, transferring, and the state-of-the-art analytical methods, such as Hadoop distributed file system, MapReduce, recommendation system, deep learning and network Analysis. At last, we discussed the future perspectives of health sciences in the era of Big Data.},
  doi      = {10.1016/j.bdr.2015.02.002},
  file     = {huang2015promises.pdf:huang2015promises.pdf:PDF},
  url      = {http://dx.doi.org/10.1016/j.bdr.2015.02.002},
}

@Article{labrie2015whats,
  author   = {Labrie, Nanon and Amati, Rebecca and Camerini, Anne Linda and Zampa, Marta and Zanini, Claudia},
  title    = {"{What}'s in it for us?" {Six} dyadic networking strategies in academia},
  journal  = {Studies in Communication Sciences},
  year     = {2015},
  volume   = {15},
  number   = {1},
  pages    = {158--160},
  abstract = {Networking skills have become increasingly important in the pursuit of academic success. Yet, relatively little has been published in scientific journals about networking in the academic context. To learn more about the importance of academic networking, the Young European Association for Communication Research and Education (YECREA) organized a panel entitled "Successful Networking for an Academic Career: The Importance of Interpersonal Communication". The panel was held during the annual meeting of the Language and Social Interaction Division at the Università della Svizzera italiana (Switzerland) in October 2013. The present conference report elaborates on the findings from the panel discussion that emerged between senior and junior scholars. Six, seemingly paradoxical yet complementary, pairs of networking strategies are discussed: active-passive; strategic-spontaneous; vertical-horizontal; instrumental-relational; interest-driven-task-driven; what is in it for me-what is in it for us networking.},
  doi      = {10.1016/j.scoms.2015.03.012},
  keywords = {Academia, Career advice, Conference panel report, Networking, Strategies},
  url      = {http://dx.doi.org/10.1016/j.scoms.2015.03.012},
}

@Article{rahim2016transmodal,
  author  = {Rahim, Mehdi and Thirion, Bertrand and Comtat, Claude and Varoquaux, Gael},
  title   = {Transmodal {Learning} of {Functional} {Networks} for {Alzheimer}'s {Disease} {Prediction}},
  journal = {IEEE Journal of Selected Topics in Signal Processing},
  year    = {2016},
  volume  = {10},
  number  = {7},
  pages   = {1204--1213},
  month   = oct,
  doi     = {10.1109/JSTSP.2016.2600400},
  groups  = {Not-so-supervised papers},
  url     = {http://ieeexplore.ieee.org/document/7543531/},
}

@Article{ross2012importance,
  author  = {Ross, Joseph S. and Lehman, Richard and Gross, Cary P.},
  title   = {The importance of clinical trial data sharing: {Toward} more open science},
  journal = {Circulation: Cardiovascular Quality and Outcomes},
  year    = {2012},
  volume  = {5},
  number  = {2},
  pages   = {238--240},
  issn    = {1941-7705 (Electronic){\textbackslash}r1941-7713 (Linking)},
  doi     = {10.1161/CIRCOUTCOMES.112.965798},
  file    = {ross2012importance.pdf:ross2012importance.pdf:PDF},
}

@Article{szekely2007measuring,
  author   = {Székely, Gábor J. and Rizzo, Maria L. and Bakirov, Nail K.},
  title    = {Measuring and testing dependence by correlation of distances},
  journal  = {Annals of Statistics},
  year     = {2007},
  volume   = {35},
  number   = {6},
  pages    = {2769--2794},
  month    = dec,
  issn     = {0090-5364},
  abstract = {Distance correlation is a new measure of dependence between random vectors. Distance covariance and distance correlation are analogous to product-moment covariance and correlation, but unlike the classical definition of correlation, distance correlation is zero only if the random vectors are independent. The empirical distance dependence measures are based on certain Euclidean distances between sample elements rather than sample moments, yet have a compact representation analogous to the classical covariance and correlation. Asymptotic properties and applications in testing independence are discussed. Implementation of the test and Monte Carlo results are also presented.},
  doi      = {10.1214/009053607000000505},
  file     = {szekely2007measuring.pdf:szekely2007measuring.pdf:PDF},
  keywords = {Distance correlation, Distance covariance, Multivariate independence},
  url      = {http://projecteuclid.org/euclid.aos/1201012979},
}

@Article{opbroek2012supervised,
  author  = {Van Opbroek, Annegreet and Ikram, M. Arfan and Vernooij, Meike W. and De Bruijne, Marleen},
  title   = {Supervised image segmentation across scanner protocols: {A} transfer learning approach},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year    = {2012},
  volume  = {7588 LNCS},
  pages   = {160--167},
  issn    = {9783642354274},
  doi     = {10.1007/978-3-642-35428-1_20},
  file    = {opbroek2012supervised.pdf:opbroek2012supervised.pdf:PDF},
}

@InProceedings{vezhnevets2010towards,
  author       = {Vezhnevets, Alexander and Buhmann, Joachim M.},
  title        = {Towards weakly supervised semantic segmentation by means of multiple instance and multitask learning},
  booktitle    = {2010 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
  year         = {2010},
  pages        = {3249--3256},
  month        = jun,
  organization = {IEEE},
  publisher    = {IEEE},
  doi          = {10.1109/CVPR.2010.5540060},
  isbn         = {978-1-4244-6984-0},
  keywords     = {Bellows, computer vision, Face detection, geometric context estimation, geometry, Humans, image level labels, Image resolution, Image segmentation, Labeling, learning (artificial intelligence), multiple instance learning, multitask learning, object recognition, Object segmentation, Pixel, pixelwise labeling, Semantic Segmentation, semantic texton forest, Tagging, Testing, weakly supervised data},
}

@Article{walport2011sharing,
  author  = {Walport, Mark and Brest, Paul},
  title   = {Sharing research data to improve public health},
  journal = {The Lancet},
  year    = {2011},
  volume  = {377},
  number  = {9765},
  pages   = {537--539},
  issn    = {0140-6736},
  doi     = {10.1016/S0140-6736(10)62234-9},
  file    = {walport2011sharing.pdf:walport2011sharing.pdf:PDF},
}

@Article{alpaydin2014single,
  author   = {Alpaydin, Ethem and Cheplygina, Veronika and Loog, Marco and Tax, David M. J.},
  title    = {Single- vs. Multiple-Instance Classification},
  journal  = {Pattern Recognition, submitted},
  year     = {2014},
  volume   = {48},
  number   = {9},
  pages    = {2831--2838},
  abstract = {© 2015 Elsevier Ltd.In multiple-instance (MI) classification, each input object or event is represented by a set of instances, named a bag, and it is the bag that carries a label. MI learning is used in different applications where data is formed in terms of such bags and where individual instances in a bag do not have a label. We review MI classification from the point of view of label information carried in the instances in a bag, that is, their sufficiency for classification. Our aim is to contrast MI with the standard approach of single-instance (SI) classification to determine when casting a problem in the MI framework is preferable. We compare instance-level classification, combination by noisy-or, and bag-level classification, using the support vector machine as the base classifier. We define a set of synthetic MI tasks at different complexities to benchmark different MI approaches. Our experiments on these and two real-world bioinformatics applications on gene expression and text categorization indicate that depending on the situation, a different decision mechanism, at the instance- or bag-level, may be appropriate. If the instances in a bag provide complementary information, a bag-level MI approach is useful; but sometimes the bag information carries no useful information at all and an instance-level SI classifier works equally well, or better.},
  doi      = {10.1016/j.patcog.2015.04.006},
  groups   = {My papers},
  keywords = {[Bioinformatics, Classification, Multiple-instance},
  url      = {http://dx.doi.org/10.1016/j.patcog.2015.04.006},
}

@Article{mueller1988density,
  author    = {{\^A}$1/4$ller, NL M{\~A} and Staples, C A and Miller, R R and Abboud, R T},
  title     = {Density mask. An objective method to quantitate emphysema using computed tomography.},
  journal   = {{CHEST} Journal},
  year      = {1988},
  volume    = {94},
  number    = {4},
  pages     = {782--787},
  publisher = {American College of Chest Physicians},
}

@InProceedings{cheplygina2012does,
  author    = {Cheplygina, Veronika and Tax, David M. J. and Loog, Marco},
  title     = {Does one rotten apple spoil the whole barrel?},
  booktitle = {International Conference on Pattern Recognition},
  year      = {2012},
  pages     = {1156-1159},
  groups    = {My papers},
}

@Article{bowdle1997informativity,
  author    = {Bowdle, Brian F and Gentner, Dedre},
  title     = {Informativity and asymmetry in comparisons},
  journal   = {Cognitive Psychology},
  year      = {1997},
  volume    = {34},
  number    = {3},
  pages     = {244--286},
  file      = {bowdle1997informativity.pdf:bowdle1997informativity.pdf:PDF},
  groups    = {Veni},
  publisher = {Elsevier},
}

@Article{albarqouni2016aggnet,
  author    = {Albarqouni, Shadi and Baur, Christoph and Achilles, Felix and Belagiannis, Vasileios and Demirci, Stefanie and Navab, Nassir},
  title     = {{AggNet}: Deep Learning From Crowds for Mitosis Detection in Breast Cancer Histology Images},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2016},
  volume    = {35},
  number    = {5},
  pages     = {1313--1321},
  month     = may,
  abstract  = {The lack of publicly available ground-truth data has been identified as the major challenge for transferring recent developments in deep learning to the biomedical imaging domain. Though crowdsourcing has enabled annotation of large scale databases for real world images, its application for biomedical purposes requires a deeper understanding and hence, more precise definition of the actual annotation task. The fact that expert tasks are being outsourced to non-expert users may lead to noisy annotations introducing disagreement between users. Despite being a valuable resource for learning annotation models from crowdsourcing, conventional machine-learning methods may have difficulties dealing with noisy annotations during training. In this manuscript, we present a new concept for learning from crowds that handle data aggregation directly as part of the learning process of the convolutional neural network (CNN) via additional crowdsourcing layer (AggNet). Besides, we present an experimental study on learning from crowds designed to answer the following questions: (i) Can deep CNN be trained with data collected from crowdsourcing?, (ii) How to adapt the CNN to train on multiple types of annotation datasets (ground truth and crowd-based)?, (iii) How does the choice of annotation and aggregation affect the accuracy? Our experimental setup involved Annot8, a self-implemented web-platform based on Crowdflower API realizing image annotation tasks for a publicly available biomedical image database. Our results give valuable insights into the functionality of deep CNN learning from crowd annotations and prove the necessity of data aggregation integration.},
  annote    = {Results with quality control (aggregate only users who had 70\% correct on labeled data) worse than results without quality controlSome expert labels are needed, the model is improved with crowd labelsResults without expert labels are poor},
  doi2      = {10.1109/TMI.2016.2528120},
  file      = {albarqouni2016aggnet.pdf:albarqouni2016aggnet.pdf:PDF},
  groups    = {Veni},
  issn2     = {1558-254X (Electronic){\textbackslash}r0278-0062 (Linking)},
  keywords  = {Aggregation, crowdsourcing, deep learning, gamification, online learning},
  publisher = {IEEE},
}

@Article{weese2016four,
  author    = {Weese, J{\"u}rgen and Lorenz, Cristian},
  title     = {Four challenges in medical image analysis from an industrial perspective},
  journal   = {Medical Image Analysis},
  year      = {2016},
  volume    = {33},
  pages     = {44--49},
  abstract  = {Today's medical imaging systems produce a huge amount of images containing a wealth of information. However, the information is hidden in the data and image analysis algorithms are needed to extract it, to make it readily available for medical decisions and to enable an efficient work flow. Advances in medical image analysis over the past 20 years mean there are now many algorithms and ideas available that allow to address medical image analysis tasks in commercial solutions with sufficient performance in terms of accuracy, reliability and speed. At the same time new challenges have arisen. Firstly, there is a need for more generic image analysis technologies that can be efficiently adapted for a specific clinical task. Secondly, efficient approaches for ground truth generation are needed to match the increasing demands regarding validation and machine learning. Thirdly, algorithms for analyzing heterogeneous image data are needed. Finally, anatomical and organ models play a crucial role in many applications, and algorithms to construct patient-specific models from medical images with a minimum of user interaction are needed. These challenges are complementary to the on-going need for more accurate, more reliable and faster algorithms, and dedicated algorithmic solutions for specific applications.},
  doi2      = {10.1016/j.media.2016.06.023},
  groups    = {Veni},
  keywords  = {Anatomical models, Ground truth generation, Heterogeneous data, Medical image analysis technologies},
  publisher = {Elsevier},
}

@Article{opbroek2014transfer,
  author    = {van Opbroek, Annegreet and Ikram, M Arfan and Vernooij, Meike W and De Bruijne, Marleen},
  title     = {Transfer learning improves supervised image segmentation across imaging protocols},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2015},
  volume    = {34},
  number    = {5},
  pages     = {1018--1030},
  abstract  = {The variation between images obtained with different scanners or different imaging protocols presents a major challenge in automatic segmentation of biomedical images. This variation especially hampers the application of otherwise successful supervised-learning techniques which, in order to perform well, often require a large amount of labeled training data that is exactly representative of the target data. We therefore propose to use transfer learning for image segmentation. Transfer-learning techniques can cope with differences in distributions between training and target data, and therefore may improve performance over supervised learning for segmentation across scanners and scan protocols. We present four transfer classifiers that can train a classification scheme with only a small amount of representative training data, in addition to a larger amount of other training data with slightly different characteristics. The performance of the four transfer classifiers was compared to that of standard supervised classification on two magnetic resonance imaging brain-segmentation tasks with multi-site data: white matter, gray matter, and cerebrospinal fluid segmentation; and white-matter-/MS-lesion segmentation. The experiments showed that when there is only a small amount of representative training data available, transfer learning can greatly outperform common supervised-learning approaches, minimizing classification errors by up to 60\%.},
  doi2      = {10.1109/TMI.2014.2366792},
  file      = {opbroek2015transfer.pdf:opbroek2015transfer.pdf:PDF;opbroek2014transfer.pdf:opbroek2014transfer.pdf:PDF},
  groups    = {Not-so-supervised papers},
  issn2     = {1558-254X (Electronic){\textbackslash}r0278-0062 (Linking)},
  keywords  = {Image segmentation, machine learning, Magnetic resonance imaging, Pattern Recognition, Transfer learning},
  language  = {eng},
  publisher = {IEEE},
  url2      = {http://www.ncbi.nlm.nih.gov/pubmed/25376036},
}

@Article{castillo2013reference,
  author    = {Castillo, Richard and Castillo, Edward and Fuentes, David and Ahmad, Moiz and Wood, Abbie M and Ludwig, Michelle S and Guerrero, Thomas},
  title     = {A reference dataset for deformable image registration spatial accuracy evaluation using the COPDgene study archive},
  journal   = {Physics in Medicine and Biology},
  year      = {2013},
  volume    = {58},
  number    = {9},
  pages     = {2861},
  month     = may,
  issn      = {2125684381},
  abstract  = {Landmark point-pairs provide a strategy to assess deformable image registration (DIR) accuracy in terms of the spatial registration of the underlying anatomy depicted in medical images. In this study, we propose to augment a publicly available database (www.dir-lab.com) of medical images with large sets of manually identified anatomic feature pairs between breath-hold computed tomography (BH-CT) images for DIR spatial accuracy evaluation. Ten BH-CT image pairs were randomly selected from the COPDgene study cases. Each patient had received CT imaging of the entire thorax in the supine position at one-fourth dose normal expiration and maximum effort full dose inspiration. Using dedicated in-house software, an imaging expert manually identified large sets of anatomic feature pairs between images. Estimates of inter- and intra-observer spatial variation in feature localization were determined by repeat measurements of multiple observers over subsets of randomly selected features. 7298 anatomic landmark features were manually paired between the 10 sets of images. Quantity of feature pairs per case ranged from 447 to 1172. Average 3D Euclidean landmark displacements varied substantially among cases, ranging from 12.29 (SD: 6.39) to 30.90 (SD: 14.05) mm. Repeat registration of uniformly sampled subsets of 150 landmarks for each case yielded estimates of observer localization error, which ranged in average from 0.58 (SD: 0.87) to 1.06 (SD: 2.38) mm for each case. The additions to the online web database (www.dir-lab.com) described in this work will broaden the applicability of the reference data, providing a freely available common dataset for targeted critical evaluation of DIR spatial accuracy performance in multiple clinical settings. Estimates of observer variance in feature localization suggest consistent spatial accuracy for all observers across both four-dimensional CT and COPDgene patient cohorts.},
  doi       = {10.1088/0031-9155/58/9/2861},
  keywords  = {Chronic Obstructive, Chronic Obstructive: genetics, Chronic Obstructive: radiograph, Computer-Assisted, Computer-Assisted: standards, Four-Dimensional Computed Tomography, Humans, Image Processing, Pulmonary Disease, Reference Standards},
  publisher = {IOP Publishing},
  url       = {http://stacks.iop.org/0031-9155/58/i=9/a=2861?key=crossref.f9b199ed3d56869d1d5900ad67330e7e},
}

@Article{campadelli2009liver,
  author    = {Campadelli, Paola and Casiraghi, Elena and Esposito, Andrea},
  title     = {Liver segmentation from computed tomography scans: A survey and a new algorithm},
  journal   = {Artificial Intelligence in Medicine},
  year      = {2009},
  volume    = {45},
  number    = {2},
  pages     = {185--196},
  issn      = {1873-2860 (Electronic){\textbackslash}r0933-3657 (Linking)},
  abstract  = {Objective: In the recent years liver segmentation from computed tomography scans has gained a lot of importance in the field of medical image processing since it is the first and fundamental step of any automated technique for the automatic liver disease diagnosis, liver volume measurement, and 3D liver volume rendering. Methods: In this paper we report a review study about the semi-automatic and automatic liver segmentation techniques, and we describe our fully automatized method. Results: The survey reveals that automatic liver segmentation is still an open problem since various weaknesses and drawbacks of the proposed works must still be addressed. Our gray-level based liver segmentation method has been developed to tackle all these problems; when tested on 40 patients it achieves satisfactory results, comparable to the mean intra- and inter-observer variation. Conclusions: We believe that our technique outperforms those presented in the literature; nevertheless, a common test set with its gold standard traced by experts, and a generally accepted performance measure are required to demonstrate it. © 2008 Elsevier B.V. All rights reserved.},
  doi       = {10.1016/j.artmed.2008.07.020},
  keywords  = {Automatic liver segmentation, Computed tomography images, Graph cut, Survey},
  publisher = {Elsevier},
}

@InProceedings{norajitra20153d,
  author       = {Norajitra, Tobias and Meinzer, Hans-Peter and Maier-Hein, Klaus H},
  title        = {{3D} statistical shape models incorporating {3D} random forest regression voting for robust {CT} liver segmentation},
  booktitle    = {SPIE Medical Imaging},
  year         = {2015},
  editor       = {Hadjiiski, Lubomir M. and Tourassi, Georgia D.},
  pages        = {941406--941406},
  month        = mar,
  organization = {International Society for Optics and Photonics},
  publisher    = {International Society for Optics and Photonics},
  doi          = {10.1117/12.2082909},
  keywords     = {Image segmentation, Liver},
  url          = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2082909},
}

@Article{donner2013global,
  author    = {Donner, Ren{\'e} and Menze, Bjoern H and Bischof, Horst and Langs, Georg},
  title     = {Global localization of {3D} anatomical structures by pre-filtered {Hough} forests and discrete optimization},
  journal   = {Medical Image Analysis},
  year      = {2013},
  volume    = {17},
  number    = {8},
  pages     = {1304--1314},
  abstract  = {The accurate localization of anatomical landmarks is a challenging task, often solved by domain specific approaches. We propose a method for the automatic localization of landmarks in complex, repetitive anatomical structures.The key idea is to combine three steps: (1) a classifier for pre-filtering anatomical landmark positions that (2) are refined through a Hough regression model, together with (3) a parts-based model of the global landmark topology to select the final landmark positions. During training landmarks are annotated in a set of example volumes. A classifier learns local landmark appearance, and Hough regressors are trained to aggregate neighborhood information to a precise landmark coordinate position. A non-parametric geometric model encodes the spatial relationships between the landmarks and derives a topology which connects mutually predictive landmarks. During the global search we classify all voxels in the query volume, and perform regression-based agglomeration of landmark probabilities to highly accurate and specific candidate points at potential landmark locations. We encode the candidates' weights together with the conformity of the connecting edges to the learnt geometric model in a Markov Random Field (MRF). By solving the corresponding discrete optimization problem, the most probable location for each model landmark is found in the query volume.We show that this approach is able to consistently localize the model landmarks despite the complex and repetitive character of the anatomical structures on three challenging data sets (hand radiographs, hand CTs, and whole body CTs), with a median localization error of 0.80. mm, 1.19. mm and 2.71. mm, respectively. © 2013 Elsevier B.V.},
  doi       = {10.1016/j.media.2013.02.004},
  keywords  = {Anatomical structure localization, Hough regression, Interest point detection, Random forests},
  publisher = {Elsevier},
}

@Article{heimann2009comparison,
  author    = {Heimann, Tobias and Van Ginneken, Bram and Styner, Martin A and Arzhaeva, Yulia and Aurich, Volker and Bauer, Christian and Beck, Andreas and Becker, Christoph and Beichel, Reinhard and Bekes, Gy{\"o}rgy and others},
  title     = {Comparison and evaluation of methods for liver segmentation from {CT} datasets},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2009},
  volume    = {28},
  number    = {8},
  pages     = {1251--1265},
  publisher = {IEEE},
}

@InProceedings{leifman2015leveraging,
  author       = {Leifman, George and Swedish, Tristan and Roesch, Karin and Raskar, Ramesh},
  title        = {Leveraging the crowd for annotation of retinal images},
  booktitle    = {International Conference of the Engineering in Medicine and Biology Society (EMBC)},
  year         = {2015},
  pages        = {7736--7739},
  month        = aug,
  organization = {IEEE},
  publisher    = {IEEE},
  doi          = {10.1109/EMBC.2015.7320185},
  isbn         = {978-1-4244-9271-8},
  keywords     = {biomedical optical imaging, crowd-sourced annotations, crowdsourcing, data validation procedure, Diabetes, eye, Labeling, large-scale datasets, medical data, Medical diagnostic imaging, medical image processing, medical images, noisy ground-truth data, nonconsistent input, retina, retinal image annotation, Retinopathy},
  url          = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7320185},
}

@Article{luu2015quantitative,
  author    = {Luu, Ha Manh and Klink, Camiel and Moelker, Adriaan and Niessen, Wiro and van Walsum, Theo},
  title     = {Quantitative evaluation of noise reduction and vesselness filters for liver vessel segmentation on abdominal {CTA} images},
  journal   = {Physics in Medicine and Biology},
  year      = {2015},
  volume    = {60},
  number    = {10},
  pages     = {3905},
  month     = may,
  doi       = {10.1088/0031-9155/60/10/3905},
  publisher = {IOP Publishing},
  url       = {http://stacks.iop.org/0031-9155/60/i=10/a=3905?key=crossref.a43a9b15a08120df9617f2905a28cc9e},
}

@InProceedings{conversano2014fully,
  author       = {Conversano, Francesco and Casciaro, Ernesto and Franchini, Rodrigo and Casciaro, Sergio and Lay-Ekuakille, Aime},
  title        = {Fully automatic {3D} segmentation measurements of human liver vessels from contrast-enhanced {CT}},
  booktitle    = {International Symposium on Medical Measurements and Applications},
  year         = {2014},
  pages        = {1--5},
  month        = jun,
  organization = {IEEE},
  publisher    = {IEEE},
  doi          = {10.1109/MeMeA.2014.6860120},
  isbn         = {978-1-4799-2921-4},
  keywords     = {2D vessel network reconstruction, 3D vessel network reconstruction, automatic extraction, automatic segmentation, automatic segmentation accuracy, biomedical image processing, Bland-Altman plots, blood vessels, CECT dataset, Computed tomography, computed tomography imaging, computerised tomography, contrast-enhanced computed tomography, contrast-enhanced CT, dice similarity coefficient, false negative ratio, false positive ratio, fully automatic 3D segmentation measurement, fully automatic algorithm, human liver vessel, image classification, image reconstruction, Image segmentation, intraoperative resection guidance, Liver, liver surgery, liver surgery planning, liver vessel network, liver vessel tree, Manuals, Medical diagnostic imaging, medical image processing, parameter configuration, Pearson correlation coefficients, phantom model, Phantoms, Sensitivity, single pixel classifications, Three-dimensional displays, vessel segmentation algorithm, volumetric reconstruction},
  url          = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6860120},
}

@Article{sauermann2015crowd,
  author    = {Sauermann, Henry and Franzoni, Chiara},
  title     = {Crowd science user contribution patterns and their implications},
  journal   = {Proceedings of the National Academy of Sciences},
  year      = {2015},
  volume    = {112},
  number    = {3},
  pages     = {679--684},
  month     = jan,
  doi       = {10.1073/pnas.1408907112},
  publisher = {National Acad Sciences},
  url       = {http://www.pnas.org/lookup/doi/10.1073/pnas.1408907112},
}

@Article{lesage2009review,
  author    = {Lesage, David and Angelini, Elsa D and Bloch, Isabelle and Funka-Lea, Gareth},
  title     = {A review of {3D} vessel lumen segmentation techniques: Models, features and extraction schemes},
  journal   = {Medical Image Analysis},
  year      = {2009},
  volume    = {13},
  number    = {6},
  pages     = {819--845},
  abstract  = {Vascular diseases are among the most important public health problems in developed countries. Given the size and complexity of modern angiographic acquisitions, segmentation is a key step toward the accurate visualization, diagnosis and quantification of vascular pathologies. Despite the tremendous amount of past and on-going dedicated research, vascular segmentation remains a challenging task. In this paper, we review state-of-the-art literature on vascular segmentation, with a particular focus on 3D contrast-enhanced imaging modalities (MRA and CTA). We structure our analysis along three axes: models, features and extraction schemes. We first detail model-based assumptions on the vessel appearance and geometry which can embedded in a segmentation approach. We then review the image features that can be extracted to evaluate these models. Finally, we discuss how existing extraction schemes combine model and feature information to perform the segmentation task. Each component (model, feature and extraction scheme) plays a crucial role toward the efficient, robust and accurate segmentation of vessels of interest. Along each axis of study, we discuss the theoretical and practical properties of recent approaches and highlight the most advanced and promising ones.},
  doi       = {10.1016/j.media.2009.07.011},
  publisher = {Elsevier},
}

@Article{levenson2015pigeons,
  author    = {Levenson, Richard M and Krupinski, Elizabeth A and Navarro, Victor M and Wasserman, Edward A},
  title     = {Pigeons {(Columba livia)} as Trainable Observers of Pathology and Radiology Breast Cancer Images},
  journal   = {PloS one},
  year      = {2015},
  volume    = {10},
  number    = {11},
  pages     = {e0141357},
  month     = nov,
  doi       = {10.1371/journal.pone.0141357},
  editor    = {Coles, Jonathan A},
  publisher = {Public Library of Science},
  url       = {http://dx.plos.org/10.1371/journal.pone.0141357},
}

@Article{marz2015toward,
  author    = {M{\"a}rz, K and Hafezi, M and Weller, T and Saffari, A and Nolden, M and Fard, N and Majlesara, A and Zelzer, S and Maleshkova, M and Volovyk, M and others},
  title     = {Toward knowledge-based liver surgery: holistic information processing for surgical decision support},
  journal   = {International Journal of Computer Assisted Radiology and Surgery},
  year      = {2015},
  volume    = {10},
  number    = {6},
  pages     = {749--759},
  month     = jun,
  doi       = {10.1007/s11548-015-1187-0},
  publisher = {Springer},
  url       = {http://link.springer.com/10.1007/s11548-015-1187-0},
}

@InProceedings{klein2010early,
  author       = {Klein, Stefan and Loog, Marco and van der Lijn, Fedde and den Heijer, Tom and Hammers, Alexander and de Bruijne, Marleen and others},
  title        = {Early diagnosis of dementia based on intersubject whole-brain dissimilarities},
  booktitle    = {International Symposium on Biomedical Imaging},
  year         = {2010},
  pages        = {249--252},
  organization = {IEEE},
  file         = {klein2010early.pdf:klein2010early.pdf:PDF},
}

@Article{xu2006mdct,
  author    = {Xu, Ye and Sonka, Milan and McLennan, Geoffrey and Guo, Junfeng and Hoffman, Eric and others},
  title     = {{MDCT-based 3-D texture classification of emphysema and early smoking related lung pathologies}},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2006},
  volume    = {25},
  number    = {4},
  pages     = {464--475},
  issn      = {0278-0062 (Print){\textbackslash}r0278-0062 (Linking)},
  abstract  = {Our goal is to enhance the ability to differentiate normal lung from subtle pathologies via multidetector row CT (MDCT) by extending a two-dimensional (2-D) texturebased tissue classification [adaptive multiple feature method (AMFM)] to use three-dimensional (3-D) texture features. We performed MDCT on 34 humans and classified volumes of interest (VOIs) in the MDCT images into five categories: EC, emphysema in severe chronic obstructive pulmonary disease (COPD); MC, mild emphysema in mild COPD; NC, normal appearing lung in mild COPD; NN, normal appearing lung in normal nonsmokers; and NS, normal appearing lung in normal smokers. COPD severity was based upon pulmonary function tests (PFTs). Airways and vessels were excluded from VOIs; 24 3-D texture features were calculated; and a Bayesian classifier was used for discrimination. A leave-one-out method was employed for validation. Sensitivity of the four-class classification in the form of 3-D/2-D was: EC: 85\%/71\%, MC: 90\%/82\%; NC: 88\%/50\%; NN: 100\%/60\%. Sensitivity and specificity for NN using a two-class classification of NN and NS in the form of 3-D/2-D were: 99\%/72\% and 100\%/75\%, respectively. We conclude that 3-D AMFM analysis of lung parenchyma improves discrimination compared to 2-D AMFM of the same VOIs. Furthermore, our results suggest that the 3-D AMFM may provide a means of discriminating subtle differences between smokers and nonsmokers both with normal PFTs.},
  doi       = {10.1109/TMI.2006.870889},
  keywords  = {Emphysema, Multidetector row computed tomography, Quantitative CT, texture analysis, Tissue classification.},
  publisher = {IEEE},
}

@Article{nguyen2012distributed,
  author    = {Nguyen, Tan B and Wang, Shijun and Anugu, Vishal and Rose, Natalie and McKenna, Matthew and Petrick, Nicholas and Burns, Joseph E and Summers, Ronald M},
  title     = {Distributed human intelligence for colonic polyp classification in computer-aided detection for {CT} colonography},
  journal   = {Radiology},
  year      = {2012},
  volume    = {262},
  number    = {3},
  pages     = {824--833},
  month     = mar,
  doi       = {10.1148/radiol.11110938},
  file      = {nguyen2012distributed.pdf:nguyen2012distributed.pdf:PDF},
  groups    = {Veni},
  publisher = {Radiological Society of North America, Inc.},
}

@Article{mitry2015crowdsourcing,
  author   = {Mitry, Danny and Peto, Tunde and Hayat, Shabina and Blows, Peter and Morgan, James and Khaw, Kay-Tee and Foster, Paul J},
  title    = {Crowdsourcing as a Screening Tool to Detect Clinical Features of Glaucomatous Optic Neuropathy from Digital Photography},
  journal  = {PloS one},
  year     = {2015},
  volume   = {10},
  number   = {2},
  pages    = {1--8},
  abstract = {Aim Crowdsourcing is the process of simplifying and outsourcing numerous tasks to many untrained individuals. Our aim was to assess the performance and repeatability of crowdsourcing in the classification of normal and glaucomatous discs from optic disc images. Methods Optic disc images (N = 127) with pre-determined disease status were selected by consensus agreement from grading experts from a large cohort study. After reading brief illustrative instructions, we requested that knowledge workers (KWs) from a crowdsourcing platform (Amazon MTurk) classified each image as normal or abnormal. Each image was classified 20 times by different KWs. Two study designs were examined to assess the effect of varying KW experience and both study designs were conducted twice for consistency. Performance was assessed by comparing the sensitivity, specificity and area under the receiver operating characteristic curve (AUC). Results Overall, 2,540 classifications were received in under 24 hours at minimal cost. The sensitivity ranged between 83?88\% across both trials and study designs, however the specificity was poor, ranging between 35?43\%. In trial 1, the highest AUC (95\%CI) was 0.64(0.62? 0.66) and in trial 2 it was 0.63(0.61?0.65). There were no significant differences between study design or trials conducted. Conclusions Crowdsourcing represents a cost-effective method of image analysis which demonstrates good repeatability and a high sensitivity. Optimisation of variables such as reward schemes, mode of image presentation, expanded response options and incorporation of training modules should be examined to determine their effect on the accuracy and reliability of this technique in retinal image analysis.},
  doi2     = {10.1371/journal.pone.0117401},
  editor   = {Merigan, William H.},
  file     = {mitry2015crowdsourcing.pdf:mitry2015crowdsourcing.pdf:PDF},
  groups   = {Veni},
  issn2    = {1932-6203 (Electronic){\textbackslash}r1932-6203 (Linking)},
}

@Article{franzoni2014crowd,
  author    = {Franzoni, Chiara and Sauermann, Henry},
  title     = {Crowd science: The organization of scientific research in open collaborative projects},
  journal   = {Research Policy},
  year      = {2014},
  volume    = {43},
  number    = {1},
  pages     = {1--20},
  issn      = {0048-7333},
  abstract  = {A growing amount of scientific research is done in an open collaborative fashion, in projects sometimes referred to as "crowd science", "citizen science", or "networked science". This paper seeks to gain a more systematic understanding of crowd science and to provide scholars with a conceptual framework and an agenda for future research. First, we briefly present three case examples that span different fields of science and illustrate the heterogeneity concerning what crowd science projects do and how they are organized. Second, we identify two fundamental elements that characterize crowd science projects - open participation and open sharing of intermediate inputs - and distinguish crowd science from other knowledge production regimes such as innovation contests or traditional "Mertonian" science. Third, we explore potential knowledge-related and motivational benefits that crowd science offers over alternative organizational modes, and potential challenges it is likely to face. Drawing on prior research on the organization of problem solving, we also consider for what kinds of tasks particular benefits or challenges are likely to be most pronounced. We conclude by outlining an agenda for future research and by discussing implications for funding agencies and policy makers. ?? 2013 Elsevier B.V. All rights reserved.},
  doi       = {10.1016/j.respol.2013.07.005},
  file      = {franzoni2014crowdscience.pdf:franzoni2014crowdscience.pdf:PDF},
  keywords  = {Citizen science, Community-based production, Crowd science, crowdsourcing, Funding, Open innovation, Problem solving},
  publisher = {Elsevier},
  url       = {http://dx.doi.org/10.1016/j.respol.2013.07.005},
}

@Article{lo2010vessel,
  author    = {Lo, Pechin and Sporring, Jon and Ashraf, Haseem and Pedersen, Jesper JH and de Bruijne, Marleen},
  title     = {Vessel-guided airway tree segmentation: A voxel classification approach},
  journal   = {Medical Image Analysis},
  year      = {2010},
  volume    = {14},
  number    = {4},
  pages     = {527--538},
  issn      = {1361-8423 (Electronic){\textbackslash}n1361-8415 (Linking)},
  doi       = {10.1016/j.media.2010.03.004},
  file      = {lo2010vessel.pdf:lo2010vessel.pdf:PDF},
  keywords  = {Airway segmentation, Appearance model, Blood vessel, Classification, Lung computed tomography},
  publisher = {Elsevier},
}

@Article{poggio2004general,
  author  = {Poggio, Tomaso and Rifkin, Ryan and Mukherjee, Sayan and Niyogi, Partha},
  title   = {General conditions for predictivity in learning theory},
  journal = {Nature},
  year    = {2004},
  volume  = {428},
  number  = {6981},
  pages   = {419--422},
}

@Article{xu2014weakly,
  author    = {Xu, Yan and Zhu, Jun-Yan and Chang, Eric I and Lai, Maode and Tu, Zhuowen},
  title     = {Weakly supervised histopathology cancer image segmentation and classification},
  journal   = {Medical Image Analysis},
  year      = {2014},
  volume    = {18},
  number    = {3},
  pages     = {591--604},
  abstract  = {Labeling a histopathology image as having cancerous regions or not is a critical task in cancer diagnosis; it is also clinically important to segment the cancer tissues and cluster them into various classes. Existing supervised approaches for image classification and segmentation require detailed manual annotations for the cancer pixels, which are time-consuming to obtain. In this paper, we propose a new learning method, multiple clustered instance learning (MCIL) (along the line of weakly supervised learning) for histopathology image segmentation. The proposed MCIL method simultaneously performs image-level classification (cancer vs. non-cancer image), medical image segmentation (cancer vs. non-cancer tissue), and patch-level clustering (different classes). We embed the clustering concept into the multiple instance learning (MIL) setting and derive a principled solution to performing the above three tasks in an integrated framework. In addition, we introduce contextual constraints as a prior for MCIL, which further reduces the ambiguity in MIL. Experimental results on histopathology colon cancer images and cytology images demonstrate the great advantage of MCIL over the competing methods.},
  doi2      = {10.1016/j.media.2014.01.010},
  groups    = {Not-so-supervised papers},
  keywords  = {Algorithms, Artificial Intelligence, Automated, Classification, Colonic Neoplasms, Computer-Assisted, Humans, Image Enhancement, Image Interpretation, methods, microscopy, Pathology, Pattern Recognition, Reproducibility of Results, Sensitivity and Specificity},
  language  = {eng},
  publisher = {Elsevier},
}

@InProceedings{ben2001stability,
  author    = {Ben-Hur, Asa and Elisseeff, Andre and Guyon, Isabelle},
  title     = {A stability based method for discovering structure in clustered data},
  booktitle = {Pacific Symposium on Biocomputing},
  year      = {2001},
  pages     = {6--17},
}

@Article{mozafari2014scaling,
  author    = {Mozafari, Barzan and Sarkar, Purna and Franklin, Michael and Jordan, Michael and Madden, Samuel},
  title     = {Scaling up crowd-sourcing to very large datasets: a case for active learning},
  journal   = {Proceedings of the VLDB Endowment},
  year      = {2014},
  volume    = {8},
  number    = {2},
  pages     = {125--136},
  month     = oct,
  doi       = {10.14778/2735471.2735474},
  publisher = {VLDB Endowment},
  url       = {http://dl.acm.org/citation.cfm?doid=2735471.2735474},
}

@Article{sun2012ecg,
  author    = {Sun, Li and Lu, Yanping and Yang, Kaitao and Li, Shaozi},
  title     = {{ECG} analysis using multiple instance learning for myocardial infarction detection},
  journal   = {IEEE Transactions on Biomedical Engineering},
  year      = {2012},
  volume    = {59},
  number    = {12},
  pages     = {3348--3356},
  month     = dec,
  issn      = {2011012111200},
  abstract  = {This paper presents a useful technique for totally automatic detection of myocardial infarction from patients' ECGs. Due to the large number of heartbeats constituting an ECG and the high cost of having all the heartbeats manually labeled, supervised learning techniques have achieved limited success in ECG classification. In this paper, we first discuss the rationale for applying multiple instance learning (MIL) to automated ECG classification and then propose a new MIL strategy called latent topic MIL, by which ECGs are mapped into a topic space defined by a number of topics identified over all the unlabeled training heartbeats and support vector machine is directly applied to the ECG-level topic vectors. Our experimental results on real ECG datasets from the PTB diagnostic database demonstrate that, compared with existing MIL and supervised learning algorithms, the proposed algorithm is able to automatically detect ECGs with myocardial ischemia without labeling any heartbeats. Moreover, it improves classification quality in terms of both sensitivity and specificity.},
  doi       = {10.1109/TBME.2012.2213597},
  keywords  = {Classification, ECG analysis, multiple instance learning (MIL), myocardial infarction (MI)},
  publisher = {IEEE},
  url       = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6280632},
}

@Article{dundar2007multiple,
  author    = {Dundar, M Murat and Fung, Glenn and Krishnapuram, Balaji and Rao, R Bharat},
  title     = {Multiple-instance learning algorithms for computer-aided detection},
  journal   = {IEEE Transactions on Biomedical Engineering},
  year      = {2007},
  volume    = {55},
  number    = {3},
  pages     = {1015--1021},
  abstract  = {Many computer-aided diagnosis (\{CAD\}) problems can be best modelled as a multiple-instance learning (\{MIL\}) problem with unbalanced data, i.e., the training data typically consists of a few positive bags, and a very large number of negative instances. Existing \{MIL\} algorithms are much too computationally expensive for these datasets. We describe \{CH\}, a framework for learning a convex hull representation of multiple instances that is significantly faster than existing \{MIL\} algorithms. Our \{CH\} framework applies to any standard hyperplane-based learning algorithm, and for some algorithms, is guaranteed to find the global optimal solution. Experimental studies on two different \{CAD\} applications further demonstrate that the proposed algorithm significantly improves diagnostic accuracy when compared to both \{MIL\} and traditional classifiers. Although not designed for standard \{MIL\} problems (which have both positive and negative bags and relatively balanced datasets), comparisons against other \{MIL\} methods on benchmark problems also indicate that the proposed method is competitive with the state-of-the-art.},
  doi2      = {10.1109/TBME.2007.909544},
  groups    = {Not-so-supervised papers},
  issn2     = {0018-9294 (Print){\textbackslash}n0018-9294 (Linking)},
  keywords  = {Alternate optimization, Convex hull, Fisher discriminant, Multiple-instance learning (MIL)},
  publisher = {IEEE},
  url2      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4360150},
}

@InProceedings{bi2007multiple,
  author    = {Bi, Jinbo and Liang, Jianming},
  title     = {Multiple instance learning of pulmonary embolism detection with geodesic distance along vascular structure},
  booktitle = {Computer Vision and Pattern Recognition (CVPR)},
  year      = {2007},
  pages     = {1--8},
  month     = jun,
  publisher = {IEEE},
  doi2      = {10.1109/CVPR.2007.383141},
  file      = {bi2007multiple.pdf:bi2007multiple.pdf:PDF},
  groups    = {Not-so-supervised papers},
  isbn2     = {1-4244-1179-3},
  keywords  = {Biomedical imaging, biomedical MRI, Bismuth, classification approach, Classification tree analysis, Clustering algorithms, computed-tomography-angiography image, computerised tomography, diseases, geodesic distance, Geophysics computing, Hemorrhaging, image classification, Image segmentation, learning (artificial intelligence), lung, Lungs, Medical diagnostic imaging, medical image processing, Medical treatment, multiple instance learning, object detection, pulmonary embolism detection, vascular structure, vascular tree},
  url2      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4270166},
}

@Article{aggarwal2001surprising,
  author    = {Aggarwal, C. and Hinneburg, A. and Keim, D.},
  title     = {On the surprising behavior of distance metrics in high dimensional space},
  journal   = {International Conference on Database Theory},
  year      = {2001},
  pages     = {420--434},
  issn      = {978-3-540-41456-8},
  abstract  = {In recent years, the effect of the curse of high dimensionality has been studied in great detail on several problems such as clustering, nearest neighbor search, and indexing. In high dimensional space the data becomes sparse, and traditional indexing and algorithmic techniques fail from a effciency and/or effectiveness perspective. Recent research results show that in high dimensional space, the concept of proximity, distance or nearest neighbor may not even be qualitatively meaningful. In this paper, we view the dimensionality curse from the point of view of the distance metrics which are used to measure the similarity between objects. We specifically examine the behavior of the commonly used L k norm and show that the problem of meaningfulness in high dimensionality is sensitive to the value of k. For example, this means that the Manhattan distance metric L(1 norm) is consistently more preferable than the Euclidean distance metric L(2 norm) for high dimensional data mining applications. Using the intuition derived from our analysis, we introduce and examine a natural extension of the L k norm to fractional distance metrics. We show that the fractional distance metric provides more meaningful results both from the theoretical and empirical perspective. The results show that fractional distance metrics can significantly improve the effectiveness of standard clustering algorithms such as the k-means algorithm.},
  doi       = {10.1007/3-540-44503-X_27},
  publisher = {Springer},
  url       = {http://link.springer.com/10.1007/3-540-44503-X_27},
}

@Article{amores2013multiple,
  author    = {Amores, Jaume},
  title     = {Multiple instance classification: Review, taxonomy and comparative study},
  journal   = {Artificial Intelligence},
  year      = {2013},
  volume    = {201},
  pages     = {81--105},
  abstract  = {Multiple Instance Learning (MIL) has become an important topic in the pattern recognition community, and many solutions to this problem have been proposed until now. Despite this fact, there is a lack of comparative studies that shed light into the characteristics and behavior of the different methods. In this work we provide such an analysis focused on the classification task (i.e., leaving out other learning tasks such as regression). In order to perform our study, we implemented fourteen methods grouped into three different families. We analyze the performance of the approaches across a variety of well-known databases, and we also study their behavior in synthetic scenarios in order to highlight their characteristics. As a result of this analysis, we conclude that methods that extract global bag-level information show a clearly superior performance in general. In this sense, the analysis permits us to understand why some types of methods are more successful than others, and it permits us to establish guidelines in the design of new MIL methods.},
  doi2      = {10.1016/j.artint.2013.06.003},
  file      = {amores2013multiple.pdf:amores2013multiple.pdf:PDF},
  groups    = {Not-so-supervised general, Veni},
  publisher = {Elsevier},
}

@InProceedings{andrews2002support,
  author    = {Andrews, S. and Tsochantaridis, I. and Hofmann, T.},
  title     = {Support vector machines for multiple-instance learning},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2002},
  pages     = {561--568},
}

@Article{balcan2008theory,
  author    = {Balcan, Maria-Florina and Blum, Avrim and Srebro, Nathan},
  title     = {A theory of learning with similarity functions},
  journal   = {Machine Learning},
  year      = {2008},
  volume    = {72},
  number    = {1-2},
  pages     = {89--112},
  month     = aug,
  doi       = {10.1007/s10994-008-5059-5},
  publisher = {Springer},
  url       = {http://link.springer.com/10.1007/s10994-008-5059-5},
}

@Article{borgwardt2005protein,
  author    = {Borgwardt, K. M. and Ong, C. S. and Sch\"{o}nauer, S. and Vishwanathan, S. V. N. and Smola, A. J. and Kriegel, H. P.},
  title     = {{Protein Function Prediction via Graph Kernels}},
  journal   = {Bioinformatics},
  year      = {2005},
  volume    = {21},
  pages     = {i47--i56},
  file      = {borgwardt2005protein.pdf:borgwardt2005protein.pdf:PDF},
  publisher = {Oxford Univ Press},
}

@InProceedings{briggs2012rank,
  author       = {Briggs, F. and Fern, X. Z. and Raich, R.},
  title        = {Rank-loss support instance machines for {MIML} instance annotation},
  booktitle    = {International Conference on Knowledge Discovery and Data Mining},
  year         = {2012},
  pages        = {534--542},
  organization = {ACM},
}

@Article{casey2008analysis,
  author    = {Casey, M. and Rhodes, C. and Slaney, M.},
  title     = {Analysis of minimum distances in high-dimensional musical spaces},
  journal   = {Audio, Speech, and Language Processing},
  year      = {2008},
  volume    = {16},
  number    = {5},
  pages     = {1015--1028},
  month     = jul,
  abstract  = {We propose an automatic method for measuring content-based music similarity, enhancing the current generation of music search engines and recommended systems. Many previous approaches to track similarity require brute-force, pair-wise processing between all audio features in a database and therefore are not practical for large collections. However, in an Internet-connected world, where users have access to millions of musical tracks, efficiency is crucial. Our approach uses features extracted from unlabeled audio data and near-neigbor retrieval using a distance threshold, determined by analysis, to solve a range of retrieval tasks. The tasks require temporal features-analogous to the technique of shingling used for text retrieval. To measure similarity, we count pairs of audio shingles, between a query and target track, that are below a distance threshold. The distribution of between-shingle distances is different for each database; therefore, we present an analysis of the distribution of minimum distances between shingles and a method for estimating a distance threshold for optimal retrieval performance. The method is compatible with locality-sensitive hashing (LSH)-allowing implementation with retrieval times several orders of magnitude faster than those using exhaustive distance computations. We evaluate the performance of our proposed method on three contrasting music similarity tasks: retrieval of mis-attributed recordings (fingerprint), retrieval of the same work performed by different artists (cover songs), and retrieval of edited and sampled versions of a query track by remix artists (remixes). Our method achieves near-perfect performance in the first two tasks and 75\% precision at 70\% recall in the third task. Each task was performed on a test database comprising 4.5 million audio shingles.},
  doi       = {10.1109/TASL.2008.925883},
  file      = {casey2008analysis.pdf:casey2008analysis.pdf:PDF},
  keywords  = {Audio shingles, Distance distributions, Locality-sensitive hashing, Matched-filter distance, Music similarity},
  publisher = {IEEE},
  url       = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4544816},
}

@Article{hara2017data,
  author  = {Hara, Kotaro and Adams, Abi and Milland, Kristy and Savage, Saiph and Callison-Burch, Chris and Bigham, Jeffrey},
  title   = {A Data-Driven Analysis of Workers' Earnings on {Amazon Mechanical Turk}},
  journal = {arXiv preprint arXiv:1712.05796},
  year    = {2017},
}

@InProceedings{de2004locally,
  author       = {De Wachter, M. and Demuynck, K. and Wambacq, P. and Van Compernolle, D.},
  title        = {A locally weighted distance measure for example based speech recognition},
  booktitle    = {International Conference on Acoustics, Speech, and Signal Processing},
  year         = {2004},
  volume       = {1},
  pages        = {I--181},
  organization = {IEEE},
}

@Book{devijver1982pattern,
  title     = {Pattern Recognition: a Statistical Approach},
  publisher = {London: Prentice-Hall},
  year      = {1982},
  author    = {P. A. Devijver and J. Kittler},
}

@Article{domingo2001quantitative,
  author    = {Domingo-Ferrer, Josep and Torra, Vicenc},
  title     = {A quantitative comparison of disclosure control methods for microdata},
  journal   = {Confidentiality, Disclosure and Data Access: Theory and Practical Applications for Statistical Agencies},
  year      = {2001},
  pages     = {111--134},
  publisher = {Amsterdam, Netherlands: North-Holland},
}

@Article{eiter1997distance,
  author    = {Eiter, T. and Mannila, H.},
  title     = {Distance measures for point sets and their computation},
  journal   = {Acta Informatica},
  year      = {1997},
  volume    = {34},
  number    = {2},
  pages     = {109--133},
  month     = feb,
  abstract  = {We consider the problem of measuring the similarity or distance between two finite sets of points in a metric space, and computing the measure. This problem has applications in, e.g., computational geometry, philosophy of science, updating or changing theories, and machine learning. We review some of the distance functions proposed in the literature, among them the minimum distance link measure, the surjec-tion measure, and the fair surjection measure, and supply polynomial time algorithms for the computation of these measures. Furthermore, we introduce the minimum link measure, a new distance function which is more appealing than the other distance functions mentioned. We also present a polynomial time algorithm for computing this new measure. We further address the issue of defining a metric on point sets. We present the metric infimum method that constructs a metric from any distance functions on point sets. In particular, the metric infimum of the minimum link measure is a quite intuitive. The computation of this measure is shown to be in NP for a broad class of instances; it is NP-hard for a natural problem class.},
  doi       = {10.1007/s002360050075},
  file      = {eiter1997distance.pdf:eiter1997distance.pdf:PDF},
  publisher = {Springer},
  url       = {http://link.springer.com/10.1007/s002360050075},
}

@InProceedings{foggia2010early,
  author    = {Foggia, P. and Percannella, G. and Soda, P. and Vento, M.},
  title     = {Early experiences in mitotic cells recognition on HEp-2 slides},
  booktitle = {Computer-Based Medical Systems},
  year      = {2010},
  pages     = {38 -43},
  month     = {oct.},
}

@InProceedings{foulds2008revisiting,
  author    = {Foulds, James and Frank, Eibe},
  title     = {Revisiting multiple-instance learning via embedded instance selection},
  booktitle = {Advances in Artificial Intelligence},
  year      = {2008},
  volume    = {5360 LNAI},
  pages     = {300--310},
  publisher = {Springer},
  abstract  = {Multiple-instance problems arise from the situations where training class labels are attached to sets of samples (named bags), instead of individual samples within each bag (called instances). Most previous multiple-instance learning (MIL) algorithms are developed based on the assumption that a bag is positive if and only if at least one of its instances is positive. Although the assumption works well in a drug activity prediction problem, it is rather restrictive for other applications, especially those in the computer vision area. We propose a learning method, MILES (Multiple-Instance Learning via Embedded instance Selection), which converts the multiple-instance learning problem to a standard supervised learning problem that does not impose the assumption relating instance labels to bag labels. MILES maps each bag into a feature space defined by the instances in the training bags via an instance similarity measure. This feature mapping often provides a large number of redundant or irrelevant features. Hence, 1-norm SVM is applied to select important features as well as construct classifiers simultaneously. We have performed extensive experiments. In comparison with other methods, MILES demonstrates competitive classification accuracy, high computation efficiency, and robustness to labeling uncertainty.},
  doi       = {10.1007/978-3-540-89378-3_29},
  isbn      = {3-540-89377-6},
  url       = {http://link.springer.com/10.1007/978-3-540-89378-3_29},
}

@Article{fu2012implementation,
  author    = {Fu, Gang and Nan, Xiaofei and Liu, Haining and Patel, Ronak and Daga, Pankaj and Chen, Yixin and Wilkins, Dawn and Doerksen, Robert},
  title     = {Implementation of multiple-instance learning in drug activity prediction},
  journal   = {BMC Bioinformatics},
  year      = {2012},
  volume    = {13},
  number    = {Suppl 15},
  pages     = {S3},
  abstract  = {In the context of drug discovery and development, much effort has been exerted to determine which conformers of a given molecule are responsible for the observed biological activity. In this work we aimed to predict bioactive conformers using a variant of supervised learning, named multiple-instance learning. A single molecule, treated as a bag of conformers, is biologically active if and only if at least one of its conformers, treated as an instance, is responsible for the observed bioactivity; and a molecule is inactive if none of its conformers is responsible for the observed bioactivity. The implementation requires instance-based embedding, and joint feature selection and classification. The goal of the present project is to implement multiple-instance learning in drug activity prediction, and subsequently to identify the bioactive conformers for each molecule. We encoded the 3-dimensional structures using pharmacophore fingerprints which are binary strings, and accomplished instance-based embedding using calculated dissimilarity distances. Four dissimilarity measures were employed and their performances were compared. 1-norm SVM was used for joint feature selection and classification. The approach was applied to four data sets, and the best proposed model for each data set was determined by using the dissimilarity measure yielding the smallest number of selected features. The predictive abilities of the proposed approach were compared with three classical predictive models without instance-based embedding. The proposed approach produced the best predictive models for one data set and second best predictive models for the rest of the data sets, based on the external validations. To validate the ability of the proposed approach to find bioactive conformers, 12 small molecules with co-crystallized structures were seeded in one data set. 10 out of 12 co-crystallized structures were indeed identified as significant conformers using the proposed approach. The proposed approach was proven not to suffer from overfitting and to be highly competitive with classical predictive models, so it is very powerful for drug activity prediction. The approach was also validated as a useful method for pursuit of bioactive conformers.},
  doi       = {10.1186/1471-2105-13-S15-S3},
  keywords  = {Algorithms, Bioinformatics, Combinatorial Libraries, Computational Biology/Bioinformatics, Computer Appl. in Life Sciences, Microarrays},
  publisher = {BioMed Central Ltd},
  url       = {http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-13-S15-S3},
}

@Article{fu2010milis,
  author    = {Fu, Z. and Robles-Kelly, A. and Zhou, J.},
  title     = {MILIS: Multiple instance learning with instance selection},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year      = {2010},
  volume    = {33},
  number    = {99},
  pages     = {1--1},
  month     = may,
  issn      = {0162-8828 VO - 33},
  abstract  = {Multiple instance learning (MIL) is a paradigm in supervised learning that deals with the classification of collections of instances called bags. Each bag contains a number of instances from which features are extracted. The complexity of MIL is largely dependent on the number of instances in the training data set. Since we are usually confronted with a large instance space even for moderately sized real-world data sets applications, it is important to design efficient instance selection techniques to speed up the training process without compromising the performance. In this paper, we address the issue of instance selection in MIL. We propose MILIS, a novel MIL algorithm based on adaptive instance selection. We do this in an alternating optimization framework by intertwining the steps of instance selection and classifier learning in an iterative manner which is guaranteed to converge. Initial instance selection is achieved by a simple yet effective kernel density estimator on the negative instances. Experimental results demonstrate the utility and efficiency of the proposed approach as compared to the state of the art.},
  doi       = {10.1109/TPAMI.2010.155},
  keywords  = {alternating optimization, feature selection, multiple instance learning, Support Vector Machine},
  publisher = {IEEE},
  url       = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5557878},
}

@InProceedings{fung2007multiple,
  author    = {Fung, Glenn and Dundar, Murat and Krishnapuram, Balaji and Rao, R Bharat},
  title     = {Multiple instance learning for computer aided diagnosis},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2007},
  volume    = {19},
  pages     = {425},
  file      = {fung2007multiple.pdf:fung2007multiple.pdf:PDF},
}

@Article{gumbel1958statistics,
  author    = {Gumbel, E. J.},
  title     = {Statistics of extremes},
  year      = {1958},
  publisher = {Columbia University Press (New York)},
}

@InCollection{hullermeier2005learning,
  author    = {H{\"u}llermeier, Eyke and Beringer, J{\"u}rgen},
  title     = {Learning from ambiguously labeled examples},
  booktitle = {Advances in Intelligent Data Analysis},
  publisher = {Springer},
  year      = {2005},
  pages     = {168--179},
}

@Conference{Harris,
  author    = {C. Harris and M. Stephens},
  title     = {A Combined Corner and Edge Detector},
  booktitle = {Proceedings of the 4th Alvey Vision Conference},
  year      = {1988},
  pages     = {147-151},
}

@Article{hoffmann2010new,
  author    = {Hoffmann, Brice and Zaslavskiy, Mikhail and Vert, Jean-Philippe and Stoven, V{\'e}ronique},
  title     = {A new protein binding pocket similarity measure based on comparison of clouds of atoms in 3D: application to ligand prediction},
  journal   = {BMC Bioinformatics},
  year      = {2010},
  volume    = {11},
  number    = {1},
  pages     = {99},
  abstract  = {Predicting which molecules can bind to a given binding site of a protein with known 3D structure is important to decipher the protein function, and useful in drug design. A classical assumption in structural biology is that proteins with similar 3D structures have related molecular functions, and therefore may bind similar ligands. However, proteins that do not display any overall sequence or structure similarity may also bind similar ligands if they contain similar binding sites. Quantitatively assessing the similarity between binding sites may therefore be useful to propose new ligands for a given pocket, based on those known for similar pockets. We propose a new method to quantify the similarity between binding pockets, and explore its relevance for ligand prediction. We represent each pocket by a cloud of atoms, and assess the similarity between two pockets by aligning their atoms in the 3D space and comparing the resulting configurations with a convolution kernel. Pocket alignment and comparison is possible even when the corresponding proteins share no sequence or overall structure similarities. In order to predict ligands for a given target pocket, we compare it to an ensemble of pockets with known ligands to identify the most similar pockets. We discuss two criteria to evaluate the performance of a binding pocket similarity measure in the context of ligand prediction, namely, area under ROC curve (AUC scores) and classification based scores. We show that the latter is better suited to evaluate the methods with respect to ligand prediction, and demonstrate the relevance of our new binding site similarity compared to existing similarity measures. This study demonstrates the relevance of the proposed method to identify ligands binding to known binding pockets. We also provide a new benchmark for future work in this field. The new method and the benchmark are available at 
http://cbio.ensmp.fr/paris/

.},
  doi       = {10.1186/1471-2105-11-99},
  keywords  = {Algorithms, Bioinformatics, Combinatorial Libraries, Computational Biology/Bioinformatics, Computer Appl. in Life Sciences, Microarrays},
  publisher = {BioMed Central Ltd},
  url       = {http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-11-99},
}

@Article{jacobs2000classification,
  author    = {Jacobs, David W and Weinshall, Daphna and Gdalyahu, Yoram},
  title     = {Classification with nonmetric distances: Image retrieval and class representation},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year      = {2000},
  volume    = {22},
  number    = {6},
  pages     = {583--600},
  month     = jun,
  abstract  = {A key problem in appearance-based vision is understanding how to use a set of labeled images to classify new images. Systems that model human performance, or that use robust image matching methods, often use nonmetric similarity judgments; but when the triangle inequality is not obeyed, most pattern recognition techniques are not applicable. Exemplar-based (nearest-neighbor) methods can be applied to a wide class of nonmetric similarity functions. The key issue, however, is to find methods for choosing good representatives of a class that accurately characterize it. We show that existing condensing techniques are ill-suited to deal with nonmetric dataspaces. We develop techniques for solving this problem, emphasizing two points: First, we show that the distance between images is not a good measure of how well one image can represent another in nonmetric spaces. Instead, we use the vector correlation between the distances from each image to other previously seen images. Second, we show that in nonmetric spaces, boundary points are less significant for capturing the structure of a class than in Euclidean spaces. We suggest that atypical points may be more important in describing classes. We demonstrate the importance of these ideas to learning that generalizes from experience by improving performance. We also suggest ways of applying parametric techniques to supervised learning problems that involve a specific nonmetric distance functions, showing how to generalize the idea of linear discriminant functions in a way that may be more useful in nonmetric spaces},
  doi       = {10.1109/34.862197},
  keywords  = {appearance-based vision, atypical points, boundary points, class representation, Computer Society, correlation methods, exemplar-based methods, Extraterrestrial measurements, Humans, image classification, Image matching, image representation, Image retrieval, Information retrieval, Jacobian matrices, learning by example, nearest-neighbor methods, nonmetric dataspaces, nonmetric distances, nonmetric similarity functions, nonmetric similarity judgments, Pattern Recognition, robust image matching methods, Robustness, Supervised learning, triangle inequality, vector correlation},
  publisher = {IEEE},
  url       = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=862197},
}

@InProceedings{jie2010learning,
  author    = {Jie, Luo and Orabona, Francesco},
  title     = {Learning from candidate labeling sets},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2010},
  volume    = {10},
  file      = {jie2010learning.pdf:jie2010learning.pdf:PDF},
}

@InCollection{kalkan2012automated,
  author    = {Kalkan, Habil and Nap, Marius and Duin, Robert P W and Loog, Marco},
  title     = {Automated Colorectal Cancer Diagnosis for Whole-Slice Histopathology},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention},
  publisher = {Springer},
  year      = {2012},
  pages     = {550--557},
  note      = {DOI: 10.1007/978-3-642-33454-2\_68},
  url       = {http://link.springer.com/10.1007/978-3-642-33454-2_68},
}

@Article{kandel2007applied,
  author  = {A. Kandel and H. Bunke and M. Last},
  title   = {Applied Graph Theory in Computer Vision and Pattern Recognition},
  journal = {Studies in Computational Intelligence},
  year    = {2007},
  volume  = {52},
}

@InProceedings{kondor2003kernel,
  author    = {Kondor, Risi I and Jebara, Tony},
  title     = {A kernel between sets of vectors},
  booktitle = {International Conference on Machine Learning},
  year      = {2003},
  volume    = {20},
  pages     = {361},
}

@Conference{kondor2002diffusion,
  author       = {Kondor, R. I. and Lafferty, J.},
  title        = {{Diffusion Kernels on Graphs and Other Discrete Input Spaces}},
  booktitle    = {International Conference on Machine Learning},
  year         = {2002},
  pages        = {315--322},
  organization = {Citeseer},
}

@Article{kuncheva2010full,
  author    = {Kuncheva, L. I.},
  title     = {Full-class set classification using the Hungarian algorithm},
  journal   = {International Journal of Machine Learning and Cybernetics},
  year      = {2010},
  volume    = {1},
  number    = {1},
  pages     = {53--61},
  month     = dec,
  doi       = {10.1007/s13042-010-0002-z},
  file      = {kuncheva2010full.pdf:kuncheva2010full.pdf:PDF},
  publisher = {Springer},
  url       = {http://link.springer.com/10.1007/s13042-010-0002-z},
}

@Conference{lee2008inexact,
  author    = {W.-J. Lee and R. P. W. Duin},
  title     = {An Inexact Graph Comparison Approach in Joint Eigenspace},
  booktitle = {Structural, Syntactic, and Statistical Pattern Recognition},
  year      = {2008},
  pages     = {35-44},
}

@InCollection{leistner2010miforests,
  author    = {Leistner, Christian and Saffari, Amir and Bischof, Horst},
  title     = {{MIForests:} Multiple-instance learning with randomized trees},
  booktitle = {European Conference on Computer Vision},
  publisher = {Springer},
  year      = {2010},
  pages     = {29--42},
  note      = {DOI: 10.1007/978-3-642-15567-3\_3},
  file      = {leistner2010miforests.pdf:leistner2010miforests.pdf:PDF},
  url       = {http://link.springer.com/10.1007/978-3-642-15567-3_3},
}

@Article{lindorff2009similarity,
  author    = {Lindorff-Larsen, Kresten and Ferkinghoff-Borg, Jesper},
  title     = {Similarity measures for protein ensembles},
  journal   = {PloS One},
  year      = {2009},
  volume    = {4},
  number    = {1},
  pages     = {e4203},
  publisher = {Public Library of Science},
}

@InProceedings{loog2004static,
  author    = {Loog, M. and van Ginneken, B.},
  title     = {Static posterior probability fusion for signal detection: applications in the detection of interstitial diseases in chest radiographs},
  booktitle = {International Conference on Pattern Recognition},
  year      = {2004},
  volume    = {1},
  pages     = {644--647},
}

@Article{muller2012multi,
  author    = {M{\"u}ller, A. and Behnke, S.},
  title     = {Multi-instance Methods for Partially Supervised Image Segmentation},
  journal   = {Partially Supervised Learning},
  year      = {2012},
  pages     = {110--119},
  publisher = {Springer},
}

@InProceedings{mandel2008multiple,
  author    = {Mandel, M. and Ellis, D. P. W.},
  title     = {Multiple-instance learning for music information retrieval},
  booktitle = {International Society for Music Information Retrieval},
  year      = {2008},
  pages     = {577--582},
  file      = {mandel2008multiple.pdf:mandel2008multiple.pdf:PDF},
}

@InProceedings{mcdowell2007cautious,
  author    = {McDowell, L. K. and Gupta, K. M. and Aha, D. W.},
  title     = {Cautious inference in collective classification},
  booktitle = {National Conference on Artificial Intelligence},
  year      = {2007},
  volume    = {7},
  pages     = {596--601},
}

@InProceedings{mendoza2012emphysema,
  author    = {Mendoza, Carlos S and Washko, George R and Ross, James C and Diaz, A A and Lynch, David A and Crapo, James D and Silverman, Edward K and Acha, Bego{\~n}a and Serrano, Carmen and Estepar, Ra{\'u}l San Jos{\'e}},
  title     = {Emphysema quantification in a multi-scanner {HRCT} cohort using local intensity distributions},
  booktitle = {International Symposium on Biomedical Imaging},
  year      = {2012},
  pages     = {474--477},
  file      = {mendoza2012emphysema.pdf:mendoza2012emphysema.pdf:PDF},
}

@InProceedings{musicant2007supervised,
  author       = {Musicant, D. R. and Christensen, J. M. and Olson, J. F.},
  title        = {Supervised learning by training on aggregate outputs},
  booktitle    = {International Conference on Data Mining},
  year         = {2007},
  pages        = {252--261},
  month        = oct,
  organization = {IEEE},
  publisher    = {IEEE},
  abstract     = {Supervised learning is a classic data mining problem where one wishes to be be able to predict an output value associated with a particular input vector. We present a new twist on this classic problem where, instead of having the training set contain an individual output value for each input vector, the output values in the training set are only given in aggregate over a number of input vectors. This new problem arose from a particular need in learning on mass spectrometry data, but could easily apply to situations when data has been aggregated in order to maintain privacy. We provide a formal description of this new problem for both classification and regression. We then examine how k-nearest neighbor, neural networks, and support vector machines can be adapted for this problem.},
  doi          = {10.1109/ICDM.2007.50},
  file         = {musicant2007supervised.pdf:musicant2007supervised.pdf:PDF},
  isbn         = {0-7695-3018-4},
  keywords     = {Aerosols, Aggregates, Computer science, Data mining, data mining problem, Data privacy, Educational institutions, formal description, input vector, k-nearest neighbor, learning (artificial intelligence), mass spectrometry data, Mass spectroscopy, neural nets, Neural networks, Scanning probe microscopy, Supervised learning, Support vector machines, training set},
  url          = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4470249},
}

@InProceedings{ning2008set,
  author       = {Ning, X. and Karypis, G.},
  title        = {The set classification problem and solution methods},
  booktitle    = {IEEE International Conference on Data Mining Workshops},
  year         = {2008},
  pages        = {720--729},
  month        = dec,
  organization = {IEEE},
  publisher    = {IEEE},
  doi          = {10.1109/ICDMW.2008.113},
  keywords     = {Cities and towns, Classification algorithms, Computer science, Conferences, Data engineering, Data mining, Drugs, Face recognition, learning (artificial intelligence), pattern classification, performance gain, Predictive models, Proteins, set classification problem, set theory, solution methods},
  url          = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4733998},
}

@Article{pkekalska2006prototype,
  author    = {P{\k{e}}kalska, El{\.z}bieta and Duin, Robert P W and Pacl{\'\i}k, Pavel},
  title     = {Prototype selection for dissimilarity-based classifiers},
  journal   = {Pattern Recognition},
  year      = {2006},
  volume    = {39},
  number    = {2},
  pages     = {189--208},
  publisher = {Elsevier},
}

@InCollection{pkekalska2002discussion,
  author    = {P{\k{e}}kalska, El{\.z}bieta and Duin, Robert P W and Skurichina, Marina},
  title     = {A discussion on the classifier projection space for classifier combining},
  booktitle = {Multiple Classifier Systems},
  publisher = {Springer},
  year      = {2002},
  pages     = {137--148},
}

@Article{pedersen2009danish,
  author    = {Pedersen, Jesper H and Ashraf, Haseem and Dirksen, Asger and Bach, Karen and Hansen, Hanne and Toennesen, Phillip and Thorsen, Hanne and Brodersen, John and Skov, Birgit Guldhammer and D{\o}ssing, Martin and others},
  title     = {The {Danish} randomized lung cancer {CT} screening trial-overall design and results of the prevalence round},
  journal   = {Journal of Thoracic Oncology},
  year      = {2009},
  volume    = {4},
  number    = {5},
  pages     = {608--614},
  issn      = {1556-1380},
  abstract  = {INTRODUCTION: Lung cancer screening with low dose computed tomography (CT) has not yet been evaluated in randomized clinical trials, although several are underway. METHODS: In The Danish Lung Cancer Screening Trial, 4104 smokers and previous smokers from 2004 to 2006 were randomized to either screening with annual low dose CT scans for 5 years or no screening. A history of cigarette smoking of at least 20 pack years was required. All participants have annual lung function tests, and questionnaires regarding health status, psychosocial consequences of screening, smoking habits, and smoking cessation. Baseline CT scans were performed in 2052 participants. Pulmonary nodules were classified according to size and morphology: (1) Nodules smaller than 5 mm and calcified (benign) nodules were tabulated, (2) Noncalcified nodules between 5 and 15 mm were rescanned after 3 months. If the nodule increased in size or was larger than 15 mm the participant was referred for diagnostic workup. RESULTS: At baseline 179 persons showed noncalcified nodules larger than 5 mm, and most were rescanned after 3 months: The rate of false-positive diagnoses was 7.9\%, and 17 individuals (0.8\%) turned out to have lung cancer. Ten of these had stage I disease. Eleven of 17 lung cancers at baseline were treated surgically, eight of these by video assisted thoracic surgery resection. CONCLUSIONS: Screening may facilitate minimal invasive treatment and can be performed with a relatively low rate of false-positive screen results compared with previous studies on lung cancer screening.},
  doi       = {10.1097/JTO.0b013e3181a0d98f},
  file      = {pedersen2009danish.pdf:pedersen2009danish.pdf:PDF},
  keywords  = {4, 608, 614, 2009, Computed tomography, ct, department of thoracic surgery, j thorac oncol, lung cancer, randomized clinical trial, rigshospitalet, rt, screening, university of copen-},
  publisher = {LWW},
}

@InProceedings{rahmani2005localized,
  author       = {Rahmani, R. and Goldman, S. A. and Zhang, H. and Krettek, J. and Fritts, J. E.},
  title        = {Localized content based image retrieval},
  booktitle    = {International Workshop on Multimedia Information Retrieval},
  year         = {2005},
  pages        = {227--236},
  organization = {ACM},
}

@Article{ramirez2012document,
  author    = {Ram{\'\i}rez-de-la-Rosa, G. and Montes-y-G{\'o}mez, M. and Solorio, T. and Villasenor-Pineda, L.},
  title     = {A document is known by the company it keeps: neighborhood consensus for short text categorization},
  journal   = {Language Resources and Evaluation},
  year      = {2012},
  pages     = {1--23},
  publisher = {Springer},
}

@Article{rasmussen2012model,
  author    = {Rasmussen, Peter M and Hansen, Lars K and Madsen, Kristoffer H and Churchill, Nathan W and Strother, Stephen C},
  title     = {Model sparsity and brain pattern interpretation of classification models in neuroimaging},
  journal   = {Pattern Recognition},
  year      = {2012},
  volume    = {45},
  number    = {6},
  pages     = {2085--2100},
  abstract  = {Interest is increasing in applying discriminative multivariate analysis techniques to the analysis of functional neuroimaging data. Model interpretation is of great importance in the neuroimaging context, and is conventionally based on a ?brain map? derived from the classification model. In this study we focus on the relative influence of model regularization parameter choices on both the model generalization, the reliability of the spatial patterns extracted from the classification model, and the ability of the resulting model to identify relevant brain networks defining the underlying neural encoding of the experiment. For a support vector machine, logistic regression and Fisher's discriminant analysis we demonstrate that selection of model regularization parameters has a strong but consistent impact on the generalizability and both the reproducibility and interpretable sparsity of the models for both ?2 and ?1 regularization. Importantly, we illustrate a trade-off between model spatial reproducibility and prediction accuracy. We show that known parts of brain networks can be overlooked in pursuing maximization of classification accuracy alone with either ?2 and/or ?1 regularization. This supports the view that the quality of spatial patterns extracted from models cannot be assessed purely by focusing on prediction accuracy. Our results instead suggest that model regularization parameters must be carefully selected, so that the model and its visualization enhance our ability to interpret the brain.},
  doi       = {10.1016/j.patcog.2011.09.011},
  publisher = {Elsevier},
}

@InProceedings{ray2005supervised,
  author       = {Ray, S. and Craven, M.},
  title        = {Supervised versus multiple instance learning: An empirical comparison},
  booktitle    = {International Conference on Machine Learning},
  year         = {2005},
  pages        = {697--704},
  organization = {ACM},
  publisher    = {ACM Press},
  doi          = {10.1145/1102351.1102439},
  isbn         = {1-59593-180-5},
  url          = {http://portal.acm.org/citation.cfm?doid=1102351.1102439},
}

@InProceedings{raykar2008bayesian,
  author       = {Raykar, V. C. and Krishnapuram, B. and Bi, J. and Dundar, M. and Rao, R. B.},
  title        = {Bayesian multiple instance learning: automatic feature selection and inductive transfer},
  booktitle    = {International Conference on Machine Learning},
  year         = {2008},
  pages        = {808--815},
  organization = {ACM},
  publisher    = {ACM Press},
  doi          = {10.1145/1390156.1390258},
  isbn         = {978-1-60558-205-4},
  url          = {http://portal.acm.org/citation.cfm?doid=1390156.1390258},
}

@Article{rubner2000earth,
  author    = {Rubner, Y. and Tomasi, C. and Guibas, L. J.},
  title     = {The earth mover's distance as a metric for image retrieval},
  journal   = {International Journal of Computer Vision},
  year      = {2000},
  volume    = {40},
  number    = {2},
  pages     = {99--121},
  publisher = {Springer},
}

@Article{muenzing2014dirboost,
  author    = {Muenzing, Sascha E A and van Ginneken, Bram and Viergever, Max A and Pluim, Josien P W},
  title     = {{DIRBoost}--An algorithm for boosting deformable image registration: Application to lung {CT} intra-subject registration},
  journal   = {Medical image analysis},
  year      = {2014},
  volume    = {18},
  number    = {3},
  pages     = {449--459},
  abstract  = {We introduce a boosting algorithm to improve on existing methods for deformable image registration (DIR). The proposed DIRBoost algorithm is inspired by the theory on hypothesis boosting, well known in the field of machine learning. DIRBoost utilizes a method for automatic registration error detection to obtain estimates of local registration quality. All areas detected as erroneously registered are subjected to boosting, i.e. undergo iterative registrations by employing boosting masks on both the fixed and moving image. We validated the DIRBoost algorithm on three different DIR methods (ANTS gSyn, NiftyReg, and DROP) on three independent reference datasets of pulmonary image scan pairs. DIRBoost reduced registration errors significantly and consistently on all reference datasets for each DIR algorithm, yielding an improvement of the registration accuracy by 5?34\% depending on the dataset and the registration algorithm employed.},
  doi       = {10.1016/j.media.2013.12.006},
  publisher = {Elsevier},
}

@Article{samsudin2010nearest,
  author    = {Samsudin, Noor A and Bradley, Andrew P},
  title     = {Nearest neighbour group-based classification},
  journal   = {Pattern Recognition},
  year      = {2010},
  volume    = {43},
  number    = {10},
  pages     = {3458--3467},
  abstract  = {The purpose of group-based classification (GBC) is to determine the class label for a set of test samples, utilising the prior knowledge that the samples belong to same, but unknown class. This can be seen as a simplification of the well studied, but computationally complex, non-sequential compound classification problem. In this paper, we extend three variants of the nearest neighbour algorithm to develop a number of non-parametric group-based classification techniques. The performances of the proposed techniques are then evaluated on both synthetic and real-world data sets and their performance compared with techniques that label test samples individually. The results show that, while no one algorithm clearly outperforms all others on all data sets, the proposed group-based classification techniques have the potential to outperform the individual-based techniques, especially as the (group) size of the test set increases. In addition, it is shown that algorithms that pool information from the whole test set perform better than two-stage approaches that undertake a vote based on the class labels of individual test samples.},
  doi2      = {10.1016/j.patcog.2010.05.010},
  groups    = {Not-so-supervised papers},
  publisher = {Elsevier},
}

@InProceedings{srinivasan1995comparing,
  author    = {Srinivasan, A. and Muggleton, S. and King, R. D.},
  title     = {Comparing the use of background knowledge by inductive logic programming systems},
  booktitle = {International Workshop on Inductive Logic Programming},
  year      = {1995},
  pages     = {199--230},
}

@InProceedings{tao2004svm,
  author    = {Tao, Q. and Scott, S. D. and Vinodchandran, N V and Osugi, T. T.},
  title     = {SVM-based generalized multiple-instance learning via approximate box counting},
  booktitle = {International Conference on Machine Learning},
  year      = {2004},
  pages     = {101},
}

@Article{tao2008kernels,
  author  = {Q. Tao and S. D. Scott and N. V. Vinodchandran and T. T. Osugi and B. Mueller},
  title   = {Kernels for Generalized Multiple-Instance Learning},
  journal = {IEEE Transaction on Pattern Analysis and Machine Intelligence},
  year    = {2008},
  volume  = {30},
  number  = {12},
  pages   = {2084-2098},
}

@InCollection{vural2006batch,
  author    = {Vural, Volkan and Fung, Glenn and Krishnapuram, Balaji and Dy, Jennifer and Rao, Bharat},
  title     = {Batch classification with applications in computer aided diagnosis},
  booktitle = {European Conference on Machine Learning (ECML)},
  publisher = {Springer},
  year      = {2006},
  pages     = {449--460},
  groups    = {Not-so-supervised papers},
  note2     = {DOI: 10.1007/11871842\_43},
  url2      = {http://link.springer.com/10.1007/11871842_43},
}

@InProceedings{wang2008adaptive,
  author    = {Wang, H. Y. and Yang, Q. and Zha, H.},
  title     = {Adaptive p-posterior mixture-model kernels for multiple instance learning},
  booktitle = {International Conference on Machine Learning},
  year      = {2008},
  pages     = {1136--1143},
  publisher = {ACM Press},
  doi       = {10.1145/1390156.1390299},
  file      = {wang2008adaptive.pdf:wang2008adaptive.pdf:PDF},
  isbn      = {978-1-60558-205-4},
  url       = {http://portal.acm.org/citation.cfm?doid=1390156.1390299},
}

@Article{weinberger2009distance,
  author    = {Weinberger, K. Q. and Saul, L. K.},
  title     = {Distance metric learning for large margin nearest neighbor classification},
  journal   = {The Journal of Machine Learning Research},
  year      = {2009},
  volume    = {10},
  pages     = {207--244},
  file      = {weinberger2009distance.pdf:weinberger2009distance.pdf:PDF},
  publisher = {JMLR.org},
}

@Article{wilson2005pattern,
  author  = {R. C. Wilson and B. Luo and E. R. Hancock},
  title   = {Pattern Vectors from Algebraic Graph Theory},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year    = {2005},
  volume  = {27},
  pages   = {1112-1124},
}

@InProceedings{woznica2010adaptive,
  author       = {Woznica, A. and Kalousis, A.},
  title        = {Adaptive Distances on Sets of Vectors},
  booktitle    = {International Conference on Data Mining},
  year         = {2010},
  pages        = {579--588},
  month        = dec,
  organization = {IEEE},
  publisher    = {IEEE},
  doi          = {10.1109/ICDM.2010.45},
  file         = {woznica2010adaptive.pdf:woznica2010adaptive.pdf:PDF},
  isbn         = {978-1-4244-9131-5},
  keywords     = {adaptive distances, complex objects, distance learning, graphs, k-nearest neighbor algorithm, learning (artificial intelligence), learning distances, sets, set theory, Training data, tuples, vector, vectorial data, Vectors},
  url          = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5694012},
}

@Article{zhang2009multi2,
  author    = {Zhang, Min-Ling and Zhou, Zhi-Hua},
  title     = {Multi-instance clustering with applications to multi-instance prediction},
  journal   = {Applied Intelligence},
  year      = {2009},
  volume    = {31},
  number    = {1},
  pages     = {47--68},
  month     = aug,
  doi       = {10.1007/s10489-007-0111-x},
  publisher = {Springer},
  url       = {http://link.springer.com/10.1007/s10489-007-0111-x},
}

@InProceedings{zhang2001dd,
  author    = {Zhang, Q. and Goldman, S.A. and others},
  title     = {EM-DD: An improved multiple-instance learning technique},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2001},
  volume    = {14},
  pages     = {1073--1080},
  publisher = {Cambridge, MA: MIT Press},
}

@InProceedings{zhu20041,
  author    = {Zhu, Ji and Rosset, Saharon and Hastie, Trevor and Tibshirani, Rob},
  title     = {1-norm support vector machines},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2004},
  volume    = {16},
  number    = {1},
  pages     = {49--56},
  publisher = {The MIT Press},
}

@TechReport{zhu2005semi,
  author      = {Xiaojin Zhu},
  title       = {Semi-Supervised Learning Literature Survey},
  institution = {Computer Sciences, University of Wisconsin-Madison},
  year        = {2005},
  number      = {1530},
  groups      = {Not-so-supervised general},
}

@Article{rokach2010ensemble,
  author    = {Rokach, L.},
  title     = {{Ensemble-based classifiers}},
  journal   = {Artificial Intelligence Review},
  year      = {2010},
  volume    = {33},
  number    = {1},
  pages     = {1--39},
  issn      = {0269-2821},
  abstract  = {The idea of ensemble methodology is to build a predictive model by integrating multiple models. It is well-known that ensemble methods can be used for improving predic- tion performance. Researchers from various disciplines such as statistics and AI considered the use of ensemble methodology. This paper, review existing ensemble techniques and can be served as a tutorial for practitioners who are interested in building ensemble based systems.},
  doi       = {10.1007/s10462-009-9124-7},
  file      = {rokach2010ensemble.PDF:rokach2010ensemble.PDF:PDF},
  keywords  = {Boosting, Classification, Ensemble of classifiers, Supervised learning},
  publisher = {Springer},
}

@Article{friedman1937use,
  author    = {Friedman, M.},
  title     = {{The use of ranks to avoid the assumption of normality implicit in the analysis of variance}},
  journal   = {Journal of the American Statistical Association},
  year      = {1937},
  volume    = {32},
  number    = {200},
  pages     = {675--701},
  month     = dec,
  abstract  = {The Friedman rank sum test is a widely-used nonparametric method in computational biology. In addition to examining the overall null hypothesis of no significant difference among any of the rank sums, it is typically of interest to conduct pairwise comparison tests. Current approaches to such tests rely on large-sample approximations, due to the numerical complexity of computing the exact distribution. These approximate methods lead to inaccurate estimates in the tail of the distribution, which is most relevant for p-value calculation. We propose an efficient, combinatorial exact approach for calculating the probability mass distribution of the rank sum difference statistic for pairwise comparison of Friedman rank sums, and compare exact results with recommended asymptotic approximations. Whereas the chi-squared approximation performs inferiorly to exact computation overall, others, particularly the normal, perform well, except for the extreme tail. Hence exact calculation offers an improvement when small p-values occur following multiple testing correction. Exact inference also enhances the identification of significant differences whenever the observed values are close to the approximate critical value. We illustrate the proposed method in the context of biological machine learning, were Friedman rank sum difference tests are commonly used for the comparison of classifiers over multiple datasets. We provide a computationally fast method to determine the exact p-value of the absolute rank sum difference of a pair of Friedman rank sums, making asymptotic tests obsolete. Calculation of exact p-values is easy to implement in statistical software and the implementation in R is provided in one of the Additional files and is also available at 
http://www.ru.nl/publish/pages/726696/friedmanrsd.zip

.},
  doi       = {10.1080/01621459.1937.10503522},
  keywords  = {Algorithms, Bioinformatics, Computational Biology/Bioinformatics, Computer Appl. in Life Sciences, Microarrays},
  publisher = {JSTOR},
  url       = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1937.10503522},
}

@InCollection{ghanbari2013connectivity,
  author    = {Ghanbari, Yasser and Smith, Alex R and Schultz, Robert T and Verma, Ragini},
  title     = {Connectivity Subnetwork Learning for Pathology and Developmental Variations},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  publisher = {Springer},
  year      = {2013},
  pages     = {90--97},
  note      = {DOI: 10.1007/978-3-642-40811-3\_12},
  url       = {http://link.springer.com/10.1007/978-3-642-40811-3_12},
}

@Article{bullmore2009complex,
  author    = {Bullmore, Ed and Sporns, Olaf},
  title     = {Complex brain networks: graph theoretical analysis of structural and functional systems},
  journal   = {Nature Reviews Neuroscience},
  year      = {2009},
  volume    = {10},
  number    = {3},
  pages     = {186--198},
  month     = mar,
  doi       = {10.1038/nrn2575},
  file      = {bullmore2009complex.pdf:bullmore2009complex.pdf:PDF},
  publisher = {Nature Publishing Group},
  url       = {http://www.nature.com/doifinder/10.1038/nrn2575},
}

@Article{rudie2012altered,
  author    = {Rudie, JD and Brown, JA and Beck-Pancer, D and Hernandez, LM and Dennis, EL and Thompson, PM and Bookheimer, SY and Dapretto, M},
  title     = {Altered Functional and Structural Brain Network Organization in Autism},
  journal   = {NeuroImage: Clinical},
  year      = {2012},
  volume    = {2},
  pages     = {79--94},
  abstract  = {Structural and functional underconnectivity have been reported for multiple brain regions, functional systems, and white matter tracts in individuals with autism spectrum disorders (ASD). Although recent developments in complex network analysis have established that the brain is a modular network exhibiting small-world properties, network level organization has not been carefully examined in ASD. Here we used resting-state functional MRI (n=42 ASD, n=37 typically developing; TD) to show that children and adolescents with ASD display reduced short and long-range connectivity within functional systems (i.e., reduced functional integration) and stronger connectivity between functional systems (i.e., reduced functional segregation), particularly in default and higher-order visual regions. Using graph theoretical methods, we show that pairwise group differences in functional connectivity are reflected in network level reductions in modularity and clustering (local efficiency), but shorter characteristic path lengths (higher global efficiency). Structural networks, generated from diffusion tensor MRI derived fiber tracts (n=51 ASD, n=43 TD), displayed lower levels of white matter integrity yet higher numbers of fibers. TD and ASD individuals exhibited similar levels of correlation between raw measures of structural and functional connectivity (n=35 ASD, n=35 TD). However, a principal component analysis combining structural and functional network properties revealed that the balance of local and global efficiency between structural and functional networks was reduced in ASD, positively correlated with age, and inversely correlated with ASD symptom severity. Overall, our findings suggest that modeling the brain as a complex network will be highly informative in unraveling the biological basis of ASD and other neuropsychiatric disorders.},
  doi       = {10.1016/j.nicl.2012.11.006},
  publisher = {Elsevier},
}

@Article{bach2012structured,
  author    = {Bach, Francis and Jenatton, Rodolphe and Mairal, Julien and Obozinski, Guillaume},
  title     = {Structured sparsity through convex optimization},
  journal   = {Statistical Science},
  year      = {2012},
  volume    = {27},
  number    = {4},
  pages     = {450--468},
  month     = nov,
  issn      = {0883-4237},
  doi       = {10.1214/12-STS394},
  file      = {bach2012structured.pdf:bach2012structured.pdf:PDF},
  keywords  = {and phrases, Convex optimization, Sparsity},
  publisher = {Institute of Mathematical Statistics},
  url       = {http://projecteuclid.org/euclid.ss/1356098550},
}

@Article{pekalska2002generalized,
  author    = {P{\k{e}}kalska, E. and Pacl{\'\i}k, P. and Duin, R. P. W.},
  title     = {A Generalized Kernel Approach to Dissimilarity-Based Classification},
  journal   = {The Journal of Machine Learning Research},
  year      = {2002},
  volume    = {2},
  pages     = {175--211},
  issn      = {1532-4435},
  publisher = {JMLR. org},
}

@InProceedings{maron1998framework,
  author       = {Maron, Oded and Lozano-P{\'e}rez, Tom{\'a}s},
  title        = {A framework for multiple-instance learning},
  booktitle    = {Advances in Neural Information Processing Systems},
  year         = {1998},
  pages        = {570--576},
  organization = {Morgan Kaufmann Publishers},
  file         = {maron1998framework.pdf:maron1998framework.pdf:PDF},
}

@Article{doan2011crowdsourcing,
  author    = {Doan, Anhai and Ramakrishnan, Raghu and Halevy, Alon Y},
  title     = {Crowdsourcing systems on the world-wide web},
  journal   = {Communications of the ACM},
  year      = {2011},
  volume    = {54},
  number    = {4},
  pages     = {86--96},
  publisher = {ACM},
}

@InProceedings{brossi2012comparison,
  author       = {Brossi, Steven D and Bradley, Andrew P},
  title        = {A Comparison of Multiple Instance and Group Based Learning},
  booktitle    = {International Conference on Digital Image Computing Techniques and Applications},
  year         = {2012},
  pages        = {1--8},
  month        = dec,
  organization = {IEEE},
  publisher    = {IEEE},
  doi          = {10.1109/DICTA.2012.6411737},
  isbn         = {978-1-4673-2181-5},
  keywords     = {Accuracy, bag size, Drugs, GB classification algorithm, group-based classification algorithms, group-based learning, learning (artificial intelligence), MIL, Multiple-instance learning, Pathology, pattern classification, percentage positives, performance evaluation, performance improvement, real-world Pap smear dataset, Standards, Supervised learning, synthetic Pap smear dataset, Training, Vectors},
  url          = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6411737},
}

@Article{kittler1998combining,
  author    = {Kittler, J.},
  title     = {{Combining classifiers: A theoretical framework}},
  journal   = {Pattern Analysis \& Applications},
  year      = {1998},
  volume    = {1},
  number    = {1},
  pages     = {18--27},
  file      = {kittler1998combining.PDF:kittler1998combining.PDF:PDF},
  publisher = {Springer},
}

@Article{breiman2001random,
  author    = {Breiman, L.},
  title     = {{Random forests}},
  journal   = {Machine Learning},
  year      = {2001},
  volume    = {45},
  number    = {1},
  pages     = {5--32},
  publisher = {Springer},
}

@InProceedings{tax2011bag,
  author    = {Tax, David M J and Loog, M. and Duin, Robert P W and Cheplygina, V. and Lee, Wan-Jui},
  title     = {Bag dissimilarities for multiple instance learning},
  booktitle = {Similarity-Based Pattern Recognition},
  year      = {2011},
  pages     = {222--234},
  publisher = {Springer},
  groups    = {My papers},
}

@Book{pekalska2005dissimilarity,
  title     = {The dissimilarity representation for pattern recognition: foundations and applications},
  publisher = {World Scientific Pub Co Inc},
  year      = {2005},
  author    = {P{\k{e}}kalska, E. and Duin, R.P.W.},
  volume    = {64},
}

@Article{lo2012extraction,
  author    = {Lo, Pechin and Van Ginneken, Bram and Reinhardt, Joseph M. and Yavarna, Tarunashree and De Jong, Pim A. and Irving, Benjamin and Fetita, Catalin and Ortner, Margarete and Pinho, Rômulo Romulo and Sijbers, Jan and Feuerstein, Marco and Fabijanska, Anna and Bauer, Christian and Beichel, Reinhard and Mendoza, Carlos S. and Wiemker, Rafael and Lee, Jaesung and Reeves, Anthony P. and Born, Silvia and Weinheimer, Oliver and Van Rikxoort, Eva M. and Tschirren, Juerg and Mori, Ken and Odry, Benjamin and Naidich, David P. and Hartmann, Ieneke and Hoffman, Eric A. and Prokop, Mathias and Pedersen, Jesper H. and de Bruijne, Marleen},
  title     = {Extraction of airways from {CT} ({EXACT}'09)},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2012},
  volume    = {31},
  number    = {11},
  pages     = {2093--2107},
  month     = nov,
  abstract  = {This paper describes a framework for establishing a reference airway tree segmentation, which was used to quantitatively evaluate fifteen different airway tree extraction algorithms in a standardized manner. Because of the sheer difficulty involved in manually constructing a complete reference standard from scratch, we propose to construct the reference using results from all algorithms that are to be evaluated. We start by subdividing each segmented airway tree into its individual branch segments. Each branch segment is then visually scored by trained observers to determine whether or not it is a correctly segmented part of the airway tree. Finally, the reference airway trees are constructed by taking the union of all correctly extracted branch segments. Fifteen airway tree extraction algorithms from different research groups are evaluated on a diverse set of twenty chest computed tomography (CT) scans of subjects ranging from healthy volunteers to patients with severe pathologies, scanned at different sites, with different CT scanner brands, models, and scanning protocols. Three performance measures covering different aspects of segmentation quality were computed for all participating algorithms. Results from the evaluation showed that no single algorithm could extract more than an average of 74\% of the total length of all branches in the reference standard, indicating substantial differences between the algorithms. A fusion scheme that obtained superior results is presented, demonstrating that there is complementary information provided by the different algorithms and there is still room for further improvements in airway segmentation algorithms.},
  doi       = {10.1109/TMI.2012.2209674},
  file      = {lo2012extraction.pdf:lo2012extraction.pdf:PDF},
  groups    = {Veni},
  keywords  = {Algorithms, Analysis of Variance, Computed tomography, Databases, evaluation, Factual, Humans, Image segmentation, lung, Lungs, Medical diagnostic imaging, pulmonary airways, Radiographic Image Enhancement, Segmentation, Tomography, Trachea, X-Ray Computed},
  publisher = {IEEE},
  url       = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6249784},
}

@Article{murphy2011semi,
  author    = {Murphy, K. and van Ginneken, B. and Klein, S. and Staring, M. and de Hoop, B.J. and Viergever, M.A. and Pluim, J.P.W.},
  title     = {Semi-automatic construction of reference standards for evaluation of image registration},
  journal   = {Medical Image Analysis},
  year      = {2011},
  volume    = {15},
  number    = {1},
  pages     = {71--84},
  abstract  = {Quantitative evaluation of image registration algorithms is a difficult and under-addressed issue due to the lack of a reference standard in most registration problems. In this work a method is presented whereby detailed reference standard data may be constructed in an efficient semi-automatic fashion. A well-distributed set of n landmarks is detected fully automatically in one scan of a pair to be registered. Using a custom-designed interface, observers define corresponding anatomic locations in the second scan for a specified subset of s of these landmarks. The remaining n?s landmarks are matched fully automatically by a thin-plate-spline based system using the s manual landmark correspondences to model the relationship between the scans. The method is applied to 47 pairs of temporal thoracic CT scans, three pairs of brain MR scans and five thoracic CT datasets with synthetic deformations. Interobserver differences are used to demonstrate the accuracy of the matched points. The utility of the reference standard data as a tool in evaluating registration is shown by the comparison of six sets of registration results on the 47 pairs of thoracic CT data.},
  doi       = {10.1016/j.media.2010.07.005},
  publisher = {Elsevier},
}

@Article{breiman1996bagging,
  author    = {Breiman, Leo},
  title     = {Bagging predictors},
  journal   = {Machine learning},
  year      = {1996},
  volume    = {24},
  number    = {2},
  pages     = {123--140},
  publisher = {Springer},
}

@Article{maaten2008visualizing,
  author  = {van der Maaten, L. and Hinton, G.},
  title   = {Visualizing data using {t-SNE}},
  journal = {Journal of Machine Learning Research},
  year    = {2008},
  volume  = {9},
  number  = {2579-2605},
  pages   = {85},
}

@Article{opbroek2015weighting,
  author    = {van Opbroek, Annegreet and Vernooij, Meike W and Ikram, M Arfan and de Bruijne, Marleen},
  title     = {Weighting training images by maximizing distribution similarity for supervised segmentation across scanners.},
  journal   = {Medical image analysis},
  year      = {2015},
  volume    = {24},
  number    = {1},
  pages     = {245--254},
  doi2      = {10.1016/j.media.2015.06.010},
  file      = {opbroek2015weighting.pdf:opbroek2015weighting.pdf:PDF},
  groups    = {Not-so-supervised papers},
  keywords  = {Algorithms, anatomy \& histology, Automated, Brain, Computer-Assisted, Data Interpretation, Diffusion Magnetic Resonance Imaging, Humans, Image Enhancement, Image Interpretation, methods, Pattern Recognition, Reproducibility of Results, Sensitivity and Specificity, Statistical, Statistical Distributions, Subtraction Technique, Supervised Machine Learning},
  language  = {eng},
  publisher = {Elsevier},
  url2      = {http://dx.doi.org/10.1016/j.media.2015.06.010},
}

@InProceedings{tax2016similarity,
  author    = {Tax, David M. J. and Cheplygina, Veronika and Duin, Robert P. W. and van de Poll, Jan},
  title     = {The Similarity between Dissimilarities},
  booktitle = {Structural, Syntactic, and Statistical Pattern Recognition (S+SSPR)},
  year      = {2016},
  pages     = {84--94},
  doi       = {10.1007/978-3-319-49055-7_8},
  groups    = {My papers},
  url       = {http://link.springer.com/10.1007/978-3-319-49055-7_8},
}

@Article{heimann2009statistical,
  author    = {Heimann, Tobias and Meinzer, Hans-Peter},
  title     = {Statistical shape models for {3D} medical image segmentation: a review},
  journal   = {Medical Image Analysis},
  year      = {2009},
  volume    = {13},
  number    = {4},
  pages     = {543--563},
  doi2      = {10.1016/j.media.2009.05.004},
  issn2     = {1361-8415},
  keywords  = {Active Appearance model, Active Shape model, Deformable surface, Statistical shape model},
  publisher = {Elsevier},
}

@Conference{borgwardt2005shortest,
  author       = {Borgwardt, K. M. and Kriegel, H. P.},
  title        = {{Shortest-Path Kernels on Graphs}},
  booktitle    = {International Conference on Data Mining},
  year         = {2005},
  pages        = {74-81},
  organization = {IEEE},
  publisher    = {IEEE Computer Society},
}

@Article{kriegeskorte2008representational,
  author    = {Kriegeskorte, Nikolaus and Mur, Marieke and Bandettini, Peter},
  title     = {Representational similarity analysis--connecting the branches of systems neuroscience},
  journal   = {Frontiers in systems neuroscience},
  year      = {2008},
  volume    = {2},
  number    = {November},
  pages     = {4--4},
  issn      = {1662-5137 (Electronic) 1662-5137 (Linking)},
  abstract  = {A FUNDAMENTAL CHALLENGE FOR SYSTEMS NEUROSCIENCE IS TO QUANTITATIVELY RELATE ITS THREE MAJOR BRANCHES OF RESEARCH: brain-activity measurement, behavioral measurement, and computational modeling. Using measured brain-activity patterns to evaluate computational network models is complicated by the need to define the correspondency between the units of the model and the channels of the brain-activity data, e.g., single-cell recordings or voxels from functional magnetic resonance imaging (fMRI). Similar correspondency problems complicate relating activity patterns between different modalities of brain-activity measurement (e.g., fMRI and invasive or scalp electrophysiology), and between subjects and species. In order to bridge these divides, we suggest abstracting from the activity patterns themselves and computing representational dissimilarity matrices (RDMs), which characterize the information carried by a given representation in a brain or model. Building on a rich psychological and mathematical literature on similarity analysis, we propose a new experimental and data-analytical framework called representational similarity analysis (RSA), in which multi-channel measures of neural activity are quantitatively related to each other and to computational theory and behavior by comparing RDMs. We demonstrate RSA by relating representations of visual objects as measured with fMRI in early visual cortex and the fusiform face area to computational models spanning a wide range of complexities. The RDMs are simultaneously related via second-level application of multidimensional scaling and tested using randomization and bootstrap techniques. We discuss the broad potential of RSA, including novel approaches to experimental design, and argue that these ideas, which have deep roots in psychology and neuroscience, will allow the integrated quantitative analysis of data from all three branches, thus contributing to a more unified systems neuroscience.},
  doi       = {10.3389/neuro.06.004.2008},
  file      = {kriegeskorte2008representational.pdf:kriegeskorte2008representational.pdf:PDF},
  keywords  = {computational modeling, electrophysiology, fmri, population code, Representation, similarity},
  publisher = {Frontiers Research Foundation},
  url       = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2605405&tool=pmcentrez&rendertype=abstract},
}

@Article{lai2006random,
  author    = {Lai, Carmen and Reinders, Marcel J T and Wessels, Lodewyk},
  title     = {Random subspace method for multivariate feature selection},
  journal   = {Pattern Recognition Letters},
  year      = {2006},
  volume    = {27},
  number    = {10},
  pages     = {1067--1076},
  file      = {lai2006random.pdf:lai2006random.pdf:PDF},
  publisher = {Elsevier},
}

@MastersThesis{cheplygina2010random,
  author = {Cheplygina, Veronika},
  title  = {{Random subspace method for one-class classifiers, MSc thesis}},
  school = {Delft University of Technology},
  year   = {2010},
  type   = {MSc thesis},
  doi    = {10.1007/978-3-642-21557-5_12},
  groups = {My papers},
  issn   = {978-3-642-21556-8},
  pages  = {1--103},
}

@InProceedings{raykar2011ranking,
  author    = {Raykar, Vikas C and Yu, Shipeng},
  title     = {Ranking annotators for crowdsourced labeling tasks},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2011},
  pages     = {1809--1817},
  abstract  = {With the advent of crowdsourcing services it has become quite cheap{\textbackslash}nand reasonably{\textbackslash}n{\textbackslash}neffective to get a dataset labeled by multiple annotators in a short{\textbackslash}namount of{\textbackslash}n{\textbackslash}ntime. Various methods have been proposed to estimate the consensus{\textbackslash}nlabels by{\textbackslash}n{\textbackslash}ncorrecting for the bias of annotators with different kinds of expertise.{\textbackslash}nOften we{\textbackslash}n{\textbackslash}nhave low quality annotators or spammers-annotators who assign labels{\textbackslash}nrandomly{\textbackslash}n{\textbackslash}n(e.g., without actually looking at the instance). Spammers can make{\textbackslash}nthe cost of{\textbackslash}n{\textbackslash}nacquiring labels very expensive and can potentially degrade the quality{\textbackslash}nof the consensus{\textbackslash}n{\textbackslash}nlabels. In this paper we formalize the notion of a spammer and define{\textbackslash}n{\textbackslash}na score which can be used to rank the annotators-with the spammers{\textbackslash}nhaving a{\textbackslash}n{\textbackslash}nscore close to zero and the good annotators having a high score close{\textbackslash}nto one.},
  file      = {raykar2011ranking.pdf:raykar2011ranking.pdf:PDF},
  journal   = {Advances in Neural Information Processing Systems (NIPS)},
  url       = {https://papers.nips.cc/paper/4469-ranking-annotators-for-crowdsourced-labeling-tasks.pdf},
}

@Article{kuncheva2010random,
  author    = {Kuncheva, Ludmila I and Rodr{\'\i}guez, Juan J and Plumpton, Catrin O and Linden, David EJ and Johnston, Stephen J},
  title     = {Random subspace ensembles for fMRI classification},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2010},
  volume    = {29},
  number    = {2},
  pages     = {531--542},
  month     = feb,
  doi       = {10.1109/TMI.2009.2037756},
  publisher = {IEEE},
  url       = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5405643},
}

@Article{cheplygina2011pruned,
  author    = {Cheplygina, Veronika and Tax, David M J},
  title     = {Pruned random subspace method for one-class classifiers},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year      = {2011},
  volume    = {6713 LNCS},
  pages     = {96--105},
  issn      = {9783642215568},
  abstract  = {The goal of one-class classification is to distinguish the target class from all the other classes using only training data from the target class. Because it is difficult for a single one-class classifier to capture all the characteristics of the target class, combining several one-class clas- sifiers may be required. Previous research has shown that the Random Subspace Method (RSM), in which classifiers are trained on different subsets of the feature space, can be effective for one-class classifiers. In this paper we show that the performance by the RSM can be noisy, and that pruning inaccurate classifiers from the ensemble can be more ef- fective than using all available classifiers. We propose to apply pruning to RSM of one-class classifiers using a supervised AUC criterion or an unsupervised consistency criterion. It appears that when the AUC cri- terion is used, the performance may be increased dramatically, while for the consistency criterion results do not improve, but only become more predictable. Keywords:},
  booktitle = {Multiple Classifier Systems},
  doi       = {10.1007/978-3-642-21557-5_12},
  groups    = {My papers},
  isbn      = {978-3-642-21556-8},
  keywords  = {Ensemble learning, One-class classification, Pruning Ensembles, Random Subspace Method},
  publisher = {Springer},
}

@InProceedings{zhang2013probabilistic,
  author    = {Zhang, Luming and Song, Mingli and Liu, Zicheng and Liu, Xiao and Bu, Jiajun and Chen, Chun},
  title     = {Probabilistic graphlet cut: Exploiting spatial structure cue for weakly supervised image segmentation},
  booktitle = {Computer Vision and Pattern Recognition (CVPR)},
  year      = {2013},
  pages     = {1908--1915},
}

@InProceedings{calana2010prototype,
  author       = {Cala{\~{n}}a, Yenisel Plasencia and Reyes, Edel Garc{\'\i}a Reyes and Orozco-Alzate, Mauricio and Duin, Robert P W},
  title        = {Prototype selection for dissimilarity representation by a genetic algorithm},
  booktitle    = {International Conference on Pattern Recognition},
  year         = {2010},
  pages        = {177--180},
  organization = {IEEE},
}

@InProceedings{cheplygina2015characterizing,
  author       = {Cheplygina, Veronika and Tax, David M J},
  title        = {Characterizing {Multiple} {Instance} {Datasets}},
  booktitle    = {Similarity-{Based} {Pattern} {Recognition}},
  year         = {2015},
  editor       = {Feragen, Aasa and Pelillo, Marcello and Loog, Marco},
  volume       = {9370},
  pages        = {15--27},
  organization = {Springer},
  publisher    = {Springer},
  abstract     = {© Springer International Publishing Switzerland 2015.In many pattern recognition problems, a single feature vector is not sufficient to describe an object. In multiple instance learning (MIL), objects are represented by sets (bags) of feature vectors (instances). This requires an adaptation of standard supervised classifiers in order to train and evaluate on these bags of instances. Like for supervised classification, several benchmark datasets and numerous classifiers are available for MIL. When performing a comparison of different MIL classifiers, it is important to understand the differences of the datasets, used in the comparison. Seemingly different (based on factors such as dimensionality) datasets may elicit very similar behaviour in classifiers, and vice versa. This has implications for what kind of conclusions may be drawn from the comparison results. We aim to give an overview of the variability of available benchmark datasets and some popular MIL classifiers. We use a dataset dissimilarity measure, based on the differences between the ROC-curves obtained by different classifiers, and embed this dataset dissimilarity matrix into a low-dimensional space. Our results show that conceptually similar datasets can behave very differently. We therefore recommend examining such dataset characteristics when making comparisons between existing and new MIL classifiers. Data and other resources are available at http://www.miproblems.org.},
  doi          = {10.1007/978-3-319-24261-3_2},
  groups       = {My papers},
  isbn         = {978-3-319-24261-3},
  url          = {http://dx.doi.org/10.1007/978-3-319-24261-3_2},
}

@InCollection{cheplygina2014network,
  author    = {Cheplygina, Veronika and Tax, David M J and Loog, Marco and Feragen, Aasa},
  title     = {Network-Guided Group Feature Selection for Classification of Autism Spectrum Disorder},
  booktitle = {Machine Learning in Medical Imaging},
  publisher = {Springer},
  year      = {2014},
  volume    = {8679},
  pages     = {190--197},
  isbn      = {978-3-319-10580-2},
  note      = {DOI: 10.1007/978-3-319-10581-9\_24},
  abstract  = {MicroRNAs (miRNAs) play key roles in the initiation and progression of various cancers by regulating genes. Regulatory interactions between genes and miRNAs are complex, as multiple miRNAs can regulate multiple genes. In addtion, these interactions vary from patient to patient and even among patients with the same cancer type, as cancer development is a heterogeneous process. These relationships are more complicated because transcription factors and other regulatory molecules can also regulate miRNAs and genes. Hence, it is important to identify the complex relationships between genes and miRNAs in cancer. In this study, we propose a computational approach to constructing modules that represent these relationships by integrating the expression data of genes and miRNAs with gene-gene interaction data. First, we used a biclustering algorithm to construct modules consisting of a subset of genes and a subset of samples to incorporate the heterogeneity of cancer cells. Second, we combined gene-gene interactions to include genes that play important roles in cancer-related pathways. Then, we selected miRNAs that are closely associated with genes in the modules based on a Gaussian Bayesian network and Bayesian Information Criteria. When we applied our approach to ovarian cancer and glioblastoma (GBM) data sets, 33 and 54 modules were constructed, respectively. In these modules, 91\% and 94\% of ovarian cancer and GBM modules, respectively, were explained either by direct regulation between genes and miRNAs or by indirect relationships via transcription factors. In addition, 48.4\% and 74.0\% of modules from ovarian cancer and GBM, respectively, were enriched with cancer-related pathways, and 51.7\% and 71.7\% of miRNAs in modules were ovarian cancer-related miRNAs and GBM-related miRNAs, respectively. Finally, we extensively analyzed significant modules and showed that most genes in these modules were related to ovarian cancer and GBM.},
  groups    = {My papers},
  url       = {http://dx.doi.org/10.1007/978-3-319-10581-9_24%5Cnhttp://dx.plos.org/10.1371/journal.pcbi.1004042},
}

@InProceedings{cheplygina2015label,
  author    = {V. Cheplygina and L. S{\o}rensen and D. M. J. Tax and M. de Bruijne and M. Loog},
  title     = {Label stability in multiple instance learning},
  booktitle = {Medical Imaging Computing and Computer Assisted Intervention (MICCAI)},
  year      = {2015},
  pages     = {539--546},
  doi2      = {10.1007/978-3-319-24553-9_66},
  groups    = {My papers},
}

@Article{cheplygina2015multiple,
  author   = {Cheplygina, Veronika and Tax, David M. J. and Loog, Marco},
  title    = {Multiple instance learning with bag dissimilarities},
  journal  = {Pattern Recognition},
  year     = {2015},
  volume   = {48},
  number   = {1},
  pages    = {264--275},
  abstract = {Multiple instance learning (MIL) is concerned with learning from sets (bags) of objects (instances), where the individual instance labels are ambiguous. In this setting, supervised learning cannot be applied directly. Often, specialized MIL methods learn by making additional assumptions about the relationship of the bag labels and instance labels. Such assumptions may fit a particular dataset, but do not generalize to the whole range of MIL problems. Other MIL methods shift the focus of assumptions from the labels to the overall (dis)similarity of bags, and therefore learn from bags directly. We propose to represent each bag by a vector of its dissimilarities to other bags in the training set, and treat these dissimilarities as a feature representation. We show several alternatives to define a dissimilarity between bags and discuss which definitions are more suitable for particular MIL problems. The experimental results show that the proposed approach is computationally inexpensive, yet very competitive with state-of-the-art algorithms on a wide range of MIL datasets.},
  doi2     = {10.1016/j.patcog.2014.07.022},
  groups   = {My papers},
  keywords = {Dissimilarity representation, Drug activity prediction, image classification, multiple instance learning, Point set distance, Text categorization},
}

@InProceedings{cheplygina2016asymmetric,
  author    = {V. Cheplygina and A. van Opbroek and M. A. Ikram and M. W. Vernooij and M. de Bruijne},
  title     = {Asymmetric similarity-weighted ensembles for image segmentation},
  booktitle = {International Symposium on Biomedical Imaging (ISBI)},
  year      = {2016},
  pages     = {273--277},
  publisher = {IEEE},
  doi2      = {10.1109/ISBI.2016.7493262},
  groups    = {My papers},
}

@InProceedings{cheplygina2016early,
  author    = {V. Cheplygina and A. Perez-Rovira and W. Kuo and H. Tiddens and M. de Bruijne},
  title     = {Early experiences with crowdsourcing airway annotations in chest {CT}},
  booktitle = {Large-scale Annotation of Biomedical data and Expert Label Synthesis (MICCAI LABELS)},
  year      = {2016},
  pages     = {209-218},
  doi2      = {10.1007/978-3-319-46976-8_22},
  groups    = {My papers},
  issn      = {9783319469751},
  journal   = {Large-scale Annotation of Biomedical data and Expert Label Synthesis},
  title2    = {Carneiro, G., Mateus, D., Peter, L., Bradley, A., Tavares, J.M.R.S., Belagiannis, V., Papa, J.P., Nascimento, J.C., Loog, M., Lu, Z., Cardoso, J.S., Cornebise, J. (eds.) Deep Learning and Data Labeling for Medical Applications, LNCS, vol. 10008},
}

@Article{dickinson2010citizen,
  author    = {Dickinson, Janis L and Zuckerberg, Benjamin and Bonter, David N},
  title     = {Citizen science as an ecological research tool: challenges and benefits},
  journal   = {Annual review of ecology, evolution and systematics},
  year      = {2010},
  volume    = {41},
  number    = {2010},
  pages     = {149--72},
  issn      = {1543-592X 978-0-8243-1441-5},
  abstract  = {Citizen science, the involvement of volunteers in research, has increased the scale of ecological field studies with continent-wide, centralized monitoring efforts and, more rarely, tapping of volunteers to conduct large, coordi-nated, field experiments. The unique benefit for the field of ecology lies in understanding processes occurring at broad geographic scales and on private lands, which are impossible to sample extensively with traditional field re-search models. Citizen science produces large, longitudinal data sets, whose potential for error and bias is poorly understood. Because it does not usually aim to uncover mechanisms underlying ecological patterns, citizen science is best viewed as complementary to more localized, hypothesis-driven re-search. In the process of addressing the impacts of current, global " exper-iments " altering habitat and climate, large-scale citizen science has led to new, quantitative approaches to emerging questions about the distribution and abundance of organisms across space and time.},
  doi       = {10.1146/annurev-ecolsys-102209-144636},
  file      = {dickinson2010citizen.pdf:dickinson2010citizen.pdf:PDF},
  keywords  = {biodiversity, climate change, crowdsourcing, fragmentation, geographical ecology, habitat loss, invasive species, macroecology, monitoring, observer quality, population ecology, sampling bias, sampling error, spatial ecology},
  publisher = {JSTOR},
}

@Article{ding2012breast,
  author    = {Ding, Jianrui and Cheng, HD and Huang, Jianhua and Liu, Jiafeng and Zhang, Yingtao},
  title     = {Breast ultrasound image classification based on multiple-instance learning},
  journal   = {Journal of Digital Imaging},
  year      = {2012},
  volume    = {25},
  number    = {5},
  pages     = {620--627},
  month     = oct,
  abstract  = {Breast ultrasound (BUS) image segmentation is a very difficult task due to poor image quality and speckle noise. In this paper, local features extracted from roughly segmented regions of interest (ROIs) are used to describe breast tumors. The roughly segmented ROI is viewed as a bag. And subregions of the ROI are considered as the instances of the bag. Multiple-instance learning (MIL) method is more suitable for classifying breast tumors using BUS images. However, due to the complexity of BUS images, traditional MIL method is not applicable. In this paper, a novel MIL method is proposed for solving such task. First, a self-organizing map is used to map the instance space to the concept space. Then, we use the distribution of the instances of each bag in the concept space to construct the bag feature vector. Finally, a support vector machine is employed for classifying the tumors. The experimental results show that the proposed method can achieve better performance: the accuracy is 0.9107 and the area under receiver operator characteristic curve is 0.96 (p {\textless} 0.005).},
  doi       = {10.1007/s10278-012-9499-x},
  keywords  = {Algorithms, Automated, Breast Neoplasms, Classification, Cluster Analysis, Computer-Assisted, Databases, Factual, Female, Humans, Image Interpretation, Mammary, methods, Models, Pathology, Pattern Recognition, ROC Curve, Sensitivity and Specificity, Support Vector Machine, Theoretical, Ultrasonography},
  language  = {eng},
  publisher = {Springer},
  url       = {http://link.springer.com/10.1007/s10278-012-9499-x},
}

@InProceedings{duin2000experiments,
  author    = {Duin, R. P W and Tax, D. M J},
  title     = {{Experiments with classifier combining rules}},
  booktitle = {Multiple Classifier Systems},
  year      = {2000},
  pages     = {16--29},
  publisher = {Springer},
  file      = {duin2000experiments.pdf:duin2000experiments.pdf:PDF},
  journal   = {Multiple Classifier Systems},
}

@InCollection{duin2010non,
  author    = {Duin, Robert P. W. and P?kalska, El?bieta},
  title     = {Non-{Euclidean} {Dissimilarities}: {Causes} and {Informativeness}},
  booktitle = {Structural, Syntactic and Statistical Pattern Recognition},
  publisher = {Springer Berlin Heidelberg},
  year      = {2010},
  pages     = {324--333},
  note      = {DOI: 10.1007/978-3-642-14980-1\_31},
  file      = {duin2010non.pdf:duin2010non.pdf:PDF},
  groups    = {Veni},
  url       = {http://link.springer.com/10.1007/978-3-642-14980-1_31},
}

@Article{erman2007offline,
  author    = {Erman, Jeffrey and Mahanti, Anirban and Arlitt, Martin and Cohen, Ira and Williamson, Carey},
  title     = {Offline/realtime traffic classification using semi-supervised learning},
  journal   = {Performance Evaluation},
  year      = {2007},
  volume    = {64},
  number    = {9},
  pages     = {1194--1213},
  publisher = {Elsevier},
}

@InProceedings{feragen2013geometric,
  author    = {Feragen, Aasa and Petersen, Jens and Grimm, Dominik and Dirksen, Asger and Pedersen, Jesper Holst and Borgwardt, Karsten and de Bruijne, Marleen},
  title     = {Geometric tree kernels: Classification of {COPD} from airway tree geometry},
  booktitle = {Information Processing in Medical Imaging},
  year      = {2013},
  pages     = {171--183},
}

@InProceedings{foncubierta2012ground,
  author       = {Foncubierta Rodr{\'\i}guez, Antonio and M{\"u}ller, Henning},
  title        = {Ground truth generation in medical imaging: a crowdsourcing-based iterative approach},
  booktitle    = {ACM Multimedia workshop on Crowdsourcing for Multimedia},
  year         = {2012},
  pages        = {9--14},
  organization = {ACM},
  file         = {foncubierta2012ground.pdf:foncubierta2012ground.pdf:PDF},
  issn         = {9781450315890},
  journal      = {Workshop on Crowdsourcing for Multimedia, ACM Multimedia},
  keywords     = {crowdsourcing, ground, information classification and retrieval},
}

@Article{foulds2011multi,
  author    = {Foulds, JR and Smyth, Padhraic},
  title     = {Multi-instance mixture models and semi-supervised learning},
  journal   = {SIAM International Conference on Data Mining},
  year      = {2011},
  number    = {Mi},
  pages     = {606--617},
  month     = apr,
  issn      = {9780898719925},
  booktitle = {International Conference on Data Mining},
  doi       = {10.1137/1.9781611972818.52},
  url       = {http://epubs.siam.org/doi/abs/10.1137/1.9781611972818.52},
}

@Article{foulds2010review,
  author    = {Foulds, J. and Frank, E.},
  title     = {A review of multi-instance learning assumptions},
  journal   = {Knowledge Engineering Review},
  year      = {2010},
  volume    = {25},
  number    = {1},
  pages     = {1},
  doi2      = {10.1017/S026988890999035X},
  file      = {foulds2010review.pdf:foulds2010review.pdf:PDF},
  publisher = {Cambridge Univ Press},
  url2      = {http://www.journals.cambridge.org/abstract_S026988890999035X},
}

@Article{gehler2007deterministic,
  author    = {Gehler, P. V. and Chapelle, O.},
  title     = {Deterministic annealing for multiple-instance learning},
  journal   = {International Conference on Artificial intelligence and Statistics},
  year      = {2007},
  pages     = {123--130},
  abstract  = {In this paper we apply deterministic annealing to different SVM formulations of the multipleinstance learning (MIL) problem. These nonconvex problems are typically solved using heuristic methods. The replacement of the integer programming formulation of the SVM formulations for MIL opens up the possibility to extend the scope of SVMs for this problem and we present a way to extend the objective function in order to incorporate more prior knowledge about the data at hand. In the experimental section we evaluate our method and compare it to the existing formulations showing that a better objective function not always translates into a better test error for datasets of little ambiguity.},
  booktitle = {International Conference on Artificial Intelligence and Statistics},
  file      = {gehler2007deterministic.pdf:gehler2007deterministic.pdf:PDF},
  keywords  = {Learning/Statistics \& Optimisation},
  url       = {http://eprints.pascal-network.org/archive/00002970/},
}

@Conference{gartner2003graph,
  author    = {G{\"a}rtner, T. and Flach, P. A. and Wrobel, S.},
  title     = {{On Graph Kernels: Hardness Results and Efficient Alternatives}},
  booktitle = {Computational Learning Theory},
  year      = {2003},
  publisher = {Springer Verlag},
  file      = {gartner2003graph.pdf:gartner2003graph.pdf:PDF},
}

@InProceedings{kandemir2014empowering,
  author    = {Kandemir, Melih and Zhang, Chong and Hamprecht, Fred A},
  title     = {Empowering multiple instance histopathology cancer diagnosis by cell graphs},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year      = {2014},
  volume    = {8674},
  pages     = {228--235},
  doi2      = {10.1007/978-3-319-10470-6_29},
  groups    = {Not-so-supervised papers},
  issn2     = {978-3-319-10470-6; 978-3-319-10469-0},
  journal   = {Medical Image Computing and Computer-Assisted Intervention - Miccai 2014, Pt Ii},
  url2      = {http://link.springer.com/10.1007/978-3-319-10470-6_29},
}

@Article{kovashka2016crowdsourcing,
  author    = {Kovashka, Adriana and Russakovsky, Olga and Fei-Fei, Li and Grauman, Kristen and others},
  title     = {Crowdsourcing in Computer Vision},
  journal   = {Foundations and Trends{\textregistered} in Computer Graphics and Vision},
  year      = {2016},
  volume    = {10},
  number    = {3},
  pages     = {177--243},
  abstract  = {The Path to Path-Traced Movies},
  annote    = {what to crowdsource (image label, bounding box, attributes,...)how to crowdsource (selecting annotators)which data to crowdsource (reduce labelling efforts, active/interactive learning)mentions the word biomedical 1x (Danna's work)similarities in 7 or 8 out of 195 papers:1) Tamuz et al. [2011] learn a kernel matrix that captures all pairwisesimilarities between objects.--{\textgreater} Algorithm to learn matrix from triplet comparisons. With kernel matrix, SVM classification.2) Wah et al. [2014] also ask the user to compare similarity, by marking which of a set of images is most similar to the query image.3) Wah et al. [2015] request similarity comparisons on localized image patchesof bird species. They first select discriminative regions, then model the probability that particular images show these regions, so they can determine which images to display to the user.--{\textgreater}Both of these learn similarity from either global or local comparisons, then visualize similarity embedding. At test time can retrieve most similar examples. Wah et al. [2015] is a bit like MIL, because discriminative patches from larger images are used.4) Wilber et al. [2015] obtain an intuitive concept embedding by jointly optimizing an automatic low-dimensional embedding objective, as well as maximizing the probability of satisfying a set of human-given similarity triplet constraints.--{\textgreater} Combines t-SNE (based on features) with triplet embedding (based on expert hints like similarities)5) Gomes et al. [2011] use individual users? notions of similarity to dis-cover object categories. Their method labels a large set of images with newly discovered categories, from user-given similarity/dissimilarity constraints--{\textgreater} Novel model of human clustering, as well as a novel machine learning method to aggregate worker annotations6) Janssens [2010] also integrate judgement on only a small set of images into a global judgement.--{\textgreater} Aggregate rankings into a global ranking7) Wilson et al. [2015] model how humans perform machine tasks, likeextrapolating from function plots and finding the best fit to the data.--{\textgreater} Not relevant for similarities?8) Lee and Cran-dall [2014] develop a system for tree identification that solicits humans for similarity feedback (which trees appear similar to a query tree)--{\textgreater} Learn similarity matrix adaptively},
  doi       = {10.1561/0600000073},
  file      = {kovashka2016crowdsourcing.pdf:kovashka2016crowdsourcing.pdf:PDF},
  groups    = {Veni},
  keywords  = {Computer Graphics, Rendering, Rendering: Forward rendering},
  publisher = {Now Publishers, Inc.},
}

@Article{lee2012bridging,
  author    = {Lee, Wan-Jui and Cheplygina, Veronika and Tax, David M J and Loog, Marco and Duin, Robert P W},
  title     = {Bridging structure and feature representations in graph matching},
  journal   = {International Journal of Pattern Recognition and Artificial Intelligence},
  year      = {2012},
  volume    = {26},
  number    = {05},
  abstract  = {Structures and features are opposite approaches in building representations for object recognition. Bridging the two is an essential problem in pattern recognition as the two opposite types of information are fundamentally different. As dissimilarities can be computed for both the dissimilarity representation can be used to combine the two. Attributed graphs contain structural as well as feature-based information. Neglecting the attributes yields a pure structural description. Isolating the features and neglecting the structure represents objects by a bag of features. In this paper we will show that weighted combinations of dissimilarities may perform better than these two extremes, indicating that these two types of information are essentially different and strengthen each other. In addition we present two more advanced integrations than weighted combining and show that these may improve the classification performances even further. © 2012 World Scientific Publishing Company.},
  doi       = {10.1142/S0218001412600051},
  groups    = {My papers},
  publisher = {World Scientific},
}

@InProceedings{li2010convex,
  author    = {Li, F. and Sminchisescu, C.},
  title     = {Convex multiple-instance learning by estimating likelihood ratio},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2010},
  pages     = {1360--1368},
  file      = {li2010convex.pdf:li2010convex.pdf:PDF},
}

@InCollection{lindner2012accurate,
  author    = {Lindner, Claudia and Thiagarajah, S and Wilkinson, J Mark and Wallis, Gillian A and Cootes, Timothy F and {arcOGEN Consortium} and others},
  title     = {Accurate fully automatic femur segmentation in pelvic radiographs using regression voting},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  publisher = {Springer},
  year      = {2012},
  pages     = {353--360},
  note      = {DOI: 10.1007/978-3-642-33454-2\_44},
  url       = {http://link.springer.com/10.1007/978-3-642-33454-2_44},
}

@InCollection{maier2014can,
  author    = {Maier-Hein, Lena and Mersmann, Sven and Kondermann, Daniel and Bodenstedt, Sebastian and Sanchez, Alexandro and Stock, Christian and Kenngott, Hannes Gotz and Eisenmann, Mathias and Speidel, Stefanie},
  title     = {Can Masses of Non-Experts Train Highly Accurate Image Classifiers?},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  publisher = {Springer},
  year      = {2014},
  pages     = {438--445},
  file      = {maier2014can.pdf:maier2014can.pdf:PDF},
  groups    = {Veni},
}

@Article{maier2015crowdtruth,
  author   = {Maier-Hein, Lena and Kondermann, Daniel and Ro{\ss}, Tobias and Mersmann, Sven and Heim, Eric and Bodenstedt, Sebastian and Kenngott, Hannes G{\"o}tz and Sanchez, Alexandro and Wagner, Martin and Preukschas, Anas and others},
  title    = {Crowdtruth validation: a new paradigm for validating algorithms that rely on image correspondences},
  journal  = {International Journal of Computer Assisted Radiology and Surgery},
  year     = {2015},
  volume   = {10},
  number   = {8},
  pages    = {1201--1212},
  abstract = {PURPOSE: Feature tracking and 3D surface reconstruction are key enabling techniques to computer-assisted minimally invasive surgery. One of the major bottlenecks related to training and validation of new algorithms is the lack of large amounts of annotated images that fully capture the wide range of anatomical/scene variance in clinical practice. To address this issue, we propose a novel approach to obtaining large numbers of high-quality reference image annotations at low cost in an extremely short period of time. METHODS: The concept is based on outsourcing the correspondence search to a crowd of anonymous users from an online community (crowdsourcing) and comprises four stages: (1) feature detection, (2) correspondence search via crowdsourcing, (3) merging multiple annotations per feature by fitting Gaussian finite mixture models, (4) outlier removal using the result of the clustering as input for a second annotation task. RESULTS: On average, 10,000 annotations were obtained within 24 h at a cost of \$100. The annotation of the crowd after clustering and before outlier removal was of expert quality with a median distance of about 1 pixel to a publically available reference annotation. The threshold for the outlier removal task directly determines the maximum annotation error, but also the number of points removed. CONCLUSIONS: Our concept is a novel and effective method for fast, low-cost and highly accurate correspondence generation that could be adapted to various other applications related to large-scale data annotation in medical image computing and computer-assisted interventions.},
  doi2     = {10.1007/s11548-015-1168-3},
  file     = {maier2015crowdtruth.pdf:maier2015crowdtruth.pdf:PDF},
  groups   = {Veni},
  keywords = {Benchmarking, crowdsourcing, Endoscopy, Feature tracking, Image correspondences, Validation},
  url2     = {http://dx.doi.org/10.1007/s11548-015-1168-3},
}

@InCollection{maier2014crowdsourcing,
  author    = {Maier-Hein, Lena and Mersmann, Sven and Kondermann, Daniel and others},
  title     = {Crowdsourcing for reference correspondence generation in endoscopic images},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year      = {2014},
  volume    = {8674 LNCS},
  number    = {PART 2},
  pages     = {349--356},
  abstract  = {Computer-assisted minimally-invasive surgery (MIS) is often based on algorithms that require establishing correspondences between endoscopic images. However, reference annotations frequently required to train or validate a method are extremely difficult to obtain because they are typically made by a medical expert with very limited resources, and publicly available data sets are still far too small to capture the wide range of anatomical/scene variance. Crowdsourcing is a  new trend that is based on outsourcing cognitive tasks to many anonymous untrained individuals from an online community. To our knowledge, this paper is the first to investigate the concept of crowdsourcing in the context of endoscopic video image annotation for computer-assisted MIS. According to our study on publicly available in vivo data with manual reference annotations, anonymous non-experts obtain a median annotation error of 2 px (n = 10,000). By applying cluster analysis to multiple annotations per correspondence, this error  can be reduced to about 1 px, which is comparable to that obtained by medical experts (n = 500). We conclude that crowdsourcing is a viable method for generating high quality reference correspondences in endoscopic video images.},
  groups    = {Veni},
  journal2  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
}

@Article{nili2014toolbox,
  author   = {Nili, Hamed and Wingfield, Cai and Walther, Alexander and Su, Li and Marslen-Wilson, William and Kriegeskorte, Nikolaus},
  title    = {A toolbox for representational similarity analysis},
  journal  = {PLoS Comput. Biol},
  year     = {2014},
  volume   = {10},
  number   = {4},
  pages    = {e1003553},
  issn     = {1553-7358 (Electronic){\textbackslash}n1553-734X (Linking)},
  abstract = {Neuronal population codes are increasingly being investigated with multivariate pattern-information analyses. A key challenge is to use measured brain-activity patterns to test computational models of brain information processing. One approach to this problem is representational similarity analysis (RSA), which characterizes a representation in a brain or computational model by the distance matrix of the response patterns elicited by a set of stimuli. The representational distance matrix encapsulates what distinctions between stimuli are emphasized and what distinctions are de-emphasized in the representation. A model is tested by comparing the representational distance matrix it predicts to that of a measured brain region. RSA also enables us to compare representations between stages of processing within a given brain or model, between brain and behavioral data, and between individuals and species. Here, we introduce a Matlab toolbox for RSA. The toolbox supports an analysis approach that is simultaneously data- and hypothesis-driven. It is designed to help integrate a wide range of computational models into the analysis of multichannel brain-activity measurements as provided by modern functional imaging and neuronal recording techniques. Tools for visualization and inference enable the user to relate sets of models to sets of brain regions and to statistically test and compare the models using nonparametric inference methods. The toolbox supports searchlight-based RSA, to continuously map a measured brain volume in search of a neuronal population code with a specific geometry. Finally, we introduce the linear-discriminant t value as a measure of representational discriminability that bridges the gap between linear decoding analyses and RSA. In order to demonstrate the capabilities of the toolbox, we apply it to both simulated and real fMRI data. The key functions are equally applicable to other modalities of brain-activity measurement. The toolbox is freely available to the community under an open-source license agreement (http://www.mrc-cbu.cam.ac.uk/methods-and-resources/toolboxes/license/).},
  doi      = {10.1371/journal.pcbi.1003553},
  file     = {nili2014toolbox.pdf:nili2014toolbox.pdf:PDF},
}

@Article{quadrianto2009estimating,
  author    = {Quadrianto, Novi and Smola, Alex J and Caetano, Tib{\'e}rio S and Le, Quoc V},
  title     = {Estimating labels from label proportions},
  journal   = {Journal of Machine Learning Research},
  year      = {2009},
  volume    = {10},
  pages     = {2349--2374},
  file      = {quadrianto2009estimating.pdf:quadrianto2009estimating.pdf:PDF},
  publisher = {JMLR. org},
}

@Article{ranard2014crowdsourcing,
  author    = {Ranard, Benjamin L and Ha, Yoonhee P and Meisel, Zachary F and Asch, David A and Hill, Shawndra S and Becker, Lance B and Seymour, Anne K and Merchant, Raina M},
  title     = {Crowdsourcing: harnessing the masses to advance health and medicine, a systematic review},
  journal   = {Journal of General Internal Medicine},
  year      = {2014},
  volume    = {29},
  number    = {1},
  pages     = {187--203},
  month     = jan,
  issn      = {1525-1497 (Electronic){\textbackslash}n0884-8734 (Linking)},
  abstract  = {OBJECTIVE: Crowdsourcing research allows investigators to engage thousands of people to provide either data or data analysis. However, prior work has not documented the use of crowdsourcing in health and medical research. We sought to systematically review the literature to describe the scope of crowdsourcing in health research and to create a taxonomy to characterize past uses of this methodology for health and medical research. DATA SOURCES: PubMed, Embase, and CINAHL through March 2013. STUDY ELIGIBILITY CRITERIA: Primary peer-reviewed literature that used crowdsourcing for health research. STUDY APPRAISAL AND SYNTHESIS METHODS: Two authors independently screened studies and abstracted data, including demographics of the crowd engaged and approaches to crowdsourcing. RESULTS: Twenty-one health-related studies utilizing crowdsourcing met eligibility criteria. Four distinct types of crowdsourcing tasks were identified: problem solving, data processing, surveillance/monitoring, and surveying. These studies collectively engaged a crowd of {\textgreater}136,395 people, yet few studies reported demographics of the crowd. Only one (5 \%) reported age, sex, and race statistics, and seven (33 \%) reported at least one of these descriptors. Most reports included data on crowdsourcing logistics such as the length of crowdsourcing (n = 18, 86 \%) and time to complete crowdsourcing task (n = 15, 71 \%). All articles (n = 21, 100 \%) reported employing some method for validating or improving the quality of data reported from the crowd. LIMITATIONS: Gray literature not searched and only a sample of online survey articles included. CONCLUSIONS AND IMPLICATIONS OF KEY FINDINGS: Utilizing crowdsourcing can improve the quality, cost, and speed of a research project while engaging large segments of the public and creating novel science. Standardized guidelines are needed on crowdsourcing metrics that should be collected and reported to provide clarity and comparability in methods.},
  doi       = {10.1007/s11606-013-2536-8},
  keywords  = {1, 10, 29, 187, 203, 1007, citizen, citizen scientist, crowdsourcing, crowd sourcing, doi, human computing, j gen intern med, s11606-013-2536-8, science},
  publisher = {Springer},
  url       = {http://link.springer.com/10.1007/s11606-013-2536-8},
}

@Article{russakovsky2015best,
  author    = {Russakovsky, Olga and Li, Li-Jia Jia and Fei-Fei, Li},
  title     = {Best of both worlds: {Human}-machine collaboration for object annotation},
  journal   = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  year      = {2015},
  volume    = {07-12-June},
  pages     = {2121--2131},
  issn      = {9781467369640},
  abstract  = {?? ?? ?? object? localization ?? ?? ???? ???? ??. ???? ????? ???? ??? ?? ??? object? detection ?? ? ?? annotation? image? ???? ??? annotation? object? ??? ???},
  booktitle = {Computer Vision and Pattern Recognition (CVPR)},
  doi       = {10.1109/CVPR.2015.7298824},
  file      = {russakovsky2015best.pdf:russakovsky2015best.pdf:PDF},
}

@Article{rudyanto2014comparing,
  author    = {Rudyanto, Rina D and Kerkstra, Sjoerd and Van Rikxoort, Eva M and Fetita, Catalin and Brillet, Pierre-Yves and Lefevre, Christophe and Xue, Wenzhe and Zhu, Xiangjun and Liang, Jianming and {\"O}ks{\"u}z, {\.I}lkay and others},
  title     = {Comparing algorithms for automated vessel segmentation in computed tomography scans of the lung: the {VESSEL12} study},
  journal   = {Medical Image Analysis},
  year      = {2014},
  volume    = {18},
  number    = {7},
  pages     = {1217--1232},
  issn      = {1361-8423 (Electronic){\textbackslash}r1361-8415 (Linking)},
  abstract  = {The VESSEL12 (VESsel SEgmentation in the Lung) challenge objectively compares the performance of different algorithms to identify vessels in thoracic computed tomography (CT) scans. Vessel segmentation is fundamental in computer aided processing of data generated by 3D imaging modalities. As manual vessel segmentation is prohibitively time consuming, any real world application requires some form of automation. Several approaches exist for automated vessel segmentation, but judging their relative merits is difficult due to a lack of standardized evaluation. We present an annotated reference dataset containing 20 CT scans and propose nine categories to perform a comprehensive evaluation of vessel segmentation algorithms from both academia and industry. Twenty algorithms participated in the VESSEL12 challenge, held at International Symposium on Biomedical Imaging (ISBI) 2012. All results have been published at the VESSEL12 website http://vessel12.grand-challenge.org. The challenge remains ongoing and open to new participants. Our three contributions are: (1) an annotated reference dataset available online for evaluation of new algorithms; (2) a quantitative scoring system for objective comparison of algorithms; and (3) performance analysis of the strengths and weaknesses of the various vessel segmentation methods in the presence of various lung diseases. ?? 2014 .},
  doi       = {10.1016/j.media.2014.07.003},
  keywords  = {Algorithm comparison, Lung vessels, Thoracic computed tomography},
  publisher = {Elsevier},
}

@Article{schneider2015joint,
  author    = {Schneider, Matthias and Hirsch, Sven and Weber, Bruno and Székely, Gábor and Menze, Bjoern H.},
  title     = {Joint 3-{D} vessel segmentation and centerline extraction using oblique {Hough} forests with steerable filters},
  journal   = {Medical Image Analysis},
  year      = {2015},
  volume    = {19},
  number    = {1},
  pages     = {220--249},
  abstract  = {CONTRIBUTIONS
We propose a novel framework for joint 3-D vessel segmentation and centerline extraction. The approach is based on multivariate Hough voting and oblique random forests (RFs) that we learn from noisy annotations. It relies on steerable filters for the efficient computation of local image features at different scales and orientations.

EXPERIMENTS
We validate both the segmentation performance and the centerline accuracy of our approach both on synthetic vascular data and four 3-D imaging datasets of the rat visual cortex at 700nm resolution. First, we evaluate the most important structural components of our approach: (1) Orthogonal subspace filtering in comparison to steerable filters that show, qualitatively, similarities to the eigenspace filters learned from local image patches. (2) Standard RF against oblique RF. Second, we compare the overall approach to different state-of-the-art methods for (1) vessel segmentation based on optimally oriented flux (OOF) and the eigenstructure of the Hessian, and (2) centerline extraction based on homotopic skeletonization and geodesic path tracing.

RESULTS
Our experiments reveal the benefit of steerable over eigenspace filters as well as the advantage of oblique split directions over univariate orthogonal splits. We further show that the learning-based approach outperforms different state-of-the-art methods and proves highly accurate and robust with regard to both vessel segmentation and centerline extraction in spite of the high level of label noise in the training data.},
  doi       = {10.1016/j.media.2014.09.007},
  publisher = {Elsevier},
}

@InProceedings{schnitzer2014choosing,
  author    = {Schnitzer, Dominik and Flexer, Arthur},
  title     = {Choosing the Metric in High--Dimensional Spaces Based on Hub Analysis},
  booktitle = {European Symposium on Artificial Neural Networks (ESANN)},
  year      = {2014},
  abstract  = {To avoid the undesired effects of distance concentration in high-dimensional spaces, previous work has already advocated the use of fractional p norms instead of the ubiquitous Euclidean norm. Closely re-lated to concentration is the emergence of hub and anti-hub objects. Hub objects have a small distance to an exceptionally large number of data points while anti-hubs lie far from all other data points. The contribution of this work is an empirical examination of concentration and hubness, re-sulting in an unsupervised approach for choosing an p norm by minimizing hubs while simultaneously maximizing nearest neighbor classification.},
}

@Article{thirion2015correlations,
  author   = {Thirion, Bertrand and Pedregosa, Fabian and Eickenberg, Michael and Thirion, Bertrand and Pedregosa, Fabian and Eickenberg, Michael},
  title    = {Correlations of correlations are not reliable statistics : implications for multivariate pattern analysis . {To} cite this version : implications for multivariate pattern analysis .},
  year     = {2015},
  abstract = {Representational Similarity Analysis is a popular framework to flexibly represent the statistical dependencies between multi-voxel patterns on the one hand, and sensory or cognitive stimuli on the other hand. It has been used in an inferen-tial framework, whereby significance is given by a permutation test on the samples. In this paper , we outline an issue with this statistical procedure: namely that the so-called pattern similarity used can be influenced by various effects, such as noise variance, which can lead to inflated type I error rates. What we propose is to rely instead on proper linear models.},
  file     = {thirion2015correlations.pdf:thirion2015correlations.pdf:PDF},
  keywords = {functional neuroimaging, inference, machine learning, Pattern analysis, Statistics},
}

@Article{vanwinckelen2016instance,
  author    = {Vanwinckelen, Gitte and Fierens, Daan and Blockeel, Hendrik and others},
  title     = {Instance-level accuracy versus bag-level accuracy in multi-instance learning},
  journal   = {Data Mining and Knowledge Discovery},
  year      = {2016},
  volume    = {30},
  number    = {2},
  pages     = {313--341},
  month     = mar,
  doi       = {10.1007/s10618-015-0416-z},
  groups    = {Veni},
  publisher = {Springer},
}

@Article{veta2014breast,
  author    = {Veta, Mitko and Pluim, Josien PW and van Diest, Paul J and Viergever, Max A},
  title     = {Breast cancer histopathology image analysis: A review},
  journal   = {IEEE Transactions on Biomedical Engineering},
  year      = {2014},
  volume    = {61},
  number    = {5},
  pages     = {1400--1411},
  issn      = {0018-9294},
  abstract  = {This paper presents an overview of methods that have been proposed for the analysis of breast cancer histopathology images. This research area has become particularly relevant with the advent of whole slide imaging (WSI) scanners, which can perform cost-effective and high-throughput histopathology slide digitization, and which aim at replacing the optical microscope as the primary tool used by pathologist. Breast cancer is the most prevalent form of cancers among women, and image analysis methods that target this disease have a huge potential to reduce the workload in a typical pathology lab and to improve the quality of the interpretation. This paper is meant as an introduction for nonexperts. It starts with an overview of the tissue preparation, staining and slide digitization processes followed by a discussion of the different image processing techniques and applications, ranging from analysis of tissue staining to computer-aided diagnosis, and prognosis of breast cancer patients. © 1964-2012 IEEE.},
  doi       = {10.1109/TBME.2014.2303852},
  file      = {veta2014breast.pdf:veta2014breast.pdf:PDF},
  keywords  = {*breast cancer/di [Diagnosis], *breast cancer/et [Etiology], *histopathology, *image analysis, adipose tissue, basophilia, Cancer diagnosis, cancer prognosis, cell cycle M phase, cell cycle phase, cell membrane, cell nucleus membrane, cell proliferation, chromatin, clinical feature, clinical practice, cytoplasm, eosin, eosinophilia, estrogen/ec [Endogenous Compound], fibroblast, follow up, gamma urogastrone/ec [Endogenous Compound], gene expression assay, gene expression profiling, hematoxylin, human, human epidermal growth factor 2/ec [Endogenous Com, Image Processing, Ki 67 antigen/ec [Endogenous Compound], lymphocyte, lymphocytic infiltration, microscopy, microtome, mitosis, pathologist, progesterone/ec [Endogenous Compound], Prostate cancer, review, staining, tissue preparation, tumor growth, unclassified drug, Workload},
  publisher = {IEEE},
  url       = {http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?reload=true&punumber=10%5Cnhttp://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=reference&D=emed12&NEWS=N&AN=2014301754},
}

@InProceedings{zhou2009multi,
  author       = {Zhou, Zhi-Hua and Sun, Yu-Yin and Li, Yu-Feng},
  title        = {Multi-instance learning by treating instances as non-{I}.{I}.{D}. samples},
  booktitle    = {Proceedings of the 26th {Annual} {International} {Conference} on {Machine} {Learning} - {ICML} '09},
  year         = {2009},
  pages        = {1--8},
  organization = {ACM},
  publisher    = {ACM Press},
  doi          = {10.1145/1553374.1553534},
  file         = {zhou2009multi.pdf:zhou2009multi.pdf:PDF},
  isbn         = {978-1-60558-516-1},
  url          = {http://portal.acm.org/citation.cfm?doid=1553374.1553534},
}

@Article{bickel2009discriminative,
  author   = {Bickel, Steffen and Br{\"u}ckner, Michael and Scheffer, Tobias},
  title    = {Discriminative learning under covariate shift},
  journal  = {Journal of Machine Learning Research},
  year     = {2009},
  volume   = {10},
  number   = {Sep},
  pages    = {2137--2155},
  issn     = {1532-4435},
  abstract = {We address classification problems for which the training instances{\textbackslash}nare governed by an input distribution that is allowed to differ{\textbackslash}narbitrarily from the test distribution---problems also referred to as{\textbackslash}nclassification under covariate shift.  We derive a solution that is{\textbackslash}npurely discriminative: neither training nor test distribution are{\textbackslash}nmodeled explicitly.  The problem of learning under covariate shift can{\textbackslash}nbe written as an integrated optimization problem. Instantiating the{\textbackslash}ngeneral optimization problem leads to a kernel logistic regression and{\textbackslash}nan exponential model classifier for covariate shift.  The optimization{\textbackslash}nproblem is convex under certain conditions; our findings also clarify{\textbackslash}nthe relationship to the known kernel mean matching procedure.  We{\textbackslash}nreport on experiments on problems of spam filtering, text{\textbackslash}nclassification, and landmine detection.},
  file     = {bickel2009discriminative.pdf:bickel2009discriminative.pdf:PDF},
  groups   = {Veni},
  keywords = {covariate shift, discriminative learning, Transfer learning},
  url      = {http://jmlr.csail.mit.edu/papers/v10/bickel09a.html%5Cnhttp://www.jmlr.org/papers/volume10/bickel09a/bickel09a.pdf},
}

@Article{chen2006miles,
  author    = {Chen, Y. and Bi, J. and Wang, J.Z.},
  title     = {{MILES}: Multiple-instance learning via embedded instance selection},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year      = {2006},
  volume    = {28},
  number    = {12},
  pages     = {1931--1947},
  publisher = {IEEE},
}

@InProceedings{cheplygina2013combining,
  author    = {Cheplygina, Veronika and Tax, David M. J. and Loog, Marco},
  title     = {Combining instance information to classify bags},
  booktitle = {Multiple Classifier Systems},
  year      = {2013},
  volume    = {7872 LNCS},
  pages     = {13--24},
  publisher = {Springer},
  abstract  = {Multiple Instance Learning is concerned with learning from sets (bags) of feature vectors (instances), where the bags are labeled, but the instances are not. One of the ways to classify bags is using a (dis)similarity space, where each bag is represented by its dissimilarities to certain prototypes, such as bags or instances from the training set. The instance-based representation preserves the most information, but is very high-dimensional, whereas the bag-based representation has lower dimensionality, but risks throwing away important information. We show a connection between these representations and propose an alternative representation based on combining classifiers, which can potentially combine the advantages of the other methods. The performances of the ensemble classifiers are disappointing, but require further investigation. The bag-based representation preserves sufficient information to classify bags correctly and produces the best results on several datasets. © Springer-Verlag 2013.},
  doi       = {10.1007/978-3-642-38067-9_2},
  groups    = {My papers},
  isbn      = {978-3-642-38066-2},
}

@InProceedings{cheplygina2014classification,
  author    = {Cheplygina, Veronika and S{\o}rensen, Lauge and Tax, David M J and Pedersen, Jesper Holst and Loog, Marco and De Bruijne, Marleen},
  title     = {Classification of {COPD} with multiple instance learning},
  booktitle = {{International} {Conference} on {Pattern} {Recognition} (ICPR)},
  year      = {2014},
  pages     = {1508--1513},
  abstract  = {?Chronic obstructive pulmonary disease (COPD) is a lung disease where early detection benefits the survival rate. COPD can be quantified by classifying patches of computed tomography images, and combining patch labels into an overall diagnosis for the image. As labeled patches are often not available, image labels are propagated to the patches, incorrectly labeling healthy patches in COPD patients as being affected by the disease. We approach quantification of COPD from lung images as a multiple instance learning (MIL) problem, which is more suitable for such weakly labeled data. We investigate various MIL assumptions in the context of COPD and show that although a concept region with COPD-related disease patterns is present, considering the whole distribution of lung tissue patches improves the performance. The best method is based on averaging instances and obtains an AUC of 0.742, which is higher than the previously reported best of 0.713 on the same dataset. Using the full training set further increases performance to 0.776, which is significantly higher (DeLong test) than previous results.},
  doi2      = {10.1109/ICPR.2014.268},
  groups    = {My papers},
  isbn2     = {978-1-4799-5208-3},
  keywords  = {Chronic obstructive pulmonary disease, Computer aided diagnosis, multiple instance learning, Supervised learning},
}

@Article{cheplygina2015on,
  author   = {Cheplygina, Veronika and Tax, David M J and Loog, Marco},
  title    = {On classification with bags, groups and sets},
  journal  = {Pattern Recognition Letters},
  year     = {2015},
  volume   = {59},
  pages    = {11--17},
  abstract = {Many classification problems can be difficult to formulate directly in terms of the traditional supervised setting, where both training and test samples are individual feature vectors. There are cases in which samples are better described by sets of feature vectors, that labels are only available for sets rather than individual samples, or, if individual labels are available, that these are not independent. To better deal with such problems, several extensions of supervised learning have been proposed, where either training and/or test objects are sets of feature vectors. However, having been proposed rather independently of each other, their mutual similarities and differences have hitherto not been mapped out. In this work, we provide an overview of such learning scenarios, propose a taxonomy to illustrate the relationships between them, and discuss directions for further research in these areas.},
  doi2     = {10.1016/j.patrec.2015.03.008},
  groups   = {My papers},
  keywords = {Group-based classification, Label dependencies, multiple instance learning, Set classification, Weakly labeled data},
}

@Article{zheng2013lp,
  author   = {Zheng, Liang and Wang, Shengjin and Liu, Ziqiong and Tian, Qi},
  title    = {Lp-{Norm} {IDF} for {Large} {Scale} {Image} {Search}},
  journal  = {Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on},
  year     = {2013},
  pages    = {1626--1633},
  issn     = {978-0-7695-4989-7},
  abstract = {The Inverse Document Frequency (IDF) is prevalently utilized in the Bag-of-Words based image search. The basic idea is to assign less weight to terms with high frequency, and vice versa. However, the estimation of visual word frequency is coarse and heuristic. Therefore, the effectiveness of the conventional IDF routine is marginal, and far from optimal. To tackle this problem, this paper introduces a novel IDF expression by the use of Lp-norm pooling technique. Carefully designed, the proposed IDF takes into account the term frequency, document frequency, the complexity of images, as well as the codebook information. Optimizing the IDF function towards optimal balancing between TF and pIDF weights yields the so-called Lp-norm IDF (pIDF). We show that the conventional IDF is a special case of our generalized version, and two novel IDFs, i.e. the average IDF and the max IDF, can also be derived from our formula. Further, by counting for the term-frequency in each image, the proposed Lp-norm IDF helps to alleviate the visual word burstiness phenomenon. Our method is evaluated through extensive experiments on three benchmark datasets (Oxford 5K, Paris 6K and Flickr 1M). We report a performance improvement of as large as 27.1\% over the baseline approach. Moreover, since the Lp-norm IDF is computed offline, no extra computation or memory cost is introduced to the system at all.},
  doi      = {10.1109/CVPR.2013.213},
  file     = {zheng2013lp.pdf:zheng2013lp.pdf:PDF},
  keywords = {bag-of-words based image search, codebook information, document frequency, document image processing, Estimation, Frequency estimation, Histograms, image complexity, Image retrieval, inverse document frequency, large scale image search, Lp-norm IDF expression, Lp-norm pooling technique, Natural language processing, pIDF weights, Quantization (signal), term frequency, TF weights, Time-frequency analysis, Visualization, visual word burstiness phenomenon, visual word frequency estimation},
  url      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6619057},
}

@InProceedings{gaertner2002multi,
  author    = {G{\"a}rtner, T. and Flach, P. A. and Kowalczyk, A. and Smola, A. J.},
  title     = {Multi-instance kernels},
  booktitle = {International Conference on Machine Learning},
  year      = {2002},
  pages     = {179--186},
  file      = {gartner2002multiinstance.pdf:gartner2002multiinstance.pdf:PDF},
}

@Article{zhou2007multi,
  author    = {Zhou, Zhi-Hua and Zhang, Min-Ling},
  title     = {Multi-instance multi-label learning with application to scene classification},
  journal   = {Advances in Neural Information Processing Systems},
  year      = {2007},
  volume    = {19},
  pages     = {1609},
  booktitle = {Advances in Neural Information Processing Systems},
  publisher = {MIT; 1998},
}

@InProceedings{xu2012multiple,
  author       = {Xu, Yan and Zhu, Jun-Yan and Chang, Eric and Tu, Zhuowen},
  title        = {Multiple clustered instance learning for histopathology cancer image classification, segmentation and clustering},
  booktitle    = {Computer Vision and Pattern Recognition},
  year         = {2012},
  pages        = {964--971},
  month        = jun,
  organization = {IEEE},
  publisher    = {IEEE},
  doi          = {10.1109/CVPR.2012.6247772},
  isbn         = {978-1-4673-1228-8},
  keywords     = {biological tissues, Biomedical imaging, Boosting, Cancer, cancer cells classification, cancer cells clustering, cancer cells segmentation, cancer tissue, Clustering algorithms, Colon, colon cancer, histopathology cancer image classification, histopathology cancer image clustering, histopathology cancer image segmentation, image classification, image-level classification, Image segmentation, medical image processing, multiple clustered instance learning, patch-level clustering, pattern clustering, pixel-level segmentation, Standards},
  url          = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6247772},
}

@InProceedings{viola2006multiple,
  author    = {Viola, P. and Platt, J. and Zhang, C.},
  title     = {Multiple instance boosting for object detection},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2006},
  volume    = {18},
  pages     = {1417},
  publisher = {Citeseer},
  abstract  = {A good image object detection algorithm is accurate, fast, and does not require exact locations of objects in a training set. We can create such an object detector by taking the architecture of the Viola-Jones detector cascade and training it with a new variant of boosting that we call MIL-Boost. MILBoost uses cost functions from the Multiple Instance Learn-ing literature combined with the AnyBoost framework. We adapt the feature selection criterion of MILBoost to optimize the performance of the Viola-Jones cascade. Experiments show that the detection rate is up to 1.6 times better using MILBoost. This increased detection rate shows the advantage of simultaneously learning the locations and scales of the objects in the training set along with the parameters of the classifier.},
}

@Article{ben2012multiple,
  author    = {Ben-Hur, A. and others},
  title     = {Multiple instance learning of Calmodulin binding sites},
  journal   = {Bioinformatics},
  year      = {2012},
  volume    = {28},
  number    = {18},
  pages     = {i416--i422},
  month     = sep,
  abstract  = {MOTIVATION Calmodulin (CaM) is a ubiquitously conserved protein that acts as a calcium sensor, and interacts with a large number of proteins. Detection of CaM binding proteins and their interaction sites experimentally requires a significant effort, so accurate methods for their prediction are important. RESULTS We present a novel algorithm (MI-1 SVM) for binding site prediction and evaluate its performance on a set of CaM-binding proteins extracted from the Calmodulin Target Database. Our approach directly models the problem of binding site prediction as a large-margin classification problem, and is able to take into account uncertainty in binding site location. We show that the proposed algorithm performs better than the standard SVM formulation, and illustrate its ability to recover known CaM binding motifs. A highly accurate cascaded classification approach using the proposed binding site prediction method to predict CaM binding proteins in Arabidopsis thaliana is also presented. AVAILABILITY Matlab code for training MI-1 SVM and the cascaded classification approach is available on request. CONTACT fayyazafsar@gmail.com or asa@cs.colostate.edu.},
  doi       = {10.1093/bioinformatics/bts416},
  publisher = {Oxford Univ Press},
  url       = {http://www.ncbi.nlm.nih.gov/pubmed/22962461},
}

@Article{jenatton2012multiscale,
  author    = {Jenatton, Rodolphe and Gramfort, Alexandre and Michel, Vincent and Obozinski, Guillaume and Eger, Evelyn and Bach, Francis and Thirion, Bertrand},
  title     = {Multiscale mining of fMRI data with hierarchical structured sparsity},
  journal   = {SIAM Journal on Imaging Sciences},
  year      = {2012},
  volume    = {5},
  number    = {3},
  pages     = {835--856},
  month     = may,
  booktitle = {2011 {International} {Workshop} on {Pattern} {Recognition} in {NeuroImaging}},
  doi       = {10.1109/PRNI.2011.15},
  isbn      = {978-1-4577-0111-5},
  keywords  = {Accuracy, Algorithm design and analysis, biomedical MRI, brain reading, Clustering algorithms, cognitive information, Convex optimization, Data mining, feature agglomeration, fMRI data, functional magnetic resonance imaging data, hierarchical models, hierarchical structured sparsity, inter-subject validation, inverse inference, Magnetic resonance imaging, medical image processing, multiscale mining, Prediction algorithms, Statistical learning, structured sparsity, univariate feature selection},
  publisher = {SIAM},
  url       = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5961256},
}

@InCollection{p?kalska2006non,
  author    = {P?kalska, El?bieta and Harol, Artsiom and Duin, Robert P. W. and Spillmann, Barbara and Bunke, Horst},
  title     = {Non-{Euclidean} or {Non}-metric {Measures} {Can} {Be} {Informative}},
  booktitle = {Structural, Syntactic and Statistical Pattern Recognition},
  publisher = {Springer Berlin Heidelberg},
  year      = {2006},
  pages     = {871--880},
  note      = {DOI: 10.1007/11815921\_96},
  url       = {http://link.springer.com/10.1007/11815921_96},
}

@InProceedings{plasencia2013informativeness,
  author    = {Yenisel {Plasencia Calana} and Veronika Cheplygina and Robert P. W. Duin and Edel Garc{\'\i}a-Reyes and Mauricio Orozco-Alzate and David M. J. Tax and Marco Loog},
  title     = {On the Informativeness of Asymmetric Dissimilarities},
  booktitle = {Similarity-Based Pattern Recognition},
  year      = {2013},
  volume    = {7953 LNCS},
  pages     = {75--89},
  publisher = {Springer},
  note      = {DOI: 10.1007/978-3-642-39140-8\_5},
  doi       = {10.1007/978-3-642-39140-8_5},
  groups    = {My papers},
  isbn      = {978-3-642-39139-2},
  issn      = {9783642391392},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
}

@InProceedings{plasenciacalana2012using,
  author    = {Plasencia Cala{\~{n}}a, Y. and Garc{\'\i}a Reyes, E. and Duin, R. P. W. and Orozco-Alzate, M.},
  title     = {On Using Asymmetry Information for Classification in Extended Dissimilarity Spaces.},
  booktitle = {Iberoamerican Congress on Pattern Recognition},
  year      = {2012},
  volume    = {7441},
  pages     = {503-510},
}

@Article{viergever2016surveya,
  author    = {Viergever, Max A. and Maintz, J.B. Antoine and Klein, Stefan and Murphy, Keelin and Staring, Marius and Pluim, Josien P.W.},
  title     = {A survey of medical image registration ? under review},
  journal   = {Medical Image Analysis},
  year      = {2016},
  volume    = {33},
  pages     = {140--144},
  issn      = {1361-8415},
  abstract  = {A retrospective view on the past two decades of the field of medical image registration is presented, guided by the article ?A survey of medical image registration? (Maintz and Viergever, 1998). It shows that the classification of the field introduced in that article is still usable, although some modifications to do justice to advances in the field would be due. The main changes over the last twenty years are the shift from extrinsic to intrinsic registration, the primacy of intensity-based registration, the breakthrough of nonlinear registration, the progress of inter-subject registration, and the availability of generic image registration software packages. Two problems that were called urgent already 20 years ago, are even more urgent nowadays: Validation of registration methods, and translation of results of image registration research to clinical practice. It may be concluded that the field of medical image registration has evolved, but still is in need of further development in various aspects.},
  doi       = {10.1016/j.media.2016.06.030},
  file      = {viergever2016survey.pdf:viergever2016survey.pdf:PDF},
  keywords  = {Medical image registration},
  publisher = {Elsevier},
}

@Article{tamuz2011adaptively,
  author   = {Tamuz, Omer and Liu, Ce and Belongie, Serge and Shamir, Ohad and Kalai, Adam Tauman},
  title    = {Adaptively {Learning} the {Crowd} {Kernel}},
  journal  = {Icml},
  year     = {2011},
  pages    = {9--9},
  month    = may,
  issn     = {9781605582054},
  abstract = {We introduce an algorithm that, given n objects, learns a similarity matrix over all n{\textasciicircum}2 pairs, from crowdsourced data alone. The algorithm samples responses to adaptively chosen triplet-based relative-similarity queries. Each query has the form "is object 'a' more similar to 'b' or to 'c'?" and is chosen to be maximally informative given the preceding responses. The output is an embedding of the objects into Euclidean space (like MDS); we refer to this as the "crowd kernel." SVMs reveal that the crowd kernel captures prominent and subtle features across a number of domains, such as "is striped" among neckties and "vowel vs. consonant" among letters.},
  doi      = {10.1145/1390156.1390207},
  file     = {tamuz2011adaptively.pdf:tamuz2011adaptively.pdf:PDF},
  url      = {http://arxiv.org/abs/1105.1033},
}

@Article{chyzhyk2015active,
  author    = {Chyzhyk, Darya and Dacosta-Aguayo, Rosal{\'\i}a and Matar{\'o}, Maria and Gra{\~n}a, Manuel},
  title     = {An active learning approach for stroke lesion segmentation on multimodal MRI data},
  journal   = {Neurocomputing},
  year      = {2015},
  volume    = {150},
  number    = {Part A},
  pages     = {26--36},
  issn      = {0925-2312},
  abstract  = {The segmentation of lesion tissue in brain images of stroke patients serves to identify the extent of the affected tissues, to perform prognosis on its recovery, and to measure its evolution in longitudinal studies. The different regions of the lesion may have different imaging contrast properties in different image modalities, making difficult the automation of the segmentation process. In this paper we consider an Active Learning selective sampling approach to build image data classifiers from multimodal MRI data to perform voxel based lesion segmentation. We report encouraging results over a dataset combining functional, anatomical and diffusion data.},
  doi       = {10.1016/j.neucom.2014.01.077},
  keywords  = {Active learning, Lesion segmentation, Multimodal MRI, Random forests, Stroke},
  publisher = {Elsevier},
}

@Article{haarromeny2016brain,
  author    = {ter Haar Romeny, Bart M and Bekkers, Erik J and Zhang, Jiong and Abbasi-Sureshjani, Samaneh and Huang, Fan and Duits, Remco and Dashtbozorg, Behdad and Berendschot, Tos TJM and Smit-Ockeloen, Iris and Eppenhof, Koen AJ and others},
  title     = {Brain-inspired algorithms for retinal image analysis},
  journal   = {Machine Vision and Applications},
  year      = {2016},
  volume    = {27},
  number    = {8},
  pages     = {1117--1135},
  keywords  = {2, diabetic retinopathy, multi-, orientation, orientation scores, retina, screening, se, tortuosity, vessel analysis},
  publisher = {Springer},
}

@InProceedings{cheplygina2012class,
  author    = {Cheplygina, V. and Tax, D. M. J. and Loog, M.},
  title     = {Class-dependent dissimilarity measures for multiple instance learning},
  booktitle = {Structural, Syntactic, and Statistical Pattern Recognition},
  year      = {2012},
  volume    = {7626 LNCS},
  pages     = {602--610},
  publisher = {Springer},
  abstract  = {Multiple Instance Learning (MIL) is concerned with learning from sets (bags) of feature vectors (instances), where the individual instance labels are ambiguous. In MIL it is often assumed that positive bags contain at least one instance from a so-called concept in instance space, whereas negative bags only contain negative instances. The classes in a MIL problem are therefore not treated in the same manner. One of the ways to classify bags in MIL problems is through the use of bag dissimilarity measures. In current dissimilarity approaches, such dissimilarity measures act on the bag as a whole and do not distinguish between positive and negative bags. In this paper we explore whether this is a reasonable approach and when and why a dissimilarity measure that is dependent on the bag label, might be more appropriate. © 2012 Springer-Verlag Berlin Heidelberg.},
  doi       = {10.1007/978-3-642-34166-3_66},
  groups    = {My papers},
  isbn      = {978-3-642-34165-6},
}

@Article{tulder2016combining,
  author    = {van Tulder, Gijs and de Bruijne, Marleen},
  title     = {Combining Generative and Discriminative Representation Learning for Lung CT Analysis With Convolutional Restricted Boltzmann Machines},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2016},
  volume    = {35},
  number    = {5},
  pages     = {1262--1272},
  month     = may,
  abstract  = {The choice of features greatly influences the performance of a tissue classification system. Despite this, many systems are built with standard, predefined filter banks that are not optimized for that particular application. Representation learning methods such as restricted Boltzmann machines may outperform these standard filter banks because they learn a feature description directly from the training data. Like many other representation learning methods, restricted Boltzmann machines are unsupervised and are trained with a generative learning objective; this allows them to learn representations from unlabeled data, but does not necessarily produce features that are optimal for classification. In this paper we propose the convolutional classification restricted Boltzmann machine, which combines a generative and a discriminative learning objective. This allows it to learn filters that are good both for describing the training data and for classification. We present experiments with feature learning for lung texture classification and airway detection in CT images. In both applications, a combination of learning objectives outperformed purely discriminative or generative learning, increasing, for instance, the lung tissue classification accuracy by 1 to 8 percentage points. This shows that discriminative learning can help an otherwise unsupervised feature learner to learn filters that are optimized for classification.},
  doi       = {10.1109/TMI.2016.2526687},
  keywords  = {deep learning, lung, machine learning, Neural network, pattern recognition and classification, representation learning, restricted Boltzmann machine, Segmentation, X-ray imaging and computed tomography},
  publisher = {IEEE},
  url       = {http://ieeexplore.ieee.org/document/7401039/},
}

@Article{tax2000combining,
  author    = {Tax, David M J and Van Breukelen, Martijn and Duin, Robert P W and Kittler, Josef},
  title     = {Combining multiple classifiers by averaging or by multiplying?},
  journal   = {Pattern Recognition},
  year      = {2000},
  volume    = {33},
  number    = {9},
  pages     = {1475--1485},
  file      = {tax2000combining.PDF:tax2000combining.PDF:PDF},
  publisher = {Elsevier},
}

@Article{mohamedhoesein2012computed,
  author    = {Mohamed Hoesein, Firdaus A.A. and van Rikxoort, Eva and van Ginneken, Bram and de Jong, Pim A. and Prokop, Mathias and Lammers, Jan-Willem J. and Zanen, Pieter},
  title     = {Computed tomography-quantified emphysema distribution is associated with lung function decline},
  journal   = {European Respiratory Journal},
  year      = {2012},
  volume    = {40},
  number    = {4},
  pages     = {844--850},
  publisher = {Eur Respiratory Soc},
}

@Article{cheplygina2016dissimilarity,
  author   = {Cheplygina, Veronika and Tax, David M. J. and Loog, Marco},
  title    = {Dissimilarity-based ensembles for multiple instance learning},
  journal  = {IEEE Transactions on Neural Networks and Learning Systems},
  year     = {2016},
  volume   = {27},
  number   = {6},
  pages    = {1379--1391},
  doi      = {10.1109/TNNLS.2015.2424254},
  groups   = {My papers},
  keywords = {Combining classifiers, Dissimilarity representation, multiple instance learning (MIL), Random subspace method (RSM)},
}

@Article{pkekalska2002dissimilarity,
  author    = {P{\k{e}}kalska, El{\.z}bieta and Duin, Robert P W},
  title     = {Dissimilarity representations allow for building good classifiers},
  journal   = {Pattern Recognition Letters},
  year      = {2002},
  volume    = {23},
  number    = {8},
  pages     = {943--956},
  publisher = {Elsevier},
}

@InCollection{kwitt2014doa,
  author    = {Kwitt, Roland and Hegenbart, Sebastian and Rasiwasia, Nikhil and Vécsei, Andreas and Uhl, Andreas},
  title     = {Do We Need Annotation Experts? A Case Study in Celiac Disease Classification},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  publisher = {Springer International Publishing},
  year      = {2014},
  pages     = {454--461},
  note      = {DOI: 10.1007/978-3-319-10470-6\_57},
  url       = {http://link.springer.com/10.1007/978-3-319-10470-6_57},
}

@Article{bergamo2010exploitinga,
  author    = {Bergamo, Alessandro},
  title     = {Exploiting weakly-labeled {Web} images to improve object classification : a domain adaptation approach},
  journal   = {Nips},
  year      = {2010},
  volume    = {1},
  pages     = {4--4},
  issn      = {9781617823800},
  abstract  = {In or- der to address this shortcoming, in recent years several authors have proposed to learn object classifiers from weakly-labeled Internet images, such as photos re- trieved by keyword-based image search engines.},
  booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
  file      = {bergamo2010exploiting.pdf:bergamo2010exploiting.pdf:PDF},
  isbn      = {978-1-61782-380-0},
  url       = {http://papers.nips.cc/paper/4064-exploiting-weakly-labeled-web-images-to-improve-object-classification-a-domain-adaptation-approach.pdf},
}

@InCollection{bunke2008graph,
  author    = {Bunke, Horst and Riesen, Kaspar},
  title     = {Graph classification based on dissimilarity space embedding},
  booktitle = {Structural, Syntactic, and Statistical Pattern Recognition},
  publisher = {Springer},
  year      = {2008},
  pages     = {996--1007},
}

@InProceedings{konyushkova2015introducing,
  author    = {Konyushkova, Ksenia and Sznitman, Raphael and Fua, Pascal},
  title     = {Introducing Geometry in Active Learning for Image Segmentation},
  booktitle = {International Conference on Computer Vision (ICCV)},
  year      = {2015},
  pages     = {2974--2982},
  doi       = {10.1109/ICCV.2015.340},
  journal   = {Proceedings of the IEEE International Conference on Computer Vision},
  url       = {http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Konyushkova_Introducing_Geometry_in_ICCV_2015_paper.html},
}

@Article{tragantedoo2011instancea,
  author    = {Tragante do O, Vinicius and Fierens, Daan and Blockeel, Hendrik},
  title     = {Instance-level accuracy versus bag-level accuracy in multi-instance learning},
  year      = {2011},
  pages     = {8--8},
  booktitle = {Benelux Conference on Artificial Intelligence},
  file      = {tragante2011instance.pdf:tragante2011instance.pdf:PDF},
}

@Article{ho1998random,
  author    = {Ho, Tin Kam},
  title     = {The random subspace method for constructing decision forests},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year      = {1998},
  volume    = {20},
  number    = {8},
  pages     = {832--844},
  file      = {ho1998random.pdf:ho1998random.pdf:PDF},
  publisher = {IEEE},
}

@InProceedings{platanios2014estimating,
  author    = {Platanios, A and Blum, Avrim and Mitchell, TM},
  title     = {Estimating Accuracy from Unlabeled Data},
  booktitle = {Uncertainty in Artificial Intelligence},
  year      = {2014},
}

@InProceedings{ghafoorian2015small,
  author    = {Ghafoorian, Mohsen and Karssemeijer, Nico and van Uden, Inge and de Leeuw, Frank E and Heskes, Tom and Marchiori, Elena and Platel, Bram},
  title     = {Small white matter lesion detection in cerebral small vessel disease},
  booktitle = {SPIE Medical Imaging},
  year      = {2015},
  editor    = {Hadjiiski, Lubomir M. and Tourassi, Georgia D.},
  volume    = {9414},
  pages     = {941411--941411},
  month     = mar,
  publisher = {International Society for Optics and Photonics},
  doi       = {10.1117/12.2081597},
  file      = {ghafoorian2015small.pdf:ghafoorian2015small.pdf:PDF},
  keywords  = {Alzheimer's Disease, Dementia, Diseases and disorders, Magnetism, Receivers, Tissues},
  url       = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2081597},
}

@Article{ithapu2014extracting,
  author    = {Ithapu, Vamsi and Singh, Vikas and Lindner, Christopher and Austin, Benjamin P and Hinrichs, Chris and Carlsson, Cynthia M and Bendlin, Barbara B and Johnson, Sterling C},
  title     = {Extracting and summarizing white matter hyperintensities using supervised segmentation methods in {Alzheimer}'s disease risk and aging studies},
  journal   = {Human Brain Mapping},
  year      = {2014},
  volume    = {35},
  number    = {8},
  pages     = {4219--4235},
  month     = feb,
  issn      = {1097-0193 (Electronic){\textbackslash}r1065-9471 (Linking)},
  abstract  = {Precise detection and quantification of white matter hyperintensities (WMH) observed in T2-weighted Fluid Attenuated Inversion Recovery (FLAIR) Magnetic Resonance Images (MRI) is of substantial interest in aging, and age-related neurological disorders such as Alzheimer's disease (AD). This is mainly because WMH may reflect co-morbid neural injury or cerebral vascular disease burden. WMH in the older population may be small, diffuse, and irregular in shape, and sufficiently heterogeneous within and across subjects. Here, we pose hyperintensity detection as a supervised inference problem and adapt two learning models, specifically, Support Vector Machines and Random Forests, for this task. Using texture features engineered by texton filter banks, we provide a suite of effective segmentation methods for this problem. Through extensive evaluations on healthy middle-aged and older adults who vary in AD risk, we show that our methods are reliable and robust in segmenting hyperintense regions. A measure of hyperintensity accumulation, referred to as normalized effective WMH volume, is shown to be associated with dementia in older adults and parental family history in cognitively normal subjects. We provide an open source library for hyperintensity detection and accumulation (interfaced with existing neuroimaging tools), that can be adapted for segmentation problems in other neuroimaging studies.},
  author2   = {Ithapu, Vamsi and Singh, Vikas and Lindner, Christopher and others},
  doi       = {10.1002/hbm.22472},
  file      = {ithapu2014extracting.pdf:ithapu2014extracting.pdf:PDF},
  keywords  = {Random forests, Segmentation, Support vector machines, White matter hyperintensities},
  publisher = {Wiley Online Library},
  url       = {http://doi.wiley.com/10.1002/hbm.22472},
}

@Article{boer2009white,
  author    = {de Boer, Renske and Vrooman, Henri A and van der Lijn, Fedde and Vernooij, Meike W and Ikram, M Arfan and van der Lugt, Aad and Breteler, Monique MB and Niessen, Wiro J},
  title     = {White matter lesion extension to automatic brain tissue segmentation on {MRI}},
  journal   = {NeuroImage},
  year      = {2009},
  volume    = {45},
  number    = {4},
  pages     = {1151--1161},
  issn      = {1095-9572 (Electronic){\textbackslash}n1053-8119 (Linking)},
  abstract  = {A fully automated brain tissue segmentation method is optimized and extended with white matter lesion segmentation. Cerebrospinal fluid (CSF), gray matter (GM) and white matter (WM) are segmented by an atlas-based k-nearest neighbor classifier on multi-modal magnetic resonance imaging data. This classifier is trained by registering brain atlases to the subject. The resulting GM segmentation is used to automatically find a white matter lesion (WML) threshold in a fluid-attenuated inversion recovery scan. False positive lesions are removed by ensuring that the lesions are within the white matter. The method was visually validated on a set of 209 subjects. No segmentation errors were found in 98\% of the brain tissue segmentations and 97\% of the WML segmentations. A quantitative evaluation using manual segmentations was performed on a subset of 6 subjects for CSF, GM and WM segmentation and an additional 14 for the WML segmentations. The results indicated that the automatic segmentation accuracy is close to the interobserver variability of manual segmentations. ?? 2009 Elsevier Inc. All rights reserved.},
  doi       = {10.1016/j.neuroimage.2009.01.011},
  keywords  = {Brain tissue segmentation, MRI, White matter hyperintensities, White matter lesions},
  publisher = {Elsevier},
}

@Article{geremia2011spatial,
  author    = {Geremia, Ezequiel and Clatz, Olivier and Menze, Bjoern H and Konukoglu, Ender and Criminisi, Antonio and Ayache, Nicholas},
  title     = {Spatial decision forests for MS lesion segmentation in multi-channel magnetic resonance images},
  journal   = {NeuroImage},
  year      = {2011},
  volume    = {57},
  number    = {2},
  pages     = {378--390},
  issn      = {3642157041},
  abstract  = {A new algorithm is presented for the automatic segmentation of Multiple Sclerosis (MS) lesions in 3D Magnetic Resonance (MR) images. It builds on a discriminative random decision forest framework to provide a voxel-wise probabilistic classification of the volume. The method uses multi-channel MR intensities (T1, T2, and FLAIR), knowledge on tissue classes and long-range spatial context to discriminate lesions from background. A symmetry feature is introduced accounting for the fact that some MS lesions tend to develop in an asymmetric way. Quantitative evaluation of the proposed methods is carried out on publicly available labeled cases from the MICCAI MS Lesion Segmentation Challenge 2008 dataset. When tested on the same data, the presented method compares favorably to all earlier methods. In an a posteriori analysis, we show how selected features during classification can be ranked according to their discriminative power and reveal the most important ones. ?? 2011 Elsevier Inc.},
  doi       = {10.1016/j.neuroimage.2011.03.080},
  keywords  = {MICCAI Grand Challenge 2008, Multiple sclerosis, Multi-sequence MRI, Random forests, Segmentation},
  publisher = {Elsevier},
}

@Article{pan2010survey,
  author    = {Pan, Sinno Jialin and Yang, Qiang},
  title     = {A survey on transfer learning},
  journal   = {IEEE Transactions on Knowledge and Data Engineering},
  year      = {2010},
  volume    = {22},
  number    = {10},
  pages     = {1345--1359},
  groups    = {Not-so-supervised general},
  publisher = {IEEE},
}

@Article{zhuang2010cross,
  author    = {Zhuang, Fuzhen and Luo, Ping and Xiong, Hui and Xiong, Yuhong and He, Qing and Shi, Zhongzhi},
  title     = {Cross-domain learning from multiple sources: a consensus regularization perspective},
  journal   = {IEEE Transactions on Knowledge and Data Engineering},
  year      = {2010},
  volume    = {22},
  number    = {12},
  pages     = {1664--1678},
  publisher = {IEEE},
}

@Article{warfield2004simultaneous,
  author    = {Warfield, Simon K and Zou, Kelly H and Wells, William M},
  title     = {Simultaneous truth and performance level estimation {(STAPLE)}: an algorithm for the validation of image segmentation},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2004},
  volume    = {23},
  number    = {7},
  pages     = {903--921},
  publisher = {IEEE},
}

@Article{chattopadhyay2012multisource,
  author    = {Chattopadhyay, Rita and Sun, Qian and Fan, Wei and Davidson, Ian and Panchanathan, Sethuraman and Ye, Jieping},
  title     = {Multisource domain adaptation and its application to early detection of fatigue},
  journal   = {ACM Transactions on Knowledge Discovery from Data},
  year      = {2012},
  volume    = {6},
  number    = {4},
  pages     = {18},
  publisher = {ACM},
}

@Article{ge2014handling,
  author    = {Ge, Liang and Gao, Jing and Ngo, Hung and Li, Kang and Zhang, Aidong},
  title     = {On handling negative transfer and imbalanced distributions in multiple source transfer learning},
  journal   = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  year      = {2014},
  volume    = {7},
  number    = {4},
  pages     = {254--271},
  issn      = {9781611972627},
  doi       = {10.1002/sam.11217},
  keywords  = {Imbalanced distribution, Multiple source, Negative transfer, Transfer learning},
  publisher = {Wiley Online Library},
}

@InProceedings{kamishima2009trbagg,
  author       = {Kamishima, Toshihiro and Hamasaki, Masahiro and Akaho, Shotaro},
  title        = {TrBagg: A simple transfer learning method and its application to personalization in collaborative tagging},
  booktitle    = {International Conference on Data Mining},
  year         = {2009},
  pages        = {219--228},
  organization = {IEEE},
  abstract     = {The aim of transfer learning is to improve prediction accuracy on a target task by exploiting the training examples for tasks that are related to the target one. Transfer learning has received more attention in recent years, because this technique is considered to be helpful in reducing the cost of labeling. In this paper, we propose a very simple approach to transfer learning: TrBagg, which is the extension of bagging. TrBagg is composed of two stages: Many weak classifiers are first generated as in standard bagging, and these classifiers are then filtered based on their usefulness for the target task. This simplicity makes it easy to work reasonably well without severe tuning of learning parameters. Further, our algorithm equips an algorithmic scheme to avoid negative transfer. We applied TrBagg to personalized tag prediction tasks for social bookmarks. Our approach has several convenient characteristics for this task such as adaptation to multiple tasks with low computational cost.},
  doi          = {10.1109/ICDM.2009.9},
  file         = {kamishima2009trbagg.pdf:kamishima2009trbagg.pdf:PDF},
  isbn         = {978-0-7695-3895-2},
  keywords     = {Bagging, Collaborative tagging, Ensemble learning, Personalization, Transfer learning},
}

@Article{zikic2014encoding,
  author    = {Zikic, D and Glocker, B and Criminisi, A},
  title     = {Encoding atlases by randomized classification forests for efficient multi-atlas label propagation},
  journal   = {Medical Image Analysis},
  year      = {2014},
  volume    = {18},
  number    = {8},
  pages     = {1262--1273},
  issn      = {1361-8423 (Electronic){\textbackslash}r1361-8415 (Linking)},
  abstract  = {We propose a method for multi-atlas label propagation (MALP) based on encoding the individual atlases by randomized classification forests. Most current approaches perform a non-linear registration between all atlases and the target image, followed by a sophisticated fusion scheme. While these approaches can achieve high accuracy, in general they do so at high computational cost. This might negatively affect the scalability to large databases and experimentation. To tackle this issue, we propose to use a small and deep classification forest to encode each atlas individually in reference to an aligned probabilistic atlas, resulting in an Atlas Forest (AF). Our classifier-based encoding differs from current MALP approaches, which represent each point in the atlas either directly as a single image/label value pair, or by a set of corresponding patches. At test time, each AF produces one probabilistic label estimate, and their fusion is done by averaging. Our scheme performs only one registration per target image, achieves good results with a simple fusion scheme, and allows for efficient experimentation. In contrast to standard forest schemes, in which each tree would be trained on all atlases, our approach retains the advantages of the standard MALP framework. The target-specific selection of atlases remains possible, and incorporation of new scans is straightforward without retraining. The evaluation on four different databases shows accuracy within the range of the state of the art at a significantly lower running time.},
  doi       = {10.1016/j.media.2014.06.010},
  keywords  = {Brain, Multi-atlas label propagation, Randomized forest, Segmentation},
  publisher = {Elsevier},
  url       = {http://dx.doi.org/10.1016/j.media.2014.06.010},
}

@Article{maillard2008automated,
  author    = {Maillard, Pauline and Delcroix, Nicolas and Crivello, Fabrice and Dufouil, Carole and Gicquel, Sebastien and Joliot, Marc and Tzourio-Mazoyer, Nathalie and Alp{\'e}rovitch, Annick and Tzourio, Christophe and Mazoyer, Bernard},
  title     = {An automated procedure for the assessment of white matter hyperintensities by multispectral (T1, T2, PD) MRI and an evaluation of its between-centre reproducibility based on two large community databases},
  journal   = {Neuroradiology},
  year      = {2008},
  volume    = {50},
  number    = {1},
  pages     = {31--42},
  month     = jan,
  issn      = {1432-1920 (Electronic){\textbackslash}r0028-3940 (Linking)},
  abstract  = {Introduction An automated procedure for the detection, quantification, localization and statistical mapping of white matter hyperintensities (WMH) on T2-weighted magnetic resonance (MR) images is presented and validated based on the results of a between-centre reproducibility study. Methods The first step is the identification of white matter (WM) tissue using a multispectral (T1, T2, PD) segmentation. In a second step, WMH are identified within the WM tissue by segmenting T2 images, isolating two different classes of WMH voxels ? low- and high-contrast WMH voxels, respectively. The reliability of the whole procedure was assessed by applying it to the analysis of two large MR imaging databases (n = 650 and n= 710, respectively) of healthy elderly subjects matched for demographic characteristics. Results Average overall WMH load and spatial distribution were found to be similar in the two samples, (1.81 and 1.79\% of the WM volume, respectively). White matter hyperintensity load was found to be significantly associated with both age and high blood pressure, with similar effects in both samples. With specific reference to the 650 subject cohort, we also found that WMH load provided by this automated procedure was significantly associated with visual grading of the severity of WMH, as assessed by a trained neurologist. Conclusion The results show that this method is sensitive, well correlated with semi-quantitative visual rating and highly reproducible.},
  annote    = {Two centers (650 and 710 subjects)T1, T2, PD modalitiesOnly intensity (univariate) per channelGaussian mixture modelMulti-class step (including WML and WM), refinement and postprocessing stepsTrain/test?Distributions WML\% for each center similar, similar correlations between WML\% and sex, age etc.{\textbackslash}cite\{maillard2008automated\} address between-center reproducibility of WML segmentation, but the method is applied per center, and the findings per center (such as correlation WML load and age) are compared and are found to be reproducible},
  doi       = {10.1007/s00234-007-0312-3},
  keywords  = {Aging, Hypertension, Reproducibility, T2 MRI, White matter hyperintensities},
  publisher = {Springer},
  url       = {http://link.springer.com/10.1007/s00234-007-0312-3},
}

@Article{jain2015automatic,
  author    = {Jain, Saurabh and Sima, Diana M and Ribbens, Annemie and Cambron, Melissa and Maertens, Anke and Van Hecke, Wim and De Mey, Johan and Barkhof, Frederik and Steenwijk, Martijn D and Daams, Marita and others},
  title     = {Automatic segmentation and volumetry of multiple sclerosis brain lesions from MR images},
  journal   = {NeuroImage: Clinical},
  year      = {2015},
  volume    = {8},
  pages     = {367--375},
  abstract  = {The location and extent of white matter lesions on magnetic resonance imaging (MRI) are important criteria for diagnosis, follow-up and prognosis of multiple sclerosis (MS). Clinical trials have shown that quantitative values, such as lesion volumes, are meaningful in MS prognosis. Manual lesion delineation for the segmentation of lesions is, however, time-consuming and suffers from observer variability. In this paper, we propose MSmetrix, an accurate and reliable automatic method for lesion segmentation based on MRI, independent of scanner or acquisition protocol and without requiring any training data. In MSmetrix, 3D T1-weighted and FLAIR MR images are used in a probabilistic model to detect white matter (WM) lesions as an outlier to normal brain while segmenting the brain tissue into grey matter, WM and cerebrospinal fluid. The actual lesion segmentation is performed based on prior knowledge about the location (within WM) and the appearance (hyperintense on FLAIR) of lesions. The accuracy of MSmetrix is evaluated by comparing its output with expert reference segmentations of 20 MRI datasets of MS patients. Spatial overlap (Dice) between the MSmetrix and the expert lesion segmentation is 0.67 ± 0.11. The intraclass correlation coefficient (ICC) equals 0.8 indicating a good volumetric agreement between the MSmetrix and expert labelling. The reproducibility of MSmetrix' lesion volumes is evaluated based on 10 MS patients, scanned twice with a short interval on three different scanners. The agreement between the first and the second scan on each scanner is evaluated through the spatial overlap and absolute lesion volume difference between them. The spatial overlap was 0.69 ± 0.14 and absolute total lesion volume difference between the two scans was 0.54 ± 0.58 ml. Finally, the accuracy and reproducibility of MSmetrix compare favourably with other publicly available MS lesion segmentation algorithms, applied on the same data using default parameter settings.},
  annote    = {MSmetrix, claim to be independent of scanner or acquisition protocol and not requiring training dataTissue segmentation, WML considered outliers of the WM classT1 and FLAIRGaussian distribution per tissue class, EM with outlier map. Outperforms two other unsupevised methodsOutlier refinement, several iterated steps.20 MS patients Amsterdam (same as Steenwijk et al paper), 10 MS patients BrusselsBrussels scanned twice, reproducibility assessedDiscussion:-against supervised methods because need to gather many different examples and noramlize images- results Steenwijk et al higher, but best-case scenario because supervised},
  doi       = {10.1016/j.nicl.2015.05.003},
  publisher = {Elsevier},
}

@Article{mayerhoefer2005texture,
  author    = {Mayerhoefer, Marius E and Breitenseher, Martin J and Kramer, Josef and Aigner, Nicolas and Hofmann, Siegfried and Materka, Andrzej},
  title     = {Texture analysis for tissue discrimination on T1-weighted MR images of the knee joint in a multicenter study: Transferability of texture features and comparison of feature selection methods and classifiers},
  journal   = {Journal of Magnetic Resonance Imaging},
  year      = {2005},
  volume    = {22},
  number    = {5},
  pages     = {674--680},
  month     = nov,
  annote    = {Multi-center study (3 centers)Texture features robustTrain / test set unclear},
  doi       = {10.1002/jmri.20429},
  keywords  = {computers, diagnostic aid, Image Processing, magnetic resonance (MR), Tissue characterization},
  publisher = {Wiley Online Library},
  url       = {http://doi.wiley.com/10.1002/jmri.20429},
}

@Article{heimann2014real,
  author    = {Heimann, Tobias and Mountney, Peter and John, Matthias and Ionasec, Razvan},
  title     = {Real-time ultrasound transducer localization in fluoroscopy images by transfer learning from synthetic training data},
  journal   = {Medical Image Analysis},
  year      = {2014},
  volume    = {18},
  number    = {8},
  pages     = {1320--1328},
  abstract  = {The fusion of image data from trans-esophageal echography (TEE) and X-ray fluoroscopy is attracting increasing interest in minimally-invasive treatment of structural heart disease. In order to calculate the needed transformation between both imaging systems, we employ a discriminative learning (DL) based approach to localize the TEE transducer in X-ray images. The successful application of DL methods is strongly dependent on the available training data, which entails three challenges: (1) the transducer can move with six degrees of freedom meaning it requires a large number of images to represent its appearance, (2) manual labeling is time consuming, and (3) manual labeling has inherent errors. This paper proposes to generate the required training data automatically from a single volumetric image of the transducer. In order to adapt this system to real X-ray data, we use unlabeled fluoroscopy images to estimate differences in feature space density and correct covariate shift by instance weighting. Two approaches for instance weighting, probabilistic classification and Kullback-Leibler importance estimation (KLIEP), are evaluated for different stages of the proposed DL pipeline. An analysis on more than 1900 images reveals that our approach reduces detection failures from 7.3\% in cross validation on the test set to zero and improves the localization error from 1.5 to 0.8. mm. Due to the automatic generation of training data, the proposed system is highly flexible and can be adapted to any medical device with minimal efforts.},
  doi2      = {10.1016/j.media.2014.04.007},
  file2     = {heimann2014realtime.pdf:heimann2014realtime.pdf:PDF},
  groups    = {Not-so-supervised papers},
  issn2     = {1361-8423 (Electronic){\textbackslash}r1361-8415 (Linking)},
  keywords  = {domain adaptation, Fluoroscopy, Object localization, Transfer learning, Ultrasound},
  language  = {eng},
  publisher = {Elsevier},
  url2      = {http://dx.doi.org/10.1016/j.media.2014.04.007},
}

@Article{shimodaira2000improving,
  author    = {Shimodaira, Hidetoshi},
  title     = {Improving predictive inference under covariate shift by weighting the log-likelihood function},
  journal   = {Journal of statistical planning and inference},
  year      = {2000},
  volume    = {90},
  number    = {2},
  pages     = {227--244},
  publisher = {Elsevier},
}

@Article{delong1988comparing,
  author    = {DeLong, Elizabeth R and DeLong, David M and Clarke-Pearson, Daniel L},
  title     = {Comparing the areas under two or more correlated receiver operating characteristic curves: a nonparametric approach},
  journal   = {Biometrics},
  year      = {1988},
  pages     = {837--845},
  publisher = {JSTOR},
}

@Article{wille2014emphysema,
  author    = {Wille, Mathilde Marie Winkler and Thomsen, Laura H and Dirksen, Asger and Petersen, Jens and Pedersen, Jesper Holst and Shaker, Saher B},
  title     = {Emphysema progression is visually detectable in low-dose CT in continuous but not in former smokers},
  journal   = {European radiology},
  year      = {2014},
  volume    = {24},
  number    = {11},
  pages     = {2692--2699},
  month     = nov,
  issn      = {1432-1084 (Electronic){\textbackslash}r0938-7994 (Linking)},
  abstract  = {OBJECTIVES: To evaluate interobserver agreement and time-trend in chest CT assessment of emphysema, airways, and interstitial abnormalities in a lung cancer screening cohort.{\textbackslash}n{\textbackslash}nMETHODS: Visual assessment of baseline and fifth-year examination of 1990 participants was performed independently by two observers. Results were standardised by means of an electronic score sheet; kappa and time-trend analyses were performed.{\textbackslash}n{\textbackslash}nRESULTS: Interobserver agreement was substantial in early emphysema diagnosis; highly significant (p?{\textless}?0.001) time-trends in both emphysema presence and grading were found (higher prevalence and grade of emphysema in late CT examinations). Significant progression in emphysema was seen in continuous smokers, but not in former smokers. Agreement on centrilobular emphysema subtype was substantial; agreement on paraseptal subtype, moderate. Agreement on panlobular and mixed subtypes was only fair. Agreement was fair regarding airway analysis. Interstitial abnormalities were infrequent in the cohort, and agreement on these was fair to moderate. A highly significant time-trend was found regarding interstitial abnormalities, which were more frequent in late examinations.{\textbackslash}n{\textbackslash}nCONCLUSIONS: Visual scoring of chest CT is able to characterise the presence, pattern, and progression of early emphysema. Continuous smokers progress; former smokers do not.{\textbackslash}n{\textbackslash}nKEY POINTS: ? Substantial interobserver consistency in determining early-stage emphysema in low-dose CT. ? Longitudinal analyses show clear time-trends for emphysema presence and grading. ? For continuous smokers, progression of emphysema was seen in all lung zones. ? For former smokers, progression of emphysema was undetectable by visual assessment. ? Onset and progression of interstitial abnormalities are visually detectable.},
  doi       = {10.1007/s00330-014-3294-7},
  file      = {wille2014emphysema.pdf:wille2014emphysema.pdf:PDF},
  keywords  = {a, b, Chronic Obstructive, Computed tomography, COPD, dirksen, disease progression, h, l, lung cancer screening, m, Observer Variation, Pulmonary Disease, s, shaker, thomsen, w, wille},
  publisher = {Springer},
  url       = {http://link.springer.com/10.1007/s00330-014-3294-7},
}

@Article{pauwels2012global,
  author    = {Pauwels, Romain A and Buist, A Sonia and Calverley, Peter M A and Jenkins, Christine R and Hurd, Suzanne S},
  title     = {Global strategy for the diagnosis, management, and prevention of chronic obstructive pulmonary disease},
  journal   = {Am. J. of Respir. and Crit. Care Med.},
  year      = {2012},
  volume    = {163},
  number    = {5},
  publisher = {American Thoracic Society},
}

@Article{gallardo2016normalizing,
  author    = {Gallardo-Estrella, Leticia and Lynch, David A and Prokop, Mathias and Stinson, Douglas and Zach, Jordan and Judy, Philip F and van Ginneken, Bram and van Rikxoort, Eva M},
  title     = {Normalizing computed tomography data reconstructed with different filter kernels: effect on emphysema quantification},
  journal   = {European radiology},
  year      = {2016},
  volume    = {26},
  number    = {2},
  pages     = {478--486},
  month     = feb,
  abstract  = {OBJECTIVES To propose and evaluate a method to reduce variability in emphysema quantification among different computed tomography (CT) reconstructions by normalizing CT data reconstructed with varying kernels. METHODS We included 369 subjects from the COPDGene study. For each subject, spirometry and a chest CT reconstructed with two kernels were obtained using two different scanners. Normalization was performed by frequency band decomposition with hierarchical unsharp masking to standardize the energy in each band to a reference value. Emphysema scores (ES), the percentage of lung voxels below -950 HU, were computed before and after normalization. Bland-Altman analysis and correlation between ES and spirometry before and after normalization were compared. Two mixed cohorts, containing data from all scanners and kernels, were created to simulate heterogeneous acquisition parameters. RESULTS The average difference in ES between kernels decreased for the scans obtained with both scanners after normalization (7.7 ± 2.7 to 0.3 ± 0.7; 7.2 ± 3.8 to -0.1 ± 0.5). Correlation coefficients between ES and FEV1, and FEV1/FVC increased significantly for the mixed cohorts. CONCLUSIONS Normalization of chest CT data reduces variation in emphysema quantification due to reconstruction filters and improves correlation between ES and spirometry. KEY POINTS ? Emphysema quantification is sensitive to the reconstruction kernel used. ? Normalization allows comparison of emphysema quantification from images reconstructed with varying kernels. ? Normalization allows comparison of emphysema quantification obtained with scanners from different manufacturers. ? Normalization improves correlation of emphysema quantification with spirometry. ? Normalization can be used to compare data from different studies and centers.},
  doi       = {10.1007/s00330-015-3824-y},
  keywords  = {Computed tomography, COPD, image reconstruction, Normalization, Pulmonary emphysema},
  publisher = {Springer},
  url       = {http://link.springer.com/10.1007/s00330-015-3824-y},
}

@Article{regan2011genetic,
  author    = {Regan, Elizabeth A and Hokanson, John E and Murphy, James R and Make, Barry and Lynch, David A and Beaty, Terri H and Curran-Everett, Douglas and Silverman, Edwin K and Crapo, James D},
  title     = {Genetic epidemiology of COPD (COPDGene) study design},
  journal   = {COPD: Journal of Chronic Obstructive Pulmonary Disease},
  year      = {2011},
  volume    = {7},
  number    = {1},
  pages     = {32--43},
  publisher = {Taylor \& Francis},
}

@Article{ginneken2011computer,
  author    = {van Ginneken, Bram and Schaefer-Prokop, Cornelia M and Prokop, Mathias},
  title     = {Computer-aided diagnosis: how to move from the laboratory to the clinic},
  journal   = {Radiology},
  year      = {2011},
  volume    = {261},
  number    = {3},
  pages     = {719--732},
  month     = dec,
  doi       = {10.1148/radiol.11091710},
  groups    = {Not-so-supervised general, Veni},
  publisher = {Radiological Society of North America, Inc.},
  url       = {http://pubs.rsna.org/doi/abs/10.1148/radiol.11091710},
}

@Article{tonnesen2013smoking,
  author    = {T{\o}nnesen, Philip},
  title     = {Smoking cessation and {COPD}},
  journal   = {European Respiratory Review},
  year      = {2013},
  volume    = {22},
  number    = {127},
  pages     = {37--43},
  publisher = {European Respiratory Society},
}

@Article{hardie2002risk,
  author    = {Hardie, J A and Buist, A S and Vollmer, W M and Ellingsen, I and Bakke, P S and M{\o}rkve, O},
  title     = {Risk of over-diagnosis of {COPD} in asymptomatic elderly never-smokers},
  journal   = {European Respiratory Journal},
  year      = {2002},
  volume    = {20},
  number    = {5},
  pages     = {1117--1122},
  publisher = {European Respiratory Society},
}

@Article{qaseem2011diagnosis,
  author    = {Qaseem, Amir and Wilt, Timothy J and Weinberger, Steven E and Hanania, Nicola A and Criner, Gerard and van der Molen, Thys and Marciniuk, Darcy D and Denberg, Tom and Schu?nemann, Holger and Wedzicha, Wisia and others},
  title     = {Diagnosis and management of stable chronic obstructive pulmonary disease: a clinical practice guideline update from the American College of Physicians, American College of Chest Physicians, American Thoracic Society, and European Respiratory Society},
  journal   = {Annals of Internal Medicine},
  year      = {2011},
  volume    = {155},
  number    = {3},
  pages     = {179--191},
  publisher = {American College of Physicians},
}

@Article{calverley2000copdearly,
  author    = {Calverley, Peter MA},
  title     = {{COPD}: Early detection and intervention},
  journal   = {{CHEST} Journal},
  year      = {2000},
  volume    = {117},
  number    = {5\_suppl\_2},
  pages     = {365S--371S},
  publisher = {American College of Chest Physicians},
}

@Article{park2008texture,
  author    = {Park, Yang Shin and Seo, Joon Beom and Kim, Namkug and Chae, Eun Jin and Oh, Yeon Mok and Do Lee, Sang and Lee, Youngjoo and Kang, Suk-Ho},
  title     = {Texture-based quantification of pulmonary emphysema on high-resolution computed tomography: comparison with density-based quantification and correlation with pulmonary function test},
  journal   = {Investigative Radiology},
  year      = {2008},
  volume    = {43},
  number    = {6},
  pages     = {395--402},
  publisher = {LWW},
}

@Article{botev2010kernel,
  author    = {Botev, Zdravko I and Grotowski, Joseph F and Kroese, Dirk P and others},
  title     = {Kernel density estimation via diffusion},
  journal   = {The Annals of Statistics},
  year      = {2010},
  volume    = {38},
  number    = {5},
  pages     = {2916--2957},
  issn      = {0090-5364},
  abstract  = {We present a new adaptive kernel density estimator based on linear diffusion processes. The proposed estimator builds on existing ideas for adaptive smoothing by incorporating information from a pilot density estimate. In addition, we propose a new plug-in bandwidth selection method that is free from the arbitrary normal reference rules used by existing methods. We present simulation examples in which the proposed approach outperforms existing methods in terms of accuracy and reliability.},
  doi       = {10.1214/10-AOS799},
  file      = {botev2010kernel.pdf:botev2010kernel.pdf:PDF},
  keywords  = {Bandwidth selection, Boundary bias, Data sharpening, Diffusion equation, Heat kernel, Langevin process, Nonparametric density estimation, Normal reference rules, Variable bandwidth},
  publisher = {Institute of Mathematical Statistics},
}

@Article{ginneken2002automatic,
  author  = {van Ginneken, Bram and Katsuragawa, Shigehiko and ter Haar Romeny, Bart M and Doi, Kunio and Viergever, Max A},
  title   = {Automatic detection of abnormalities in chest radiographs using local texture analysis},
  journal = {IEEE TMI},
  year    = {2002},
  volume  = {21},
  number  = {2},
  pages   = {139--149},
}

@Article{wolpert1996lack,
  author    = {Wolpert, David H},
  title     = {The lack of a priori distinctions between learning algorithms},
  journal   = {Neural computation},
  year      = {1996},
  volume    = {8},
  number    = {7},
  pages     = {1341--1390},
  publisher = {MIT Press},
}

@Article{decenciere2014feedback,
  author  = {Decenci{\`e}re, Etienne and Zhang, Xiwei and Cazuguel, Guy and Lay, Bruno and Cochener, B{\'e}atrice and Trone, Caroline and Gain, Philippe and Ordonez, Richard and Massin, Pascale and Erginay, Ali and Charton, B{\'e}atrice and Klein, Jean-Claude},
  title   = {Feedback on a publicly distributed image database: the {M}essidor database},
  journal = {Image Analysis and Stereology},
  year    = {2014},
  pages   = {231--234},
}

@InProceedings{kohlberger2012evaluating,
  author       = {Kohlberger, Timo and Singh, Vivek and Alvino, Chris and Bahlmann, Claus and Grady, Leo},
  title        = {Evaluating segmentation error without ground truth},
  booktitle    = {Medical Image Computing and Computer-Assisted Intervention},
  year         = {2012},
  pages        = {528--536},
  organization = {Springer},
}

@Article{athey2017beyond,
  author    = {Athey, Susan},
  title     = {Beyond prediction: Using big data for policy problems},
  journal   = {Science},
  year      = {2017},
  volume    = {355},
  number    = {6324},
  pages     = {483--485},
  publisher = {American Association for the Advancement of Science},
}

@Article{artaechevarria2009combination,
  author    = {Artaechevarria, Xabier and Munoz-Barrutia, Arrate and Ortiz-de-Sol{\'o}rzano, Carlos},
  title     = {Combination strategies in multi-atlas image segmentation: Application to brain MR data},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2009},
  volume    = {28},
  number    = {8},
  pages     = {1266--1277},
  publisher = {IEEE},
}

@Article{boedeker2004emphysema,
  author    = {Boedeker, Kirsten L and McNitt-Gray, Michael F and Rogers, Sarah R and Truong, Dao A and Brown, Matthew S and Gjertson, David W and Goldin, Jonathan G},
  title     = {Emphysema: Effect of Reconstruction Algorithm on CT Imaging Measures},
  journal   = {Radiology},
  year      = {2004},
  volume    = {232},
  number    = {1},
  pages     = {295--301},
  doi       = {10.1148/radiol.2321030383},
  publisher = {Radiological Society of North America},
}

@InCollection{cheng2012domain,
  author    = {Cheng, Bo and Zhang, Daoqiang and Shen, Dinggang},
  title     = {Domain transfer learning for {MCI} conversion prediction},
  booktitle = {Medical Image Computing and Computer-Assisted Interventions},
  publisher = {Springer},
  year      = {2012},
  pages     = {82--90},
  abstract  = {Abstract In recent studies of Alzheimer's disease (AD), it has increasing attentions in identifying mild cognitive impairment ( MCI ) converters ( MCI -C) from MCI non-converters ( MCI -NC). Note that MCI is a prodromal stage of AD, with possibility to convert to AD. Most ... {\textbackslash}n},
  file      = {cheng2012domain.pdf:cheng2012domain.pdf:PDF},
  issn      = {978-3-642-33414-6},
  journal   = {Medical Image Computing and Computer- ?},
  url       = {http://link.springer.com/chapter/10.1007/978-3-642-33415-3_11%5Cnpapers2://publication/uuid/9DEDD3BA-CBEF-4056-A88B-03DF3F697EDF},
}

@Article{cheng2015multimodal,
  author    = {Cheng, Bo and Liu, Mingxia and Suk, Heung-Il and Shen, Dinggang and {Alzheimer's Disease Neuroimaging Initiative}},
  title     = {Multimodal manifold-regularized transfer learning for {MCI} conversion prediction},
  journal   = {Brain imaging and behavior},
  year      = {2015},
  volume    = {9},
  number    = {4},
  pages     = {1--14},
  abstract  = {In recent studies of Alzheimer's disease (AD), it has increasing attentions in identifying mild cognitive impairment (MCI) converters (MCI-C) from MCI non-converters (MCI-NC). Note that MCI is a prodromal stage of AD, with possibility to convert to AD. Most traditional methods for MCI conversion prediction learn information only from MCI subjects (including MCI-C and MCI-NC), not from other related subjects, e.g., AD and normal controls (NC), which can actually aid the classification between MCI-C and MCI-NC. In this paper, we propose a novel domain-transfer learning method for MCI conversion prediction. Different from most existing methods, we classify MCI-C and MCI-NC with aid from the domain knowledge learned with AD and NC subjects as auxiliary domain to further improve the classification performance. Our method contains two key components: (1) the cross-domain kernel learning for transferring auxiliary domain knowledge, and (2) the adapted support vector machine (SVM) decision function construction for cross-domain and auxiliary domain knowledge fusion. Experimental results on the Alzheimer's Disease neuroimaging initiative (ADNI) database show that the proposed method can significantly improve the classification performance between MCI-C and MCI-NC, with aid of domain knowledge learned from AD and NC subjects.},
  doi2      = {10.1007/s11682-015-9356-x},
  file      = {cheng2015multimodal.pdf:cheng2015multimodal.pdf:PDF},
  groups    = {Not-so-supervised papers},
  issn2     = {9783319022666},
  keywords  = {Manifold regularization, Mild cognitive impairment conversion, Multimodal classification, Sample selection, semi-supervised learning, Transfer learning},
  publisher = {Springer},
}

@InCollection{guerrero2014manifold,
  author    = {Guerrero, Ricardo and Ledig, Christian and Rueckert, Daniel},
  title     = {Manifold alignment and transfer learning for classification of {Alzheimer's} disease},
  booktitle = {Machine Learning in Medical Imaging (MICCAI MLMI)},
  publisher = {Springer},
  year      = {2014},
  volume    = {8679},
  pages     = {77--84},
  abstract  = {© Springer International Publishing Switzerland 2014. Magnetic resonance (MR) images acquired at different field strengths have different intensity appearance and thus cannot be easily combined into a single manifold space. A framework to learn a joint low-dimensional representation of brain MR images, acquired either at 1.5 or 3 Tesla, is proposed. In this manifold subspace, knowledge can be shared and transfered between the two distinct but related datasets. The joint manifold subspace is built using an adaptation of Laplacian eigenmaps (LE) from a data-driven region of interest (ROI). The ROI is learned using sparse regression to perform simultaneous variable selection at multiple levels of alignment to the MNI152 template. Additionally, a stability selection re-sampling scheme is used to reduce sampling bias while learning the ROI. Knowledge about the intrinsic embedding coordinates of different instances, common to both feature spaces, is used to constrain their alignment in the joint manifold. Alzheimer?s Disease (AD) classification results obtained with the proposed approach are presented using data from more than 1500 subjects from ADNI-1, ADNI-GO and ADNI-2 datasets. Results calculated using the learned joint manifold in general outperform those obtained in each independent manifold. Accuracies calculated on ADNI-1 are comparable to other state-of-the-art approaches. To our knowledge, classification accuracies have not been reported before on the complete ADNI (-1, -GO and -2) cohort combined.},
  doi2      = {10.1007/978-3-319-10581-9_10},
  groups    = {Not-so-supervised papers},
  keywords  = {and daniel rueckert, biomedical image analysis group, christian ledig, for classification of alzheimer, ifold alignment and transfer, imperial college london, learning, ricardo guerrero, s disease},
  url2      = {http://link.springer.com/10.1007/978-3-319-10581-9_10},
}

@Article{hu2008no,
  author    = {Hu, Roland and Damper, Robert I},
  title     = {A No Panacea Theorem for classifier combination},
  journal   = {Pattern Recognition},
  year      = {2008},
  volume    = {41},
  number    = {8},
  pages     = {2665--2673},
  issn      = {0769525210},
  abstract  = {We introduce the 'No Panacea Theorem' (NPT) for multiple classifier combination, previously proved only in the case of two classifiers and two classes. In this paper, we extend the NPT to cases of multiple classifiers and multiple classes. We prove that if the combination function is continuous and diverse, there exists a situation in which the combination algorithm will give very bad performance. The proof relies on constructing 'pathological' probability density distributions that have high densities in particular areas such that the combination functions give incorrect classification. Thus, there is no optimal combination algorithm that is suitable in all situations. It can be seen from this theorem that the probability density functions (pdfs) play an important role in the performance of combination algorithms, so studying the pdfs becomes the first step of finding a good combination algorithm. Although devised for classifier combination, the NPT is also relevant to all supervised classification problems. © 2008 Elsevier Ltd. All rights reserved.},
  doi       = {10.1016/j.patcog.2008.01.022},
  file      = {hu2008no.pdf:hu2008no.pdf:PDF},
  keywords  = {Gaussian mixtures, 'No Free Lunch' theorems, Probability density functions},
  publisher = {Elsevier},
}

@Article{kloeppel2011comparison,
  author    = {Klöppel, Stefan and Abdulkadir, Ahmed and Hadjidemetriou, Stathis and Issleib, Sabine and Frings, Lars and Thanh, Thao Nguyen and Mader, Irina and Teipel, Stefan J. and Hüll, Michael and Ronneberger, Olaf},
  title     = {A comparison of different automated methods for the detection of white matter lesions in {MRI} data},
  journal   = {NeuroImage},
  year      = {2011},
  volume    = {57},
  number    = {2},
  pages     = {416--422},
  issn      = {1095-9572 (Electronic) 1053-8119 (Linking)},
  abstract  = {White matter hyperintensities (WMH) are the focus of intensive research and have been linked to cognitive impairment and depression in the elderly. Cumbersome manual outlining procedures make research on WMH labour intensive and prone to subjective bias.This study compares fully automated supervised detection methods that learn to identify WMH from manual examples against unsupervised approaches on the combination of FLAIR and T1 weighted images. Data were collected from ten subjects with mild cognitive impairment and another set of ten individuals who fulfilled diagnostic criteria for dementia. Data were split into balanced groups to create a training set used to optimize the different methods. Manual outlining served as gold standard to evaluate performance of the automated methods that identified each voxel either as intact or as part of a WMH.Otsu's approach for multiple thresholds which is based only on voxel intensities of the FLAIR image produced a high number of false positives at grey matter boundaries. Performance on an independent test set was similarly disappointing when simply applying a threshold to the FLAIR that was found from training data. Among the supervised methods, precision-recall curves of support vector machines (SVM) indicated advantages over the performance achieved by K-nearest-neighbor classifiers (KNN). The curves indicated a clear benefit from optimizing the threshold of the SVM decision value and the voting rule of the KNN. Best performance was reached by selecting training voxels according to their distance to the lesion boundary and repeated training after replacing the feature vectors from those voxels that did not form support vectors of the SVM.The study demonstrates advantages of SVM for the problem of detecting WMH at least for studies that include only FLAIR and T1 weighted images. Various optimization strategies are discussed and compared against each other. © 2011 Elsevier Inc.},
  author2   = {Kl{\"o}ppel, Stefan and Abdulkadir, Ahmed and others},
  doi       = {10.1016/j.neuroimage.2011.04.053},
  keywords  = {Dementia, Imaging, KNN, SVM, White matter hyperintensities},
  publisher = {Elsevier},
  url       = {http://dx.doi.org/10.1016/j.neuroimage.2011.04.053},
}

@InProceedings{kooi2014boosting,
  author       = {Kooi, Thijs and Karssemeijer, Nico},
  title        = {Boosting classification performance in computer aided diagnosis of breast masses in raw full-field digital mammography using processed and screen film images},
  booktitle    = {SPIE Medical Imaging},
  year         = {2014},
  editor       = {Aylward, Stephen and Hadjiiski, Lubomir M.},
  volume       = {9035},
  pages        = {90351B--90351B},
  month        = mar,
  organization = {International Society for Optics and Photonics},
  abstract     = {The introduction of Full-Field Digital Mammography (FFDM) in breast screening has brought with it several advantages in terms and processing facilities and image quality and Computer Aided Detection (CAD) systems are now sprouting that make use of this modality. A major drawback however, is that FFDM data is still relatively scarce and therefore, CAD system's performance are inhibited by a lack of training examples. In this paper, we explore the incorporation of more ubiquitous Screen Film Mammograms (SFM) and FFDM processed by the manufacturer, in training a system for the detection of tumour masses. We compute a small set of additional quantitative features in the raw data, that make explicit use of the log-linearity of the energy imparted on the detector in raw FFDM. We explore four di erent fusion methods: a weighted average, a majority vote, a convex combination of classi er outputs, based on the training error and an additional classi er, that combines the output of the three individual label estimates. Results are evaluated based on the Partial Area Under the Curve (PAUC) around a clinically relevant operating point. All fusion methods perform signi cantly better than any of the individual classi ers but we nd no signi cant di erence between the fusion techniques. © 2014 SPIE.},
  doi          = {10.1117/12.2042863},
  file         = {kooi2014boosting.pdf:kooi2014boosting.pdf:PDF},
  groups       = {Not-so-supervised papers},
  issn         = {9780819498281},
  journal      = {Progress in Biomedical Optics and Imaging - Proceedings of SPIE},
  keywords     = {Atomic force microscope, Atomic force microscopy, Boosting classification performance in computer ai, Breast, computer-aided diagnosis, Digital mammography, Image quality, Mammography, Sensors},
  url          = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2042863},
}

@InCollection{lombaert2014laplacian,
  author    = {Lombaert, Herve and Zikic, Darko and Criminisi, Antonio and Ayache, Nicholas},
  title     = {Laplacian Forests: Semantic Image Segmentation by Guided Bagging},
  booktitle = {Medical Image Computing and Computer-Assisted Interventions},
  publisher = {Springer},
  year      = {2014},
  volume    = {86741007},
  pages     = {496--504},
  doi       = {10.1007/978-3},
  journal   = {Polina Golland Nobuhiko Hata; Christian Barillot LNCS -Lecture Notes in Computer Science. {\textless}10},
  keywords  = {()},
  url       = {https://hal.inria.fr/hal-01009672},
}

@Article{vanschoren2014openml,
  author    = {Vanschoren, Joaquin and Van Rijn, Jan N and Bischl, Bernd and Torgo, Luis},
  title     = {OpenML: networked science in machine learning},
  journal   = {ACM SIGKDD Explorations Newsletter},
  year      = {2014},
  volume    = {15},
  number    = {2},
  pages     = {49--60},
  publisher = {ACM},
}

@InCollection{wang2014multi,
  author    = {Wang, Hongzhi and Cao, Yu and Syeda-Mahmood, Tanveer},
  title     = {Multi-atlas Segmentation with Learning-Based Label Fusion},
  booktitle = {Machine Learning in Medical Imaging},
  publisher = {Springer},
  year      = {2014},
  pages     = {256--263},
  doi       = {10.1007/978-3-319-10581-9_32},
  file      = {wang2014multiatlas.pdf:wang2014multiatlas.pdf:PDF},
  issn      = {978-3-319-10580-2},
  journal   = {Machine Learning in Medical Imaging},
}

@Article{wang2013multi,
  author    = {Wang, Hongzhi and Suh, Jung Wook and Das, Sandhitsu R and Pluta, John B and Craige, Caryne and Yushkevich, Paul A},
  title     = {Multi-atlas segmentation with joint label fusion},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year      = {2013},
  volume    = {35},
  number    = {3},
  pages     = {611--623},
  issn      = {1191001202},
  doi       = {10.1038/nmeth.2250.Digestion},
  file      = {wang2013multi.pdf:wang2013multi.pdf:PDF},
  publisher = {IEEE},
}

@Article{wang2002mining,
  author       = {Wang, Haixun and Yu, Philip S},
  title        = {Mining {Concept}-{Drifting} {Data} {Streams} using {Ensemble} {Classifiers}},
  journal      = {Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '02},
  year         = {2002},
  pages        = {1--10},
  issn         = {1581137370},
  booktitle    = {Knowledge Discovery and Data mining},
  doi          = {10.1145/956750.956778},
  organization = {ACM},
}

@InCollection{sun2013transfer,
  author    = {Sun, Shiliang and Xu, Zhijie and Yang, Mo},
  title     = {Transfer learning with part-based ensembles},
  booktitle = {Multiple Classifier Systems},
  publisher = {Springer},
  year      = {2013},
  volume    = {7872 LNCS},
  pages     = {271--282},
  doi       = {10.1007/978-3-642-38067-9_24},
  file      = {sun2013transfer.pdf:sun2013transfer.pdf:PDF},
  issn      = {9783642380662},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords  = {multi-source learning, Part-based model, Support Vector Machine, Transfer learning},
}

@InProceedings{sun2011two,
  author    = {Sun, Qian and Chattopadhyay, Rita and Panchanathan, Sethuraman and Ye, Jieping},
  title     = {A two-stage weighting framework for multi-source domain adaptation},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2011},
  pages     = {505--513},
  issn      = {9781618395993},
  journal   = {Nips},
}

@InProceedings{bermudez2016scalable,
  author       = {Berm{\'u}dez-Chac{\'o}n, R{\'o}ger and Becker, Carlos and Salzmann, Mathieu and Fua, Pascal},
  title        = {Scalable Unsupervised Domain Adaptation for Electron Microscopy},
  booktitle    = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year         = {2016},
  pages        = {326--334},
  organization = {Springer},
  groups       = {Not-so-supervised papers},
}

@InCollection{chen2015identification,
  author    = {Chen, Liang and Tong, Tong and Ho, Chin Pang and Patel, Rajiv and Cohen, David and Dawson, Angela C. and Halse, Omid and Geraghty, Olivia and Rinne, Paul E. M. and White, Christopher J. and Nakornchai, Tagore and Bentley, Paul and Rueckert, Daniel},
  title     = {Identification of Cerebral Small Vessel Disease Using Multiple Instance Learning},
  booktitle = {Medical Image Computing and Computer Assisted Intervention (MICCAI)},
  publisher = {Springer International Publishing},
  year      = {2015},
  pages     = {523--530},
  groups    = {Not-so-supervised papers},
  note2     = {https://www.evernote.com/shard/s380/nl/66985950/86a4d55f-1162-4436-bb1f-b909af6d5d0a},
  url2      = {http://link.springer.com/10.1007/978-3-319-24553-9_64},
}

@InProceedings{liu2010lesion,
  author     = {Liu, Qingshan and Qian, Zhen and Marvasty, Idean and Rinehart, Sarah and Voros, Szilard and Metaxas, Dimitris N.},
  title      = {Lesion-specific coronary artery calcium quantification for predicting cardiac event with multiple instance support vector machines},
  year       = {2010},
  pages      = {484--492},
  publisher  = {Springer Berlin Heidelberg},
  abstract   = {Conventional whole-heart CAC quantification has been demonstrated to be insufficient in predicting coronary events, especially in accurately predicting near-term coronary events in high-risk adults. In this paper, we propose a lesion-specific CAC quantification framework to improve CAC's near-term predictive value in intermediate to high-risk populations with a novel multiple instance support vector machines (MISVM) approach. Our method works on data sets acquired with clinical imaging protocols on conventional CT scanners without modifying the CT hardware or updating the imaging protocol. The calcific lesions are quantified by geometric information, density, and some clinical measurements. A MISVM model is built to predict cardiac events, and moreover, to give a better insight of the characterization of vulnerable or culprit lesions in CAC. Experimental results on 31 patients showed significant improvement of the predictive value with the ROC analysis, the net reclassification improvement evaluation, and the leave-one-out validation against the conventional methods.},
  booktitle2 = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
  doi2       = {10.1007/978-3-642-15705-9_59},
  groups     = {Not-so-supervised papers},
  isbn2      = {3-642-15704-1},
  url2       = {http://link.springer.com/10.1007/978-3-642-15705-9_59},
  volume2    = {6361 LNCS},
}

@InProceedings{lu2011effective,
  author    = {Lu, Le and Bi, Jinbo and Wolf, Matthias and Salganicoff, Marcos},
  title     = {Effective {3D} object detection and regression using probabilistic segmentation features in {CT} images},
  booktitle = {Computer Vision and Pattern Recognition (CVPR)},
  year      = {2011},
  pages     = {1049--1056},
  publisher = {IEEE},
  doi2      = {10.1109/CVPR.2011.5995359},
  groups    = {Not-so-supervised papers},
  isbn2     = {978-1-4577-0394-2},
  keywords  = {3D medical images, 3D object detection, automatic clinical reporting, Biomedical imaging, Cancer, cancer staging, Computed tomography, Computer aided diagnosis, computerised tomography, CT images, feature extraction, Image segmentation, importance ranking, medical image processing, multiple instance regression method, object detection, Probabilistic logic, probabilistic segmentation features, regression analysis, Three dimensional displays, volumes of interest},
  url2      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5995359},
}

@InCollection{mahapatra2013semi,
  author    = {Mahapatra, Dwarikanath and Schüffler, Peter J. and Tielbeek, Jeroen A. W. and Vos, Franciscus M. and Buhmann, Joachim M.},
  title     = {Semi-Supervised and Active Learning for Automatic Segmentation of {Crohn's} Disease},
  publisher = {Springer Berlin Heidelberg},
  year      = {2013},
  pages     = {214--221},
  groups    = {Not-so-supervised papers},
  note2     = {DOI: 10.1007/978-3-642-40763-5\_27},
  url2      = {http://link.springer.com/10.1007/978-3-642-40763-5_27},
}

@InProceedings{manivannan2016subcategory,
  author    = {Manivannan, Siyamalan and Cobb, Caroline and Burgess, Stephen and Trucco, Emanuele},
  title     = {Sub-category Classifiers for Multiple-instance Learning and Its Application to Retinal Nerve Fiber Layer Visibility Classification},
  booktitle = {Medical Image Computing and Computer Assisted Intervention (MICCAI)},
  year      = {2016},
  abstract  = {We propose a novel multiple instance learning method to assess the visibility (visible/not visible) of the retinal nerve fiber layer (RNFL) in fundus camera images. Using only image-level labels, our approach learns to classify the images as well as to localize the RNFL visible regions. We transform the original feature space to a discrimi-native subspace, and learn a region-level classifier in that subspace. We propose a margin-based loss function to jointly learn this subspace and the region-level classifier. Experiments with a RNFL dataset containing 576 images annotated by two experienced ophthalmologists give an agree-ment (kappa values) of 0.65 and 0.58 respectively, with an inter-annotator agreement of 0.62. Note that our system gives higher agreements with the more experienced annotator. Comparative tests with three public datasets (MESSIDOR and DR for diabetic retinopathy, UCSB for breast cancer) show improved performance over the state-of-the-art.},
  doi2      = {10.1007/978-3-319-46723-8},
  groups    = {Not-so-supervised papers},
  issn2     = {9783319467238},
}

@Article{melendez2016combining,
  author   = {Melendez, Jaime and van Ginneken, Bram and Maduskar, Pragnya and Philipsen, Rick H. H. M. and Ayles, Helen and Sánchez, Clara I.},
  title    = {On Combining Multiple-Instance Learning and Active Learning for Computer-Aided Detection of Tuberculosis},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2016},
  volume   = {35},
  number   = {4},
  pages    = {1013--1024},
  abstract = {The major advantage of multiple-instance learning (MIL) applied to a computer-aided detection (CAD) system is that it allows optimizing the latter with case-level labels instead of accurate lesion outlines as traditionally required for a supervised approach. As shown in previous work, a MIL-based CAD system can perform comparably to its supervised counterpart considering complex tasks such as chest radiograph scoring in tuberculosis (TB) detection. However, despite this remarkable achievement, the uncertainty inherent to MIL can lead to a less satisfactory outcome if analysis at lower levels (e.g., regions or pixels) is needed. This issue may seriously compromise the applicability of MIL to tasks related to quantification or grading, or detection of highly localized lesions. In this paper, we propose to reduce uncertainty by embedding a MIL classifier within an active learning (AL) framework. To minimize the labeling effort, we develop a novel instance selection mechanism that exploits the MIL problem definition through one-class classification. We adapt this mechanism to provide meaningful regions instead of individual instances for expert labeling, which is a more appropriate strategy given the application domain. In addition, and contrary to usual AL methods, a single iteration is performed. To show the effectiveness of our approach, we compare the output of a MIL-based CAD system trained with and without the proposed AL framework. The task is to detect textural abnormalities related to TB. Both quantitative and qualitative evaluations at the pixel level are carried out. Our method significantly improves the MIL-based classification.},
  doi2     = {10.1109/TMI.2015.2505672},
  groups   = {Not-so-supervised papers, Veni},
  keywords = {Active learning, chest radiography, Computer-aided detection (CAD), Multiple-instance learning, tuberculosis},
  language = {eng},
}

@Article{venkatesan2015simpler,
  author  = {Venkatesan, Ragav and Chandakkar, Parag Shridhar and Li, Baoxin},
  title   = {Simpler non-parametric methods provide as good or better results to multiple-instance learning .},
  journal = {International Conference on Computer Vision (ICCV)},
  year    = {2015},
  pages   = {2605--2613},
  doi     = {10.1109/ICCV.2015.299},
  file    = {venkatesan2015simpler.pdf:venkatesan2015simpler.pdf:PDF},
  groups  = {Not-so-supervised papers},
}

@Article{zhang2012multi,
  author   = {Zhang, Daoqiang and Shen, Dinggang},
  title    = {Multi-modal multi-task learning for joint prediction of multiple regression and classification variables in {Alzheimer}'s disease},
  journal  = {NeuroImage},
  year     = {2012},
  volume   = {59},
  number   = {2},
  pages    = {895--907},
  abstract = {Many machine learning and pattern classification methods have been applied to the diagnosis of Alzheimer's disease (AD) and its prodromal stage, i.e., mild cognitive impairment (MCI). Recently, rather than predicting categorical variables as in classification, several pattern regression methods have also been used to estimate continuous clinical variables from brain images. However, most existing regression methods focus on estimating multiple clinical variables separately and thus cannot utilize the intrinsic useful correlation information among different clinical variables. On the other hand, in those regression methods, only a single modality of data (usually only the structural MRI) is often used, without considering the complementary information that can be provided by different modalities. In this paper, we propose a general methodology, namely multi-modal multi-task (M3T) learning, to jointly predict multiple variables from multi-modal data. Here, the variables include not only the clinical variables used for regression but also the categorical variable used for classification, with different tasks corresponding to prediction of different variables. Specifically, our method contains two key components, i.e., (1) a multi-task feature selection which selects the common subset of relevant features for multiple variables from each modality, and (2) a multi-modal support vector machine which fuses the above-selected features from all modalities to predict multiple (regression and classification) variables. To validate our method, we perform two sets of experiments on ADNI baseline MRI, FDG-PET, and cerebrospinal fluid (CSF) data from 45 AD patients, 91 MCI patients, and 50 healthy controls (HC). In the first set of experiments, we estimate two clinical variables such as Mini Mental State Examination (MMSE) and Alzheimer's Disease Assessment Scale-Cognitive Subscale (ADAS-Cog), as well as one categorical variable (with value of 'AD', 'MCI' or 'HC'), from the baseline MRI, FDG-PET, and CSF data. In the second set of experiments, we predict the 2-year changes of MMSE and ADAS-Cog scores and also the conversion of MCI to AD from the baseline MRI, FDG-PET, and CSF data. The results on both sets of experiments demonstrate that our proposed M3T learning scheme can achieve better performance on both regression and classification tasks than the conventional learning methods. ?? 2011 Elsevier Inc.},
  doi2     = {10.1016/j.neuroimage.2011.09.069},
  file     = {zhang2012multi.pdf:zhang2012multi.pdf:PDF},
  groups   = {Not-so-supervised papers},
  issn2    = {1095-9572 (Electronic){\textbackslash}n1053-8119 (Linking)},
  keywords = {ADAS-Cog, Alzheimer's disease (AD), MCI conversion, MMSE, Multi-modality, Multi-modal multi-task (M3T) learning, Multi-task feature selection},
  url2     = {http://dx.doi.org/10.1016/j.neuroimage.2011.09.069},
}

@Article{zhou2013modeling,
  author   = {Zhou, Jiayu and Liu, Jun and Narayan, Vaibhav A. and Ye, Jieping},
  title    = {Modeling disease progression via multi-task learning},
  journal  = {NeuroImage},
  year     = {2013},
  volume   = {78},
  pages    = {233--248},
  abstract = {Alzheimer's disease (AD), the most common type of dementia, is a severe neurodegenerative disorder. Identifying biomarkers that can track the progress of the disease has recently received increasing attentions in AD research. An accurate prediction of disease progression would facilitate optimal decision-making for clinicians and patients. A definitive diagnosis of AD requires autopsy confirmation, thus many clinical/cognitive measures including Mini Mental State Examination (MMSE) and Alzheimer's Disease Assessment Scale cognitive subscale (ADAS-Cog) have been designed to evaluate the cognitive status of the patients and used as important criteria for clinical diagnosis of probable AD. In this paper, we consider the problem of predicting disease progression measured by the cognitive scores and selecting biomarkers predictive of the progression. Specifically, we formulate the prediction problem as a multi-task regression problem by considering the prediction at each time point as a task and propose two novel multi-task learning formulations. We have performed extensive experiments using data from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Specifically, we use the baseline MRI features to predict MMSE/ADAS-Cog scores in the next 4years. Results demonstrate the effectiveness of the proposed multi-task learning formulations for disease progression in comparison with single-task learning algorithms including ridge regression and Lasso. We also perform longitudinal stability selection to identify and analyze the temporal patterns of biomarkers in disease progression. We observe that cortical thickness average of left middle temporal, cortical thickness average of left and right Entorhinal, and white matter volume of left Hippocampus play significant roles in predicting ADAS-Cog at all time points. We also observe that several MRI biomarkers provide significant information for predicting MMSE scores for the first 2years, however very few are shown to be significant in predicting MMSE score at later stages. The lack of predictable MRI biomarkers in later stages may contribute to the lower prediction performance of MMSE than that of ADAS-Cog in our study and other related studies.},
  doi2     = {10.1016/j.neuroimage.2013.03.073},
  groups   = {Not-so-supervised papers},
}

@Article{quellec2016multiple,
  author = {Quellec, G and Lamard, M and Cozic, M and Coatrieux, G and Cazuguel, G},
  title  = {Multiple-Instance Learning for Anomaly Detection in Digital Mammography},
}

@Article{melendez2014novel,
  author   = {Melendez, Jaime and van Ginneken, Bram and Maduskar, Pragnya and Philipsen, Rick H H M and Reither, Klaus and Breuninger, Marianne and Adetifa, Ifedayo M O and Maane, Rahmatulai and Ayles, Helen and Sanchez, Clara I},
  title    = {A novel multiple-instance learning-based approach to computer-aided detection of tuberculosis on chest x-rays},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2014},
  volume   = {34},
  number   = {1},
  pages    = {179--192},
  abstract = {To reach performance levels comparable to human experts, computer-aided detection (CAD) systems are typically optimized following a supervised learning approach that relies on large training databases comprising manually annotated lesions. However, manually outlining those lesions constitutes a difficult and time-consuming process that renders detailedly annotated data difficult to obtain. In this paper, we investigate an alternative approach, namely multiple-instance learning (MIL), that does not require detailed information for optimization. We have applied MIL to a CAD system for tuberculosis detection. Only the case condition (normal or abnormal) was required during training. Based upon the well-known miSVM technique, we propose an improved algorithm that overcomes miSVM's drawbacks related to positive instance underestimation and costly iteration. To show the advantages of our MIL-based approach as compared with a traditional supervised one, experiments with three X-ray databases were conducted. The area under the receiver operating characteristic curve was utilized as a performance measure. With the first database, for which training lesion annotations were available, our MIL-based method was comparable to the supervised system ( 0.86 versus 0.88 ). When evaluating the remaining databases, given their large difference with the previous image set, the most appealing strategy was to retrain the CAD systems. However, since only the case condition was available, only the MIL-based system could be retrained. This scenario, which is common in real-world applications, demonstrates the better adaptation capabilities of the proposed approach. After retraining, our MIL-based system significantly outperformed the supervised one ( 0.86 versus 0.79 and 0.91 versus 0.85 , and p=0.0002 , respectively).},
  doi2     = {10.1109/TMI.2014.2350539},
  file     = {melendez2015novel.pdf:melendez2015novel.pdf:PDF},
  groups   = {Not-so-supervised papers, Veni},
  issn2    = {0278-0062},
  keywords = {chest radiography, Computer-aided detection (CAD), Multiple-instance learning (MIL), tuberculosis},
}

@Article{wang2012seeing,
  author    = {Wang, Shijun and McKenna, Matthew T and Nguyen, Tan B and Burns, Joseph E and Petrick, Nicholas and Sahiner, Berkman and Summers, Ronald M},
  title     = {Seeing is believing: Video classification for computed tomographic colonography using multiple-instance learning},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2012},
  volume    = {31},
  number    = {5},
  pages     = {1141--1153},
  abstract  = {In this paper, we present development and testing results for a novel colonic polyp classification method for use as part of a computed tomographic colonography (CTC) computer-aided detection (CAD) system. Inspired by the interpretative methodology of radiologists using 3-D fly-through mode in CTC reading, we have developed an algorithm which utilizes sequences of images (referred to here as videos) for classification of CAD marks. For each CAD mark, we created a video composed of a series of intraluminal, volume-rendered images visualizing the detection from multiple viewpoints. We then framed the video classification question as a multiple-instance learning (MIL) problem. Since a positive (negative) bag may contain negative (positive) instances, which in our case depends on the viewing angles and camera distance to the target, we developed a novel MIL paradigm to accommodate this class of problems. We solved the new MIL problem by maximizing a L2-norm soft margin using semidefinite programming, which can optimize relevant parameters automatically. We tested our method by analyzing a CTC data set obtained from 50 patients from three medical centers. Our proposed method showed significantly better performance compared with several traditional MIL methods.},
  doi2      = {10.1109/TMI.2012.2187304},
  file      = {wang2012seeing.pdf:wang2012seeing.pdf:PDF},
  groups    = {Not-so-supervised papers},
  issn2     = {0278-0062 VO - 31},
  keywords  = {Computed tomographic colonography (CTC), Multiple-instance learning, semidefinite programming, video analysis},
  language  = {eng},
  publisher = {IEEE},
  url2      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6191379},
}

@Article{goetz2016dalsa,
  author    = {Goetz, Michael and Weber, Christian and Binczyk, Franciszek and Polanska, Joanna and Tarnawski, Rafal and Bobek-Billewicz, Barbara and Koethe, Ullrich and Kleesiek, Jens and Stieltjes, Bram and Maier-Hein, Klaus H.},
  title     = {{DALSA}: {Domain} adaptation for supervised learning from sparsely annotated {MR} images},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2016},
  volume    = {35},
  number    = {1},
  pages     = {184--196},
  abstract  = {We propose a new method that employs transfer learning techniques to effectively correct sampling selection errors introduced by sparse annotations during supervised learning for automated tumor segmentation. The practicality of current learning-based automated tissue classification approaches is severely impeded by their dependency on manually segmented training databases that need to be recreated for each scenario of application, site, or acquisition setup. The comprehensive annotation of reference datasets can be highly labor-intensive, complex, and error-prone. The proposed method derives high-quality classifiers for the different tissue classes from sparse and unambiguous annotations and employs domain adaptation techniques for effectively correcting sampling selection errors introduced by the sparse sampling. The new approach is validated on labeled, multi-modal MR images of 19 patients with malignant gliomas and by comparative analysis on the BraTS 2013 challenge data sets. Compared to training on fully labeled data, we reduced the time for labeling and training by a factor greater than 70 and 180 respectively without sacrificing accuracy. This dramatically eases the establishment and constant extension of large annotated databases in various scenarios and imaging setups and thus represents an important step towards practical applicability of learning-based approaches in tissue classification.},
  annote    = {From Duplicate 2 (DALSA: Domain Adaptation for Supervised Learning From Sparsely Annotated MR Images - Goetz, Michael; Weber, Christian; Binczyk, Franciszek; Polanska, Joanna; Tarnawski, Rafal; Bobek-Billewicz, Barbara; Koethe, Ullrich; Kleesiek, Jens; Stieltjes, Bram; Maier-Hein, Klaus H.)tumor segmentationcomplex and error-prone task, ambiguity at tissue borderslow inter- and intraobserver variability implies that reference segmentations contain errorsunsupervised approaches (incl STAPLE) proposed to limit problems of supervised learning. These approaches reduce variance but cannot solve the problem of ambiguitytime-consuming, 1 hr to create a high-quality segmentationTrained on sparse annotations need to be created. 1-2 slices, represent 1\% of voxelstraining and test have different class priorsleave-one-patient-out validationcompare fully supervised, uniformly sampled, and uniformly sampled with domain adaptationweighted random forest and weighted SVMgeneral point: training sampling ratio matters!},
  doi2      = {10.1109/TMI.2015.2463078},
  groups    = {Not-so-supervised papers},
  issue     = {1},
  keywords  = {Automatic multi-modal segmentation, Brain tumor segmentation, domain adaptation, Glioma, random forest, Transfer learning},
  publisher = {IEEE},
}

@Article{quellec2012multiple,
  author    = {Quellec, Gw{\'e}nol{\'e} and Lamard, Mathieu and Abr{\`a}moff, Michael D and Decenci{\`e}re, Etienne and Lay, Bruno and Erginay, Ali and Cochener, B{\'e}atrice and Cazuguel, Guy},
  title     = {A multiple-instance learning framework for diabetic retinopathy screening},
  journal   = {Medical Image Analysis},
  year      = {2012},
  volume    = {16},
  number    = {6},
  pages     = {1228--1240},
  abstract  = {A novel multiple-instance learning framework, for automated image classification, is presented in this paper. Given reference images marked by clinicians as relevant or irrelevant, the image classifier is trained to detect patterns, of arbitrary size, that only appear in relevant images. After training, similar patterns are sought in new images in order to classify them as either relevant or irrelevant images. Therefore, no manual segmentations are required. As a consequence, large image datasets are available for training. The proposed framework was applied to diabetic retinopathy screening in 2-D retinal image datasets: Messidor (1200 images) and e-ophtha, a dataset of 25,702 examination records from the Ophdiat screening network (107,799 images). In this application, an image (or an examination record) is relevant if the patient should be referred to an ophthalmologist. Trained on one half of Messidor, the classifier achieved high performance on the other half of Messidor (Az=0.881) and on e-ophtha (Az=0.761). We observed, in a subset of 273 manually segmented images from e-ophtha, that all eight types of diabetic retinopathy lesions are detected.},
  doi2      = {10.1016/j.media.2012.06.003},
  groups    = {Not-so-supervised papers},
  publisher = {Elsevier},
}

@Article{su2016interactive,
  author    = {Su, Hang and Yin, Zhaozheng and Huh, Seungil and Kanade, Takeo and Zhu, Jun},
  title     = {Interactive Cell Segmentation based on Active and Semi-supervised Learning},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2016},
  volume    = {35},
  number    = {3},
  pages     = {762--777},
  month     = mar,
  doi2      = {10.1109/TMI.2015.2494582},
  groups    = {Not-so-supervised papers},
  keywords  = {Active learning, cell segmentation, label propagation, microscopy image analysis, Verification propagation},
  publisher = {IEEE},
  url2      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7307213},
}

@Article{tong2014multiple,
  author    = {Tong, Tong and Wolz, Robin and Gao, Qinquan and Hajnal, Joseph V and Rueckert, Daniel},
  title     = {Multiple instance learning for classification of dementia in brain {MRI}},
  journal   = {Medical Image Analysis},
  year      = {2014},
  volume    = {16},
  number    = {Pt 2},
  pages     = {599--606},
  doi2      = {10.1016/j.media.2014.04.006},
  groups    = {Not-so-supervised papers, Veni},
  isbn2     = {9783642407628},
  issn2     = {13618423},
  keywords  = {Algorithms, Alzheimer Disease, Artificial Intelligence, Brain, complications, Dementia, Humans, Image Enhancement, Image Interpretation, Computer-Assisted, Magnetic resonance imaging, methods, Pathology, Pattern Recognition, Automated, Reproducibility of Results, Sensitivity and Specificity},
  language  = {eng},
  pmid2     = {24858570},
  publisher = {Elsevier B.V.},
  url2      = {http://dx.doi.org/10.1016/j.media.2014.04.006},
}

@Article{wachinger2016domain,
  author    = {Wachinger, Christian and Reuter, Martin},
  title     = {Domain adaptation for {Alzheimer}'s disease diagnostics},
  journal   = {NeuroImage},
  year      = {2016},
  volume    = {139},
  pages     = {470--479},
  abstract  = {With the increasing prevalence of Alzheimer's disease, research focuses on the early computer-aided diagnosis of dementia with the goal to understand the disease process, determine risk and preserving factors, and explore preventive therapies. By now, large amounts of data from multi-site studies have been made available for developing, training, and evaluating automated classifiers. Yet, their translation to the clinic remains challenging, in part due to their limited generalizability across different datasets. In this work, we describe a compact classification approach that mitigates overfitting by regularizing the multinomial regression with the mixed ?1/?2 norm. We combine volume, thickness, and anatomical shape features from MRI scans to characterize neuroanatomy for the three-class classification of Alzheimer's disease, mild cognitive impairment and healthy controls. We demonstrate high classification accuracy via independent evaluation within the scope of the CADDementia challenge. We, furthermore, demonstrate that variations between source and target datasets can substantially influence classification accuracy. The main contribution of this work addresses this problem by proposing an approach for supervised domain adaptation based on instance weighting. Integration of this method into our classifier allows us to assess different strategies for domain adaptation. Our results demonstrate (i) that training on only the target training set yields better results than the naïve combination (union) of source and target training sets, and (ii) that domain adaptation with instance weighting yields the best classification results, especially if only a small training component of the target dataset is available. These insights imply that successful deployment of systems for computer-aided diagnostics to the clinic depends not only on accurate classifiers that avoid overfitting, but also on a dedicated domain adaptation strategy.},
  annote    = {Classification normal, MCI, ADShow that different source and target datasets decrease performance (e.g. CADDementia challenge everybody overestimated their performance)Training on target only better than training on unionLinear model with sparsity to prevent overfitting - despite this still differences in dsitributionsSupervised transfer (some labeled target data available)Importance weighting, based on manually selected patient characteristics?For classification 147 features describing shape and volume are usedDomain adaptation important for translation to clinic},
  doi2      = {10.1016/j.neuroimage.2016.05.053},
  groups    = {Not-so-supervised papers},
  publisher = {Elsevier},
}

@InProceedings{wu2009min,
  author    = {Wu, Dijia and Bi, Jinbo and Boyer, Kim},
  title     = {A min-max framework of cascaded classifier with multiple instance learning for computer aided diagnosis},
  booktitle = {Computer Vision and Pattern Recognition (CVPR)},
  year      = {2009},
  pages     = {1359--1366},
  publisher = {IEEE},
  doi2      = {10.1109/CVPR.2009.5206778},
  groups    = {Not-so-supervised papers},
  isbn2     = {978-1-4244-3992-8},
  keywords  = {Biomedical imaging, block-coordinate optimization algorithm, Cancer detection, cascade classification, cascaded classifier, Character generation, Colon, colon cancer detection, Computed tomography, computed tomography image, Computer aided diagnosis, computerised tomography, Constraint optimization, Coronary arteriosclerosis, Design automation, extremely unbalanced data, image classification, Image converters, joint optimization problem, learning (artificial intelligence), malignant structure, Medical diagnostic imaging, medical image, medical image processing, minimax techniques, minmax framework, multiple instance learning, potentially diseased structure detection, pulmonary embolism detection, quadratically constrained quadratic program, quadratic programming},
  url2      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5206778},
}

@InProceedings{venkatesan2012classification,
  author    = {Venkatesan, Ragav and Chandakkar, P. and Baoxin Li, Baoxin and Li, H. K.},
  title     = {Classification of diabetic retinopathy images using multi-class multiple-instance learning based on color correlogram features},
  booktitle = {International {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}},
  year      = {2012},
  volume    = {2012},
  pages     = {1462--1465},
  month     = aug,
  publisher = {IEEE},
  abstract  = {All people with diabetes have the risk of developing diabetic retinopathy (DR), a vision-threatening complication. Early detection and timely treatment can reduce the occurrence of blindness due to DR. Computer-aided diagnosis has the potential benefit of improving the accuracy and speed in DR detection. This study is concerned with automatic classification of images with microaneurysm (MA) and neovascularization (NV), two important DR clinical findings. Together with normal images, this presents a 3-class classification problem. We propose a modified color auto-correlogram feature (AutoCC) with low dimensionality that is spectrally tuned towards DR images. Recognizing the fact that the images with or without MA or NV are generally different only in small, localized regions, we propose to employ a multi-class, multiple-instance learning framework for performing the classification task using the proposed feature. Extensive experiments including comparison with a few state-of-art image classification approaches have been performed and the results suggest that the proposed approach is promising as it outperforms other methods by a large margin.},
  doi2      = {10.1109/EMBC.2012.6346216},
  file      = {venkatesan2012classification.pdf:venkatesan2012classification.pdf:PDF},
  groups    = {Not-so-supervised papers},
  isbn2     = {978-1-4577-1787-1},
  issn2     = {9781424441198},
  journal   = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
  keywords  = {3-class classification problem, Aneurysm, Artificial Intelligence, automatic image classification, blindness, Color, color correlogram features, computer-aided diagnosis, Conferences, Databases, Factual, Diabetes, diabetic retinopathy, diabetic retinopathy image classification, Diagnostic Techniques, Ophthalmological, diseases, DR detection, DR images, eye, feature extraction, Histograms, Humans, image classification, Image color analysis, image colour analysis, Image Interpretation, Computer-Assisted, Image Processing, Computer-Assisted, learning (artificial intelligence), medical image processing, microaneurysm, multiclass multiple-instance learning framework, neovascularization, Photography, Retinal Neovascularization, Retinal Vessels, Retinopathy, Support vector machines, vision defects, vision-threatening complication},
  language  = {eng},
  url2      = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6346216},
}

@Article{bi2008improved,
  author    = {Bi, Jinbo and Xiong, Tao and Yu, Shipeng and Dundar, Murat and Rao, R Bharat},
  title     = {An {Improved} {Multi}-task {Learning} {Approach}},
  journal   = {Machine Learning and Knowledge Discovery in Databases},
  year      = {2008},
  pages     = {117--132},
  address   = {Berlin, Heidelberg},
  booktitle = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}},
  file      = {bi2008improved.pdf:bi2008improved.pdf:PDF},
  groups    = {Not-so-supervised papers},
  note2     = {DOI: 10.1007/978-3-540-87479-9\_26},
  publisher = {Springer Berlin Heidelberg},
}

@Article{shin2016deep,
  author    = {Shin, Hoo-Chang and Roth, Holger R and Gao, Mingchen and Lu, Le and Xu, Ziyue and Nogues, Isabella and Yao, Jianhua and Mollura, Daniel and Summers, Ronald M},
  title     = {Deep Convolutional Neural Networks for Computer-Aided Detection: {CNN} Architectures, Dataset Characteristics and Transfer Learning},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2016},
  volume    = {35},
  number    = {5},
  pages     = {1285--1298},
  month     = may,
  issn      = {0278-0062 VO - 35},
  abstract  = {Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets (i.e. ImageNet) and the revival of deep convolutional neural networks (CNN). CNNs enable learning data-driven, highly representative, layered hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models (supervised) pre-trained from natural image dataset to medical image tasks (although domain transfer between two medical image datasets is also possible). In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computeraided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, with 85\% sensitivity at 3 false positive per patient, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks.},
  doi       = {10.1109/TMI.2016.2528162},
  groups    = {Not-so-supervised papers},
  keywords  = {Biomedical imaging, Computer aided diagnosis, image analysis, machine learning, Neural networks},
  publisher = {IEEE},
  url       = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7404017},
}

@InProceedings{ghafoorian2017transfer,
  author       = {Ghafoorian, Mohsen and Mehrtash, Alireza and Kapur, Tina and Karssemeijer, Nico and Marchiori, Elena and Pesteie, Mehran and Guttmann, Charles RG and de Leeuw, Frank-Erik and Tempany, Clare M and van Ginneken, Bram and others},
  title        = {Transfer Learning for Domain Adaptation in {MRI}: Application in Brain Lesion Segmentation},
  booktitle    = {Medical Image Computing and Computer-Assisted Intervention},
  year         = {2017},
  pages        = {516--524},
  organization = {Springer},
}

@InProceedings{mahapatra2013weakly,
  author       = {Mahapatra, Dwarikanath and Vezhnevets, Alexander and Schuffler, Peter J and Tielbeek, Jeroen AW and Vos, Frans M and Buhmann, Joachim M},
  title        = {Weakly supervised semantic segmentation of {Crohn's} disease tissues from abdominal {MRI}},
  booktitle    = {International Symposium on Biomedical Imaging (ISBI)},
  year         = {2013},
  pages        = {844--847},
  month        = apr,
  organization = {IEEE},
  publisher    = {IEEE},
  doi2         = {10.1109/ISBI.2013.6556607},
  groups       = {Not-so-supervised papers},
  isbn2        = {978-1-4673-6455-3},
  keywords     = {abdominal magnetic resonance images, abdominal MRI, Accuracy, biological tissues, Biomedical imaging, biomedical MRI, Crohn Disease, Crohn's disease tissues, data driven fashion, diseases, feature extraction, Frequency selective surfaces, Image segmentation, medical image processing, medical imaging, MIM, multiimage model, Semantics, Semantic Segmentation, superpixel features, Training, Weakly supervised, weakly supervised semantic segmentation},
  url2         = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6556607},
}

@Article{kandemir2015computer,
  author   = {Kandemir, Melih and Hamprecht, Fred A},
  title    = {Computer-aided diagnosis from weak supervision: A benchmarking study},
  journal  = {Computerized Medical Imaging and Graphics},
  year     = {2015},
  volume   = {42},
  pages    = {44--50},
  abstract = {Supervised machine learning is a powerful tool frequently used in computer-aided diagnosis (CAD) applications. The bottleneck of this technique is its demand for fine grained expert annotations, which are tedious for medical image analysis applications. Furthermore, information is typically localized in diagnostic images, which makes representation of an entire image by a single feature set problematic. The multiple instance learning framework serves as a remedy to these two problems by allowing labels to be provided for groups of observations, called bags, and assuming the group label to be the maximum of the instance labels within the bag. This setup can effectively be applied to CAD by splitting a given diagnostic image into a Cartesian grid, treating each grid element (patch) as an instance by representing it with a feature set, and grouping instances belonging to the same image into a bag. We quantify the power of existing multiple instance learning methods by evaluating their performance on two distinct CAD applications: (i) Barrett's cancer diagnosis and (ii) diabetic retinopathy screening. In the experiments, mi-Graph appears as the best-performing method in bag-level prediction (i.e. diagnosis) for both of these applications that have drastically different visual characteristics. For instance-level prediction (i.e. disease localization), mi-SVM ranks as the most accurate method.},
  doi2     = {10.1016/j.compmedimag.2014.11.010},
  file     = {kandemir2014computer.pdf:kandemir2014computer.pdf:PDF},
  groups   = {Not-so-supervised papers},
  keywords = {Cancer diagnosis, Diabetic retinopathy screening, multiple instance learning},
}

@Article{sun2014survey,
  author    = {Sun, Shiliang and Shi, Honglei and Wu, Yuanbin},
  title     = {A survey of multi-source domain adaptation},
  journal   = {Information Fusion},
  year      = {2014},
  issn      = {8621543451},
  groups    = {Not-so-supervised general},
  keywords  = {domain adaptation, machine learning, multi-source learning},
  publisher = {Elsevier},
}

@Article{litjens2017survey,
  author  = {Litjens, Geert and Kooi, Thijs and Bejnordi, Babak Ehteshami and Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Ghafoorian, Mohsen and van der Laak, Jeroen AWM and van Ginneken, Bram and S{\'a}nchez, Clara I},
  title   = {A survey on deep learning in medical image analysis},
  journal = {arXiv preprint arXiv:1702.05747},
  year    = {2017},
  groups  = {Not-so-supervised general, Veni},
}

@InProceedings{weidmann2003two,
  author    = {Weidmann, N. and Frank, E. and Pfahringer, B.},
  title     = {A two-level learning method for generalized multi-instance problems},
  booktitle = {European Conference on Machine Learning},
  year      = {2003},
  pages     = {468--479},
  publisher = {Springer},
  note      = {DOI: 10.1007/978-3-540-39857-8\_42},
  url       = {http://link.springer.com/10.1007/978-3-540-39857-8_42},
}

@Article{quellec2017multiple,
  author    = {Quellec, Gwenole and Cazuguel, Guy and Cochener, Beatrice and Lamard, Mathieu},
  title     = {Multiple-instance learning for medical image and video analysis},
  journal   = {IEEE Reviews in Biomedical Engineering},
  year      = {2017},
  groups    = {Not-so-supervised general},
  publisher = {IEEE},
}

@Article{kim2016scale,
  author  = {Kim, H and Hwang, Sangheum},
  title   = {Scale-invariant feature learning using deconvolutional neural networks for weakly-supervised semantic segmentation. arXiv preprint},
  journal = {arXiv preprint arXiv:1602.04984},
  year    = {2016},
  groups  = {Not-so-supervised papers},
}

@Article{chen2017automatic,
  author    = {Chen, Sihong and Qin, Jing and Ji, Xing and Lei, Baiying and Wang, Tianfu and Ni, Dong and Cheng, Jie-Zhi},
  title     = {Automatic scoring of multiple semantic attributes with multi-task feature leverage: A study on pulmonary nodules in {CT} images},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2017},
  volume    = {36},
  number    = {3},
  pages     = {802--814},
  groups    = {Not-so-supervised papers},
  publisher = {IEEE},
}

@Article{christodoulidis2017multisource,
  author    = {Christodoulidis, Stergios and Anthimopoulos, Marios and Ebner, Lukas and Christe, Andreas and Mougiakakou, Stavroula},
  title     = {Multisource Transfer Learning With Convolutional Neural Networks for Lung Pattern Analysis},
  journal   = {IEEE journal of biomedical and health informatics},
  year      = {2017},
  volume    = {21},
  number    = {1},
  pages     = {76--84},
  groups    = {Not-so-supervised papers},
  publisher = {IEEE},
}

@InProceedings{ravishankar2016understanding,
  author       = {Ravishankar, Hariharan and Sudhakar, Prasad and Venkataramani, Rahul and Thiruvenkadam, Sheshadri and Annangi, Pavan and Babu, Narayanan and Vaidya, Vivek},
  title        = {Understanding the Mechanisms of Deep Transfer Learning for Medical Images},
  booktitle    = {Large-Scale Annotation of Biomedical Data and Expert Label Synthesis (MICCAI LABELS)},
  year         = {2016},
  pages        = {188--196},
  organization = {Springer},
  groups       = {Not-so-supervised papers},
}

@InCollection{schlegl2014unsupervised,
  author    = {Schlegl, Thomas and Ofner, Joachim and Langs, Georg},
  title     = {Unsupervised pre-training across image domains improves lung tissue classification},
  booktitle = {Medical Computer Vision: Algorithms for Big Data},
  publisher = {Springer},
  year      = {2014},
  pages     = {82--93},
  file      = {schlegl2014unsupervised.pdf:schlegl2014unsupervised.pdf:PDF},
  groups    = {Not-so-supervised papers},
  note2     = {DOI: 10.1007/978-3-319-13972-2\_8},
  url2      = {http://link.springer.com/10.1007/978-3-319-13972-2_8},
}

@Article{zhang2017automatic,
  author    = {Zhang, Ruikai and Zheng, Yali and Mak, Tony Wing Chung and Yu, Ruoxi and Wong, Sunny H and Lau, James YW and Poon, Carmen CY},
  title     = {Automatic detection and classification of colorectal polyps by transferring low-level {CNN} features from nonmedical domain},
  journal   = {IEEE Journal of Biomedical and Health Informatics},
  year      = {2017},
  volume    = {21},
  number    = {1},
  pages     = {41--47},
  groups    = {Not-so-supervised papers},
  publisher = {IEEE},
}

@Article{conjeti2016supervised,
  author    = {Conjeti, Sailesh and Katouzian, Amin and Roy, Abhijit Guha and Peter, Lo{\"\i}c and Sheet, Debdoot and Carlier, St{\'e}phane and Laine, Andrew and Navab, Nassir},
  title     = {Supervised domain adaptation of decision forests: Transfer of models trained in vitro for in vivo intravascular ultrasound tissue characterization},
  journal   = {Medical image analysis},
  year      = {2016},
  volume    = {32},
  pages     = {1--17},
  abstract  = {In this paper, we propose a supervised domain adaptation (DA) framework for adapting decision forests in the presence of distribution shift between training (source) and testing (target) domains, given few labeled examples. We introduce a novel method for DA through an error-correcting hierarchical transfer relaxation scheme with domain alignment, feature normalization, and leaf posterior reweighting to correct for the distribution shift between the domains. For the first time we apply DA to the challenging problem of extending in vitro trained forests (source domain) for in vivo applications (target domain). The proof-of-concept is provided for in vivo characterization of atherosclerotic tissues using intravascular ultrasound signals, where presence of flowing blood is a source of distribution shift between the two domains. This potentially leads to misclassification upon direct deployment of in vitro trained classifier, thus motivating the need for DA as obtaining reliable in vivo training labels is often challenging if not infeasible. Exhaustive validations and parameter sensitivity analysis substantiate the reliability of the proposed DA framework and demonstrates improved tissue characterization performance for scenarios where adaptation is conducted in presence of only a few examples. The proposed method can thus be leveraged to reduce annotation costs and improve computational efficiency over conventional retraining approaches.},
  annote    = {From Duplicate 2 (Supervised domain adaptation of decision forests: Transfer of models trained in vitro for in vivo intravascular ultrasound tissue characterization. - Conjeti, Sailesh; Katouzian, Amin; Roy, Abhijit Guha; Peter, Loïc Loic; Sheet, Debdoot; Carlier, Stéphane Stephane; Laine, Andrew; Navab, Nassir)From Duplicate 2 (Supervised domain adaptation of decision forests: Transfer of models trained in vitro for in vivo intravascular ultrasound tissue characterization - Conjeti, Sailesh; Katouzian, Amin; Roy, Abhijit Guha; Peter, Loïc; Sheet, Debdoot; Carlier, Stéphane; Laine, Andrew; Navab, Nassir)Supervised wrt targetRF random forestsUltrasound tissue characterizationsource: in vitro, target: in vivo. blood flow causes distribution shiftForests are trained on source, then using labeled target data the node splits and the posteriors are adapted (so no full training)Preprocessing with domain alignment through robust PCA (Hauberg et al). Target is aligned with source to avoid retraining},
  doi2      = {10.1016/j.media.2016.02.005},
  groups    = {Not-so-supervised papers},
  keywords  = {domain adaptation, Intravascular ultrasound, Random forests, Tissue characterization},
  language  = {eng},
  publisher = {Elsevier},
}

@Article{hwang2016self,
  author    = {Hwang, Sangheum and Kim, Hyo-Eun},
  title     = {Self-Transfer Learning for Fully Weakly Supervised Object Localization},
  journal   = {arXiv preprint arXiv:1602.01625},
  year      = {2016},
  pages     = {239--246},
  abstract  = {Recent advances of deep learning have achieved remarkable performances in various challenging computer vision tasks. Especially in object localization, deep convolutional neural networks outperform traditional approaches based on extraction of data/task-driven features instead of hand-crafted features. Although location information of region-of-interests (ROIs) gives good prior for object localization, it requires heavy annotation efforts from human resources. Thus a weakly supervised framework for object localization is introduced. The term "weakly" means that this framework only uses image-level labeled datasets to train a network. With the help of transfer learning which adopts weight parameters of a pre-trained network, the weakly supervised learning framework for object localization performs well because the pre-trained network already has well-trained class-specific features. However, those approaches cannot be used for some applications which do not have pre-trained networks or well-localized large scale images. Medical image analysis is a representative among those applications because it is impossible to obtain such pre-trained networks. In this work, we present a "fully" weakly supervised framework for object localization ("semi"-weakly is the counterpart which uses pre-trained filters for weakly supervised localization) named as self-transfer learning (STL). It jointly optimizes both classification and localization networks simultaneously. By controlling a supervision level of the localization network, STL helps the localization network focus on correct ROIs without any types of priors. We evaluate the proposed STL framework using two medical image datasets, chest X-rays and mammograms, and achieve signiticantly better localization performance compared to previous weakly supervised approaches.},
  groups    = {Not-so-supervised papers},
  note2     = {DOI: 10.1007/978-3-319-46723-8\_28},
  publisher = {Springer International Publishing},
  url2      = {http://link.springer.com/10.1007/978-3-319-46723-8_28},
}

@Article{azizi2017transfer,
  author    = {Azizi, Shekoofeh and Mousavi, Parvin and Yan, Pingkun and Tahmasebi, Amir and Kwak, Jin Tae and Xu, Sheng and Turkbey, Baris and Choyke, Peter and Pinto, Peter and Wood, Bradford and others},
  title     = {Transfer learning from RF to B-mode temporal enhanced ultrasound features for prostate cancer detection},
  journal   = {International Journal of Computer Assisted Radiology and Surgery},
  year      = {2017},
  pages     = {1--11},
  groups    = {Not-so-supervised papers},
  publisher = {Springer},
}

@InProceedings{cha2017bladder,
  author       = {Cha, Kenny H and Hadjiiski, Lubomir M and Chan, Heang-Ping and Samala, Ravi K and Cohan, Richard H and Caoili, Elaine M and Paramagul, Chintana and Alva, Ajjai and Weizer, Alon Z},
  title        = {Bladder cancer treatment response assessment using deep learning in CT with transfer learning},
  booktitle    = {SPIE Medical Imaging},
  year         = {2017},
  pages        = {1013404--1013404},
  organization = {International Society for Optics and Photonics},
  groups       = {Not-so-supervised papers},
}

@Article{chang2017unsupervised,
  author    = {Chang, Hang and Han, Ju and Zhong, Cheng and Snijders, Antoine and Mao, Jian-Hua},
  title     = {Unsupervised Transfer Learning via Multi-Scale Convolutional Sparse Coding for Biomedical Applications},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year      = {2017},
  groups    = {Not-so-supervised papers},
  publisher = {IEEE},
}

@InProceedings{chen2017transfer,
  author       = {Chen, Quan and Xu, Xiang and Hu, Shiliang and Li, Xiao and Zou, Qing and Li, Yunpeng},
  title        = {A Transfer learning approach for classification of clinical significant prostate cancers from mpMRI scans},
  booktitle    = {SPIE Medical Imaging},
  year         = {2017},
  pages        = {101344F--101344F},
  organization = {International Society for Optics and Photonics},
  groups       = {Not-so-supervised papers},
}

@Article{conjeti2017learning,
  author  = {Conjeti, Sailesh and Paschali, Magdalini and Katouzian, Amin and Navab, Nassir},
  title   = {Learning Robust Hash Codes for Multiple Instance Image Retrieval},
  journal = {arXiv preprint arXiv:1703.05724},
  year    = {2017},
  groups  = {Not-so-supervised papers},
}

@Article{dhungel2017deep,
  author    = {Dhungel, Neeraj and Carneiro, Gustavo and Bradley, Andrew P},
  title     = {A deep learning approach for the analysis of masses in mammograms with minimal user intervention},
  journal   = {Medical Image Analysis},
  year      = {2017},
  volume    = {37},
  pages     = {114--128},
  groups    = {Not-so-supervised papers},
  publisher = {Elsevier},
}

@InProceedings{elmahdy2017low,
  author       = {Elmahdy, Mohamed S and Abdeldayem, Sara S and Yassine, Inas A},
  title        = {Low quality dermal image classification using transfer learning},
  booktitle    = {IEEE EMBS International Conference on Biomedical \& Health Informatics (BHI)},
  year         = {2017},
  pages        = {373--376},
  organization = {IEEE},
  groups       = {Not-so-supervised papers},
}

@Article{hou2015efficient,
  author   = {Hou, Le and Samaras, Dimitris and Kurc, Tahsin M and Gao, Yi and Davis, James E and Saltz, Joel H},
  title    = {Efficient Multiple Instance Convolutional Neural Networks for Gigapixel Resolution Image Classification},
  journal  = {arXiv preprint},
  year     = {2015},
  abstract = {Convolutional Neural Networks (CNNs) are state-of-the-art models for many image and video classification tasks. However, training on large-size training samples is cur-rently computationally impossible. Hence when the train-ing data is multi-gigapixel images, only small patches of the original images can be used as training input. Since there is no guarantee that each patch is discriminative, we advo-cate the use of Multiple Instance Learning (MIL) to combine evidence from multiple patches sampled from the same im-age. In this paper we propose a framework that integrates MIL with CNNs. In our algorithm, patches of the images or videos are treated as instances, where only the image-or video-level label is given. Our algorithm iteratively identi-fies discriminative patches in a high resolution image and trains a CNN on them. In the test phase, instead of using voting to the predict the label of the image, we train a lo-gistic regression model to aggregate the patch-level predic-tions. Our method selects discriminative patches more ro-bustly through the use of Gaussian smoothing. We apply our method to glioma (the most common brain cancer) subtype classification based on multi-gigapixel whole slide images (WSI) from The Cancer Genome Atlas (TCGA) dataset. We can classify Glioblastoma (GBM) and Low-Grade Glioma (LGG) with an accuracy of 97\%. Furthermore, for the first time, we attempt to classify the three most common sub-types of LGG, a much more challenging task. We achieved an accuracy of 57.1\% which is similar to the inter-observer agreement between experienced pathologists.},
  groups   = {Not-so-supervised papers},
}

@Article{huang2017epithelium,
  author    = {Huang, Yue and Zheng, Han and Liu, Chi and Ding, Xinghao and Rohde, Gustavo},
  title     = {Epithelium-stroma classification via convolutional neural networks and unsupervised domain adaptation in histopathological images},
  journal   = {IEEE Journal of Biomedical and Health Informatics},
  year      = {2017},
  groups    = {Not-so-supervised papers},
  publisher = {IEEE},
}

@Article{huang2017simultaneous,
  author  = {Huang, Yawen and Shao, Ling and Frangi, Alejandro F},
  title   = {Simultaneous Super-Resolution and Cross-Modality Synthesis of 3D Medical Images using Weakly-Supervised Joint Convolutional Sparse Coding},
  journal = {arXiv preprint arXiv:1705.02596},
  year    = {2017},
  groups  = {Not-so-supervised papers},
}

@Article{hussein2017risk,
  author  = {Hussein, Sarfaraz and Cao, Kunlin and Song, Qi and Bagci, Ulas},
  title   = {Risk Stratification of Lung Nodules Using {3D} {CNN}-Based Multi-task Learning},
  journal = {arXiv preprint arXiv:1704.08797},
  year    = {2017},
  groups  = {Not-so-supervised papers},
}

@InProceedings{huynh2017comparison,
  author       = {Huynh, Benjamin Q and Antropova, Natasha and Giger, Maryellen L},
  title        = {Comparison of Breast {DCE-MRI} Contrast Time Points for Predicting Response to Neoadjuvant Chemotherapy Using Deep Convolutional Neural Network Features with Transfer Learning},
  booktitle    = {SPIE Medical Imaging},
  year         = {2017},
  pages        = {101340U--101340U},
  organization = {International Society for Optics and Photonics},
  groups       = {Not-so-supervised papers},
}

@Article{jaisakthi2017automatic,
  author  = {Jaisakthi, SM and Chandrabose, Aravindan and Mirunalini, P},
  title   = {Automatic Skin Lesion Segmentation using Semi-supervised Learning Technique},
  journal = {arXiv preprint arXiv:1703.04301},
  year    = {2017},
  groups  = {Not-so-supervised papers},
}

@InProceedings{kisilev2016medical,
  author       = {Kisilev, Pavel and Sason, Eli and Barkan, Ella and Hashoul, Sharbell},
  title        = {Medical Image Description Using Multi-task-loss {CNN}},
  booktitle    = {Large-Scale Annotation of Biomedical Data and Expert Label Synthesis (MICCAI LABELS)},
  year         = {2016},
  pages        = {121--129},
  organization = {Springer},
  groups       = {Not-so-supervised papers},
}

@Article{menegola2017knowledge,
  author  = {Menegola, Afonso and Fornaciali, Michel and Pires, Ramon and Bittencourt, Fl{\'a}via Vasques and Avila, Sandra and Valle, Eduardo},
  title   = {Knowledge transfer for melanoma screening with deep learning},
  journal = {arXiv preprint arXiv:1703.07479},
  year    = {2017},
  groups  = {Not-so-supervised papers},
}

@Article{meng2017liver,
  author    = {Meng, Dan and Zhang, Libo and Cao, Guitao and Cao, Wenming and Zhang, Guixu and Hu, Bing},
  title     = {Liver fibrosis classification based on transfer learning and FCNet for ultrasound images},
  journal   = {IEEE Access},
  year      = {2017},
  groups    = {Not-so-supervised papers},
  publisher = {IEEE},
}

@Article{murphree2017transfer,
  author  = {Murphree, Dennis H and Ngufor, Che},
  title   = {Transfer Learning for Melanoma Detection: Participation in {ISIC} 2017 Skin Lesion Classification Challenge},
  journal = {arXiv preprint arXiv:1703.05235},
  year    = {2017},
  groups  = {Not-so-supervised papers},
}

@Article{rajchl2016learning,
  author  = {Rajchl, Martin and Lee, Matthew CH and Schrans, Franklin and Davidson, Alice and Passerat-Palmbach, Jonathan and Tarroni, Giacomo and Alansary, Amir and Oktay, Ozan and Kainz, Bernhard and Rueckert, Daniel},
  title   = {Learning under Distributed Weak Supervision},
  journal = {arXiv preprint arXiv:1606.01100},
  year    = {2016},
}

@InProceedings{sousa2015transfer,
  author       = {Sousa, Ricardo Gamelas and Esteves, Tiago and Rocha, Sara and Figueiredo, Francisco and de S{\'a}, Joaquim M and Alexandre, Lu{\'\i}s A and Santos, Jorge M and Silva, Luis M},
  title        = {Transfer learning for the recognition of immunogold particles in TEM imaging},
  booktitle    = {International Work-Conference on Artificial Neural Networks},
  year         = {2015},
  pages        = {374--384},
  organization = {Springer},
  groups       = {Not-so-supervised papers},
}

@Article{tajbakhsh2016convolutional,
  author    = {Tajbakhsh, Nima and Shin, Jae Y and Gurudu, Suryakanth R and Hurst, R Todd and Kendall, Christopher B and Gotway, Michael B and Liang, Jianming},
  title     = {Convolutional neural networks for medical image analysis: full training or fine tuning?},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2016},
  volume    = {35},
  number    = {5},
  pages     = {1299--1312},
  groups    = {Not-so-supervised papers},
  publisher = {IEEE},
}

@Book{herrera2016multiple,
  title     = {Multiple Instance Learning: Foundations and Algorithms},
  publisher = {Springer},
  year      = {2016},
  author    = {Herrera, Francisco and Ventura, Sebasti{\'a}n and Bello, Rafael and Cornelis, Chris and Zafra, Amelia and S{\'a}nchez-Tarrag{\'o}, D{\'a}nel and Vluymans, Sarah},
  groups    = {Not-so-supervised general},
}

@Article{maierhein2017surgical,
  author    = {Lena Maier-Hein and Swaroop S. Vedula and Stefanie Speidel and Nassir Navab and Ron Kikinis and Adrian Park and Matthias Eisenmann and Hubertus Feussner and Germain Forestier and Stamatia Giannarou and Makoto Hashizume and Darko Katic and Hannes Kenngott and Michael Kranzfelder and Anand Malpani and Keno März and Thomas Neumuth and Nicolas Padoy and Carla Pugh and Nicolai Schoch and Danail Stoyanov and Russell Taylor and Martin Wagner and Gregory D. Hager and Pierre Jannin},
  title     = {Surgical data science for next-generation interventions},
  journal   = {Nature Biomedical Engineering},
  year      = {2017},
  volume    = {1},
  number    = {9},
  pages     = {691--696},
  month     = {sep},
  doi       = {10.1038/s41551-017-0132-7},
  publisher = {Springer Nature},
}

@Article{moccia2017uncertainty,
  author  = {Moccia, Sara and Wirkert, Sebastian J and Kenngott, Hannes and Vemuri, Anant S and Apitz, Martin and Mayer, Benjamin and De Momi, E and Mattos, LS and Maier-Hein, L},
  title   = {Uncertainty-aware organ classification for surgical data science applications in laparoscopy},
  journal = {arXiv preprint arXiv:1706.07002},
  year    = {2017},
}

@Article{oquab2015object,
  author    = {Oquab, Maxime and Bottou, Léon and Laptev, Ivan and Sivic, Josef},
  title     = {Is object localization for free? - {Weakly}-supervised learning with convolutional neural networks},
  journal   = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  year      = {2015},
  volume    = {07-12-June},
  number    = {iii},
  pages     = {685--694},
  issn      = {9781467369640},
  abstract  = {weakly supervised CNN? ?? object? classification?? ? ??(location? classification ??)},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  doi       = {10.1109/CVPR.2015.7298668},
  groups    = {Veni},
}

@Article{kooi2017large,
  author    = {Kooi, Thijs and Litjens, Geert and van Ginneken, Bram and Gubern-M{\'e}rida, Albert and S{\'a}nchez, Clara I and Mann, Ritse and den Heeten, Ard and Karssemeijer, Nico},
  title     = {Large scale deep learning for computer aided detection of mammographic lesions},
  journal   = {Medical image analysis},
  year      = {2017},
  volume    = {35},
  pages     = {303--312},
  publisher = {Elsevier},
}

@Article{rajpurkar2017chexnet,
  author  = {Rajpurkar, Pranav and Irvin, Jeremy and Zhu, Kaylie and Yang, Brandon and Mehta, Hershel and Duan, Tony and Ding, Daisy and Bagul, Aarti and Langlotz, Curtis and Shpanskaya, Katie and others},
  title   = {CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning},
  journal = {arXiv preprint arXiv:1711.05225},
  year    = {2017},
}

@InCollection{orting2017crowdsourced,
  author    = {{\O}rting, Silas Nyboe and Cheplygina, Veronika and Petersen, Jens and Thomsen, Laura H and Wille, Mathilde MW and de Bruijne, Marleen},
  title     = {Crowdsourced emphysema assessment},
  booktitle = {Intravascular Imaging and Computer Assisted Stenting, and Large-Scale Annotation of Biomedical Data and Expert Label Synthesis},
  publisher = {Springer},
  year      = {2017},
  pages     = {126--135},
  groups    = {My papers, Veni},
}

@MastersThesis{afentoulidis2017gamification,
  author = {Grigorios Afentoulidis},
  title  = {Gamification in Enterprise Crowdsourcing},
  school = {Delft University of Technology},
  year   = {2017},
  groups = {Veni},
}

@InCollection{caruana1998multitask,
  author    = {Caruana, Rich},
  title     = {Multitask learning},
  booktitle = {Learning to learn},
  publisher = {Springer},
  year      = {1998},
  pages     = {95--133},
}

@InProceedings{maaten2012stochastic,
  author       = {van der Maaten, Laurens and Weinberger, Kilian},
  title        = {Stochastic triplet embedding},
  booktitle    = {Machine Learning for Signal Processing (MLSP), 2012 IEEE International Workshop on},
  year         = {2012},
  pages        = {1--6},
  organization = {IEEE},
}

@InProceedings{schweikert2009empirical,
  author    = {Schweikert, Gabriele and R{\"a}tsch, Gunnar and Widmer, Christian and Sch{\"o}lkopf, Bernhard},
  title     = {An empirical analysis of domain adaptation algorithms for genomic sequence analysis},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2009},
  number    = {1},
  pages     = {1433--1440},
  journal   = {Nips},
  url       = {http://eprints.pascal-network.org/archive/00004350/%5Cnhttp://eprints.pascal-network.org/archive/00004350/01/NIPS2008-Schweikert_5401%5B0%5D.pdf},
}

@Article{steenwijk2013accurate,
  author    = {Steenwijk, Martijn D and Pouwels, Petra J W and Daams, Marita and van Dalen, Jan Willem and Caan, Matthan WA and Richard, Edo and Barkhof, Frederik and Vrenken, Hugo},
  title     = {Accurate white matter lesion segmentation by k nearest neighbor classification with tissue type priors {(kNN-TTPs)}},
  journal   = {NeuroImage: Clinical},
  year      = {2013},
  volume    = {3},
  pages     = {462--469},
  abstract  = {INTRODUCTION
The segmentation and volumetric quantification of white matter (WM) lesions play an important role in monitoring and studying neurological diseases such as multiple sclerosis (MS) or cerebrovascular disease. This is often interactively done using 2D magnetic resonance images. Recent developments in acquisition techniques allow for 3D imaging with much thinner sections, but the large number of images per subject makes manual lesion outlining infeasible. This warrants the need for a reliable automated approach. Here we aimed to improve k nearest neighbor (kNN) classification of WM lesions by optimizing intensity normalization and using spatial tissue type priors (TTPs).

METHODS
The kNN-TTP method used kNN classification with 3.0T 3DFLAIR and 3DT1 intensities as well as MNI-normalized spatial coordinates as features. Additionally, TTPs were computed by nonlinear registration of data from healthy controls. Intensity features were normalized using variance scaling, robust range normalization or histogram matching. The algorithm was then trained and evaluated using a leave-one-out experiment among 20 patients with MS against a reference segmentation that was created completely manually. The performance of each normalization method was evaluated both with and without TTPs in the feature set. Volumetric agreement was evaluated using intra-class coefficient (ICC), and voxelwise spatial agreement was evaluated using Dice similarity index (SI). Finally, the robustness of the method across different scanners and patient populations was evaluated using an independent sample of elderly subjects with hypertension.

RESULTS
The intensity normalization method had a large influence on the segmentation performance, with average SI values ranging from 0.66 to 0.72 when no TTPs were used. Independent of the normalization method, the inclusion of TTPs as features increased performance particularly by reducing the lesion detection error. Best performance was achieved using variance scaled intensity features and including TTPs in the feature set: this yielded ICC=0.93 and average SI=0.75±0.08. Validation of the method in an independent sample of elderly subjects with hypertension, yielded even higher ICC=0.96 and SI=0.84±0.14.

CONCLUSION
Adding TTPs increases the performance of kNN based MS lesion segmentation methods. Best performance was achieved using variance scaling for intensity normalization and including TTPs in the feature set, showing excellent agreement with the reference segmentations across a wide range of lesion severity, irrespective of the scanner used or the pathological substrate of the lesions.},
  author2   = {Steenwijk, Martijn D and Pouwels, Petra J W and others},
  doi       = {10.1016/j.nicl.2013.10.003},
  publisher = {Elsevier},
}

@Article{wijk2010comparing,
  author    = {van Wijk, Bernadette CM and Stam, Cornelis J and Daffertshofer, Andreas},
  title     = {Comparing brain networks of different size and connectivity density using graph theory},
  journal   = {PLoS One},
  year      = {2010},
  volume    = {5},
  number    = {10},
  pages     = {e13701},
  month     = oct,
  doi       = {10.1371/journal.pone.0013701},
  editor    = {Sporns, Olaf},
  file      = {wijk2010comparing.pdf:wijk2010comparing.pdf:PDF},
  publisher = {Public Library of Science},
  url       = {http://dx.plos.org/10.1371/journal.pone.0013701},
}

@Article{ikram2011rotterdam2,
  author    = {Ikram, M Arfan and van der Lugt, Aad and Niessen, Wiro J and Krestin, Gabriel P and Koudstaal, Peter J and Hofman, Albert and Breteler, Monique MB and Vernooij, Meike W},
  title     = {The {Rotterdam Scan Study}: design and update up to 2012},
  journal   = {European Journal of Epidemiology},
  year      = {2011},
  volume    = {26},
  number    = {10},
  pages     = {811--824},
  issn      = {0393-2990},
  abstract  = {Neuroimaging plays an important role in etiologic research on neurological diseases in the elderly. The Rotterdam Scan Study was initiated as part of the ongoing Rotterdam Study with the aim to unravel causes of neurological disease by performing neuroimaging in a population-based longitudinal setting. In 1995 and 1999 random subsets of the Rotterdam Study underwent neuroimaging, whereas from 2005 onwards MRI has been implemented into the core protocol of the Rotterdam Study. In this paper, we discuss the background and rationale of the Rotterdam Scan Study. We also describe the imaging protocol and post-processing techniques, and highlight the main findings to date. Finally, we make recommendations for future research, which will also be the main focus of investigation in the Rotterdam Scan Study.},
  doi       = {10.1007/s10654-011-9624-z},
  keywords  = {á, á cohort study á, dementia á, epidemiology á population-based á, flow á, infarcts á cerebral blood, risk factors á neuroimaging, s disease á microbleeds, stroke á alzheimer, white matter lesions á},
  publisher = {Springer},
}

@Article{li2008multi,
  author       = {Li, Shoushan and Zong, Chengqing},
  title        = {Multi-domain adaptation for sentiment classication: {Using} multiple classi er combining methods},
  journal      = {Nlp-Ke},
  year         = {2008},
  pages        = {1--8},
  issn         = {9781424427802},
  booktitle    = {Natural Language Processing and Knowledge Engineering},
  file         = {li2008multidomain.pdf:li2008multidomain.pdf:PDF},
  keywords     = {classifier combining, domain adaptation, multiple, sentiment classification},
  organization = {IEEE},
}

@InProceedings{liang2007computer,
  author       = {Liang, Jianming and Bi, Jinbo},
  title        = {Computer aided detection of pulmonary embolism with tobogganing and mutiple instance classification in {CT} pulmonary angiography},
  booktitle    = {Information Processing in Medical Imaging (IPMI)},
  year         = {2007},
  pages        = {630--641},
  address      = {Berlin, Heidelberg},
  organization = {Springer},
  groups       = {Not-so-supervised papers},
  note2        = {DOI: 10.1007/978-3-540-73273-0\_52},
  url2         = {http://link.springer.com/10.1007/978-3-540-73273-0_52},
}

@Article{sabuncu2015clinical,
  author    = {Sabuncu, Mert R and Konukoglu, Ender and Alzheimer?s Disease Neuroimaging Initiative and others},
  title     = {Clinical prediction from structural brain MRI scans: a large-scale empirical study},
  journal   = {Neuroinformatics},
  year      = {2015},
  volume    = {13},
  number    = {1},
  pages     = {31--46},
  month     = jan,
  annote    = {Motivation: classification important in neuroimaging, but little effort to compare algorithmsThree classifiers (SVM, RF-type classifier, relevance voxel machine), T1 scans, four feature setsClassifcation and regression on entire scansDifferent datasets including ADNI, ABIDE etc.Preprocessing in FreeSurfer, scanners / scanning parameters not mentioned.. Some datasets contain scans from different sites (number of sites listed).No best classifier!Features more important than algorithm},
  doi       = {10.1007/s12021-014-9238-1},
  publisher = {Springer},
  url       = {http://link.springer.com/10.1007/s12021-014-9238-1},
}

@Article{ross2017exploiting,
  author  = {Ross, Tobias and Zimmerer, David and Vemuri, Anant and Isensee, Fabian and Bodenstedt, Sebastian and Both, Fabian and Kessler, Philip and Wagner, Martin and M{\"u}ller, Beat and Kenngott, Hannes and others},
  title   = {Exploiting the potential of unlabeled endoscopic video data with self-supervised learning},
  journal = {arXiv preprint arXiv:1711.09726},
  year    = {2017},
}

@InProceedings{law2017efficient,
  author    = {Marc T. Law and Yaoliang Yu and Raquel Urtasun and Richard S. Zemel and Eric P. Xing},
  title     = {Efficient Multiple Instance Metric Learning Using Weakly Supervised Data},
  booktitle = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
  year      = {2017},
  month     = {jul},
  publisher = {{IEEE}},
  doi       = {10.1109/cvpr.2017.630},
}

@InProceedings{ponti2011combining,
  author       = {Ponti Jr, Moacir P},
  title        = {Combining classifiers: from the creation of ensembles to the decision fusion},
  booktitle    = {Graphics, Patterns and Images Tutorials (SIBGRAPI-T), 2011 24th SIBGRAPI Conference on},
  year         = {2011},
  pages        = {1--10},
  organization = {IEEE},
}

@InProceedings{dubost2017gpunet,
  author       = {Dubost, Florian and Bortsova, Gerda and Adams, Hieab and Ikram, Arfan and Niessen, Wiro and Vernooij, Meike and de Bruijne, Marleen},
  title        = {{GP-Unet}: Lesion Detection from Weak Labels with a {3D} Regression Network},
  booktitle    = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year         = {2017},
  pages        = {214--221},
  organization = {Springer},
}

@Article{herrera2014crowdsourcing,
  author  = {de Herrera, Alba Garc{\'\i}a Seco and Foncubierta-Rodr{\'\i}guez, Antonio and Markonis, Dimitrios and Schaer, Roger and M{\"u}ller, Henning},
  title   = {Crowdsourcing for medical image classification},
  journal = {Swiss Medical Informatics},
  year    = {2014},
  volume  = {30},
}

@Article{carbonneau2017bag,
  author  = {Carbonneau, Marc-Andr{\'e} and Granger, Eric and Gagnon, Ghyslain},
  title   = {Bag-Level Aggregation for Multiple Instance Active Learning in Instance Classification Problems},
  journal = {arXiv preprint arXiv:1710.02584},
  year    = {2017},
}

@Article{rastegari2015discriminative,
  author    = {Rastegari, Mohammad and Hajishirzi, Hannaneh and Farhadi, Ali},
  title     = {Discriminative and consistent similarities in instance-level {Multiple} {Instance} {Learning}},
  journal   = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  year      = {2015},
  volume    = {07-12-June},
  pages     = {740--748},
  issn      = {9781467369640},
  abstract  = {In this paper we present a bottom-up method to instance- level Multiple Instance Learning (MIL) that learns to dis- cover positive instances with globally constrained reason- ing about local pairwise similarities. We discover positive instances by optimizing for a ranking such that positive (top rank) instances are highly and consistently similar to each other and dissimilar to negative instances. Our approach takes advantage of a discriminative notion of pairwise sim- ilarity coupled with a structural cue in the form of a con- sistency metric that measures the quality of each similarity. We learn a similarity function for every pair of instances in positive bags by how similarly they differ from instances in negative bags, the only certain labels in MIL. Our ex- periments demonstrate that our method consistently outper- forms state-of-the-art MIL methods both at bag-level and instance-level predictions in standard benchmarks, image category recognition, and text categorization datasets},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  doi       = {10.1109/CVPR.2015.7298674},
}

@InCollection{oneil2017crowdsourcing,
  author    = {O'Neil, Alison Q and Murchison, John T and van Beek, Edwin JR and Goatman, Keith A},
  title     = {Crowdsourcing Labels for Pathological Patterns in CT Lung Scans: Can Non-experts Contribute Expert-Quality Ground Truth?},
  booktitle = {Intravascular Imaging and Computer Assisted Stenting, and Large-Scale Annotation of Biomedical Data and Expert Label Synthesis},
  publisher = {Springer},
  year      = {2017},
  pages     = {96--105},
}

@Article{hossain2015crowdsourcing,
  author    = {Hossain, Mokter and Kauranen, Ilkka},
  title     = {Crowdsourcing: a comprehensive literature review},
  journal   = {Strategic Outsourcing: An International Journal},
  year      = {2015},
  volume    = {8},
  number    = {1},
  pages     = {2--22},
  publisher = {Emerald Group Publishing Limited},
}

@Article{bejnordi2017diagnostic,
  author    = {Bejnordi, Babak Ehteshami and Veta, Mitko and van Diest, Paul Johannes and van Ginneken, Bram and Karssemeijer, Nico and Litjens, Geert and van der Laak, Jeroen AWM and Hermsen, Meyke and Manson, Quirine F and Balkenhol, Maschenka and others},
  title     = {Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer},
  journal   = {JAMA},
  year      = {2017},
  volume    = {318},
  number    = {22},
  pages     = {2199--2210},
  publisher = {American Medical Association},
}

@Article{li2017thoracic,
  author  = {Li, Zhe and Wang, Chong and Han, Mei and Xue, Yuan and Wei, Wei and Li, Li-Jia and Li, Fei-Fei},
  title   = {Thoracic Disease Identification and Localization with Limited Supervision},
  journal = {arXiv preprint arXiv:1711.06373},
  year    = {2017},
}

@Article{armato2011lung,
  author    = {Armato, Samuel G and McLennan, Geoffrey and Bidaut, Luc and McNitt-Gray, Michael F and Meyer, Charles R and Reeves, Anthony P and Zhao, Binsheng and Aberle, Denise R and Henschke, Claudia I and Hoffman, Eric A and others},
  title     = {The lung image database consortium {(LIDC)} and image database resource initiative {(IDRI)}: a completed reference database of lung nodules on {CT} scans},
  journal   = {Medical Physics},
  year      = {2011},
  volume    = {38},
  number    = {2},
  pages     = {915--931},
  publisher = {Wiley Online Library},
}

@Article{depeursinge2012building,
  author    = {Depeursinge, Adrien and Vargas, Alejandro and Platon, Alexandra and Geissbuhler, Antoine and Poletti, Pierre-Alexandre and M{\"u}ller, Henning},
  title     = {Building a reference multimedia database for interstitial lung diseases},
  journal   = {Computerized medical imaging and graphics},
  year      = {2012},
  volume    = {36},
  number    = {3},
  pages     = {227--238},
  publisher = {Elsevier},
}

@Article{cheplygina2017transfer,
  author  = {Cheplygina, Veronika and Pe{\~n}a, Isabel Pino and Pedersen, Jesper Holst and Lynch, David A and S{\o}rensen, Lauge and de Bruijne, Marleen},
  title   = {Transfer learning for multi-center classification of chronic obstructive pulmonary disease},
  journal = {Journal of Biomedical and Health Informatics},
  year    = {2017},
  doi2    = {10.1109/JBHI.2017.2769800},
}

@InProceedings{hoffer2015deep,
  author       = {Hoffer, Elad and Ailon, Nir},
  title        = {Deep metric learning using triplet network},
  booktitle    = {Similarity-Based Pattern Recognition (SIMBAD)},
  year         = {2015},
  pages        = {84--92},
  organization = {Springer},
}

@Article{liu2018landmark,
  author    = {Liu, Mingxia and Zhang, Jun and Adeli, Ehsan and Shen, Dinggang},
  title     = {Landmark-based deep multi-instance learning for brain disease diagnosis},
  journal   = {Medical image analysis},
  year      = {2018},
  volume    = {43},
  pages     = {157--168},
  publisher = {Elsevier},
}

@Article{erickson2017machine,
  author    = {Erickson, Bradley J and Korfiatis, Panagiotis and Akkus, Zeynettin and Kline, Timothy L},
  title     = {Machine Learning for Medical Imaging},
  journal   = {RadioGraphics},
  year      = {2017},
  volume    = {37},
  number    = {2},
  pages     = {505--515},
  publisher = {Radiological Society of North America},
}

@Article{guan2017who,
  author  = {Guan, Melody Y and Gulshan, Varun and Dai, Andrew M and Hinton, Geoffrey E},
  title   = {Who Said What: Modeling individual labelers improves classification},
  journal = {arXiv preprint arXiv:1703.08774},
  year    = {2017},
}

@InProceedings{mao2013volunteering,
  author    = {Mao, Andrew and Kamar, Ece and Chen, Yiling and Horvitz, Eric and Schwamb, Megan E and Lintott, Chris J and Smith, Arfon M},
  title     = {Volunteering versus work for pay: Incentives and tradeoffs in crowdsourcing},
  booktitle = {First AAAI conference on human computation and crowdsourcing},
  year      = {2013},
}

@InProceedings{cheplygina2017exploring,
  author    = {Cheplygina, Veronika and Moeskops, Pim and Veta, Mitko and Bozorg, Behdad Dasht and Pluim, Josien},
  title     = {Exploring the similarity of medical imaging classification problems},
  booktitle = {Intravascular Imaging and Computer Assisted Stenting, and Large-Scale Annotation of Biomedical Data and Expert Label Synthesis},
  year      = {2017},
}

@Article{shin2017joint,
  author  = {Shin, Seung Yeon and Lee, Soochahn and Yun, Il Dong and Lee, Kyoung Mu},
  title   = {Joint Weakly and Semi-Supervised Deep Learning for Localization and Classification of Masses in Breast Ultrasound Images},
  journal = {arXiv preprint arXiv:1710.03778},
  year    = {2017},
}

@Article{rajchl2017deepcut,
  author    = {Rajchl, Martin and Lee, Matthew CH and Oktay, Ozan and Kamnitsas, Konstantinos and Passerat-Palmbach, Jonathan and Bai, Wenjia and Damodaram, Mellisa and Rutherford, Mary A and Hajnal, Joseph V and Kainz, Bernhard and others},
  title     = {Deepcut: Object segmentation from bounding box annotations using convolutional neural networks},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2017},
  volume    = {36},
  number    = {2},
  pages     = {674--683},
  publisher = {IEEE},
}

@InProceedings{kamnitsas2017unsupervised,
  author       = {Kamnitsas, Konstantinos and Baumgartner, Christian and Ledig, Christian and Newcombe, Virginia and Simpson, Joanna and Kane, Andrew and Menon, David and Nori, Aditya and Criminisi, Antonio and Rueckert, Daniel and others},
  title        = {Unsupervised domain adaptation in brain lesion segmentation with adversarial networks},
  booktitle    = {International Conference on Information Processing in Medical Imaging (IPMI)},
  year         = {2017},
  pages        = {597--609},
  organization = {Springer},
}

@InProceedings{maken2014multiple,
  author       = {Maken, Fahira A and Gal, Yaniv and Mcclymont, Darryl and Bradley, Andrew P},
  title        = {Multiple Instance Learning for Breast Cancer Magnetic Resonance Imaging},
  booktitle    = {Digital lmage Computing: Techniques and Applications (DICTA)},
  year         = {2014},
  pages        = {1},
  organization = {IEEE},
  file         = {maken2014multiple.pdf:maken2014multiple.pdf:PDF},
  groups       = {Not-so-supervised papers},
  keywords     = {biomedical MRI, Breast cancer, breast cancer magnetic resonance imaging, breast MRI, Cancer, citation-kNN, feature extraction, image classification, learning (artificial intelligence), Lesions, Magnetic resonance imaging, mass-like lesions, MIL, multiple instance learning, Radio frequency, random forest classifier, receiver operating characteristics curve, region-of-interest based features, T2 weighted magnetic resonance images, tile-based features},
  note2        = {DOI: 10.1109/DICTA.2014.7008118},
  url2         = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7008118},
}

@InProceedings{lu2017multiple,
  author       = {Lu, Donghuan and Ding, Weiguang and Merkur, Andrew and Sarunic, Marinko V and Beg, Mirza Faisal},
  title        = {Multiple instance learning for age-related macular degeneration diagnosis in optical coherence tomography images},
  booktitle    = {International Symposium on Biomedical Imaging (ISBI)},
  year         = {2017},
  pages        = {139--142},
  organization = {IEEE},
}

@Article{stainvas2014cancer,
  author  = {Stainvas, Inna and Manevitch, Alexandra and Leichter, Isaac},
  title   = {Cancer Detection with Multiple Radiologists via Soft Multiple Instance Logistic Regression and $ L\_1 $ Regularization},
  journal = {arXiv preprint arXiv:1412.2873},
  year    = {2014},
}

@InProceedings{hofer2017simple,
  author       = {Hofer, Christoph and Kwitt, Roland and H{\"o}ller, Yvonne and Trinka, Eugen and Uhl, Andreas},
  title        = {Simple domain adaptation for cross-dataset analyses of brain {MRI} data},
  booktitle    = {International Symposium on Biomedical Imaging (ISBI)},
  year         = {2017},
  pages        = {441--445},
  organization = {IEEE},
}

@Article{hon2017towards,
  author  = {Hon, Marcia and Khan, Naimul},
  title   = {Towards {Alzheimer's} Disease Classification through Transfer Learning},
  journal = {arXiv preprint arXiv:1711.11117},
  year    = {2017},
}

@InProceedings{li2017exploring,
  author       = {Li, Xiuli and Zhang, Hao and Zhang, Xiaolu and Liu, Hao and Xie, Guotong},
  title        = {Exploring transfer learning for gastrointestinal bleeding detection on small-size imbalanced endoscopy images},
  booktitle    = {International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
  year         = {2017},
  pages        = {1994--1997},
  organization = {IEEE},
}

@InProceedings{ribeiro2017exploring,
  author       = {Ribeiro, Eduardo and H{\"a}fner, Michael and Wimmer, Georg and Tamaki, Toru and Tischendorf, JJW and Yoshida, Shigeto and Tanaka, Shinji and Uhl, Andreas},
  title        = {Exploring texture transfer learning for colonic polyp classification via convolutional neural networks},
  booktitle    = {International Symposium on Biomedical Imaging (ISBI)},
  year         = {2017},
  pages        = {1044--1048},
  organization = {IEEE},
}

@Article{nanni2017handcrafted,
  author    = {Nanni, Loris and Ghidoni, Stefano and Brahnam, Sheryl},
  title     = {Handcrafted vs. non-handcrafted features for computer vision classification},
  journal   = {Pattern Recognition},
  year      = {2017},
  volume    = {71},
  pages     = {158--172},
  publisher = {Elsevier},
}

@Article{mahmood2017unsupervised,
  author  = {Mahmood, Faisal and Chen, Richard and Durr, Nicholas J},
  title   = {Unsupervised Reverse Domain Adaption for Synthetic Medical Images via Adversarial Training},
  journal = {arXiv preprint arXiv:1711.06606},
  year    = {2017},
}

@InCollection{gadermayr2016domain,
  author       = {Gadermayr, Michael and Strauch, Martin and Klinkhammer, Barbara Mara and Djudjaj, Sonja and Boor, Peter and Merhof, Dorit},
  title        = {Domain Adaptive Classification for Compensating Variability in Histopathological Whole Slide Images},
  booktitle    = {International Conference Image Analysis and Recognition},
  publisher    = {Springer International Publishing},
  year         = {2016},
  pages        = {616--622},
  groups       = {Not-so-supervised papers},
  note2        = {DOI: 10.1007/978-3-319-41501-7\_69},
  organization = {Springer},
  url2         = {http://link.springer.com/10.1007/978-3-319-41501-7_69},
}

@InProceedings{liu2017feature,
  author       = {Liu, Tianjiao and Xie, Shuaining and Zhang, Yukang and Yu, Jing and Niu, Lijuan and Sun, Weidong},
  title        = {Feature selection and thyroid nodule classification using transfer learning},
  booktitle    = {International Symposium on Biomedical Imaging (ISBI)},
  year         = {2017},
  pages        = {1096--1099},
  organization = {IEEE},
}

@InProceedings{zuluaga2011learning,
  author       = {Zuluaga, Maria A and Hush, Don and Leyton, Edgar J F Delgado and Hoyos, Marcela Hern{\'a}ndez and Orkisz, Maciej},
  title        = {Learning from only positive and unlabeled data to detect lesions in vascular {CT} images},
  booktitle    = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year         = {2011},
  pages        = {9--16},
  organization = {Springer},
}

@Article{borji2018negative,
  author    = {Borji, Ali},
  title     = {Negative results in computer vision: A perspective},
  journal   = {Image and Vision Computing},
  year      = {2018},
  volume    = {69},
  pages     = {1--8},
  publisher = {Elsevier},
}

@Article{cozman2006risks,
  author    = {Cozman, Fabio and Cohen, Ira},
  title     = {Risks of semi-supervised learning},
  journal   = {Semi-supervised learning},
  year      = {2006},
  pages     = {56--72},
  publisher = {MIT press},
}

@Article{zhu2009introduction,
  author    = {Zhu, Xiaojin and Goldberg, Andrew B},
  title     = {Introduction to semi-supervised learning},
  journal   = {Synthesis lectures on artificial intelligence and machine learning},
  year      = {2009},
  volume    = {3},
  number    = {1},
  pages     = {1--130},
  publisher = {Morgan \& Claypool Publishers},
}

@Article{loog2015semi,
  author    = {Loog, Marco and Jensen, Are Charles},
  title     = {Semi-supervised nearest mean classification through a constrained log-likelihood},
  journal   = {IEEE Transactions on Neural Networks and Learning Systems},
  year      = {2015},
  volume    = {26},
  number    = {5},
  pages     = {995--1006},
  publisher = {IEEE},
}

@Article{krijthe2017robust,
  author    = {Krijthe, Jesse H and Loog, Marco},
  title     = {Robust semi-supervised least squares classification by implicit constraints},
  journal   = {Pattern Recognition},
  year      = {2017},
  volume    = {63},
  pages     = {115--126},
  publisher = {Elsevier},
}

@InProceedings{daniels2002open,
  author       = {Daniels, Mats and Faulkner, Xristine and Newman, Ian},
  title        = {Open ended group projects, motivating students and preparing them for the 'real world'},
  booktitle    = {Software Engineering Education and Training, 2002.(CSEE\&T 2002). Proceedings. 15th Conference on},
  year         = {2002},
  pages        = {115--126},
  organization = {IEEE},
}

@Article{larkin2001providing,
  author    = {Larkin, Martha J},
  title     = {Providing support for student independence through scaffolded instruction},
  journal   = {Teaching exceptional children},
  year      = {2001},
  volume    = {34},
  number    = {1},
  pages     = {30--34},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA},
}

@InProceedings{an2016semi,
  author       = {An, Le and Adeli, Ehsan and Liu, Mingxia and Zhang, Jun and Shen, Dinggang},
  title        = {Semi-supervised hierarchical multimodal feature and sample selection for {Alzheimer’s} disease diagnosis},
  booktitle    = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year         = {2016},
  pages        = {79--87},
  organization = {Springer},
}

@InProceedings{bai2017semi,
  author       = {Bai, Wenjia and Oktay, Ozan and Sinclair, Matthew and Suzuki, Hideaki and Rajchl, Martin and Tarroni, Giacomo and Glocker, Ben and King, Andrew and Matthews, Paul M and Rueckert, Daniel},
  title        = {Semi-supervised learning for network-based cardiac {MR} image segmentation},
  booktitle    = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year         = {2017},
  pages        = {253--260},
  organization = {Springer},
}

@InProceedings{borga2016semi,
  author       = {Borga, Magnus and Andersson, Thord and Leinhard, Olof Dahlqvist},
  title        = {Semi-supervised learning of anatomical manifolds for atlas-based segmentation of medical images},
  booktitle    = {International Conference on Pattern Recognition (ICPR)},
  year         = {2016},
  pages        = {3146--3149},
  organization = {IEEE},
}

@Article{dittrich2014spatio,
  author    = {Dittrich, Eva and Raviv, Tammy Riklin and Kasprian, Gregor and Donner, Ren{\'e} and Brugger, Peter C and Prayer, Daniela and Langs, Georg},
  title     = {A spatio-temporal latent atlas for semi-supervised learning of fetal brain segmentations and morphological age estimation},
  journal   = {Medical image analysis},
  year      = {2014},
  volume    = {18},
  number    = {1},
  pages     = {9--21},
  publisher = {Elsevier},
}

@InProceedings{gu2017semi,
  author       = {Gu, Lin and Zheng, Yinqiang and Bise, Ryoma and Sato, Imari and Imanishi, Nobuaki and Aiso, Sadakazu},
  title        = {Semi-supervised learning for biomedical image segmentation via forest oriented super pixels (voxels)},
  booktitle    = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year         = {2017},
  pages        = {702--710},
  organization = {Springer},
}

@InProceedings{baur2017semi,
  author       = {Baur, Christoph and Albarqouni, Shadi and Navab, Nassir},
  title        = {Semi-supervised Deep Learning for Fully Convolutional Networks},
  booktitle    = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year         = {2017},
  pages        = {311--319},
  organization = {Springer},
}

@Article{mahapatra2016combining,
  author    = {Mahapatra, Dwarikanath},
  title     = {Combining multiple expert annotations using semi-supervised learning and graph cuts for medical image segmentation},
  journal   = {Computer Vision and Image Understanding},
  year      = {2016},
  volume    = {151},
  pages     = {114--123},
  publisher = {Elsevier},
}

@InProceedings{tiwari2010semi,
  author       = {Tiwari, Pallavi and Kurhanewicz, John and Rosen, Mark and Madabhushi, Anant},
  title        = {Semi supervised multi kernel {(SeSMiK)} graph embedding: identifying aggressive prostate cancer via magnetic resonance imaging and spectroscopy},
  booktitle    = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year         = {2010},
  pages        = {666--673},
  organization = {Springer},
}

@InProceedings{wang2017direct,
  author       = {Wang, Liansheng and Li, Shusheng and Chen, Yiping and Lin, Jiankun and Liu, Changhua and Zeng, Xiantong and Li, Shuo},
  title        = {Direct aneurysm volume estimation by multi-view semi-supervised manifold learning},
  booktitle    = {International Symposium on Biomedical Imaging},
  year         = {2017},
  pages        = {1222--1225},
  organization = {IEEE},
}

@Article{xie2013multiple,
  author    = {Xie, Yuchen and Ho, Jeffrey and Vemuri, Baba C},
  title     = {Multiple atlas construction from a heterogeneous brain {MR} image collection},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2013},
  volume    = {32},
  number    = {3},
  pages     = {628--635},
  publisher = {IEEE},
}

@InProceedings{moeskops2016deep,
  author       = {Moeskops, Pim and Wolterink, Jelmer M and van der Velden, Bas H M and Gilhuijs, Kenneth G A and Leiner, Tim and Viergever, Max A and I{\v{s}}gum, Ivana},
  title        = {Deep learning for multi-task medical image segmentation in multiple modalities},
  booktitle    = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year         = {2016},
  pages        = {478--486},
  organization = {Springer},
}

@Article{filipovych2011semi,
  author    = {Filipovych, Roman and Davatzikos, Christos and Alzheimer's Disease Neuroimaging Initiative and others},
  title     = {Semi-supervised pattern classification of medical images: application to mild cognitive impairment {(MCI)}},
  journal   = {NeuroImage},
  year      = {2011},
  volume    = {55},
  number    = {3},
  pages     = {1109--1119},
  publisher = {Elsevier},
}

@Article{ciurte2014semi,
  author    = {Ciurte, Anca and Bresson, Xavier and Cuisenaire, Olivier and Houhou, Nawal and Nedevschi, Sergiu and Thiran, Jean-Philippe and Cuadra, Meritxell Bach},
  title     = {Semi-supervised segmentation of ultrasound images based on patch representation and continuous min cut},
  journal   = {PloS one},
  year      = {2014},
  volume    = {9},
  number    = {7},
  pages     = {e100972},
  publisher = {Public Library of Science},
}

@InProceedings{singh2011identifying,
  author       = {Singh, Shantanu and Janoos, Firdaus and P{\'e}cot, Thierry and Caserta, Enrico and Leone, Gustavo and Rittscher, Jens and Machiraju, Raghu},
  title        = {Identifying nuclear phenotypes using semi-supervised metric learning},
  booktitle    = {Information Processing in Medical Imaging (IPMI)},
  year         = {2011},
  pages        = {398--410},
  organization = {Springer},
}

@InProceedings{huang2008semi,
  author       = {Huang, Wei and Chan, Kap Luk and Gao, Yan and Zhou, Jiayin and Chong, Vincent},
  title        = {Semi-supervised nasopharyngeal carcinoma lesion extraction from magnetic resonance images using online spectral clustering with a learned metric},
  booktitle    = {International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year         = {2008},
  pages        = {51--58},
  organization = {Springer},
}

@InProceedings{gass2013semi,
  author       = {Gass, Tobias and Sz{\'e}kely, G{\'a}bor and Goksel, Orcun},
  title        = {Semi-supervised segmentation using multiple segmentation hypotheses from a single atlas},
  booktitle    = {MICCAI Workshop on Medical Computer Vision},
  year         = {2012},
  pages        = {29--37},
  organization = {Springer},
}

@InProceedings{rikxoort2010multi,
  author    = {van Rikxoort, E and Galperin-Aizenberg, M and Goldin, J and Kockelkorn, T T J P and van Ginneken, B and Brown, M},
  title     = {Multi-classifier semi-supervised classification of tuberculosis patterns on chest {CT} scans},
  booktitle = {Pulmonary Image Analysis (MICCAI PIA)},
  year      = {2010},
  pages     = {41--48},
}

@Article{ruder2017overview,
  author  = {Ruder, Sebastian},
  title   = {An overview of multi-task learning in deep neural networks},
  journal = {arXiv preprint arXiv:1706.05098},
  year    = {2017},
}

@InProceedings{batmanghelich2011disease,
  author       = {Batmanghelich, Kayhan N and Dong, H Ye and Pohl, Kilian M and Taskar, Ben and Davatzikos, Christos and others},
  title        = {Disease classification and prediction via semi-supervised dimensionality reduction},
  booktitle    = {International Symposium on Biomedical Imaging (ISBI)},
  year         = {2011},
  pages        = {1086--1090},
  organization = {IEEE},
}

@Article{song2009semi,
  author    = {Song, Yangqiu and Zhang, Changshui and Lee, Jianguo and Wang, Fei and Xiang, Shiming and Zhang, Dan},
  title     = {Semi-supervised discriminative classification with application to tumorous tissues segmentation of MR brain images},
  journal   = {Pattern Analysis and Applications},
  year      = {2009},
  volume    = {12},
  number    = {2},
  pages     = {99--115},
  publisher = {Springer},
}

@InProceedings{murthy2017center,
  author       = {Murthy, Veda and Hou, Le and Samaras, Dimitris and Kurc, Tahsin M and Saltz, Joel H},
  title        = {Center-focusing multi-task {CNN} with injected features for classification of glioma nuclear images},
  booktitle    = {IEEE Winter Conference on Applications of Computer Vision (WACV)},
  year         = {2017},
  pages        = {834--841},
  organization = {IEEE},
}

@Article{jia2017constrained,
  author    = {Jia, Zhipeng and Huang, Xingyi and Eric, I and Chang, Chao and Xu, Yan},
  title     = {Constrained deep weak supervision for histopathology image segmentation},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2017},
  volume    = {36},
  number    = {11},
  pages     = {2376--2388},
  publisher = {IEEE},
}

@Article{tomczak2017deep,
  author  = {Tomczak, Jakub M and Ilse, Maximilian and Welling, Max},
  title   = {Deep Learning with Permutation-invariant Operator for Multi-instance Histopathology Classification},
  journal = {arXiv preprint arXiv:1712.00310},
  year    = {2017},
}

@Article{alex2017semisupervised,
  author    = {Alex, Varghese and Vaidhya, Kiran and Thirunavukkarasu, Subramaniam and Kesavadas, Chandrasekharan and Krishnamurthi, Ganapathy},
  title     = {Semisupervised learning using denoising autoencoders for brain lesion detection and segmentation},
  journal   = {Journal of Medical Imaging},
  year      = {2017},
  volume    = {4},
  number    = {4},
  pages     = {041311},
  publisher = {International Society for Optics and Photonics},
}

@Article{prasad2009multi,
  author    = {Prasad, Mithun and Sowmya, Arcot and Wilson, Peter},
  title     = {Multi-level classification of emphysema in {HRCT} lung images},
  journal   = {Pattern Analysis and Applications},
  year      = {2009},
  volume    = {12},
  number    = {1},
  pages     = {9--20},
  publisher = {Springer},
}

@InProceedings{deng2009imagenet,
  author       = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  title        = {Imagenet: A large-scale hierarchical image database},
  booktitle    = {Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on},
  year         = {2009},
  pages        = {248--255},
  organization = {IEEE},
}

@Article{russakovsky2015imagenet,
  author    = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  title     = {Imagenet large scale visual recognition challenge},
  journal   = {International Journal of Computer Vision},
  year      = {2015},
  volume    = {115},
  number    = {3},
  pages     = {211--252},
  publisher = {Springer},
}

@Article{zhou2017places,
  author    = {Zhou, Bolei and Lapedriza, Agata and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  title     = {Places: A 10 million image database for scene recognition},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year      = {2017},
  publisher = {IEEE},
}

@InProceedings{kandemir2015asymmetric,
  author    = {Kandemir, Melih},
  title     = {Asymmetric transfer learning with deep gaussian processes},
  booktitle = {International Conference on Machine Learning},
  year      = {2015},
  pages     = {730--738},
}

@Book{chapelle2006semi,
  title     = {Semi-supervised learning},
  publisher = {MIT press Cambridge},
  year      = {2006},
  author    = {Chapelle, Olivier and Sch{\"o}lkopf, Bernhard and Zien, Alexander and others},
  volume    = {2},
}

@Article{adal2014automated,
  author    = {Adal, Kedir M and Sidib{\'e}, D{\'e}sir{\'e} and Ali, Sharib and Chaum, Edward and Karnowski, Thomas P and M{\'e}riaudeau, Fabrice},
  title     = {Automated detection of microaneurysms using scale-adapted blob analysis and semi-supervised learning},
  journal   = {Computer methods and programs in biomedicine},
  year      = {2014},
  volume    = {114},
  number    = {1},
  pages     = {1--10},
  publisher = {Elsevier},
}

@InProceedings{parag2014small,
  author       = {Parag, Toufiq and Plaza, Stephen and Scheffer, Louis},
  title        = {Small sample learning of superpixel classifiers for {EM} segmentation},
  booktitle    = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  year         = {2014},
  pages        = {389--397},
  organization = {Springer},
}

@InProceedings{schmolitzky2008patterns,
  author       = {Schmolitzky, Axel and Sch{\"u}mmer, Till},
  title        = {Patterns for Supervising Thesis Projects.},
  booktitle    = {EuroPLoP},
  year         = {2008},
  organization = {Citeseer},
}

@InProceedings{zagalsky2015emergence,
  author       = {Zagalsky, Alexey and Feliciano, Joseph and Storey, Margaret-Anne and Zhao, Yiyun and Wang, Weiliang},
  title        = {The emergence of github as a collaborative platform for education},
  booktitle    = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work \& Social Computing},
  year         = {2015},
  pages        = {1906--1917},
  organization = {ACM},
}

@TechReport{hicks2010adapting,
  author      = {Hicks, Michael and Foster, Jeffrey S},
  title       = {Adapting Scrum to Managing a Research Group},
  institution = {University of Maryland},
  year        = {2010},
}

@Article{codella2017skin,
  author  = {Codella, Noel CF and Gutman, David and Celebi, M Emre and Helba, Brian and Marchetti, Michael A and Dusza, Stephen W and Kalloo, Aadi and Liopyris, Konstantinos and Mishra, Nabin and Kittler, Harald and others},
  title   = {Skin lesion analysis toward melanoma detection: A challenge at the 2017 {International Symposium on Biomedical Imaging (ISBI)}, hosted by the {International Skin Imaging Collaboration (ISIC)}},
  journal = {arXiv preprint arXiv:1710.05006},
  year    = {2017},
}

@Article{abbasi2004early,
  author    = {Abbasi, Naheed R and Shaw, Helen M and Rigel, Darrell S and Friedman, Robert J and McCarthy, William H and Osman, Iman and Kopf, Alfred W and Polsky, David},
  title     = {Early diagnosis of cutaneous melanoma: revisiting the ABCD criteria},
  journal   = {Jama},
  year      = {2004},
  volume    = {292},
  number    = {22},
  pages     = {2771--2776},
  publisher = {American Medical Association},
}

@Article{kouw2017mr,
  author  = {Kouw, Wouter M and Loog, Marco and Bartels, Lambertus W and Mendrik, Adri{\"e}nne M},
  title   = {{MR} Acquisition-Invariant Representation Learning},
  journal = {arXiv preprint arXiv:1709.07944},
  year    = {2017},
}

@InProceedings{spanhol2017deep,
  author       = {Spanhol, Fabio A and Oliveira, Luiz S and Cavalin, Paulo R and Petitjean, Caroline and Heutte, Laurent},
  title        = {Deep features for breast cancer histopathological image classification},
  booktitle    = {IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  year         = {2017},
  pages        = {1868--1873},
  organization = {IEEE},
}

@InProceedings{lou2012quality,
  author       = {Lou, Xinghua and Fiaschi, Luca and Koethe, Ullrich and Hamprecht, Fred A},
  title        = {Quality classification of microscopic imagery with weakly supervised learning},
  booktitle    = {International Workshop on Machine Learning in Medical Imaging},
  year         = {2012},
  pages        = {176--183},
  organization = {Springer},
}

@Article{ciompi2010fusing,
  author    = {Ciompi, Francesco and Pujol, Oriol and Gatta, Carlo and Rodr{\'\i}guez-Leor, Oriol and Mauri-Ferr{\'e}, Josepa and Radeva, Petia},
  title     = {Fusing in-vitro and in-vivo intravascular ultrasound data for plaque characterization},
  journal   = {International Journal of Cardiovascular Imaging},
  year      = {2010},
  volume    = {26},
  number    = {7},
  pages     = {763--779},
  publisher = {Springer},
}

@InProceedings{bar2015chest,
  author       = {Bar, Yaniv and Diamant, Idit and Wolf, Lior and Lieberman, Sivan and Konen, Eli and Greenspan, Hayit},
  title        = {Chest pathology detection using deep learning with non-medical training},
  booktitle    = {International Symposium on Biomedical Imaging (ISBI)},
  year         = {2015},
  pages        = {294--297},
  organization = {IEEE},
}

@Article{ciompi2015automatic,
  author    = {Ciompi, Francesco and de Hoop, Bartjan and van Riel, Sarah J and Chung, Kaman and Scholten, Ernst Th and Oudkerk, Matthijs and de Jong, Pim A and Prokop, Mathias and van Ginneken, Bram},
  title     = {Automatic classification of pulmonary peri-fissural nodules in computed tomography using an ensemble of {2D} views and a convolutional neural network out-of-the-box},
  journal   = {Medical image analysis},
  year      = {2015},
  volume    = {26},
  number    = {1},
  pages     = {195--202},
  publisher = {Elsevier},
}

@Article{ilse2018attention,
  author  = {Ilse, Maximilian and Tomczak, Jakub M and Welling, Max},
  title   = {Attention-based deep multiple instance learning},
  journal = {arXiv preprint arXiv:1802.04712},
  year    = {2018},
}

@PhdThesis{biggio2010adversarial,
  author = {Biggio, Battista},
  title  = {Adversarial Pattern Classification},
  school = {University of Cagliari, Cagliari (Italy)},
  year   = {2010},
}

@InProceedings{goodfellow2014generative,
  author    = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  title     = {Generative adversarial nets},
  booktitle = {Advances in neural information processing systems},
  year      = {2014},
  pages     = {2672--2680},
}

@Book{ambrose2010learning,
  title     = {How learning works: Seven research-based principles for smart teaching},
  publisher = {John Wiley \& Sons},
  year      = {2010},
  author    = {Ambrose, Susan A and Bridges, Michael W and DiPietro, Michele and Lovett, Marsha C and Norman, Marie K},
}

@Article{uttl2017meta,
  author    = {Uttl, Bob and White, Carmela A and Gonzalez, Daniela Wong},
  title     = {Meta-analysis of faculty's teaching effectiveness: Student evaluation of teaching ratings and student learning are not related},
  journal   = {Studies in Educational Evaluation},
  year      = {2017},
  volume    = {54},
  pages     = {22--42},
  publisher = {Elsevier},
}

@Article{,
}

@Article{dumitrache2018crowdsourcing,
  author    = {Dumitrache, Anca and Aroyo, Lora and Welty, Chris},
  title     = {Crowdsourcing ground truth for medical relation extraction},
  journal   = {ACM Transactions on Interactive Intelligent Systems (TiiS)},
  year      = {2018},
  volume    = {8},
  number    = {2},
  pages     = {12},
  publisher = {ACM},
}

@InCollection{albarqouni2016playsourcing,
  author    = {Albarqouni, Shadi and Matl, Stefan and Baust, Maximilian and Navab, Nassir and Demirci, Stefanie},
  title     = {Playsourcing: a novel concept for knowledge creation in biomedical research},
  booktitle = {Deep Learning and Data Labeling for Medical Applications},
  publisher = {Springer},
  year      = {2016},
  pages     = {269--277},
}

@InProceedings{boorboor2018crowdsourcing,
  author       = {Boorboor, Saeed and Nadeem, Saad and Park, Ji Hwan and Baker, Kevin and Kaufman, Arie},
  title        = {Crowdsourcing lung nodules detection and annotation},
  booktitle    = {Medical Imaging 2018: Imaging Informatics for Healthcare, Research, and Applications},
  year         = {2018},
  volume       = {10579},
  pages        = {105791D},
  organization = {International Society for Optics and Photonics},
}

@Article{brady2014rapid,
  author    = {Brady, Christopher J and Villanti, Andrea C and Pearson, Jennifer L and Kirchner, Thomas R and Gup, Omesh and Shah, Chirag},
  title     = {Rapid grading of fundus photos for diabetic retinopathy using crowdsourcing},
  journal   = {Investigative Ophthalmology \& Visual Science},
  year      = {2014},
  volume    = {55},
  number    = {13},
  pages     = {4826--4826},
  publisher = {The Association for Research in Vision and Ophthalmology},
}

@Article{bruggemann2018exploring,
  author    = {Bruggemann, Jacob and Lander, Gabriel C and Su, Andrew I},
  title     = {Exploring applications of crowdsourcing to cryo-{EM}},
  journal   = {Journal of structural biology},
  year      = {2018},
  volume    = {203},
  number    = {1},
  pages     = {37--45},
  publisher = {Elsevier},
}

@InProceedings{cabrera2017counting,
  author       = {Cabrera-Bean, Margarita and Pages-Zamora, Alba and Diaz-Vilor, Carles and Postigo-Camps, Mar{\'\i}a and Cuadrado-S{\'a}nchez, Daniel and Luengo-Oroz, Miguel Angel},
  title        = {Counting Malaria Parasites with a two-stage {EM} based algorithm using crowsourced data},
  booktitle    = {Engineering in Medicine and Biology Society (EMBC), 2017 39th Annual International Conference of the IEEE},
  year         = {2017},
  pages        = {2283--2287},
  organization = {IEEE},
}

@InProceedings{chavez2013crowdsourcing,
  author       = {Ch{\'a}vez-Arag{\'o}n, Alberto and Lee, Won-Sook and Vyas, Aseem},
  title        = {A crowdsourcing web platform-hip joint segmentation by non-expert contributors},
  booktitle    = {Medical Measurements and Applications Proceedings (MeMeA), 2013 IEEE International Symposium on},
  year         = {2013},
  pages        = {350--354},
  organization = {IEEE},
}

@Article{cheplygina2018crowd,
  author  = {Cheplygina, Veronika and Pluim, Josien P W},
  title   = {Crowd disagreement of medical images is informative},
  journal = {arXiv preprint arXiv:1806.08174},
  year    = {2018},
}

@InProceedings{della2014preliminary,
  author       = {Della Mea, Vincenzo and Maddalena, Eddy and Mizzaro, Stefano and Machin, Piernicola and Beltrami, Carlo A},
  title        = {Preliminary results from a crowdsourcing experiment in immunohistochemistry},
  booktitle    = {Diagnostic pathology},
  year         = {2014},
  volume       = {9},
  number       = {1},
  pages        = {S6},
  organization = {BioMed Central},
}

@Article{dos2015crowdsourcing,
  author    = {dos Reis, Francisco J Candido and Lynn, Stuart and Ali, H Raza and Eccles, Diana and Hanby, Andrew and Provenzano, Elena and Caldas, Carlos and Howat, William J and McDuffus, Leigh-Anne and Liu, Bin and others},
  title     = {Crowdsourcing the general public for large scale molecular pathology studies in cancer},
  journal   = {EBioMedicine},
  year      = {2015},
  volume    = {2},
  number    = {7},
  pages     = {681--689},
  publisher = {Elsevier},
}

@InProceedings{eickhoff2014crowd,
  author       = {Eickhoff, Carsten},
  title        = {Crowd-powered experts: Helping surgeons interpret breast cancer images},
  booktitle    = {Proceedings of the First International Workshop on Gamification for Information Retrieval},
  year         = {2014},
  pages        = {53--56},
  organization = {ACM},
}

@Article{ganz2017crowdsourcing,
  author    = {Ganz, Melanie and Kondermann, Daniel and Andrulis, Jonas and Knudsen, Gitte Moos and Maier-Hein, Lena},
  title     = {Crowdsourcing for error detection in cortical surface delineations},
  journal   = {International journal of computer assisted radiology and surgery},
  year      = {2017},
  volume    = {12},
  number    = {1},
  pages     = {161--166},
  publisher = {Springer},
}

@InCollection{gur2017towards,
  author    = {Gur, Yaniv and Moradi, Mehdi and Bulu, Hakan and Guo, Yufan and Compas, Colin and Syeda-Mahmood, Tanveer},
  title     = {Towards an efficient way of building annotated medical image collections for big data studies},
  booktitle = {Intravascular Imaging and Computer Assisted Stenting, and Large-Scale Annotation of Biomedical Data and Expert Label Synthesis},
  publisher = {Springer},
  year      = {2017},
  pages     = {87--95},
}

@PhdThesis{heim2018large,
  author = {Heim, Eric},
  title  = {Large-scale medical image annotation with quality-controlled crowdsourcing},
  year   = {2018},
}

@InCollection{heller2017web,
  author    = {Heller, Nicholas and Stanitsas, Panagiotis and Morellas, Vassilios and Papanikolopoulos, Nikolaos},
  title     = {A Web-Based Platform for Distributed Annotation of Computerized Tomography Scans},
  booktitle = {Intravascular Imaging and Computer Assisted Stenting, and Large-Scale Annotation of Biomedical Data and Expert Label Synthesis},
  publisher = {Springer},
  year      = {2017},
  pages     = {136--145},
}

@Article{holst2015crowd,
  author    = {Holst, Daniel and Kowalewski, Timothy M and White, Lee W and Brand, Timothy C and Harper, Jonathan D and Sorensen, Mathew D and Truong, Mireille and Simpson, Khara and Tanaka, Alyssa and Smith, Roger and others},
  title     = {Crowd-sourced assessment of technical skills: differentiating animate surgical skill through the wisdom of crowds},
  journal   = {Journal of endourology},
  year      = {2015},
  volume    = {29},
  number    = {10},
  pages     = {1183--1188},
  publisher = {Mary Ann Liebert, Inc. 140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA},
}

@InCollection{huang2017swiftree,
  author    = {Huang, Mian and Hamarneh, Ghassan},
  title     = {SwifTree: Interactive Extraction of 3D Trees Supporting Gaming and Crowdsourcing},
  booktitle = {Intravascular Imaging and Computer Assisted Stenting, and Large-Scale Annotation of Biomedical Data and Expert Label Synthesis},
  publisher = {Springer},
  year      = {2017},
  pages     = {116--125},
}

@Article{keshavan2018combining,
  author    = {Keshavan, Anisha and Yeatman, Jason and Rokem, Ariel},
  title     = {Combining citizen science and deep learning to amplify expertise in neuroimaging},
  journal   = {bioRxiv},
  year      = {2018},
  pages     = {363382},
  publisher = {Cold Spring Harbor Laboratory},
}

@Article{lawson2017crowdsourcing,
  author    = {Lawson, Jonathan and Robinson-Vyas, Rupesh J and McQuillan, Janette P and Paterson, Andy and Christie, Sarah and Kidza-Griffiths, Matthew and McDuffus, Leigh-Anne and Moutasim, Karwan A and Shaw, Emily C and Kiltie, Anne E and others},
  title     = {Crowdsourcing for translational research: analysis of biomarker expression using cancer microarrays},
  journal   = {British journal of cancer},
  year      = {2017},
  volume    = {116},
  number    = {2},
  pages     = {237},
  publisher = {Nature Publishing Group},
}

@Article{lee2014mechanical,
  author    = {Lee, Aaron Y and Tufail, Adnan},
  title     = {Mechanical Turk based system for macular {OCT} segmentation},
  journal   = {Investigative Ophthalmology \& Visual Science},
  year      = {2014},
  volume    = {55},
  number    = {13},
  pages     = {4787--4787},
  publisher = {The Association for Research in Vision and Ophthalmology},
}

@InProceedings{maier2016crowd,
  author       = {Maier-Hein, Lena and Ross, Tobias and Gr{\"o}hl, Janek and Glocker, Ben and Bodenstedt, Sebastian and Stock, Christian and Heim, Eric and G{\"o}tz, Michael and Wirkert, S and Kenngott, Hannes and others},
  title        = {Crowd-algorithm collaboration for large-scale endoscopic image annotation with confidence},
  booktitle    = {International Conference on Medical Image Computing and Computer-Assisted Intervention},
  year         = {2016},
  pages        = {616--623},
  organization = {Springer},
}

@Article{rajchl2017employing,
  author  = {Rajchl, Martin and Koch, Lisa M and Ledig, Christian and Passerat-Palmbach, Jonathan and Misawa, Kazunari and Mori, Kensaku and Rueckert, Daniel},
  title   = {Employing Weak Annotations for Medical Image Analysis Problems},
  journal = {arXiv preprint arXiv:1708.06297},
  year    = {2017},
}

@Article{lee2016use,
  author    = {Lee, Aaron Y and Lee, Cecilia S and Keane, Pearse A and Tufail, Adnan},
  title     = {Use of Mechanical Turk as a MapReduce framework for macular {OCT} segmentation},
  journal   = {Journal of ophthalmology},
  year      = {2016},
  volume    = {2016},
  publisher = {Hindawi},
}

@Article{mitry2016accuracy,
  author    = {Mitry, Danny and Zutis, Kris and Dhillon, Baljean and Peto, Tunde and Hayat, Shabina and Khaw, Kay-Tee and Morgan, James E and Moncur, Wendy and Trucco, Emanuele and Foster, Paul J},
  title     = {The accuracy and reliability of crowdsource annotations of digital retinal images},
  journal   = {Translational vision science \& technology},
  year      = {2016},
  volume    = {5},
  number    = {5},
  pages     = {6--6},
  publisher = {The Association for Research in Vision and Ophthalmology},
}

@Article{mudie2017crowdsourcing,
  author    = {Mudie, Lucy I and Wang, Xueyang and Friedman, David S and Brady, Christopher J},
  title     = {Crowdsourcing and Automated Retinal Image Analysis for Diabetic Retinopathy},
  journal   = {Current diabetes reports},
  year      = {2017},
  volume    = {17},
  number    = {11},
  pages     = {106},
  publisher = {Springer},
}

@Article{mckenna2012strategies,
  author    = {McKenna, Matthew T and Wang, Shijun and Nguyen, Tan B and Burns, Joseph E and Petrick, Nicholas and Summers, Ronald M},
  title     = {Strategies for improved interpretation of computer-aided detections for CT colonography utilizing distributed human intelligence},
  journal   = {Medical image analysis},
  year      = {2012},
  volume    = {16},
  number    = {6},
  pages     = {1280--1292},
  publisher = {Elsevier},
}

@Article{mitry2013crowdsourcing,
  author    = {Mitry, Danny and Peto, Tunde and Hayat, Shabina and Morgan, James E and Khaw, Kay-Tee and Foster, Paul J},
  title     = {Crowdsourcing as a novel technique for retinal fundus photography classification: Analysis of Images in the EPIC Norfolk Cohort on behalf of the UKBiobank Eye and Vision Consortium},
  journal   = {PloS one},
  year      = {2013},
  volume    = {8},
  number    = {8},
  pages     = {e71154},
  publisher = {Public Library of Science},
}

@InCollection{lejeune2017expected,
  author    = {Lejeune, Laurent and Christoudias, Mario and Sznitman, Raphael},
  title     = {Expected exponential loss for gaze-based video and volume ground truth annotation},
  booktitle = {Intravascular Imaging and Computer Assisted Stenting, and Large-Scale Annotation of Biomedical Data and Expert Label Synthesis},
  publisher = {Springer},
  year      = {2017},
  pages     = {106--115},
}

@Article{luengo2012crowdsourcing,
  author    = {Luengo-Oroz, Miguel Angel and Arranz, Asier and Frean, John},
  title     = {Crowdsourcing malaria parasite quantification: an online game for analyzing images of infected thick blood smears},
  journal   = {Journal of medical Internet research},
  year      = {2012},
  volume    = {14},
  number    = {6},
  publisher = {JMIR Publications Inc.},
}

@InProceedings{park2017crowdsourcing,
  author       = {Park, Ji Hwan and Mirhosseini, Seyedkoosha and Nadeem, Saad and Marino, Joseph and Kaufman, Arie and Baker, Kevin and Barish, Matthew},
  title        = {Crowdsourcing for identification of polyp-free segments in virtual colonoscopy videos},
  booktitle    = {Medical Imaging 2017: Imaging Informatics for Healthcare, Research, and Applications},
  year         = {2017},
  volume       = {10138},
  pages        = {101380V},
  organization = {International Society for Optics and Photonics},
}

@InProceedings{park2018crowd,
  author       = {Park, Ji Hwan and Nadeem, Saad and Marino, Joseph and Baker, Kevin and Barish, Matthew and Kaufman, Arie},
  title        = {Crowd-assisted polyp annotation of virtual colonoscopy videos},
  booktitle    = {Medical Imaging 2018: Imaging Informatics for Healthcare, Research, and Applications},
  year         = {2018},
  volume       = {10579},
  pages        = {105790M},
  organization = {International Society for Optics and Photonics},
}

@Article{sonabend2017defining,
  author    = {Sonabend, Adam M and Zacharia, Brad E and Cloney, Michael B and Sonabend, Aar{\'o}n and Showers, Christopher and Ebiana, Victoria and Nazarian, Matthew and Swanson, Kristin R and Baldock, Anne and Brem, Henry and others},
  title     = {Defining glioblastoma resectability through the wisdom of the crowd: a proof-of-principle study},
  journal   = {Neurosurgery},
  year      = {2017},
  volume    = {80},
  number    = {4},
  pages     = {590--601},
  publisher = {Oxford University Press},
}

@InProceedings{timmermans2018crowdsourcing,
  author    = {Timmermans, Benjamin and Szl{\'a}vik, Zolt{\'a}n and Sips, Robert-Jan},
  title     = {Crowdsourcing ground truth data for analysing brainstem tumors in children},
  booktitle = {Belgium Netherlands Artificial Intelligence Conference (BNAIC)},
}

@Article{irshad2017crowdsourcing,
  author    = {Irshad, Humayun and Oh, Eun-Yeong and Schmolze, Daniel and Quintana, Liza M and Collins, Laura and Tamimi, Rulla M and Beck, Andrew H},
  title     = {Crowdsourcing scoring of immunohistochemistry images: Evaluating Performance of the Crowd and an Automated Computational Method},
  journal   = {Scientific Reports},
  year      = {2017},
  volume    = {7},
  pages     = {43286},
  publisher = {Nature Publishing Group},
}

@InProceedings{irshad2014crowdsourcing,
  author       = {Irshad, Humayun and Montaser-Kouhsari, Laleh and Waltz, Gail and Bucur, Octavian and Nowak, JA and Dong, Fei and Knoblauch, Nicholas W and Beck, Andrew H},
  title        = {Crowdsourcing image annotation for nucleus detection and segmentation in computational pathology: evaluating experts, automated methods, and the crowd},
  booktitle    = {Pacific Symposium on Biocomputing Co-Chairs},
  year         = {2014},
  pages        = {294--305},
  organization = {World Scientific},
}

@Book{bain2011best,
  title     = {What the best college teachers do},
  publisher = {Harvard University Press},
  year      = {2011},
  author    = {Bain, Ken},
}

@Book{boice2000advice,
  title     = {Advice for new faculty members: Nihil nimus.},
  publisher = {Allyn \& Bacon},
  year      = {2000},
  author    = {Boice, Robert},
}

@Book{barker2010helm,
  title     = {At the helm: Leading your laboratory},
  publisher = {Cold Spring Harbor Laboratory Press Cold Spring Harbor, New York},
  year      = {2010},
  author    = {Barker, Kathy},
}

@Article{,
}

@Article{,
}

@InProceedings{xu2016neuron,
  author    = {Xu, Kun and Su, Hang and Zhu, Jun and Guan, Ji-Song and Zhang, Bo},
  title     = {Neuron Segmentation based on CNN with Semi-supervised Regularization},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  year      = {2016},
  pages     = {20--28},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:My papers\;0\;1\;\;\;\;;
1 StaticGroup:Not-so-supervised papers\;0\;1\;\;\;\;;
1 StaticGroup:Not-so-supervised general\;0\;1\;\;\;\;;
1 StaticGroup:Veni\;0\;1\;\;\;\;;
}
